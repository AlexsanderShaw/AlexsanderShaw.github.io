<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Hadoop - 标签 - V4ler1an</title>
        <link>https://www.v4ler1an.com/tags/hadoop/</link>
        <description>Hadoop - 标签 - V4ler1an</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 19 Oct 2019 21:57:40 &#43;0800</lastBuildDate><atom:link href="https://www.v4ler1an.com/tags/hadoop/" rel="self" type="application/rss+xml" /><item>
    <title>Hadoop--初学到漏洞(六)--分布式环境搭建</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop6/</link>
    <pubDate>Sat, 19 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop6/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞六--分布式环境搭建">Hadoop&ndash;初学到漏洞(六)&ndash;分布式环境搭建</h1>
<h2 id="服务器功能规划">服务器功能规划</h2>
<table>
  <thead>
      <tr>
          <th>zy1</th>
          <th>zy2</th>
          <th>zy3</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>NameNode</td>
          <td>ResourceManage</td>
          <td></td>
      </tr>
      <tr>
          <td>DataNode</td>
          <td>DataNode</td>
          <td>DataNode</td>
      </tr>
      <tr>
          <td>NodeManager</td>
          <td>NodeManager</td>
          <td>NodeManager</td>
      </tr>
      <tr>
          <td>HistoryServer</td>
          <td></td>
          <td>SecondaryNameNode</td>
      </tr>
      <tr>
          <td>ip：10.251.0.144</td>
          <td>ip：10.251.0.150</td>
          <td>ip：10.251.0.151</td>
      </tr>
  </tbody>
</table>
<h2 id="一解压hadoop目录">一、解压Hadoop目录</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz
</span></span><span class="line"><span class="cl">tar -zxvf hadoop-2.8.5.tar.gz -C /opt/bigdata
</span></span><span class="line"><span class="cl">mv hadoop-2.8.5 hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><p>在伪分布式安装时，已经配置了hadoop的环境变量，无需再重复配置了。验证：</p>]]></description>
</item><item>
    <title>Hadoop--初学到漏洞(五)--HDFS</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop5/</link>
    <pubDate>Fri, 18 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop5/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞五--hdfs">Hadoop&ndash;初学到漏洞(五)&ndash;HDFS</h1>
<h2 id="一架构">一、架构</h2>
<p>HDFS遵循主从架构。</p>
<p></p>
<ul>
<li><strong>Block数据块;</strong>
<ol>
<li>基本存储单位，一般大小为64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本）</li>
<li>一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于Block大小，那么实际占用的空间为其文件的大小</li>
<li>基本的读写单位，类似于磁盘的页，每次都是读写一个块</li>
<li>每个块都会被复制到多台机器，默认复制3份</li>
</ol>
</li>
<li><strong>NameNode</strong>
<ol>
<li>存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小</li>
<li>一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件</li>
<li>数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）</li>
<li>NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性</li>
</ol>
</li>
<li><strong>Secondary NameNode</strong>
<ol>
<li>定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机</li>
</ol>
</li>
<li><strong>DataNode</strong>
<ol>
<li>保存具体的block数据</li>
<li>负责数据的读写操作和复制操作</li>
<li>DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息</li>
<li>DataNode之间会进行通信，复制数据块，保证数据的冗余性</li>
</ol>
</li>
</ul>
<h2 id="二写文件">二、写文件</h2>
<p></p>]]></description>
</item><item>
    <title>Hadoop--初学到漏洞(四)--YARN</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop4/</link>
    <pubDate>Thu, 17 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop4/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞四--yarn">Hadoop&ndash;初学到漏洞(四)&ndash;YARN</h1>
<h2 id="一架构">一、架构</h2>
<p>YARN的架构如下图所示：</p>
<p></p>
<p></p>
<p>YARN将资源管理和任务调度监控拆分成了独立的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster）。</p>]]></description>
</item><item>
    <title>Hadoop--初学到漏洞(三)--MapReduce</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop3/</link>
    <pubDate>Wed, 16 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop3/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞三--mapreduce">Hadoop&ndash;初学到漏洞(三)&ndash;MapReduce</h1>
<h2 id="一简介">一、简介</h2>
<p>MapReduce是一种分布式计算方式，指定一个Map函数，把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>]]></description>
</item><item>
    <title>Hadoop--初学到漏洞(二)--环境搭建--本机模式</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop2-1/</link>
    <pubDate>Tue, 15 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop2-1/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞二--环境搭建--本机模式">Hadoop&ndash;初学到漏洞(二)&ndash;环境搭建&ndash;本机模式</h1>
<h2 id="前言">前言</h2>
<p>有条件的买一组服务器做集群，没有条件的配置高性能机器搭建虚拟机。此处以虚拟机进行搭建集群（多个Linux主机）。</p>
<p>第一次首先进行本机模式的Hadoop搭建。</p>]]></description>
</item><item>
    <title>Hadoop--初学到漏洞(一)--相关概念</title>
    <link>https://www.v4ler1an.com/2019/10/hadoop1/</link>
    <pubDate>Mon, 14 Oct 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.v4ler1an.com/2019/10/hadoop1/</guid>
    <description><![CDATA[<h1 id="hadoop--初学到漏洞一--相关概念">Hadoop&ndash;初学到漏洞(一)&ndash;相关概念</h1>
<p><strong>本系列将从Hadoop学习到其漏洞复现分析进行完整记录。</strong></p>
<h2 id="一大数据">一、大数据</h2>
<h3 id="1-概念">1. 概念</h3>
<p>Big Data：主要是指无法在一定范围内用常规润健工具进行捕捉、管理和处理的数据集合，需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力的海量、高增长率和多样化的信息资产。一言概括：<strong>数据多到传统方案无法处理</strong>。</p>]]></description>
</item></channel>
</rss>
